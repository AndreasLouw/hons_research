{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":52942,"status":"ok","timestamp":1694589467467,"user":{"displayName":"Andreas Louw","userId":"11183032721846533402"},"user_tz":-120},"id":"sMTacwHyZP-0","outputId":"5d80e7c8-4b59-4ff3-cb6a-411f867cc88b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.2+cu118)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.27.4.1)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.6)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.23.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2023.7.22)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n","Collecting datasets\n","  Downloading datasets-2.14.5-py3-none-any.whl (519 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.6/519.6 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting evaluate\n","  Downloading evaluate-0.4.0-py3-none-any.whl (81 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.4/81.4 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting wandb\n","  Downloading wandb-0.15.10-py3-none-any.whl (2.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m90.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n","Collecting dill<0.3.8,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n","Collecting xxhash (from datasets)\n","  Downloading xxhash-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting multiprocess (from datasets)\n","  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]<2023.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.5)\n","Collecting huggingface-hub<1.0.0,>=0.14.0 (from datasets)\n","  Downloading huggingface_hub-0.17.1-py3-none-any.whl (294 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.8/294.8 kB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n","Collecting responses<0.19 (from evaluate)\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n","Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n","  Downloading GitPython-3.1.36-py3-none-any.whl (189 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.5/189.5 kB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n","Collecting sentry-sdk>=1.0.0 (from wandb)\n","  Downloading sentry_sdk-1.30.0-py2.py3-none-any.whl (218 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m218.8/218.8 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb)\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Collecting pathtools (from wandb)\n","  Downloading pathtools-0.1.2.tar.gz (11 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting setproctitle (from wandb)\n","  Downloading setproctitle-1.3.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n","Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n","Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n","Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.2.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n","  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.12.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.5.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.7.22)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n","Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n","  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n","Building wheels for collected packages: pathtools\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8791 sha256=b8d221d38e03b6d396cc281862dc193981d8828b3d97164c92a092022f935955\n","  Stored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n","Successfully built pathtools\n","Installing collected packages: pathtools, xxhash, smmap, setproctitle, sentry-sdk, docker-pycreds, dill, responses, multiprocess, huggingface-hub, gitdb, GitPython, wandb, datasets, evaluate\n","Successfully installed GitPython-3.1.36 datasets-2.14.5 dill-0.3.7 docker-pycreds-0.4.0 evaluate-0.4.0 gitdb-4.0.10 huggingface-hub-0.17.1 multiprocess-0.70.15 pathtools-0.1.2 responses-0.18.0 sentry-sdk-1.30.0 setproctitle-1.3.2 smmap-5.0.0 wandb-0.15.10 xxhash-3.3.0\n","Collecting git+https://github.com/huggingface/transformers\n","  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-d9uvccwa\n","  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-d9uvccwa\n","  Resolved https://github.com/huggingface/transformers to commit b4773273949b9360d1d38e51fc572340e0eda216\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.0.dev0) (3.12.2)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.0.dev0) (0.17.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.0.dev0) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.0.dev0) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.0.dev0) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.0.dev0) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.0.dev0) (2.31.0)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.34.0.dev0)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.3.1 (from transformers==4.34.0.dev0)\n","  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m86.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.0.dev0) (4.66.1)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers==4.34.0.dev0) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers==4.34.0.dev0) (4.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.34.0.dev0) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.34.0.dev0) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.34.0.dev0) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.34.0.dev0) (2023.7.22)\n","Building wheels for collected packages: transformers\n","  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for transformers: filename=transformers-4.34.0.dev0-py3-none-any.whl size=7658257 sha256=719c958187db31d98e165e448f99647f1b7e102f5c0c3c17763d3372a9fc7c0e\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-djlczc4n/wheels/c0/14/d6/6c9a5582d2ac191ec0a483be151a4495fe1eb2a6706ca49f1b\n","Successfully built transformers\n","Installing collected packages: tokenizers, safetensors, transformers\n","Successfully installed safetensors-0.3.3 tokenizers-0.13.3 transformers-4.34.0.dev0\n","Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.15.10)\n","Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n","Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.36)\n","Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n","Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.30.0)\n","Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n","Requirement already satisfied: pathtools in /usr/local/lib/python3.10/dist-packages (from wandb) (0.1.2)\n","Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n","Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n","Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n","Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.10)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2023.7.22)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.0)\n","Collecting accelerate\n","  Downloading accelerate-0.22.0-py3-none-any.whl (251 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.2/251.2 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n","Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.1+cu118)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.12.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (3.27.4.1)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (16.0.6)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n","Installing collected packages: accelerate\n","Successfully installed accelerate-0.22.0\n"]}],"source":["!pip install torch torchvision\n","!pip install datasets evaluate wandb\n","!pip install git+https://github.com/huggingface/transformers\n","!pip install wandb\n","!pip install accelerate"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27402,"status":"ok","timestamp":1694589494866,"user":{"displayName":"Andreas Louw","userId":"11183032721846533402"},"user_tz":-120},"id":"xu5wBqMkkf62","outputId":"008cbefd-209c-46ec-f678-9680e39d36ab"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":121147,"status":"ok","timestamp":1694589615970,"user":{"displayName":"Andreas Louw","userId":"11183032721846533402"},"user_tz":-120},"id":"SDb4tIi39i1u","outputId":"9a0b9b74-b23b-4f2d-abdb-80c45878ad3e"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n","  inflating: data/classification/val/29/23668.jpg  \n","  inflating: data/classification/val/29/23674.jpg  \n","  inflating: data/classification/val/29/23687.jpg  \n","  inflating: data/classification/val/29/23689.jpg  \n","  inflating: data/classification/val/29/23690.jpg  \n","  inflating: data/classification/val/29/23699.jpg  \n","  inflating: data/classification/val/29/23704.jpg  \n","  inflating: data/classification/val/29/23707.jpg  \n","  inflating: data/classification/val/29/23712.jpg  \n","  inflating: data/classification/val/29/23716.jpg  \n","  inflating: data/classification/val/29/23745.jpg  \n","  inflating: data/classification/val/29/23746.jpg  \n","  inflating: data/classification/val/29/23747.jpg  \n","  inflating: data/classification/val/29/23771.jpg  \n","  inflating: data/classification/val/29/23792.jpg  \n","  inflating: data/classification/val/29/23794.jpg  \n","  inflating: data/classification/val/29/23818.jpg  \n","  inflating: data/classification/val/29/23820.jpg  \n","  inflating: data/classification/val/29/23832.jpg  \n","  inflating: data/classification/val/29/23838.jpg  \n","  inflating: data/classification/val/29/23839.jpg  \n","  inflating: data/classification/val/29/23842.jpg  \n","  inflating: data/classification/val/29/23844.jpg  \n","  inflating: data/classification/val/29/23849.jpg  \n","  inflating: data/classification/val/29/23851.jpg  \n","  inflating: data/classification/val/29/23857.jpg  \n","  inflating: data/classification/val/29/23868.jpg  \n","  inflating: data/classification/val/29/23895.jpg  \n","  inflating: data/classification/val/29/23904.jpg  \n","  inflating: data/classification/val/29/23908.jpg  \n","  inflating: data/classification/val/29/23946.jpg  \n","  inflating: data/classification/val/29/23959.jpg  \n","  inflating: data/classification/val/29/23960.jpg  \n","  inflating: data/classification/val/29/23983.jpg  \n","  inflating: data/classification/val/29/24019.jpg  \n","  inflating: data/classification/val/29/24022.jpg  \n","  inflating: data/classification/val/29/24031.jpg  \n","  inflating: data/classification/val/29/24042.jpg  \n","  inflating: data/classification/val/29/24051.jpg  \n","  inflating: data/classification/val/29/24068.jpg  \n","  inflating: data/classification/val/29/24070.jpg  \n","  inflating: data/classification/val/29/24078.jpg  \n","  inflating: data/classification/val/29/24083.jpg  \n","  inflating: data/classification/val/29/24092.jpg  \n","  inflating: data/classification/val/29/24095.jpg  \n","  inflating: data/classification/val/3/01864.jpg  \n","  inflating: data/classification/val/3/01866.jpg  \n","  inflating: data/classification/val/3/01881.jpg  \n","  inflating: data/classification/val/3/01893.jpg  \n","  inflating: data/classification/val/3/01894.jpg  \n","  inflating: data/classification/val/3/01908.jpg  \n","  inflating: data/classification/val/3/01911.jpg  \n","  inflating: data/classification/val/3/01912.jpg  \n","  inflating: data/classification/val/3/01919.jpg  \n","  inflating: data/classification/val/3/01925.jpg  \n","  inflating: data/classification/val/3/01932.jpg  \n","  inflating: data/classification/val/3/01940.jpg  \n","  inflating: data/classification/val/3/01967.jpg  \n","  inflating: data/classification/val/3/01991.jpg  \n","  inflating: data/classification/val/3/01999.jpg  \n","  inflating: data/classification/val/3/02009.jpg  \n","  inflating: data/classification/val/3/02022.jpg  \n","  inflating: data/classification/val/3/02031.jpg  \n","  inflating: data/classification/val/3/02038.jpg  \n","  inflating: data/classification/val/3/02039.jpg  \n","  inflating: data/classification/val/3/02041.jpg  \n","  inflating: data/classification/val/3/02045.jpg  \n","  inflating: data/classification/val/3/02046.jpg  \n","  inflating: data/classification/val/3/02050.jpg  \n","  inflating: data/classification/val/3/02051.jpg  \n","  inflating: data/classification/val/3/02061.jpg  \n","  inflating: data/classification/val/3/02064.jpg  \n","  inflating: data/classification/val/3/02077.jpg  \n","  inflating: data/classification/val/3/02085.jpg  \n","  inflating: data/classification/val/3/02089.jpg  \n","  inflating: data/classification/val/3/02100.jpg  \n","  inflating: data/classification/val/3/02105.jpg  \n","  inflating: data/classification/val/3/02111.jpg  \n","  inflating: data/classification/val/3/02114.jpg  \n","  inflating: data/classification/val/3/02119.jpg  \n","  inflating: data/classification/val/3/02127.jpg  \n","  inflating: data/classification/val/3/02131.jpg  \n","  inflating: data/classification/val/3/02132.jpg  \n","  inflating: data/classification/val/3/02133.jpg  \n","  inflating: data/classification/val/3/02173.jpg  \n","  inflating: data/classification/val/3/02182.jpg  \n","  inflating: data/classification/val/3/02199.jpg  \n","  inflating: data/classification/val/3/02201.jpg  \n","  inflating: data/classification/val/3/02205.jpg  \n","  inflating: data/classification/val/3/02209.jpg  \n","  inflating: data/classification/val/3/02212.jpg  \n","  inflating: data/classification/val/3/02216.jpg  \n","  inflating: data/classification/val/3/02218.jpg  \n","  inflating: data/classification/val/3/02237.jpg  \n","  inflating: data/classification/val/3/02239.jpg  \n","  inflating: data/classification/val/3/02247.jpg  \n","  inflating: data/classification/val/3/02250.jpg  \n","  inflating: data/classification/val/3/02251.jpg  \n","  inflating: data/classification/val/3/02255.jpg  \n","  inflating: data/classification/val/3/02261.jpg  \n","  inflating: data/classification/val/3/02288.jpg  \n","  inflating: data/classification/val/3/02297.jpg  \n","  inflating: data/classification/val/3/02303.jpg  \n","  inflating: data/classification/val/3/02320.jpg  \n","  inflating: data/classification/val/3/02324.jpg  \n","  inflating: data/classification/val/3/02331.jpg  \n","  inflating: data/classification/val/3/02335.jpg  \n","  inflating: data/classification/val/3/02337.jpg  \n","  inflating: data/classification/val/3/02341.jpg  \n","  inflating: data/classification/val/3/02347.jpg  \n","  inflating: data/classification/val/3/02356.jpg  \n","  inflating: data/classification/val/3/02363.jpg  \n","  inflating: data/classification/val/3/02374.jpg  \n","  inflating: data/classification/val/3/02377.jpg  \n","  inflating: data/classification/val/3/02440.jpg  \n","  inflating: data/classification/val/3/02482.jpg  \n","  inflating: data/classification/val/3/02493.jpg  \n","  inflating: data/classification/val/3/02519.jpg  \n","  inflating: data/classification/val/3/02527.jpg  \n","  inflating: data/classification/val/3/02539.jpg  \n","  inflating: data/classification/val/3/02540.jpg  \n","  inflating: data/classification/val/3/02550.jpg  \n","  inflating: data/classification/val/3/02563.jpg  \n","  inflating: data/classification/val/3/02570.jpg  \n","  inflating: data/classification/val/3/02579.jpg  \n","  inflating: data/classification/val/3/02598.jpg  \n","  inflating: data/classification/val/3/02621.jpg  \n","  inflating: data/classification/val/3/02641.jpg  \n","  inflating: data/classification/val/3/02668.jpg  \n","  inflating: data/classification/val/3/02669.jpg  \n","  inflating: data/classification/val/3/02685.jpg  \n","  inflating: data/classification/val/3/02692.jpg  \n","  inflating: data/classification/val/3/02694.jpg  \n","  inflating: data/classification/val/3/02705.jpg  \n","  inflating: data/classification/val/3/02710.jpg  \n","  inflating: data/classification/val/3/02733.jpg  \n","  inflating: data/classification/val/3/02734.jpg  \n","  inflating: data/classification/val/3/02736.jpg  \n","  inflating: data/classification/val/3/02745.jpg  \n","  inflating: data/classification/val/3/02748.jpg  \n","  inflating: data/classification/val/3/02757.jpg  \n","  inflating: data/classification/val/3/02775.jpg  \n","  inflating: data/classification/val/3/02783.jpg  \n","  inflating: data/classification/val/3/02819.jpg  \n","  inflating: data/classification/val/3/02867.jpg  \n","  inflating: data/classification/val/3/02879.jpg  \n","  inflating: data/classification/val/3/02889.jpg  \n","  inflating: data/classification/val/3/02893.jpg  \n","  inflating: data/classification/val/3/02900.jpg  \n","  inflating: data/classification/val/3/02906.jpg  \n","  inflating: data/classification/val/3/02908.jpg  \n","  inflating: data/classification/val/30/24123.jpg  \n","  inflating: data/classification/val/30/24125.jpg  \n","  inflating: data/classification/val/30/24129.jpg  \n","  inflating: data/classification/val/30/24143.jpg  \n","  inflating: data/classification/val/30/24176.jpg  \n","  inflating: data/classification/val/30/24177.jpg  \n","  inflating: data/classification/val/30/24178.jpg  \n","  inflating: data/classification/val/30/24207.jpg  \n","  inflating: data/classification/val/30/24210.jpg  \n","  inflating: data/classification/val/30/24215.jpg  \n","  inflating: data/classification/val/30/24222.jpg  \n","  inflating: data/classification/val/30/24236.jpg  \n","  inflating: data/classification/val/30/24249.jpg  \n","  inflating: data/classification/val/30/24262.jpg  \n","  inflating: data/classification/val/30/24269.jpg  \n","  inflating: data/classification/val/30/24282.jpg  \n","  inflating: data/classification/val/30/24283.jpg  \n","  inflating: data/classification/val/30/24296.jpg  \n","  inflating: data/classification/val/30/24303.jpg  \n","  inflating: data/classification/val/30/24308.jpg  \n","  inflating: data/classification/val/30/24314.jpg  \n","  inflating: data/classification/val/30/24320.jpg  \n","  inflating: data/classification/val/30/24327.jpg  \n","  inflating: data/classification/val/30/24342.jpg  \n","  inflating: data/classification/val/30/24356.jpg  \n","  inflating: data/classification/val/30/24359.jpg  \n","  inflating: data/classification/val/30/24362.jpg  \n","  inflating: data/classification/val/30/24375.jpg  \n","  inflating: data/classification/val/30/24377.jpg  \n","  inflating: data/classification/val/30/24388.jpg  \n","  inflating: data/classification/val/30/24391.jpg  \n","  inflating: data/classification/val/30/24396.jpg  \n","  inflating: data/classification/val/30/24397.jpg  \n","  inflating: data/classification/val/30/24399.jpg  \n","  inflating: data/classification/val/30/24410.jpg  \n","  inflating: data/classification/val/30/24411.jpg  \n","  inflating: data/classification/val/30/24441.jpg  \n","  inflating: data/classification/val/30/24451.jpg  \n","  inflating: data/classification/val/30/24463.jpg  \n","  inflating: data/classification/val/30/24475.jpg  \n","  inflating: data/classification/val/30/24502.jpg  \n","  inflating: data/classification/val/30/24506.jpg  \n","  inflating: data/classification/val/30/24523.jpg  \n","  inflating: data/classification/val/30/24553.jpg  \n","  inflating: data/classification/val/30/24568.jpg  \n","  inflating: data/classification/val/30/24576.jpg  \n","  inflating: data/classification/val/30/24582.jpg  \n","  inflating: data/classification/val/30/24592.jpg  \n","  inflating: data/classification/val/31/24604.jpg  \n","  inflating: data/classification/val/31/24621.jpg  \n","  inflating: data/classification/val/31/24631.jpg  \n","  inflating: data/classification/val/31/24632.jpg  \n","  inflating: data/classification/val/31/24648.jpg  \n","  inflating: data/classification/val/31/24649.jpg  \n","  inflating: data/classification/val/31/24651.jpg  \n","  inflating: data/classification/val/31/24665.jpg  \n","  inflating: data/classification/val/31/24677.jpg  \n","  inflating: data/classification/val/31/24696.jpg  \n","  inflating: data/classification/val/31/24702.jpg  \n","  inflating: data/classification/val/31/24709.jpg  \n","  inflating: data/classification/val/31/24717.jpg  \n","  inflating: data/classification/val/31/24725.jpg  \n","  inflating: data/classification/val/31/24761.jpg  \n","  inflating: data/classification/val/31/24770.jpg  \n","  inflating: data/classification/val/31/24771.jpg  \n","  inflating: data/classification/val/31/24780.jpg  \n","  inflating: data/classification/val/31/24790.jpg  \n","  inflating: data/classification/val/31/24798.jpg  \n","  inflating: data/classification/val/31/24805.jpg  \n","  inflating: data/classification/val/31/24808.jpg  \n","  inflating: data/classification/val/31/24813.jpg  \n","  inflating: data/classification/val/31/24826.jpg  \n","  inflating: data/classification/val/32/24842.jpg  \n","  inflating: data/classification/val/32/24850.jpg  \n","  inflating: data/classification/val/32/24871.jpg  \n","  inflating: data/classification/val/32/24875.jpg  \n","  inflating: data/classification/val/32/24916.jpg  \n","  inflating: data/classification/val/32/24921.jpg  \n","  inflating: data/classification/val/32/24922.jpg  \n","  inflating: data/classification/val/32/24961.jpg  \n","  inflating: data/classification/val/32/24966.jpg  \n","  inflating: data/classification/val/32/24968.jpg  \n","  inflating: data/classification/val/32/24973.jpg  \n","  inflating: data/classification/val/32/24975.jpg  \n","  inflating: data/classification/val/32/24989.jpg  \n","  inflating: data/classification/val/32/25002.jpg  \n","  inflating: data/classification/val/32/25003.jpg  \n","  inflating: data/classification/val/32/25014.jpg  \n","  inflating: data/classification/val/32/25020.jpg  \n","  inflating: data/classification/val/32/25025.jpg  \n","  inflating: data/classification/val/32/25028.jpg  \n","  inflating: data/classification/val/32/25033.jpg  \n","  inflating: data/classification/val/32/25045.jpg  \n","  inflating: data/classification/val/32/25052.jpg  \n","  inflating: data/classification/val/32/25066.jpg  \n","  inflating: data/classification/val/32/25067.jpg  \n","  inflating: data/classification/val/33/25088.jpg  \n","  inflating: data/classification/val/33/25089.jpg  \n","  inflating: data/classification/val/33/25109.jpg  \n","  inflating: data/classification/val/33/25121.jpg  \n","  inflating: data/classification/val/33/25122.jpg  \n","  inflating: data/classification/val/33/25126.jpg  \n","  inflating: data/classification/val/33/25131.jpg  \n","  inflating: data/classification/val/33/25132.jpg  \n","  inflating: data/classification/val/33/25140.jpg  \n","  inflating: data/classification/val/33/25145.jpg  \n","  inflating: data/classification/val/33/25157.jpg  \n","  inflating: data/classification/val/33/25178.jpg  \n","  inflating: data/classification/val/33/25190.jpg  \n","  inflating: data/classification/val/33/25207.jpg  \n","  inflating: data/classification/val/33/25215.jpg  \n","  inflating: data/classification/val/33/25220.jpg  \n","  inflating: data/classification/val/33/25231.jpg  \n","  inflating: data/classification/val/33/25243.jpg  \n","  inflating: data/classification/val/33/25273.jpg  \n","  inflating: data/classification/val/33/25276.jpg  \n","  inflating: data/classification/val/33/25285.jpg  \n","  inflating: data/classification/val/33/25288.jpg  \n","  inflating: data/classification/val/33/25289.jpg  \n","  inflating: data/classification/val/33/25323.jpg  \n","  inflating: data/classification/val/33/25324.jpg  \n","  inflating: data/classification/val/33/25337.jpg  \n","  inflating: data/classification/val/33/25355.jpg  \n","  inflating: data/classification/val/33/25357.jpg  \n","  inflating: data/classification/val/33/25369.jpg  \n","  inflating: data/classification/val/34/25390.jpg  \n","  inflating: data/classification/val/34/25400.jpg  \n","  inflating: data/classification/val/34/25418.jpg  \n","  inflating: data/classification/val/34/25432.jpg  \n","  inflating: data/classification/val/34/25436.jpg  \n","  inflating: data/classification/val/34/25440.jpg  \n","  inflating: data/classification/val/34/25442.jpg  \n","  inflating: data/classification/val/34/25455.jpg  \n","  inflating: data/classification/val/34/25457.jpg  \n","  inflating: data/classification/val/34/25461.jpg  \n","  inflating: data/classification/val/34/25481.jpg  \n","  inflating: data/classification/val/34/25519.jpg  \n","  inflating: data/classification/val/34/25520.jpg  \n","  inflating: data/classification/val/34/25521.jpg  \n","  inflating: data/classification/val/34/25526.jpg  \n","  inflating: data/classification/val/34/25533.jpg  \n","  inflating: data/classification/val/34/25552.jpg  \n","  inflating: data/classification/val/34/25559.jpg  \n","  inflating: data/classification/val/34/25560.jpg  \n","  inflating: data/classification/val/34/25575.jpg  \n","  inflating: data/classification/val/34/25583.jpg  \n","  inflating: data/classification/val/34/25584.jpg  \n","  inflating: data/classification/val/34/25588.jpg  \n","  inflating: data/classification/val/34/25616.jpg  \n","  inflating: data/classification/val/34/25620.jpg  \n","  inflating: data/classification/val/34/25626.jpg  \n","  inflating: data/classification/val/34/25628.jpg  \n","  inflating: data/classification/val/34/25635.jpg  \n","  inflating: data/classification/val/34/25638.jpg  \n","  inflating: data/classification/val/34/25647.jpg  \n","  inflating: data/classification/val/34/25651.jpg  \n","  inflating: data/classification/val/34/25688.jpg  \n","  inflating: data/classification/val/34/25693.jpg  \n","  inflating: data/classification/val/34/25703.jpg  \n","  inflating: data/classification/val/35/25722.jpg  \n","  inflating: data/classification/val/35/25754.jpg  \n","  inflating: data/classification/val/35/25755.jpg  \n","  inflating: data/classification/val/35/25761.jpg  \n","  inflating: data/classification/val/35/25772.jpg  \n","  inflating: data/classification/val/35/25773.jpg  \n","  inflating: data/classification/val/35/25774.jpg  \n","  inflating: data/classification/val/35/25788.jpg  \n","  inflating: data/classification/val/35/25797.jpg  \n","  inflating: data/classification/val/35/25825.jpg  \n","  inflating: data/classification/val/35/25837.jpg  \n","  inflating: data/classification/val/35/25841.jpg  \n","  inflating: data/classification/val/35/25848.jpg  \n","  inflating: data/classification/val/36/25850.jpg  \n","  inflating: data/classification/val/36/25852.jpg  \n","  inflating: data/classification/val/36/25862.jpg  \n","  inflating: data/classification/val/36/25868.jpg  \n","  inflating: data/classification/val/36/25879.jpg  \n","  inflating: data/classification/val/36/25880.jpg  \n","  inflating: data/classification/val/36/25903.jpg  \n","  inflating: data/classification/val/36/25922.jpg  \n","  inflating: data/classification/val/36/25925.jpg  \n","  inflating: data/classification/val/36/25931.jpg  \n","  inflating: data/classification/val/37/25959.jpg  \n","  inflating: data/classification/val/37/25974.jpg  \n","  inflating: data/classification/val/37/25976.jpg  \n","  inflating: data/classification/val/37/25979.jpg  \n","  inflating: data/classification/val/37/25988.jpg  \n","  inflating: data/classification/val/37/25990.jpg  \n","  inflating: data/classification/val/37/25994.jpg  \n","  inflating: data/classification/val/37/26009.jpg  \n","  inflating: data/classification/val/37/26057.jpg  \n","  inflating: data/classification/val/37/26065.jpg  \n","  inflating: data/classification/val/37/26073.jpg  \n","  inflating: data/classification/val/37/26079.jpg  \n","  inflating: data/classification/val/37/26083.jpg  \n","  inflating: data/classification/val/37/26085.jpg  \n","  inflating: data/classification/val/37/26086.jpg  \n","  inflating: data/classification/val/37/26091.jpg  \n","  inflating: data/classification/val/37/26092.jpg  \n","  inflating: data/classification/val/37/26095.jpg  \n","  inflating: data/classification/val/37/26110.jpg  \n","  inflating: data/classification/val/37/26129.jpg  \n","  inflating: data/classification/val/37/26137.jpg  \n","  inflating: data/classification/val/37/26139.jpg  \n","  inflating: data/classification/val/37/26148.jpg  \n","  inflating: data/classification/val/37/26157.jpg  \n","  inflating: data/classification/val/37/26170.jpg  \n","  inflating: data/classification/val/37/26206.jpg  \n","  inflating: data/classification/val/37/26207.jpg  \n","  inflating: data/classification/val/37/26226.jpg  \n","  inflating: data/classification/val/37/26236.jpg  \n","  inflating: data/classification/val/37/26241.jpg  \n","  inflating: data/classification/val/37/26249.jpg  \n","  inflating: data/classification/val/37/26251.jpg  \n","  inflating: data/classification/val/37/26261.jpg  \n","  inflating: data/classification/val/37/26269.jpg  \n","  inflating: data/classification/val/37/26275.jpg  \n","  inflating: data/classification/val/37/26292.jpg  \n","  inflating: data/classification/val/37/26315.jpg  \n","  inflating: data/classification/val/37/26338.jpg  \n","  inflating: data/classification/val/37/26339.jpg  \n","  inflating: data/classification/val/37/26344.jpg  \n","  inflating: data/classification/val/37/26348.jpg  \n","  inflating: data/classification/val/37/26350.jpg  \n","  inflating: data/classification/val/37/26358.jpg  \n","  inflating: data/classification/val/37/26376.jpg  \n","  inflating: data/classification/val/37/26389.jpg  \n","  inflating: data/classification/val/37/26401.jpg  \n","  inflating: data/classification/val/37/26407.jpg  \n","  inflating: data/classification/val/37/26411.jpg  \n","  inflating: data/classification/val/37/26423.jpg  \n","  inflating: data/classification/val/37/26425.jpg  \n","  inflating: data/classification/val/37/26445.jpg  \n","  inflating: data/classification/val/37/26452.jpg  \n","  inflating: data/classification/val/37/26460.jpg  \n","  inflating: data/classification/val/37/26467.jpg  \n","  inflating: data/classification/val/37/26485.jpg  \n","  inflating: data/classification/val/37/26501.jpg  \n","  inflating: data/classification/val/37/26505.jpg  \n","  inflating: data/classification/val/37/26521.jpg  \n","  inflating: data/classification/val/37/26534.jpg  \n","  inflating: data/classification/val/37/26537.jpg  \n","  inflating: data/classification/val/37/26547.jpg  \n","  inflating: data/classification/val/37/26568.jpg  \n","  inflating: data/classification/val/37/26569.jpg  \n","  inflating: data/classification/val/37/26578.jpg  \n","  inflating: data/classification/val/37/26601.jpg  \n","  inflating: data/classification/val/37/26609.jpg  \n","  inflating: data/classification/val/37/26625.jpg  \n","  inflating: data/classification/val/37/26626.jpg  \n","  inflating: data/classification/val/37/26647.jpg  \n","  inflating: data/classification/val/37/26652.jpg  \n","  inflating: data/classification/val/37/26656.jpg  \n","  inflating: data/classification/val/37/26658.jpg  \n","  inflating: data/classification/val/37/26675.jpg  \n","  inflating: data/classification/val/37/26680.jpg  \n","  inflating: data/classification/val/37/26687.jpg  \n","  inflating: data/classification/val/37/26691.jpg  \n","  inflating: data/classification/val/37/26706.jpg  \n","  inflating: data/classification/val/37/26715.jpg  \n","  inflating: data/classification/val/37/26727.jpg  \n","  inflating: data/classification/val/38/26753.jpg  \n","  inflating: data/classification/val/38/26759.jpg  \n","  inflating: data/classification/val/38/26760.jpg  \n","  inflating: data/classification/val/38/26770.jpg  \n","  inflating: data/classification/val/38/26773.jpg  \n","  inflating: data/classification/val/38/26774.jpg  \n","  inflating: data/classification/val/38/26792.jpg  \n","  inflating: data/classification/val/38/26793.jpg  \n","  inflating: data/classification/val/38/26799.jpg  \n","  inflating: data/classification/val/38/26818.jpg  \n","  inflating: data/classification/val/38/26822.jpg  \n","  inflating: data/classification/val/38/26837.jpg  \n","  inflating: data/classification/val/38/26843.jpg  \n","  inflating: data/classification/val/38/26849.jpg  \n","  inflating: data/classification/val/38/26851.jpg  \n","  inflating: data/classification/val/38/26852.jpg  \n","  inflating: data/classification/val/38/26857.jpg  \n","  inflating: data/classification/val/38/26862.jpg  \n","  inflating: data/classification/val/38/26863.jpg  \n","  inflating: data/classification/val/38/26874.jpg  \n","  inflating: data/classification/val/38/26880.jpg  \n","  inflating: data/classification/val/38/26881.jpg  \n","  inflating: data/classification/val/38/26889.jpg  \n","  inflating: data/classification/val/38/26892.jpg  \n","  inflating: data/classification/val/38/26897.jpg  \n","  inflating: data/classification/val/38/26898.jpg  \n","  inflating: data/classification/val/38/26904.jpg  \n","  inflating: data/classification/val/38/26940.jpg  \n","  inflating: data/classification/val/38/26942.jpg  \n","  inflating: data/classification/val/38/26945.jpg  \n","  inflating: data/classification/val/38/26954.jpg  \n","  inflating: data/classification/val/38/26964.jpg  \n","  inflating: data/classification/val/38/26982.jpg  \n","  inflating: data/classification/val/38/26989.jpg  \n","  inflating: data/classification/val/38/27010.jpg  \n","  inflating: data/classification/val/38/27037.jpg  \n","  inflating: data/classification/val/38/27042.jpg  \n","  inflating: data/classification/val/38/27046.jpg  \n","  inflating: data/classification/val/38/27061.jpg  \n","  inflating: data/classification/val/38/27067.jpg  \n","  inflating: data/classification/val/38/27080.jpg  \n","  inflating: data/classification/val/38/27100.jpg  \n","  inflating: data/classification/val/38/27110.jpg  \n","  inflating: data/classification/val/38/27114.jpg  \n","  inflating: data/classification/val/38/27120.jpg  \n","  inflating: data/classification/val/38/27135.jpg  \n","  inflating: data/classification/val/38/27165.jpg  \n","  inflating: data/classification/val/38/27168.jpg  \n","  inflating: data/classification/val/38/27170.jpg  \n","  inflating: data/classification/val/38/27187.jpg  \n","  inflating: data/classification/val/38/27195.jpg  \n","  inflating: data/classification/val/38/27196.jpg  \n","  inflating: data/classification/val/38/27201.jpg  \n","  inflating: data/classification/val/38/27221.jpg  \n","  inflating: data/classification/val/38/27231.jpg  \n","  inflating: data/classification/val/38/27246.jpg  \n","  inflating: data/classification/val/38/27260.jpg  \n","  inflating: data/classification/val/38/27285.jpg  \n","  inflating: data/classification/val/38/27309.jpg  \n","  inflating: data/classification/val/38/27320.jpg  \n","  inflating: data/classification/val/38/27325.jpg  \n","  inflating: data/classification/val/38/27327.jpg  \n","  inflating: data/classification/val/38/27333.jpg  \n","  inflating: data/classification/val/38/27348.jpg  \n","  inflating: data/classification/val/38/27356.jpg  \n","  inflating: data/classification/val/38/27372.jpg  \n","  inflating: data/classification/val/38/27396.jpg  \n","  inflating: data/classification/val/38/27398.jpg  \n","  inflating: data/classification/val/38/27428.jpg  \n","  inflating: data/classification/val/38/27462.jpg  \n","  inflating: data/classification/val/38/27463.jpg  \n","  inflating: data/classification/val/38/27479.jpg  \n","  inflating: data/classification/val/38/27490.jpg  \n","  inflating: data/classification/val/38/27502.jpg  \n","  inflating: data/classification/val/38/27508.jpg  \n","  inflating: data/classification/val/38/27512.jpg  \n","  inflating: data/classification/val/38/27516.jpg  \n","  inflating: data/classification/val/38/27561.jpg  \n","  inflating: data/classification/val/38/27567.jpg  \n","  inflating: data/classification/val/38/27571.jpg  \n","  inflating: data/classification/val/38/27572.jpg  \n","  inflating: data/classification/val/38/27581.jpg  \n","  inflating: data/classification/val/38/27582.jpg  \n","  inflating: data/classification/val/38/27590.jpg  \n","  inflating: data/classification/val/38/27597.jpg  \n","  inflating: data/classification/val/39/27599.jpg  \n","  inflating: data/classification/val/39/27612.jpg  \n","  inflating: data/classification/val/39/27629.jpg  \n","  inflating: data/classification/val/39/27634.jpg  \n","  inflating: data/classification/val/39/27642.jpg  \n","  inflating: data/classification/val/39/27663.jpg  \n","  inflating: data/classification/val/39/27682.jpg  \n","  inflating: data/classification/val/39/27690.jpg  \n","  inflating: data/classification/val/39/27695.jpg  \n","  inflating: data/classification/val/39/27697.jpg  \n","  inflating: data/classification/val/39/27709.jpg  \n","  inflating: data/classification/val/39/27710.jpg  \n","  inflating: data/classification/val/39/27716.jpg  \n","  inflating: data/classification/val/39/27717.jpg  \n","  inflating: data/classification/val/39/27722.jpg  \n","  inflating: data/classification/val/39/27734.jpg  \n","  inflating: data/classification/val/39/27744.jpg  \n","  inflating: data/classification/val/39/27755.jpg  \n","  inflating: data/classification/val/39/27763.jpg  \n","  inflating: data/classification/val/39/27772.jpg  \n","  inflating: data/classification/val/39/27781.jpg  \n","  inflating: data/classification/val/39/27786.jpg  \n","  inflating: data/classification/val/39/27794.jpg  \n","  inflating: data/classification/val/39/27799.jpg  \n","  inflating: data/classification/val/39/27811.jpg  \n","  inflating: data/classification/val/39/27812.jpg  \n","  inflating: data/classification/val/39/27819.jpg  \n","  inflating: data/classification/val/39/27830.jpg  \n","  inflating: data/classification/val/39/27835.jpg  \n","  inflating: data/classification/val/39/27836.jpg  \n","  inflating: data/classification/val/39/27840.jpg  \n","  inflating: data/classification/val/39/27844.jpg  \n","  inflating: data/classification/val/39/27845.jpg  \n","  inflating: data/classification/val/39/27854.jpg  \n","  inflating: data/classification/val/39/27855.jpg  \n","  inflating: data/classification/val/39/27858.jpg  \n","  inflating: data/classification/val/39/27859.jpg  \n","  inflating: data/classification/val/39/27867.jpg  \n","  inflating: data/classification/val/39/27878.jpg  \n","  inflating: data/classification/val/39/27899.jpg  \n","  inflating: data/classification/val/39/27909.jpg  \n","  inflating: data/classification/val/39/27916.jpg  \n","  inflating: data/classification/val/39/27944.jpg  \n","  inflating: data/classification/val/39/27948.jpg  \n","  inflating: data/classification/val/39/27967.jpg  \n","  inflating: data/classification/val/39/27979.jpg  \n","  inflating: data/classification/val/39/27991.jpg  \n","  inflating: data/classification/val/39/27998.jpg  \n","  inflating: data/classification/val/39/28002.jpg  \n","  inflating: data/classification/val/39/28003.jpg  \n","  inflating: data/classification/val/39/28008.jpg  \n","  inflating: data/classification/val/39/28023.jpg  \n","  inflating: data/classification/val/39/28027.jpg  \n","  inflating: data/classification/val/39/28032.jpg  \n","  inflating: data/classification/val/39/28049.jpg  \n","  inflating: data/classification/val/39/28056.jpg  \n","  inflating: data/classification/val/39/28062.jpg  \n","  inflating: data/classification/val/39/28068.jpg  \n","  inflating: data/classification/val/39/28098.jpg  \n","  inflating: data/classification/val/39/28105.jpg  \n","  inflating: data/classification/val/39/28107.jpg  \n","  inflating: data/classification/val/39/28195.jpg  \n","  inflating: data/classification/val/39/28200.jpg  \n","  inflating: data/classification/val/39/28208.jpg  \n","  inflating: data/classification/val/39/28210.jpg  \n","  inflating: data/classification/val/39/28222.jpg  \n","  inflating: data/classification/val/39/28232.jpg  \n","  inflating: data/classification/val/39/28242.jpg  \n","  inflating: data/classification/val/39/28243.jpg  \n","  inflating: data/classification/val/39/28251.jpg  \n","  inflating: data/classification/val/39/28255.jpg  \n","  inflating: data/classification/val/39/28271.jpg  \n","  inflating: data/classification/val/39/28274.jpg  \n","  inflating: data/classification/val/39/28281.jpg  \n","  inflating: data/classification/val/39/28283.jpg  \n","  inflating: data/classification/val/39/28284.jpg  \n","  inflating: data/classification/val/39/28294.jpg  \n","  inflating: data/classification/val/39/28299.jpg  \n","  inflating: data/classification/val/39/28309.jpg  \n","  inflating: data/classification/val/39/28328.jpg  \n","  inflating: data/classification/val/39/28329.jpg  \n","  inflating: data/classification/val/39/28350.jpg  \n","  inflating: data/classification/val/39/28351.jpg  \n","  inflating: data/classification/val/39/28359.jpg  \n","  inflating: data/classification/val/39/28371.jpg  \n","  inflating: data/classification/val/39/28394.jpg  \n","  inflating: data/classification/val/39/28398.jpg  \n","  inflating: data/classification/val/39/28406.jpg  \n","  inflating: data/classification/val/39/28408.jpg  \n","  inflating: data/classification/val/39/28416.jpg  \n","  inflating: data/classification/val/39/28439.jpg  \n","  inflating: data/classification/val/39/28446.jpg  \n","  inflating: data/classification/val/39/28469.jpg  \n","  inflating: data/classification/val/39/28472.jpg  \n","  inflating: data/classification/val/39/28474.jpg  \n","  inflating: data/classification/val/39/28484.jpg  \n","  inflating: data/classification/val/39/28502.jpg  \n","  inflating: data/classification/val/39/28524.jpg  \n","  inflating: data/classification/val/39/28533.jpg  \n","  inflating: data/classification/val/39/28537.jpg  \n","  inflating: data/classification/val/39/28539.jpg  \n","  inflating: data/classification/val/39/28554.jpg  \n","  inflating: data/classification/val/39/28558.jpg  \n","  inflating: data/classification/val/39/28563.jpg  \n","  inflating: data/classification/val/39/28569.jpg  \n","  inflating: data/classification/val/39/28606.jpg  \n","  inflating: data/classification/val/39/28625.jpg  \n","  inflating: data/classification/val/39/28637.jpg  \n","  inflating: data/classification/val/39/28640.jpg  \n","  inflating: data/classification/val/39/28647.jpg  \n","  inflating: data/classification/val/39/28661.jpg  \n","  inflating: data/classification/val/39/28667.jpg  \n","  inflating: data/classification/val/39/28682.jpg  \n","  inflating: data/classification/val/39/28686.jpg  \n","  inflating: data/classification/val/39/28687.jpg  \n","  inflating: data/classification/val/39/28699.jpg  \n","  inflating: data/classification/val/39/28715.jpg  \n","  inflating: data/classification/val/39/28722.jpg  \n","  inflating: data/classification/val/39/28726.jpg  \n","  inflating: data/classification/val/39/28736.jpg  \n","  inflating: data/classification/val/39/28737.jpg  \n","  inflating: data/classification/val/39/28748.jpg  \n","  inflating: data/classification/val/39/28758.jpg  \n","  inflating: data/classification/val/39/28760.jpg  \n","  inflating: data/classification/val/39/28761.jpg  \n","  inflating: data/classification/val/39/28762.jpg  \n","  inflating: data/classification/val/39/28765.jpg  \n","  inflating: data/classification/val/39/28770.jpg  \n","  inflating: data/classification/val/39/28780.jpg  \n","  inflating: data/classification/val/39/28784.jpg  \n","  inflating: data/classification/val/39/28816.jpg  \n","  inflating: data/classification/val/39/28819.jpg  \n","  inflating: data/classification/val/39/28827.jpg  \n","  inflating: data/classification/val/39/28837.jpg  \n","  inflating: data/classification/val/39/28851.jpg  \n","  inflating: data/classification/val/39/28875.jpg  \n","  inflating: data/classification/val/39/28877.jpg  \n","  inflating: data/classification/val/39/28879.jpg  \n","  inflating: data/classification/val/39/28891.jpg  \n","  inflating: data/classification/val/39/28894.jpg  \n","  inflating: data/classification/val/39/28913.jpg  \n","  inflating: data/classification/val/39/28916.jpg  \n","  inflating: data/classification/val/39/28918.jpg  \n","  inflating: data/classification/val/39/28937.jpg  \n","  inflating: data/classification/val/39/28938.jpg  \n","  inflating: data/classification/val/39/28945.jpg  \n","  inflating: data/classification/val/39/28968.jpg  \n","  inflating: data/classification/val/39/28984.jpg  \n","  inflating: data/classification/val/39/29028.jpg  \n","  inflating: data/classification/val/39/29032.jpg  \n","  inflating: data/classification/val/39/29051.jpg  \n","  inflating: data/classification/val/39/29059.jpg  \n","  inflating: data/classification/val/39/29062.jpg  \n","  inflating: data/classification/val/39/29072.jpg  \n","  inflating: data/classification/val/39/29093.jpg  \n","  inflating: data/classification/val/39/29095.jpg  \n","  inflating: data/classification/val/39/29096.jpg  \n","  inflating: data/classification/val/39/29121.jpg  \n","  inflating: data/classification/val/39/29124.jpg  \n","  inflating: data/classification/val/39/29150.jpg  \n","  inflating: data/classification/val/4/02920.jpg  \n","  inflating: data/classification/val/4/02981.jpg  \n","  inflating: data/classification/val/4/02982.jpg  \n","  inflating: data/classification/val/4/03002.jpg  \n","  inflating: data/classification/val/4/03003.jpg  \n","  inflating: data/classification/val/4/03005.jpg  \n","  inflating: data/classification/val/4/03007.jpg  \n","  inflating: data/classification/val/4/03023.jpg  \n","  inflating: data/classification/val/4/03058.jpg  \n","  inflating: data/classification/val/4/03062.jpg  \n","  inflating: data/classification/val/4/03073.jpg  \n","  inflating: data/classification/val/4/03082.jpg  \n","  inflating: data/classification/val/4/03089.jpg  \n","  inflating: data/classification/val/4/03098.jpg  \n","  inflating: data/classification/val/4/03101.jpg  \n","  inflating: data/classification/val/4/03107.jpg  \n","  inflating: data/classification/val/4/03125.jpg  \n","  inflating: data/classification/val/4/03130.jpg  \n","  inflating: data/classification/val/4/03132.jpg  \n","  inflating: data/classification/val/4/03149.jpg  \n","  inflating: data/classification/val/4/03154.jpg  \n","  inflating: data/classification/val/4/03157.jpg  \n","  inflating: data/classification/val/4/03162.jpg  \n","  inflating: data/classification/val/4/03180.jpg  \n","  inflating: data/classification/val/4/03183.jpg  \n","  inflating: data/classification/val/4/03190.jpg  \n","  inflating: data/classification/val/4/03192.jpg  \n","  inflating: data/classification/val/4/03198.jpg  \n","  inflating: data/classification/val/4/03213.jpg  \n","  inflating: data/classification/val/4/03220.jpg  \n","  inflating: data/classification/val/4/03237.jpg  \n","  inflating: data/classification/val/4/03279.jpg  \n","  inflating: data/classification/val/4/03282.jpg  \n","  inflating: data/classification/val/4/03283.jpg  \n","  inflating: data/classification/val/4/03289.jpg  \n","  inflating: data/classification/val/4/03297.jpg  \n","  inflating: data/classification/val/4/03308.jpg  \n","  inflating: data/classification/val/4/03317.jpg  \n","  inflating: data/classification/val/4/03327.jpg  \n","  inflating: data/classification/val/4/03332.jpg  \n","  inflating: data/classification/val/4/03333.jpg  \n","  inflating: data/classification/val/4/03355.jpg  \n","  inflating: data/classification/val/4/03362.jpg  \n","  inflating: data/classification/val/4/03363.jpg  \n","  inflating: data/classification/val/4/03365.jpg  \n","  inflating: data/classification/val/4/03366.jpg  \n","  inflating: data/classification/val/4/03367.jpg  \n","  inflating: data/classification/val/4/03384.jpg  \n","  inflating: data/classification/val/4/03390.jpg  \n","  inflating: data/classification/val/4/03412.jpg  \n","  inflating: data/classification/val/40/29203.jpg  \n","  inflating: data/classification/val/40/29205.jpg  \n","  inflating: data/classification/val/40/29235.jpg  \n","  inflating: data/classification/val/40/29253.jpg  \n","  inflating: data/classification/val/40/29254.jpg  \n","  inflating: data/classification/val/40/29256.jpg  \n","  inflating: data/classification/val/40/29259.jpg  \n","  inflating: data/classification/val/40/29272.jpg  \n","  inflating: data/classification/val/40/29276.jpg  \n","  inflating: data/classification/val/40/29306.jpg  \n","  inflating: data/classification/val/40/29318.jpg  \n","  inflating: data/classification/val/40/29329.jpg  \n","  inflating: data/classification/val/40/29331.jpg  \n","  inflating: data/classification/val/40/29339.jpg  \n","  inflating: data/classification/val/40/29372.jpg  \n","  inflating: data/classification/val/40/29382.jpg  \n","  inflating: data/classification/val/40/29384.jpg  \n","  inflating: data/classification/val/40/29396.jpg  \n","  inflating: data/classification/val/40/29403.jpg  \n","  inflating: data/classification/val/40/29408.jpg  \n","  inflating: data/classification/val/40/29414.jpg  \n","  inflating: data/classification/val/40/29422.jpg  \n","  inflating: data/classification/val/40/29425.jpg  \n","  inflating: data/classification/val/40/29430.jpg  \n","  inflating: data/classification/val/40/29435.jpg  \n","  inflating: data/classification/val/40/29461.jpg  \n","  inflating: data/classification/val/40/29462.jpg  \n","  inflating: data/classification/val/40/29468.jpg  \n","  inflating: data/classification/val/40/29479.jpg  \n","  inflating: data/classification/val/40/29483.jpg  \n","  inflating: data/classification/val/41/29508.jpg  \n","  inflating: data/classification/val/41/29514.jpg  \n","  inflating: data/classification/val/41/29516.jpg  \n","  inflating: data/classification/val/41/29523.jpg  \n","  inflating: data/classification/val/41/29549.jpg  \n","  inflating: data/classification/val/41/29564.jpg  \n","  inflating: data/classification/val/41/29565.jpg  \n","  inflating: data/classification/val/41/29572.jpg  \n","  inflating: data/classification/val/41/29579.jpg  \n","  inflating: data/classification/val/41/29600.jpg  \n","  inflating: data/classification/val/41/29609.jpg  \n","  inflating: data/classification/val/41/29627.jpg  \n","  inflating: data/classification/val/41/29641.jpg  \n","  inflating: data/classification/val/41/29647.jpg  \n","  inflating: data/classification/val/41/29656.jpg  \n","  inflating: data/classification/val/41/29666.jpg  \n","  inflating: data/classification/val/41/29682.jpg  \n","  inflating: data/classification/val/41/29689.jpg  \n","  inflating: data/classification/val/41/29690.jpg  \n","  inflating: data/classification/val/41/29697.jpg  \n","  inflating: data/classification/val/41/29716.jpg  \n","  inflating: data/classification/val/41/29725.jpg  \n","  inflating: data/classification/val/41/29733.jpg  \n","  inflating: data/classification/val/41/29737.jpg  \n","  inflating: data/classification/val/41/29740.jpg  \n","  inflating: data/classification/val/41/29752.jpg  \n","  inflating: data/classification/val/41/29766.jpg  \n","  inflating: data/classification/val/42/29775.jpg  \n","  inflating: data/classification/val/42/29776.jpg  \n","  inflating: data/classification/val/42/29777.jpg  \n","  inflating: data/classification/val/42/29780.jpg  \n","  inflating: data/classification/val/42/29789.jpg  \n","  inflating: data/classification/val/42/29796.jpg  \n","  inflating: data/classification/val/42/29802.jpg  \n","  inflating: data/classification/val/42/29810.jpg  \n","  inflating: data/classification/val/42/29845.jpg  \n","  inflating: data/classification/val/42/29846.jpg  \n","  inflating: data/classification/val/42/29856.jpg  \n","  inflating: data/classification/val/42/29873.jpg  \n","  inflating: data/classification/val/42/29875.jpg  \n","  inflating: data/classification/val/42/29878.jpg  \n","  inflating: data/classification/val/42/29879.jpg  \n","  inflating: data/classification/val/42/29881.jpg  \n","  inflating: data/classification/val/42/29893.jpg  \n","  inflating: data/classification/val/42/29898.jpg  \n","  inflating: data/classification/val/42/29899.jpg  \n","  inflating: data/classification/val/42/29901.jpg  \n","  inflating: data/classification/val/42/29902.jpg  \n","  inflating: data/classification/val/42/29936.jpg  \n","  inflating: data/classification/val/42/29966.jpg  \n","  inflating: data/classification/val/42/29972.jpg  \n","  inflating: data/classification/val/42/29992.jpg  \n","  inflating: data/classification/val/42/30005.jpg  \n","  inflating: data/classification/val/42/30007.jpg  \n","  inflating: data/classification/val/42/30008.jpg  \n","  inflating: data/classification/val/42/30041.jpg  \n","  inflating: data/classification/val/42/30043.jpg  \n","  inflating: data/classification/val/42/30051.jpg  \n","  inflating: data/classification/val/43/30089.jpg  \n","  inflating: data/classification/val/43/30126.jpg  \n","  inflating: data/classification/val/43/30133.jpg  \n","  inflating: data/classification/val/43/30138.jpg  \n","  inflating: data/classification/val/43/30144.jpg  \n","  inflating: data/classification/val/43/30146.jpg  \n","  inflating: data/classification/val/43/30155.jpg  \n","  inflating: data/classification/val/43/30158.jpg  \n","  inflating: data/classification/val/43/30165.jpg  \n","  inflating: data/classification/val/43/30182.jpg  \n","  inflating: data/classification/val/43/30184.jpg  \n","  inflating: data/classification/val/43/30185.jpg  \n","  inflating: data/classification/val/43/30217.jpg  \n","  inflating: data/classification/val/43/30226.jpg  \n","  inflating: data/classification/val/43/30241.jpg  \n","  inflating: data/classification/val/43/30246.jpg  \n","  inflating: data/classification/val/43/30248.jpg  \n","  inflating: data/classification/val/43/30258.jpg  \n","  inflating: data/classification/val/43/30268.jpg  \n","  inflating: data/classification/val/44/30274.jpg  \n","  inflating: data/classification/val/44/30285.jpg  \n","  inflating: data/classification/val/44/30292.jpg  \n","  inflating: data/classification/val/44/30295.jpg  \n","  inflating: data/classification/val/44/30305.jpg  \n","  inflating: data/classification/val/44/30315.jpg  \n","  inflating: data/classification/val/44/30361.jpg  \n","  inflating: data/classification/val/44/30363.jpg  \n","  inflating: data/classification/val/44/30388.jpg  \n","  inflating: data/classification/val/44/30400.jpg  \n","  inflating: data/classification/val/44/30409.jpg  \n","  inflating: data/classification/val/44/30418.jpg  \n","  inflating: data/classification/val/44/30424.jpg  \n","  inflating: data/classification/val/44/30441.jpg  \n","  inflating: data/classification/val/44/30450.jpg  \n","  inflating: data/classification/val/44/30466.jpg  \n","  inflating: data/classification/val/44/30471.jpg  \n","  inflating: data/classification/val/44/30475.jpg  \n","  inflating: data/classification/val/44/30477.jpg  \n","  inflating: data/classification/val/44/30481.jpg  \n","  inflating: data/classification/val/44/30493.jpg  \n","  inflating: data/classification/val/44/30502.jpg  \n","  inflating: data/classification/val/44/30506.jpg  \n","  inflating: data/classification/val/44/30519.jpg  \n","  inflating: data/classification/val/44/30534.jpg  \n","  inflating: data/classification/val/44/30542.jpg  \n","  inflating: data/classification/val/44/30569.jpg  \n","  inflating: data/classification/val/44/30593.jpg  \n","  inflating: data/classification/val/44/30606.jpg  \n","  inflating: data/classification/val/44/30622.jpg  \n","  inflating: data/classification/val/44/30631.jpg  \n","  inflating: data/classification/val/44/30633.jpg  \n","  inflating: data/classification/val/44/30640.jpg  \n","  inflating: data/classification/val/44/30652.jpg  \n","  inflating: data/classification/val/44/30671.jpg  \n","  inflating: data/classification/val/44/30682.jpg  \n","  inflating: data/classification/val/44/30689.jpg  \n","  inflating: data/classification/val/44/30691.jpg  \n","  inflating: data/classification/val/44/30709.jpg  \n","  inflating: data/classification/val/44/30724.jpg  \n","  inflating: data/classification/val/44/30729.jpg  \n","  inflating: data/classification/val/44/30746.jpg  \n","  inflating: data/classification/val/44/30747.jpg  \n","  inflating: data/classification/val/44/30754.jpg  \n","  inflating: data/classification/val/44/30760.jpg  \n","  inflating: data/classification/val/44/30772.jpg  \n","  inflating: data/classification/val/44/30773.jpg  \n","  inflating: data/classification/val/44/30774.jpg  \n","  inflating: data/classification/val/44/30775.jpg  \n","  inflating: data/classification/val/44/30776.jpg  \n","  inflating: data/classification/val/44/30783.jpg  \n","  inflating: data/classification/val/44/30792.jpg  \n","  inflating: data/classification/val/45/30812.jpg  \n","  inflating: data/classification/val/45/30819.jpg  \n","  inflating: data/classification/val/45/30824.jpg  \n","  inflating: data/classification/val/45/30825.jpg  \n","  inflating: data/classification/val/45/30840.jpg  \n","  inflating: data/classification/val/45/30845.jpg  \n","  inflating: data/classification/val/45/30851.jpg  \n","  inflating: data/classification/val/45/30875.jpg  \n","  inflating: data/classification/val/45/30887.jpg  \n","  inflating: data/classification/val/45/30890.jpg  \n","  inflating: data/classification/val/45/30898.jpg  \n","  inflating: data/classification/val/45/30902.jpg  \n","  inflating: data/classification/val/45/30915.jpg  \n","  inflating: data/classification/val/45/30941.jpg  \n","  inflating: data/classification/val/45/30945.jpg  \n","  inflating: data/classification/val/45/30950.jpg  \n","  inflating: data/classification/val/45/30954.jpg  \n","  inflating: data/classification/val/45/30955.jpg  \n","  inflating: data/classification/val/45/30965.jpg  \n","  inflating: data/classification/val/45/30967.jpg  \n","  inflating: data/classification/val/45/30973.jpg  \n","  inflating: data/classification/val/45/30974.jpg  \n","  inflating: data/classification/val/45/30986.jpg  \n","  inflating: data/classification/val/45/30987.jpg  \n","  inflating: data/classification/val/45/30994.jpg  \n","  inflating: data/classification/val/45/30996.jpg  \n","  inflating: data/classification/val/45/31001.jpg  \n","  inflating: data/classification/val/45/31013.jpg  \n","  inflating: data/classification/val/45/31017.jpg  \n","  inflating: data/classification/val/45/31018.jpg  \n","  inflating: data/classification/val/45/31046.jpg  \n","  inflating: data/classification/val/45/31064.jpg  \n","  inflating: data/classification/val/45/31071.jpg  \n","  inflating: data/classification/val/45/31088.jpg  \n","  inflating: data/classification/val/45/31116.jpg  \n","  inflating: data/classification/val/45/31122.jpg  \n","  inflating: data/classification/val/45/31127.jpg  \n","  inflating: data/classification/val/45/31132.jpg  \n","  inflating: data/classification/val/45/31163.jpg  \n","  inflating: data/classification/val/45/31198.jpg  \n","  inflating: data/classification/val/45/31203.jpg  \n","  inflating: data/classification/val/45/31206.jpg  \n","  inflating: data/classification/val/45/31208.jpg  \n","  inflating: data/classification/val/45/31227.jpg  \n","  inflating: data/classification/val/45/31243.jpg  \n","  inflating: data/classification/val/45/31254.jpg  \n","  inflating: data/classification/val/45/31271.jpg  \n","  inflating: data/classification/val/45/31286.jpg  \n","  inflating: data/classification/val/45/31288.jpg  \n","  inflating: data/classification/val/45/31305.jpg  \n","  inflating: data/classification/val/45/31318.jpg  \n","  inflating: data/classification/val/45/31321.jpg  \n","  inflating: data/classification/val/45/31334.jpg  \n","  inflating: data/classification/val/45/31350.jpg  \n","  inflating: data/classification/val/45/31352.jpg  \n","  inflating: data/classification/val/45/31358.jpg  \n","  inflating: data/classification/val/45/31367.jpg  \n","  inflating: data/classification/val/45/31374.jpg  \n","  inflating: data/classification/val/45/31392.jpg  \n","  inflating: data/classification/val/45/31417.jpg  \n","  inflating: data/classification/val/45/31422.jpg  \n","  inflating: data/classification/val/45/31431.jpg  \n","  inflating: data/classification/val/45/31434.jpg  \n","  inflating: data/classification/val/45/31438.jpg  \n","  inflating: data/classification/val/45/31443.jpg  \n","  inflating: data/classification/val/45/31446.jpg  \n","  inflating: data/classification/val/45/31453.jpg  \n","  inflating: data/classification/val/45/31478.jpg  \n","  inflating: data/classification/val/45/31479.jpg  \n","  inflating: data/classification/val/45/31486.jpg  \n","  inflating: data/classification/val/45/31519.jpg  \n","  inflating: data/classification/val/45/31533.jpg  \n","  inflating: data/classification/val/45/31550.jpg  \n","  inflating: data/classification/val/45/31555.jpg  \n","  inflating: data/classification/val/45/31556.jpg  \n","  inflating: data/classification/val/45/31565.jpg  \n","  inflating: data/classification/val/45/31571.jpg  \n","  inflating: data/classification/val/45/31573.jpg  \n","  inflating: data/classification/val/45/31578.jpg  \n","  inflating: data/classification/val/45/31587.jpg  \n","  inflating: data/classification/val/45/31594.jpg  \n","  inflating: data/classification/val/45/31597.jpg  \n","  inflating: data/classification/val/45/31599.jpg  \n","  inflating: data/classification/val/45/31614.jpg  \n","  inflating: data/classification/val/45/31615.jpg  \n","  inflating: data/classification/val/45/31622.jpg  \n","  inflating: data/classification/val/45/31630.jpg  \n","  inflating: data/classification/val/45/31644.jpg  \n","  inflating: data/classification/val/45/31651.jpg  \n","  inflating: data/classification/val/45/31660.jpg  \n","  inflating: data/classification/val/45/31677.jpg  \n","  inflating: data/classification/val/45/31678.jpg  \n","  inflating: data/classification/val/45/31686.jpg  \n","  inflating: data/classification/val/45/31690.jpg  \n","  inflating: data/classification/val/45/31694.jpg  \n","  inflating: data/classification/val/45/31709.jpg  \n","  inflating: data/classification/val/45/31721.jpg  \n","  inflating: data/classification/val/45/31740.jpg  \n","  inflating: data/classification/val/45/31746.jpg  \n","  inflating: data/classification/val/45/31750.jpg  \n","  inflating: data/classification/val/45/31773.jpg  \n","  inflating: data/classification/val/45/31774.jpg  \n","  inflating: data/classification/val/45/31782.jpg  \n","  inflating: data/classification/val/45/31800.jpg  \n","  inflating: data/classification/val/45/31806.jpg  \n","  inflating: data/classification/val/45/31849.jpg  \n","  inflating: data/classification/val/45/31856.jpg  \n","  inflating: data/classification/val/46/31875.jpg  \n","  inflating: data/classification/val/46/31876.jpg  \n","  inflating: data/classification/val/46/31893.jpg  \n","  inflating: data/classification/val/46/31894.jpg  \n","  inflating: data/classification/val/46/31907.jpg  \n","  inflating: data/classification/val/46/31908.jpg  \n","  inflating: data/classification/val/46/31914.jpg  \n","  inflating: data/classification/val/46/31924.jpg  \n","  inflating: data/classification/val/46/31925.jpg  \n","  inflating: data/classification/val/46/31942.jpg  \n","  inflating: data/classification/val/46/31952.jpg  \n","  inflating: data/classification/val/46/31983.jpg  \n","  inflating: data/classification/val/46/31990.jpg  \n","  inflating: data/classification/val/46/31997.jpg  \n","  inflating: data/classification/val/46/32012.jpg  \n","  inflating: data/classification/val/46/32015.jpg  \n","  inflating: data/classification/val/46/32031.jpg  \n","  inflating: data/classification/val/46/32046.jpg  \n","  inflating: data/classification/val/46/32062.jpg  \n","  inflating: data/classification/val/46/32070.jpg  \n","  inflating: data/classification/val/46/32072.jpg  \n","  inflating: data/classification/val/46/32103.jpg  \n","  inflating: data/classification/val/46/32107.jpg  \n","  inflating: data/classification/val/46/32110.jpg  \n","  inflating: data/classification/val/46/32126.jpg  \n","  inflating: data/classification/val/46/32132.jpg  \n","  inflating: data/classification/val/46/32142.jpg  \n","  inflating: data/classification/val/46/32147.jpg  \n","  inflating: data/classification/val/46/32155.jpg  \n","  inflating: data/classification/val/46/32157.jpg  \n","  inflating: data/classification/val/46/32163.jpg  \n","  inflating: data/classification/val/46/32168.jpg  \n","  inflating: data/classification/val/46/32174.jpg  \n","  inflating: data/classification/val/46/32176.jpg  \n","  inflating: data/classification/val/46/32183.jpg  \n","  inflating: data/classification/val/46/32187.jpg  \n","  inflating: data/classification/val/46/32191.jpg  \n","  inflating: data/classification/val/46/32193.jpg  \n","  inflating: data/classification/val/46/32194.jpg  \n","  inflating: data/classification/val/46/32208.jpg  \n","  inflating: data/classification/val/46/32218.jpg  \n","  inflating: data/classification/val/46/32241.jpg  \n","  inflating: data/classification/val/46/32244.jpg  \n","  inflating: data/classification/val/46/32252.jpg  \n","  inflating: data/classification/val/46/32263.jpg  \n","  inflating: data/classification/val/46/32286.jpg  \n","  inflating: data/classification/val/46/32296.jpg  \n","  inflating: data/classification/val/46/32304.jpg  \n","  inflating: data/classification/val/46/32316.jpg  \n","  inflating: data/classification/val/46/32324.jpg  \n","  inflating: data/classification/val/46/32326.jpg  \n","  inflating: data/classification/val/46/32331.jpg  \n","  inflating: data/classification/val/46/32341.jpg  \n","  inflating: data/classification/val/46/32346.jpg  \n","  inflating: data/classification/val/46/32353.jpg  \n","  inflating: data/classification/val/46/32379.jpg  \n","  inflating: data/classification/val/46/32391.jpg  \n","  inflating: data/classification/val/46/32398.jpg  \n","  inflating: data/classification/val/46/32404.jpg  \n","  inflating: data/classification/val/46/32407.jpg  \n","  inflating: data/classification/val/46/32409.jpg  \n","  inflating: data/classification/val/46/32428.jpg  \n","  inflating: data/classification/val/46/32429.jpg  \n","  inflating: data/classification/val/46/32470.jpg  \n","  inflating: data/classification/val/46/32473.jpg  \n","  inflating: data/classification/val/46/32510.jpg  \n","  inflating: data/classification/val/47/32517.jpg  \n","  inflating: data/classification/val/47/32525.jpg  \n","  inflating: data/classification/val/47/32526.jpg  \n","  inflating: data/classification/val/47/32527.jpg  \n","  inflating: data/classification/val/47/32546.jpg  \n","  inflating: data/classification/val/47/32560.jpg  \n","  inflating: data/classification/val/47/32564.jpg  \n","  inflating: data/classification/val/47/32574.jpg  \n","  inflating: data/classification/val/47/32598.jpg  \n","  inflating: data/classification/val/47/32608.jpg  \n","  inflating: data/classification/val/47/32615.jpg  \n","  inflating: data/classification/val/47/32622.jpg  \n","  inflating: data/classification/val/47/32633.jpg  \n","  inflating: data/classification/val/47/32637.jpg  \n","  inflating: data/classification/val/47/32652.jpg  \n","  inflating: data/classification/val/47/32655.jpg  \n","  inflating: data/classification/val/47/32661.jpg  \n","  inflating: data/classification/val/47/32662.jpg  \n","  inflating: data/classification/val/47/32663.jpg  \n","  inflating: data/classification/val/47/32666.jpg  \n","  inflating: data/classification/val/47/32694.jpg  \n","  inflating: data/classification/val/47/32697.jpg  \n","  inflating: data/classification/val/47/32698.jpg  \n","  inflating: data/classification/val/47/32703.jpg  \n","  inflating: data/classification/val/47/32706.jpg  \n","  inflating: data/classification/val/47/32745.jpg  \n","  inflating: data/classification/val/47/32754.jpg  \n","  inflating: data/classification/val/47/32797.jpg  \n","  inflating: data/classification/val/47/32815.jpg  \n","  inflating: data/classification/val/47/32829.jpg  \n","  inflating: data/classification/val/47/32830.jpg  \n","  inflating: data/classification/val/47/32853.jpg  \n","  inflating: data/classification/val/47/32858.jpg  \n","  inflating: data/classification/val/47/32859.jpg  \n","  inflating: data/classification/val/47/32867.jpg  \n","  inflating: data/classification/val/47/32877.jpg  \n","  inflating: data/classification/val/47/32880.jpg  \n","  inflating: data/classification/val/47/32882.jpg  \n","  inflating: data/classification/val/47/32889.jpg  \n","  inflating: data/classification/val/47/32920.jpg  \n","  inflating: data/classification/val/47/32929.jpg  \n","  inflating: data/classification/val/47/32934.jpg  \n","  inflating: data/classification/val/47/32944.jpg  \n","  inflating: data/classification/val/47/32949.jpg  \n","  inflating: data/classification/val/47/32971.jpg  \n","  inflating: data/classification/val/47/32973.jpg  \n","  inflating: data/classification/val/47/32974.jpg  \n","  inflating: data/classification/val/47/32977.jpg  \n","  inflating: data/classification/val/47/33006.jpg  \n","  inflating: data/classification/val/47/33010.jpg  \n","  inflating: data/classification/val/47/33020.jpg  \n","  inflating: data/classification/val/47/33032.jpg  \n","  inflating: data/classification/val/47/33036.jpg  \n","  inflating: data/classification/val/47/33057.jpg  \n","  inflating: data/classification/val/47/33059.jpg  \n","  inflating: data/classification/val/47/33081.jpg  \n","  inflating: data/classification/val/47/33082.jpg  \n","  inflating: data/classification/val/47/33085.jpg  \n","  inflating: data/classification/val/47/33086.jpg  \n","  inflating: data/classification/val/47/33101.jpg  \n","  inflating: data/classification/val/47/33114.jpg  \n","  inflating: data/classification/val/47/33138.jpg  \n","  inflating: data/classification/val/47/33139.jpg  \n","  inflating: data/classification/val/47/33140.jpg  \n","  inflating: data/classification/val/47/33146.jpg  \n","  inflating: data/classification/val/47/33149.jpg  \n","  inflating: data/classification/val/47/33161.jpg  \n","  inflating: data/classification/val/47/33167.jpg  \n","  inflating: data/classification/val/47/33169.jpg  \n","  inflating: data/classification/val/47/33176.jpg  \n","  inflating: data/classification/val/47/33207.jpg  \n","  inflating: data/classification/val/47/33219.jpg  \n","  inflating: data/classification/val/47/33226.jpg  \n","  inflating: data/classification/val/47/33229.jpg  \n","  inflating: data/classification/val/47/33236.jpg  \n","  inflating: data/classification/val/47/33250.jpg  \n","  inflating: data/classification/val/47/33274.jpg  \n","  inflating: data/classification/val/47/33279.jpg  \n","  inflating: data/classification/val/47/33282.jpg  \n","  inflating: data/classification/val/47/33305.jpg  \n","  inflating: data/classification/val/47/33323.jpg  \n","  inflating: data/classification/val/47/33330.jpg  \n","  inflating: data/classification/val/48/33338.jpg  \n","  inflating: data/classification/val/48/33340.jpg  \n","  inflating: data/classification/val/48/33350.jpg  \n","  inflating: data/classification/val/48/33359.jpg  \n","  inflating: data/classification/val/48/33361.jpg  \n","  inflating: data/classification/val/48/33385.jpg  \n","  inflating: data/classification/val/48/33391.jpg  \n","  inflating: data/classification/val/48/33411.jpg  \n","  inflating: data/classification/val/48/33419.jpg  \n","  inflating: data/classification/val/48/33420.jpg  \n","  inflating: data/classification/val/48/33434.jpg  \n","  inflating: data/classification/val/48/33446.jpg  \n","  inflating: data/classification/val/48/33450.jpg  \n","  inflating: data/classification/val/48/33472.jpg  \n","  inflating: data/classification/val/48/33475.jpg  \n","  inflating: data/classification/val/48/33486.jpg  \n","  inflating: data/classification/val/48/33498.jpg  \n","  inflating: data/classification/val/48/33514.jpg  \n","  inflating: data/classification/val/48/33527.jpg  \n","  inflating: data/classification/val/48/33529.jpg  \n","  inflating: data/classification/val/48/33545.jpg  \n","  inflating: data/classification/val/48/33562.jpg  \n","  inflating: data/classification/val/48/33569.jpg  \n","  inflating: data/classification/val/48/33581.jpg  \n","  inflating: data/classification/val/48/33611.jpg  \n","  inflating: data/classification/val/48/33614.jpg  \n","  inflating: data/classification/val/48/33616.jpg  \n","  inflating: data/classification/val/48/33617.jpg  \n","  inflating: data/classification/val/48/33619.jpg  \n","  inflating: data/classification/val/48/33672.jpg  \n","  inflating: data/classification/val/48/33678.jpg  \n","  inflating: data/classification/val/48/33686.jpg  \n","  inflating: data/classification/val/48/33694.jpg  \n","  inflating: data/classification/val/48/33704.jpg  \n","  inflating: data/classification/val/48/33714.jpg  \n","  inflating: data/classification/val/48/33726.jpg  \n","  inflating: data/classification/val/48/33730.jpg  \n","  inflating: data/classification/val/48/33740.jpg  \n","  inflating: data/classification/val/48/33741.jpg  \n","  inflating: data/classification/val/48/33765.jpg  \n","  inflating: data/classification/val/48/33771.jpg  \n","  inflating: data/classification/val/48/33775.jpg  \n","  inflating: data/classification/val/48/33779.jpg  \n","  inflating: data/classification/val/48/33781.jpg  \n","  inflating: data/classification/val/48/33782.jpg  \n","  inflating: data/classification/val/48/33783.jpg  \n","  inflating: data/classification/val/48/33785.jpg  \n","  inflating: data/classification/val/48/33792.jpg  \n","  inflating: data/classification/val/48/33793.jpg  \n","  inflating: data/classification/val/48/33795.jpg  \n","  inflating: data/classification/val/48/33797.jpg  \n","  inflating: data/classification/val/48/33799.jpg  \n","  inflating: data/classification/val/48/33805.jpg  \n","  inflating: data/classification/val/48/33827.jpg  \n","  inflating: data/classification/val/48/33835.jpg  \n","  inflating: data/classification/val/48/33853.jpg  \n","  inflating: data/classification/val/48/33862.jpg  \n","  inflating: data/classification/val/48/33881.jpg  \n","  inflating: data/classification/val/48/33886.jpg  \n","  inflating: data/classification/val/48/33895.jpg  \n","  inflating: data/classification/val/48/33902.jpg  \n","  inflating: data/classification/val/48/33957.jpg  \n","  inflating: data/classification/val/48/33973.jpg  \n","  inflating: data/classification/val/48/33975.jpg  \n","  inflating: data/classification/val/48/33978.jpg  \n","  inflating: data/classification/val/48/33984.jpg  \n","  inflating: data/classification/val/48/33993.jpg  \n","  inflating: data/classification/val/48/33999.jpg  \n","  inflating: data/classification/val/48/34002.jpg  \n","  inflating: data/classification/val/48/34003.jpg  \n","  inflating: data/classification/val/48/34014.jpg  \n","  inflating: data/classification/val/48/34049.jpg  \n","  inflating: data/classification/val/48/34067.jpg  \n","  inflating: data/classification/val/48/34073.jpg  \n","  inflating: data/classification/val/48/34074.jpg  \n","  inflating: data/classification/val/48/34078.jpg  \n","  inflating: data/classification/val/48/34082.jpg  \n","  inflating: data/classification/val/48/34087.jpg  \n","  inflating: data/classification/val/48/34095.jpg  \n","  inflating: data/classification/val/48/34099.jpg  \n","  inflating: data/classification/val/48/34105.jpg  \n","  inflating: data/classification/val/48/34128.jpg  \n","  inflating: data/classification/val/48/34129.jpg  \n","  inflating: data/classification/val/48/34185.jpg  \n","  inflating: data/classification/val/48/34187.jpg  \n","  inflating: data/classification/val/48/34204.jpg  \n","  inflating: data/classification/val/48/34207.jpg  \n","  inflating: data/classification/val/48/34222.jpg  \n","  inflating: data/classification/val/48/34226.jpg  \n","  inflating: data/classification/val/48/34251.jpg  \n","  inflating: data/classification/val/48/34267.jpg  \n","  inflating: data/classification/val/48/34270.jpg  \n","  inflating: data/classification/val/48/34280.jpg  \n","  inflating: data/classification/val/48/34287.jpg  \n","  inflating: data/classification/val/48/34315.jpg  \n","  inflating: data/classification/val/48/34320.jpg  \n","  inflating: data/classification/val/48/34331.jpg  \n","  inflating: data/classification/val/48/34333.jpg  \n","  inflating: data/classification/val/48/34362.jpg  \n","  inflating: data/classification/val/48/34363.jpg  \n","  inflating: data/classification/val/48/34379.jpg  \n","  inflating: data/classification/val/48/34384.jpg  \n","  inflating: data/classification/val/48/34387.jpg  \n","  inflating: data/classification/val/48/34396.jpg  \n","  inflating: data/classification/val/48/34424.jpg  \n","  inflating: data/classification/val/48/34441.jpg  \n","  inflating: data/classification/val/48/34449.jpg  \n","  inflating: data/classification/val/48/34453.jpg  \n","  inflating: data/classification/val/48/34456.jpg  \n","  inflating: data/classification/val/48/34468.jpg  \n","  inflating: data/classification/val/48/34477.jpg  \n","  inflating: data/classification/val/48/34479.jpg  \n","  inflating: data/classification/val/48/34484.jpg  \n","  inflating: data/classification/val/48/34488.jpg  \n","  inflating: data/classification/val/48/34505.jpg  \n","  inflating: data/classification/val/48/34514.jpg  \n","  inflating: data/classification/val/48/34517.jpg  \n","  inflating: data/classification/val/48/34520.jpg  \n","  inflating: data/classification/val/48/34531.jpg  \n","  inflating: data/classification/val/48/34543.jpg  \n","  inflating: data/classification/val/48/34553.jpg  \n","  inflating: data/classification/val/48/34558.jpg  \n","  inflating: data/classification/val/48/34563.jpg  \n","  inflating: data/classification/val/48/34565.jpg  \n","  inflating: data/classification/val/48/34566.jpg  \n","  inflating: data/classification/val/48/34571.jpg  \n","  inflating: data/classification/val/48/34573.jpg  \n","  inflating: data/classification/val/48/34595.jpg  \n","  inflating: data/classification/val/48/34601.jpg  \n","  inflating: data/classification/val/48/34607.jpg  \n","  inflating: data/classification/val/48/34617.jpg  \n","  inflating: data/classification/val/48/34631.jpg  \n","  inflating: data/classification/val/48/34651.jpg  \n","  inflating: data/classification/val/48/34655.jpg  \n","  inflating: data/classification/val/48/34669.jpg  \n","  inflating: data/classification/val/48/34672.jpg  \n","  inflating: data/classification/val/48/34697.jpg  \n","  inflating: data/classification/val/48/34707.jpg  \n","  inflating: data/classification/val/48/34714.jpg  \n","  inflating: data/classification/val/49/34741.jpg  \n","  inflating: data/classification/val/49/34745.jpg  \n","  inflating: data/classification/val/49/34749.jpg  \n","  inflating: data/classification/val/49/34751.jpg  \n","  inflating: data/classification/val/49/34762.jpg  \n","  inflating: data/classification/val/49/34779.jpg  \n","  inflating: data/classification/val/49/34795.jpg  \n","  inflating: data/classification/val/49/34798.jpg  \n","  inflating: data/classification/val/49/34810.jpg  \n","  inflating: data/classification/val/49/34825.jpg  \n","  inflating: data/classification/val/49/34868.jpg  \n","  inflating: data/classification/val/49/34883.jpg  \n","  inflating: data/classification/val/49/34891.jpg  \n","  inflating: data/classification/val/49/34903.jpg  \n","  inflating: data/classification/val/49/34922.jpg  \n","  inflating: data/classification/val/49/34924.jpg  \n","  inflating: data/classification/val/49/34928.jpg  \n","  inflating: data/classification/val/49/34930.jpg  \n","  inflating: data/classification/val/49/34940.jpg  \n","  inflating: data/classification/val/49/34941.jpg  \n","  inflating: data/classification/val/49/34947.jpg  \n","  inflating: data/classification/val/49/34952.jpg  \n","  inflating: data/classification/val/49/34959.jpg  \n","  inflating: data/classification/val/49/34965.jpg  \n","  inflating: data/classification/val/49/34971.jpg  \n","  inflating: data/classification/val/49/34975.jpg  \n","  inflating: data/classification/val/49/34979.jpg  \n","  inflating: data/classification/val/49/35002.jpg  \n","  inflating: data/classification/val/49/35021.jpg  \n","  inflating: data/classification/val/49/35032.jpg  \n","  inflating: data/classification/val/49/35035.jpg  \n","  inflating: data/classification/val/49/35042.jpg  \n","  inflating: data/classification/val/49/35044.jpg  \n","  inflating: data/classification/val/49/35059.jpg  \n","  inflating: data/classification/val/49/35061.jpg  \n","  inflating: data/classification/val/49/35069.jpg  \n","  inflating: data/classification/val/49/35070.jpg  \n","  inflating: data/classification/val/49/35084.jpg  \n","  inflating: data/classification/val/49/35106.jpg  \n","  inflating: data/classification/val/49/35110.jpg  \n","  inflating: data/classification/val/49/35118.jpg  \n","  inflating: data/classification/val/49/35121.jpg  \n","  inflating: data/classification/val/49/35129.jpg  \n","  inflating: data/classification/val/49/35130.jpg  \n","  inflating: data/classification/val/49/35159.jpg  \n","  inflating: data/classification/val/49/35168.jpg  \n","  inflating: data/classification/val/49/35172.jpg  \n","  inflating: data/classification/val/49/35179.jpg  \n","  inflating: data/classification/val/49/35182.jpg  \n","  inflating: data/classification/val/49/35190.jpg  \n","  inflating: data/classification/val/49/35208.jpg  \n","  inflating: data/classification/val/49/35228.jpg  \n","  inflating: data/classification/val/49/35230.jpg  \n","  inflating: data/classification/val/49/35231.jpg  \n","  inflating: data/classification/val/49/35250.jpg  \n","  inflating: data/classification/val/49/35263.jpg  \n","  inflating: data/classification/val/49/35297.jpg  \n","  inflating: data/classification/val/49/35307.jpg  \n","  inflating: data/classification/val/49/35311.jpg  \n","  inflating: data/classification/val/49/35331.jpg  \n","  inflating: data/classification/val/49/35356.jpg  \n","  inflating: data/classification/val/49/35370.jpg  \n","  inflating: data/classification/val/49/35372.jpg  \n","  inflating: data/classification/val/49/35376.jpg  \n","  inflating: data/classification/val/49/35382.jpg  \n","  inflating: data/classification/val/5/03420.jpg  \n","  inflating: data/classification/val/5/03421.jpg  \n","  inflating: data/classification/val/5/03426.jpg  \n","  inflating: data/classification/val/5/03450.jpg  \n","  inflating: data/classification/val/5/03458.jpg  \n","  inflating: data/classification/val/5/03464.jpg  \n","  inflating: data/classification/val/5/03468.jpg  \n","  inflating: data/classification/val/5/03481.jpg  \n","  inflating: data/classification/val/5/03489.jpg  \n","  inflating: data/classification/val/5/03494.jpg  \n","  inflating: data/classification/val/5/03511.jpg  \n","  inflating: data/classification/val/5/03519.jpg  \n","  inflating: data/classification/val/5/03522.jpg  \n","  inflating: data/classification/val/5/03529.jpg  \n","  inflating: data/classification/val/5/03544.jpg  \n","  inflating: data/classification/val/5/03556.jpg  \n","  inflating: data/classification/val/5/03566.jpg  \n","  inflating: data/classification/val/5/03567.jpg  \n","  inflating: data/classification/val/5/03574.jpg  \n","  inflating: data/classification/val/5/03578.jpg  \n","  inflating: data/classification/val/5/03580.jpg  \n","  inflating: data/classification/val/5/03593.jpg  \n","  inflating: data/classification/val/5/03604.jpg  \n","  inflating: data/classification/val/5/03609.jpg  \n","  inflating: data/classification/val/5/03619.jpg  \n","  inflating: data/classification/val/5/03651.jpg  \n","  inflating: data/classification/val/5/03656.jpg  \n","  inflating: data/classification/val/5/03659.jpg  \n","  inflating: data/classification/val/5/03660.jpg  \n","  inflating: data/classification/val/5/03694.jpg  \n","  inflating: data/classification/val/5/03725.jpg  \n","  inflating: data/classification/val/5/03733.jpg  \n","  inflating: data/classification/val/5/03739.jpg  \n","  inflating: data/classification/val/5/03742.jpg  \n","  inflating: data/classification/val/5/03768.jpg  \n","  inflating: data/classification/val/5/03787.jpg  \n","  inflating: data/classification/val/5/03804.jpg  \n","  inflating: data/classification/val/5/03807.jpg  \n","  inflating: data/classification/val/5/03810.jpg  \n","  inflating: data/classification/val/5/03817.jpg  \n","  inflating: data/classification/val/5/03828.jpg  \n","  inflating: data/classification/val/5/03843.jpg  \n","  inflating: data/classification/val/5/03844.jpg  \n","  inflating: data/classification/val/5/03852.jpg  \n","  inflating: data/classification/val/5/03854.jpg  \n","  inflating: data/classification/val/5/03872.jpg  \n","  inflating: data/classification/val/5/03881.jpg  \n","  inflating: data/classification/val/5/03897.jpg  \n","  inflating: data/classification/val/5/03899.jpg  \n","  inflating: data/classification/val/5/03901.jpg  \n","  inflating: data/classification/val/5/03905.jpg  \n","  inflating: data/classification/val/50/35384.jpg  \n","  inflating: data/classification/val/50/35387.jpg  \n","  inflating: data/classification/val/50/35389.jpg  \n","  inflating: data/classification/val/50/35390.jpg  \n","  inflating: data/classification/val/50/35393.jpg  \n","  inflating: data/classification/val/50/35436.jpg  \n","  inflating: data/classification/val/50/35471.jpg  \n","  inflating: data/classification/val/50/35475.jpg  \n","  inflating: data/classification/val/50/35477.jpg  \n","  inflating: data/classification/val/50/35479.jpg  \n","  inflating: data/classification/val/50/35494.jpg  \n","  inflating: data/classification/val/50/35500.jpg  \n","  inflating: data/classification/val/50/35518.jpg  \n","  inflating: data/classification/val/50/35531.jpg  \n","  inflating: data/classification/val/50/35545.jpg  \n","  inflating: data/classification/val/50/35555.jpg  \n","  inflating: data/classification/val/50/35562.jpg  \n","  inflating: data/classification/val/50/35573.jpg  \n","  inflating: data/classification/val/50/35576.jpg  \n","  inflating: data/classification/val/50/35579.jpg  \n","  inflating: data/classification/val/50/35582.jpg  \n","  inflating: data/classification/val/50/35586.jpg  \n","  inflating: data/classification/val/50/35589.jpg  \n","  inflating: data/classification/val/50/35591.jpg  \n","  inflating: data/classification/val/50/35609.jpg  \n","  inflating: data/classification/val/50/35643.jpg  \n","  inflating: data/classification/val/50/35645.jpg  \n","  inflating: data/classification/val/50/35649.jpg  \n","  inflating: data/classification/val/50/35650.jpg  \n","  inflating: data/classification/val/50/35672.jpg  \n","  inflating: data/classification/val/50/35675.jpg  \n","  inflating: data/classification/val/50/35685.jpg  \n","  inflating: data/classification/val/50/35699.jpg  \n","  inflating: data/classification/val/50/35705.jpg  \n","  inflating: data/classification/val/50/35715.jpg  \n","  inflating: data/classification/val/50/35731.jpg  \n","  inflating: data/classification/val/50/35734.jpg  \n","  inflating: data/classification/val/50/35741.jpg  \n","  inflating: data/classification/val/50/35745.jpg  \n","  inflating: data/classification/val/50/35754.jpg  \n","  inflating: data/classification/val/50/35763.jpg  \n","  inflating: data/classification/val/50/35765.jpg  \n","  inflating: data/classification/val/50/35769.jpg  \n","  inflating: data/classification/val/50/35779.jpg  \n","  inflating: data/classification/val/50/35791.jpg  \n","  inflating: data/classification/val/50/35799.jpg  \n","  inflating: data/classification/val/50/35802.jpg  \n","  inflating: data/classification/val/50/35814.jpg  \n","  inflating: data/classification/val/50/35840.jpg  \n","  inflating: data/classification/val/50/35850.jpg  \n","  inflating: data/classification/val/50/35857.jpg  \n","  inflating: data/classification/val/50/35877.jpg  \n","  inflating: data/classification/val/50/35885.jpg  \n","  inflating: data/classification/val/50/35895.jpg  \n","  inflating: data/classification/val/50/35899.jpg  \n","  inflating: data/classification/val/50/35922.jpg  \n","  inflating: data/classification/val/50/35924.jpg  \n","  inflating: data/classification/val/50/35935.jpg  \n","  inflating: data/classification/val/50/35939.jpg  \n","  inflating: data/classification/val/50/35963.jpg  \n","  inflating: data/classification/val/50/35964.jpg  \n","  inflating: data/classification/val/50/35976.jpg  \n","  inflating: data/classification/val/50/35980.jpg  \n","  inflating: data/classification/val/50/35986.jpg  \n","  inflating: data/classification/val/50/36003.jpg  \n","  inflating: data/classification/val/50/36013.jpg  \n","  inflating: data/classification/val/50/36025.jpg  \n","  inflating: data/classification/val/50/36032.jpg  \n","  inflating: data/classification/val/50/36038.jpg  \n","  inflating: data/classification/val/50/36042.jpg  \n","  inflating: data/classification/val/50/36046.jpg  \n","  inflating: data/classification/val/50/36077.jpg  \n","  inflating: data/classification/val/50/36078.jpg  \n","  inflating: data/classification/val/50/36107.jpg  \n","  inflating: data/classification/val/50/36111.jpg  \n","  inflating: data/classification/val/50/36122.jpg  \n","  inflating: data/classification/val/50/36131.jpg  \n","  inflating: data/classification/val/50/36136.jpg  \n","  inflating: data/classification/val/50/36138.jpg  \n","  inflating: data/classification/val/50/36148.jpg  \n","  inflating: data/classification/val/50/36153.jpg  \n","  inflating: data/classification/val/50/36156.jpg  \n","  inflating: data/classification/val/50/36163.jpg  \n","  inflating: data/classification/val/50/36172.jpg  \n","  inflating: data/classification/val/50/36185.jpg  \n","  inflating: data/classification/val/50/36190.jpg  \n","  inflating: data/classification/val/50/36192.jpg  \n","  inflating: data/classification/val/50/36193.jpg  \n","  inflating: data/classification/val/50/36194.jpg  \n","  inflating: data/classification/val/50/36196.jpg  \n","  inflating: data/classification/val/50/36214.jpg  \n","  inflating: data/classification/val/50/36245.jpg  \n","  inflating: data/classification/val/50/36248.jpg  \n","  inflating: data/classification/val/50/36257.jpg  \n","  inflating: data/classification/val/50/36262.jpg  \n","  inflating: data/classification/val/50/36263.jpg  \n","  inflating: data/classification/val/50/36270.jpg  \n","  inflating: data/classification/val/50/36280.jpg  \n","  inflating: data/classification/val/50/36311.jpg  \n","  inflating: data/classification/val/50/36319.jpg  \n","  inflating: data/classification/val/50/36328.jpg  \n","  inflating: data/classification/val/50/36353.jpg  \n","  inflating: data/classification/val/50/36361.jpg  \n","  inflating: data/classification/val/50/36371.jpg  \n","  inflating: data/classification/val/50/36387.jpg  \n","  inflating: data/classification/val/50/36397.jpg  \n","  inflating: data/classification/val/50/36415.jpg  \n","  inflating: data/classification/val/50/36417.jpg  \n","  inflating: data/classification/val/50/36422.jpg  \n","  inflating: data/classification/val/50/36431.jpg  \n","  inflating: data/classification/val/50/36438.jpg  \n","  inflating: data/classification/val/50/36439.jpg  \n","  inflating: data/classification/val/50/36440.jpg  \n","  inflating: data/classification/val/50/36453.jpg  \n","  inflating: data/classification/val/50/36468.jpg  \n","  inflating: data/classification/val/50/36497.jpg  \n","  inflating: data/classification/val/50/36507.jpg  \n","  inflating: data/classification/val/50/36521.jpg  \n","  inflating: data/classification/val/50/36522.jpg  \n","  inflating: data/classification/val/50/36531.jpg  \n","  inflating: data/classification/val/50/36538.jpg  \n","  inflating: data/classification/val/50/36540.jpg  \n","  inflating: data/classification/val/50/36541.jpg  \n","  inflating: data/classification/val/50/36548.jpg  \n","  inflating: data/classification/val/50/36557.jpg  \n","  inflating: data/classification/val/50/36584.jpg  \n","  inflating: data/classification/val/50/36585.jpg  \n","  inflating: data/classification/val/50/36603.jpg  \n","  inflating: data/classification/val/50/36629.jpg  \n","  inflating: data/classification/val/50/36638.jpg  \n","  inflating: data/classification/val/50/36640.jpg  \n","  inflating: data/classification/val/50/36648.jpg  \n","  inflating: data/classification/val/50/36652.jpg  \n","  inflating: data/classification/val/50/36660.jpg  \n","  inflating: data/classification/val/50/36676.jpg  \n","  inflating: data/classification/val/50/36680.jpg  \n","  inflating: data/classification/val/50/36696.jpg  \n","  inflating: data/classification/val/50/36711.jpg  \n","  inflating: data/classification/val/50/36723.jpg  \n","  inflating: data/classification/val/50/36760.jpg  \n","  inflating: data/classification/val/50/36770.jpg  \n","  inflating: data/classification/val/51/36815.jpg  \n","  inflating: data/classification/val/51/36824.jpg  \n","  inflating: data/classification/val/51/36826.jpg  \n","  inflating: data/classification/val/51/36828.jpg  \n","  inflating: data/classification/val/51/36830.jpg  \n","  inflating: data/classification/val/51/36845.jpg  \n","  inflating: data/classification/val/51/36867.jpg  \n","  inflating: data/classification/val/51/36880.jpg  \n","  inflating: data/classification/val/51/36885.jpg  \n","  inflating: data/classification/val/51/36906.jpg  \n","  inflating: data/classification/val/51/36915.jpg  \n","  inflating: data/classification/val/51/36930.jpg  \n","  inflating: data/classification/val/51/36935.jpg  \n","  inflating: data/classification/val/51/36947.jpg  \n","  inflating: data/classification/val/51/36949.jpg  \n","  inflating: data/classification/val/51/36960.jpg  \n","  inflating: data/classification/val/51/36980.jpg  \n","  inflating: data/classification/val/51/36986.jpg  \n","  inflating: data/classification/val/51/36997.jpg  \n","  inflating: data/classification/val/51/37001.jpg  \n","  inflating: data/classification/val/51/37008.jpg  \n","  inflating: data/classification/val/51/37011.jpg  \n","  inflating: data/classification/val/51/37021.jpg  \n","  inflating: data/classification/val/51/37022.jpg  \n","  inflating: data/classification/val/51/37032.jpg  \n","  inflating: data/classification/val/51/37034.jpg  \n","  inflating: data/classification/val/51/37050.jpg  \n","  inflating: data/classification/val/51/37053.jpg  \n","  inflating: data/classification/val/51/37054.jpg  \n","  inflating: data/classification/val/51/37060.jpg  \n","  inflating: data/classification/val/51/37083.jpg  \n","  inflating: data/classification/val/51/37088.jpg  \n","  inflating: data/classification/val/51/37089.jpg  \n","  inflating: data/classification/val/51/37105.jpg  \n","  inflating: data/classification/val/51/37108.jpg  \n","  inflating: data/classification/val/51/37118.jpg  \n","  inflating: data/classification/val/51/37128.jpg  \n","  inflating: data/classification/val/51/37149.jpg  \n","  inflating: data/classification/val/51/37160.jpg  \n","  inflating: data/classification/val/51/37162.jpg  \n","  inflating: data/classification/val/51/37170.jpg  \n","  inflating: data/classification/val/51/37194.jpg  \n","  inflating: data/classification/val/51/37210.jpg  \n","  inflating: data/classification/val/51/37224.jpg  \n","  inflating: data/classification/val/51/37228.jpg  \n","  inflating: data/classification/val/51/37239.jpg  \n","  inflating: data/classification/val/51/37257.jpg  \n","  inflating: data/classification/val/51/37259.jpg  \n","  inflating: data/classification/val/51/37260.jpg  \n","  inflating: data/classification/val/51/37267.jpg  \n","  inflating: data/classification/val/51/37295.jpg  \n","  inflating: data/classification/val/51/37300.jpg  \n","  inflating: data/classification/val/51/37314.jpg  \n","  inflating: data/classification/val/51/37316.jpg  \n","  inflating: data/classification/val/51/37328.jpg  \n","  inflating: data/classification/val/51/37343.jpg  \n","  inflating: data/classification/val/51/37369.jpg  \n","  inflating: data/classification/val/51/37392.jpg  \n","  inflating: data/classification/val/51/37409.jpg  \n","  inflating: data/classification/val/51/37418.jpg  \n","  inflating: data/classification/val/51/37420.jpg  \n","  inflating: data/classification/val/51/37422.jpg  \n","  inflating: data/classification/val/51/37440.jpg  \n","  inflating: data/classification/val/51/37449.jpg  \n","  inflating: data/classification/val/51/37476.jpg  \n","  inflating: data/classification/val/51/37477.jpg  \n","  inflating: data/classification/val/51/37486.jpg  \n","  inflating: data/classification/val/51/37492.jpg  \n","  inflating: data/classification/val/51/37494.jpg  \n","  inflating: data/classification/val/51/37506.jpg  \n","  inflating: data/classification/val/51/37538.jpg  \n","  inflating: data/classification/val/51/37540.jpg  \n","  inflating: data/classification/val/51/37563.jpg  \n","  inflating: data/classification/val/51/37568.jpg  \n","  inflating: data/classification/val/51/37585.jpg  \n","  inflating: data/classification/val/51/37602.jpg  \n","  inflating: data/classification/val/51/37605.jpg  \n","  inflating: data/classification/val/51/37606.jpg  \n","  inflating: data/classification/val/51/37612.jpg  \n","  inflating: data/classification/val/51/37613.jpg  \n","  inflating: data/classification/val/51/37623.jpg  \n","  inflating: data/classification/val/51/37625.jpg  \n","  inflating: data/classification/val/51/37629.jpg  \n","  inflating: data/classification/val/51/37645.jpg  \n","  inflating: data/classification/val/51/37654.jpg  \n","  inflating: data/classification/val/51/37661.jpg  \n","  inflating: data/classification/val/51/37666.jpg  \n","  inflating: data/classification/val/51/37669.jpg  \n","  inflating: data/classification/val/51/37681.jpg  \n","  inflating: data/classification/val/51/37682.jpg  \n","  inflating: data/classification/val/51/37688.jpg  \n","  inflating: data/classification/val/51/37697.jpg  \n","  inflating: data/classification/val/51/37710.jpg  \n","  inflating: data/classification/val/51/37720.jpg  \n","  inflating: data/classification/val/51/37722.jpg  \n","  inflating: data/classification/val/51/37728.jpg  \n","  inflating: data/classification/val/51/37739.jpg  \n","  inflating: data/classification/val/51/37765.jpg  \n","  inflating: data/classification/val/51/37767.jpg  \n","  inflating: data/classification/val/51/37770.jpg  \n","  inflating: data/classification/val/51/37779.jpg  \n","  inflating: data/classification/val/51/37782.jpg  \n","  inflating: data/classification/val/51/37793.jpg  \n","  inflating: data/classification/val/51/37801.jpg  \n","  inflating: data/classification/val/51/37808.jpg  \n","  inflating: data/classification/val/51/37818.jpg  \n","  inflating: data/classification/val/51/37825.jpg  \n","  inflating: data/classification/val/51/37833.jpg  \n","  inflating: data/classification/val/51/37837.jpg  \n","  inflating: data/classification/val/51/37855.jpg  \n","  inflating: data/classification/val/51/37857.jpg  \n","  inflating: data/classification/val/51/37859.jpg  \n","  inflating: data/classification/val/51/37863.jpg  \n","  inflating: data/classification/val/51/37878.jpg  \n","  inflating: data/classification/val/51/37900.jpg  \n","  inflating: data/classification/val/51/37916.jpg  \n","  inflating: data/classification/val/51/37929.jpg  \n","  inflating: data/classification/val/51/37941.jpg  \n","  inflating: data/classification/val/51/37944.jpg  \n","  inflating: data/classification/val/51/37948.jpg  \n","  inflating: data/classification/val/51/37967.jpg  \n","  inflating: data/classification/val/51/37982.jpg  \n","  inflating: data/classification/val/51/37999.jpg  \n","  inflating: data/classification/val/51/38002.jpg  \n","  inflating: data/classification/val/51/38017.jpg  \n","  inflating: data/classification/val/51/38023.jpg  \n","  inflating: data/classification/val/51/38032.jpg  \n","  inflating: data/classification/val/51/38047.jpg  \n","  inflating: data/classification/val/51/38048.jpg  \n","  inflating: data/classification/val/51/38055.jpg  \n","  inflating: data/classification/val/51/38074.jpg  \n","  inflating: data/classification/val/51/38101.jpg  \n","  inflating: data/classification/val/51/38137.jpg  \n","  inflating: data/classification/val/51/38138.jpg  \n","  inflating: data/classification/val/51/38155.jpg  \n","  inflating: data/classification/val/51/38176.jpg  \n","  inflating: data/classification/val/51/38190.jpg  \n","  inflating: data/classification/val/51/38201.jpg  \n","  inflating: data/classification/val/51/38226.jpg  \n","  inflating: data/classification/val/51/38239.jpg  \n","  inflating: data/classification/val/51/38241.jpg  \n","  inflating: data/classification/val/51/38254.jpg  \n","  inflating: data/classification/val/51/38258.jpg  \n","  inflating: data/classification/val/51/38262.jpg  \n","  inflating: data/classification/val/51/38272.jpg  \n","  inflating: data/classification/val/51/38274.jpg  \n","  inflating: data/classification/val/51/38308.jpg  \n","  inflating: data/classification/val/51/38309.jpg  \n","  inflating: data/classification/val/51/38311.jpg  \n","  inflating: data/classification/val/51/38320.jpg  \n","  inflating: data/classification/val/51/38321.jpg  \n","  inflating: data/classification/val/51/38338.jpg  \n","  inflating: data/classification/val/51/38340.jpg  \n","  inflating: data/classification/val/51/38344.jpg  \n","  inflating: data/classification/val/51/38369.jpg  \n","  inflating: data/classification/val/51/38388.jpg  \n","  inflating: data/classification/val/51/38392.jpg  \n","  inflating: data/classification/val/51/38405.jpg  \n","  inflating: data/classification/val/51/38441.jpg  \n","  inflating: data/classification/val/51/38454.jpg  \n","  inflating: data/classification/val/51/38469.jpg  \n","  inflating: data/classification/val/51/38470.jpg  \n","  inflating: data/classification/val/51/38491.jpg  \n","  inflating: data/classification/val/51/38503.jpg  \n","  inflating: data/classification/val/51/38508.jpg  \n","  inflating: data/classification/val/51/38513.jpg  \n","  inflating: data/classification/val/51/38516.jpg  \n","  inflating: data/classification/val/51/38523.jpg  \n","  inflating: data/classification/val/51/38533.jpg  \n","  inflating: data/classification/val/51/38539.jpg  \n","  inflating: data/classification/val/51/38543.jpg  \n","  inflating: data/classification/val/51/38548.jpg  \n","  inflating: data/classification/val/51/38556.jpg  \n","  inflating: data/classification/val/51/38558.jpg  \n","  inflating: data/classification/val/51/38578.jpg  \n","  inflating: data/classification/val/51/38579.jpg  \n","  inflating: data/classification/val/51/38588.jpg  \n","  inflating: data/classification/val/51/38609.jpg  \n","  inflating: data/classification/val/51/38610.jpg  \n","  inflating: data/classification/val/51/38611.jpg  \n","  inflating: data/classification/val/51/38612.jpg  \n","  inflating: data/classification/val/51/38624.jpg  \n","  inflating: data/classification/val/51/38634.jpg  \n","  inflating: data/classification/val/51/38651.jpg  \n","  inflating: data/classification/val/51/38667.jpg  \n","  inflating: data/classification/val/51/38678.jpg  \n","  inflating: data/classification/val/51/38679.jpg  \n","  inflating: data/classification/val/51/38682.jpg  \n","  inflating: data/classification/val/51/38683.jpg  \n","  inflating: data/classification/val/52/38705.jpg  \n","  inflating: data/classification/val/52/38707.jpg  \n","  inflating: data/classification/val/52/38717.jpg  \n","  inflating: data/classification/val/52/38749.jpg  \n","  inflating: data/classification/val/52/38760.jpg  \n","  inflating: data/classification/val/52/38771.jpg  \n","  inflating: data/classification/val/52/38774.jpg  \n","  inflating: data/classification/val/52/38810.jpg  \n","  inflating: data/classification/val/52/38811.jpg  \n","  inflating: data/classification/val/52/38828.jpg  \n","  inflating: data/classification/val/52/38831.jpg  \n","  inflating: data/classification/val/52/38841.jpg  \n","  inflating: data/classification/val/52/38849.jpg  \n","  inflating: data/classification/val/52/38857.jpg  \n","  inflating: data/classification/val/52/38858.jpg  \n","  inflating: data/classification/val/52/38887.jpg  \n","  inflating: data/classification/val/52/38894.jpg  \n","  inflating: data/classification/val/52/38898.jpg  \n","  inflating: data/classification/val/52/38901.jpg  \n","  inflating: data/classification/val/52/38913.jpg  \n","  inflating: data/classification/val/52/38920.jpg  \n","  inflating: data/classification/val/52/38933.jpg  \n","  inflating: data/classification/val/52/38938.jpg  \n","  inflating: data/classification/val/52/38939.jpg  \n","  inflating: data/classification/val/52/38944.jpg  \n","  inflating: data/classification/val/52/38946.jpg  \n","  inflating: data/classification/val/53/38956.jpg  \n","  inflating: data/classification/val/53/38962.jpg  \n","  inflating: data/classification/val/53/38966.jpg  \n","  inflating: data/classification/val/53/38975.jpg  \n","  inflating: data/classification/val/53/38985.jpg  \n","  inflating: data/classification/val/53/39003.jpg  \n","  inflating: data/classification/val/53/39005.jpg  \n","  inflating: data/classification/val/53/39014.jpg  \n","  inflating: data/classification/val/53/39022.jpg  \n","  inflating: data/classification/val/53/39035.jpg  \n","  inflating: data/classification/val/53/39041.jpg  \n","  inflating: data/classification/val/53/39063.jpg  \n","  inflating: data/classification/val/53/39065.jpg  \n","  inflating: data/classification/val/53/39085.jpg  \n","  inflating: data/classification/val/53/39122.jpg  \n","  inflating: data/classification/val/53/39123.jpg  \n","  inflating: data/classification/val/53/39125.jpg  \n","  inflating: data/classification/val/54/39129.jpg  \n","  inflating: data/classification/val/54/39147.jpg  \n","  inflating: data/classification/val/54/39190.jpg  \n","  inflating: data/classification/val/54/39193.jpg  \n","  inflating: data/classification/val/54/39194.jpg  \n","  inflating: data/classification/val/54/39209.jpg  \n","  inflating: data/classification/val/54/39227.jpg  \n","  inflating: data/classification/val/54/39228.jpg  \n","  inflating: data/classification/val/54/39252.jpg  \n","  inflating: data/classification/val/54/39255.jpg  \n","  inflating: data/classification/val/54/39282.jpg  \n","  inflating: data/classification/val/54/39283.jpg  \n","  inflating: data/classification/val/54/39294.jpg  \n","  inflating: data/classification/val/54/39296.jpg  \n","  inflating: data/classification/val/54/39300.jpg  \n","  inflating: data/classification/val/54/39301.jpg  \n","  inflating: data/classification/val/54/39308.jpg  \n","  inflating: data/classification/val/54/39311.jpg  \n","  inflating: data/classification/val/54/39319.jpg  \n","  inflating: data/classification/val/54/39326.jpg  \n","  inflating: data/classification/val/54/39355.jpg  \n","  inflating: data/classification/val/54/39358.jpg  \n","  inflating: data/classification/val/54/39374.jpg  \n","  inflating: data/classification/val/54/39375.jpg  \n","  inflating: data/classification/val/54/39380.jpg  \n","  inflating: data/classification/val/54/39381.jpg  \n","  inflating: data/classification/val/54/39386.jpg  \n","  inflating: data/classification/val/54/39395.jpg  \n","  inflating: data/classification/val/54/39401.jpg  \n","  inflating: data/classification/val/54/39410.jpg  \n","  inflating: data/classification/val/54/39452.jpg  \n","  inflating: data/classification/val/54/39470.jpg  \n","  inflating: data/classification/val/54/39513.jpg  \n","  inflating: data/classification/val/54/39517.jpg  \n","  inflating: data/classification/val/54/39531.jpg  \n","  inflating: data/classification/val/54/39532.jpg  \n","  inflating: data/classification/val/54/39556.jpg  \n","  inflating: data/classification/val/54/39560.jpg  \n","  inflating: data/classification/val/54/39564.jpg  \n","  inflating: data/classification/val/54/39599.jpg  \n","  inflating: data/classification/val/54/39636.jpg  \n","  inflating: data/classification/val/54/39645.jpg  \n","  inflating: data/classification/val/54/39648.jpg  \n","  inflating: data/classification/val/54/39655.jpg  \n","  inflating: data/classification/val/54/39664.jpg  \n","  inflating: data/classification/val/54/39668.jpg  \n","  inflating: data/classification/val/54/39670.jpg  \n","  inflating: data/classification/val/54/39671.jpg  \n","  inflating: data/classification/val/54/39697.jpg  \n","  inflating: data/classification/val/54/39698.jpg  \n","  inflating: data/classification/val/54/39699.jpg  \n","  inflating: data/classification/val/54/39704.jpg  \n","  inflating: data/classification/val/54/39714.jpg  \n","  inflating: data/classification/val/54/39716.jpg  \n","  inflating: data/classification/val/54/39722.jpg  \n","  inflating: data/classification/val/54/39744.jpg  \n","  inflating: data/classification/val/54/39745.jpg  \n","  inflating: data/classification/val/54/39757.jpg  \n","  inflating: data/classification/val/54/39774.jpg  \n","  inflating: data/classification/val/54/39775.jpg  \n","  inflating: data/classification/val/54/39777.jpg  \n","  inflating: data/classification/val/54/39779.jpg  \n","  inflating: data/classification/val/54/39796.jpg  \n","  inflating: data/classification/val/54/39807.jpg  \n","  inflating: data/classification/val/54/39820.jpg  \n","  inflating: data/classification/val/54/39850.jpg  \n","  inflating: data/classification/val/54/39852.jpg  \n","  inflating: data/classification/val/54/39859.jpg  \n","  inflating: data/classification/val/54/39860.jpg  \n","  inflating: data/classification/val/54/39863.jpg  \n","  inflating: data/classification/val/54/39889.jpg  \n","  inflating: data/classification/val/54/39906.jpg  \n","  inflating: data/classification/val/54/39908.jpg  \n","  inflating: data/classification/val/54/39912.jpg  \n","  inflating: data/classification/val/54/39918.jpg  \n","  inflating: data/classification/val/54/39931.jpg  \n","  inflating: data/classification/val/54/39937.jpg  \n","  inflating: data/classification/val/54/39945.jpg  \n","  inflating: data/classification/val/54/39949.jpg  \n","  inflating: data/classification/val/54/39960.jpg  \n","  inflating: data/classification/val/54/39963.jpg  \n","  inflating: data/classification/val/54/39967.jpg  \n","  inflating: data/classification/val/54/39984.jpg  \n","  inflating: data/classification/val/54/39988.jpg  \n","  inflating: data/classification/val/54/39994.jpg  \n","  inflating: data/classification/val/54/39998.jpg  \n","  inflating: data/classification/val/54/40001.jpg  \n","  inflating: data/classification/val/54/40003.jpg  \n","  inflating: data/classification/val/55/40007.jpg  \n","  inflating: data/classification/val/55/40015.jpg  \n","  inflating: data/classification/val/55/40053.jpg  \n","  inflating: data/classification/val/55/40090.jpg  \n","  inflating: data/classification/val/55/40092.jpg  \n","  inflating: data/classification/val/55/40105.jpg  \n","  inflating: data/classification/val/55/40112.jpg  \n","  inflating: data/classification/val/55/40118.jpg  \n","  inflating: data/classification/val/55/40122.jpg  \n","  inflating: data/classification/val/55/40129.jpg  \n","  inflating: data/classification/val/55/40130.jpg  \n","  inflating: data/classification/val/55/40142.jpg  \n","  inflating: data/classification/val/55/40144.jpg  \n","  inflating: data/classification/val/55/40145.jpg  \n","  inflating: data/classification/val/55/40163.jpg  \n","  inflating: data/classification/val/55/40169.jpg  \n","  inflating: data/classification/val/55/40176.jpg  \n","  inflating: data/classification/val/55/40185.jpg  \n","  inflating: data/classification/val/56/40198.jpg  \n","  inflating: data/classification/val/56/40200.jpg  \n","  inflating: data/classification/val/56/40212.jpg  \n","  inflating: data/classification/val/56/40218.jpg  \n","  inflating: data/classification/val/56/40225.jpg  \n","  inflating: data/classification/val/56/40238.jpg  \n","  inflating: data/classification/val/56/40250.jpg  \n","  inflating: data/classification/val/56/40254.jpg  \n","  inflating: data/classification/val/56/40258.jpg  \n","  inflating: data/classification/val/56/40265.jpg  \n","  inflating: data/classification/val/56/40273.jpg  \n","  inflating: data/classification/val/56/40279.jpg  \n","  inflating: data/classification/val/56/40280.jpg  \n","  inflating: data/classification/val/56/40282.jpg  \n","  inflating: data/classification/val/56/40292.jpg  \n","  inflating: data/classification/val/56/40351.jpg  \n","  inflating: data/classification/val/56/40363.jpg  \n","  inflating: data/classification/val/56/40381.jpg  \n","  inflating: data/classification/val/56/40390.jpg  \n","  inflating: data/classification/val/56/40395.jpg  \n","  inflating: data/classification/val/56/40408.jpg  \n","  inflating: data/classification/val/56/40413.jpg  \n","  inflating: data/classification/val/56/40431.jpg  \n","  inflating: data/classification/val/56/40462.jpg  \n","  inflating: data/classification/val/56/40467.jpg  \n","  inflating: data/classification/val/56/40476.jpg  \n","  inflating: data/classification/val/56/40477.jpg  \n","  inflating: data/classification/val/56/40478.jpg  \n","  inflating: data/classification/val/56/40482.jpg  \n","  inflating: data/classification/val/56/40484.jpg  \n","  inflating: data/classification/val/56/40485.jpg  \n","  inflating: data/classification/val/56/40486.jpg  \n","  inflating: data/classification/val/56/40509.jpg  \n","  inflating: data/classification/val/56/40529.jpg  \n","  inflating: data/classification/val/56/40537.jpg  \n","  inflating: data/classification/val/56/40546.jpg  \n","  inflating: data/classification/val/56/40559.jpg  \n","  inflating: data/classification/val/56/40572.jpg  \n","  inflating: data/classification/val/56/40579.jpg  \n","  inflating: data/classification/val/56/40595.jpg  \n","  inflating: data/classification/val/56/40612.jpg  \n","  inflating: data/classification/val/56/40614.jpg  \n","  inflating: data/classification/val/56/40616.jpg  \n","  inflating: data/classification/val/56/40619.jpg  \n","  inflating: data/classification/val/56/40622.jpg  \n","  inflating: data/classification/val/56/40629.jpg  \n","  inflating: data/classification/val/56/40645.jpg  \n","  inflating: data/classification/val/57/40666.jpg  \n","  inflating: data/classification/val/57/40677.jpg  \n","  inflating: data/classification/val/57/40690.jpg  \n","  inflating: data/classification/val/57/40718.jpg  \n","  inflating: data/classification/val/57/40722.jpg  \n","  inflating: data/classification/val/57/40725.jpg  \n","  inflating: data/classification/val/57/40736.jpg  \n","  inflating: data/classification/val/57/40743.jpg  \n","  inflating: data/classification/val/57/40744.jpg  \n","  inflating: data/classification/val/57/40768.jpg  \n","  inflating: data/classification/val/57/40773.jpg  \n","  inflating: data/classification/val/57/40776.jpg  \n","  inflating: data/classification/val/57/40777.jpg  \n","  inflating: data/classification/val/57/40779.jpg  \n","  inflating: data/classification/val/57/40781.jpg  \n","  inflating: data/classification/val/57/40792.jpg  \n","  inflating: data/classification/val/57/40796.jpg  \n","  inflating: data/classification/val/57/40801.jpg  \n","  inflating: data/classification/val/57/40803.jpg  \n","  inflating: data/classification/val/57/40805.jpg  \n","  inflating: data/classification/val/57/40817.jpg  \n","  inflating: data/classification/val/57/40830.jpg  \n","  inflating: data/classification/val/57/40852.jpg  \n","  inflating: data/classification/val/57/40859.jpg  \n","  inflating: data/classification/val/57/40875.jpg  \n","  inflating: data/classification/val/57/40878.jpg  \n","  inflating: data/classification/val/57/40879.jpg  \n","  inflating: data/classification/val/57/40931.jpg  \n","  inflating: data/classification/val/57/40947.jpg  \n","  inflating: data/classification/val/57/40961.jpg  \n","  inflating: data/classification/val/57/40963.jpg  \n","  inflating: data/classification/val/57/40971.jpg  \n","  inflating: data/classification/val/57/40981.jpg  \n","  inflating: data/classification/val/57/41002.jpg  \n","  inflating: data/classification/val/57/41006.jpg  \n","  inflating: data/classification/val/57/41018.jpg  \n","  inflating: data/classification/val/57/41022.jpg  \n","  inflating: data/classification/val/57/41024.jpg  \n","  inflating: data/classification/val/58/41045.jpg  \n","  inflating: data/classification/val/58/41052.jpg  \n","  inflating: data/classification/val/58/41062.jpg  \n","  inflating: data/classification/val/58/41066.jpg  \n","  inflating: data/classification/val/58/41069.jpg  \n","  inflating: data/classification/val/58/41080.jpg  \n","  inflating: data/classification/val/58/41107.jpg  \n","  inflating: data/classification/val/58/41118.jpg  \n","  inflating: data/classification/val/58/41122.jpg  \n","  inflating: data/classification/val/58/41132.jpg  \n","  inflating: data/classification/val/58/41143.jpg  \n","  inflating: data/classification/val/58/41156.jpg  \n","  inflating: data/classification/val/58/41159.jpg  \n","  inflating: data/classification/val/58/41166.jpg  \n","  inflating: data/classification/val/58/41186.jpg  \n","  inflating: data/classification/val/58/41218.jpg  \n","  inflating: data/classification/val/58/41230.jpg  \n","  inflating: data/classification/val/58/41237.jpg  \n","  inflating: data/classification/val/58/41244.jpg  \n","  inflating: data/classification/val/58/41246.jpg  \n","  inflating: data/classification/val/58/41248.jpg  \n","  inflating: data/classification/val/58/41258.jpg  \n","  inflating: data/classification/val/58/41286.jpg  \n","  inflating: data/classification/val/58/41294.jpg  \n","  inflating: data/classification/val/58/41307.jpg  \n","  inflating: data/classification/val/58/41311.jpg  \n","  inflating: data/classification/val/58/41318.jpg  \n","  inflating: data/classification/val/58/41320.jpg  \n","  inflating: data/classification/val/58/41331.jpg  \n","  inflating: data/classification/val/58/41344.jpg  \n","  inflating: data/classification/val/58/41367.jpg  \n","  inflating: data/classification/val/58/41369.jpg  \n","  inflating: data/classification/val/58/41409.jpg  \n","  inflating: data/classification/val/58/41410.jpg  \n","  inflating: data/classification/val/58/41423.jpg  \n","  inflating: data/classification/val/58/41444.jpg  \n","  inflating: data/classification/val/58/41461.jpg  \n","  inflating: data/classification/val/58/41465.jpg  \n","  inflating: data/classification/val/58/41471.jpg  \n","  inflating: data/classification/val/58/41473.jpg  \n","  inflating: data/classification/val/58/41479.jpg  \n","  inflating: data/classification/val/58/41486.jpg  \n","  inflating: data/classification/val/58/41490.jpg  \n","  inflating: data/classification/val/58/41491.jpg  \n","  inflating: data/classification/val/58/41494.jpg  \n","  inflating: data/classification/val/58/41500.jpg  \n","  inflating: data/classification/val/58/41502.jpg  \n","  inflating: data/classification/val/58/41521.jpg  \n","  inflating: data/classification/val/58/41524.jpg  \n","  inflating: data/classification/val/58/41526.jpg  \n","  inflating: data/classification/val/58/41527.jpg  \n","  inflating: data/classification/val/58/41533.jpg  \n","  inflating: data/classification/val/58/41538.jpg  \n","  inflating: data/classification/val/58/41539.jpg  \n","  inflating: data/classification/val/58/41556.jpg  \n","  inflating: data/classification/val/58/41579.jpg  \n","  inflating: data/classification/val/58/41583.jpg  \n","  inflating: data/classification/val/58/41590.jpg  \n","  inflating: data/classification/val/58/41597.jpg  \n","  inflating: data/classification/val/58/41614.jpg  \n","  inflating: data/classification/val/58/41617.jpg  \n","  inflating: data/classification/val/58/41636.jpg  \n","  inflating: data/classification/val/58/41638.jpg  \n","  inflating: data/classification/val/58/41655.jpg  \n","  inflating: data/classification/val/58/41656.jpg  \n","  inflating: data/classification/val/58/41686.jpg  \n","  inflating: data/classification/val/58/41730.jpg  \n","  inflating: data/classification/val/58/41739.jpg  \n","  inflating: data/classification/val/58/41775.jpg  \n","  inflating: data/classification/val/58/41778.jpg  \n","  inflating: data/classification/val/58/41779.jpg  \n","  inflating: data/classification/val/58/41788.jpg  \n","  inflating: data/classification/val/58/41807.jpg  \n","  inflating: data/classification/val/58/41812.jpg  \n","  inflating: data/classification/val/58/41832.jpg  \n","  inflating: data/classification/val/58/41842.jpg  \n","  inflating: data/classification/val/58/41846.jpg  \n","  inflating: data/classification/val/58/41877.jpg  \n","  inflating: data/classification/val/58/41890.jpg  \n","  inflating: data/classification/val/58/41899.jpg  \n","  inflating: data/classification/val/58/41900.jpg  \n","  inflating: data/classification/val/58/41923.jpg  \n","  inflating: data/classification/val/58/41924.jpg  \n","  inflating: data/classification/val/58/41927.jpg  \n","  inflating: data/classification/val/58/41932.jpg  \n","  inflating: data/classification/val/58/41933.jpg  \n","  inflating: data/classification/val/58/41954.jpg  \n","  inflating: data/classification/val/58/41958.jpg  \n","  inflating: data/classification/val/58/41959.jpg  \n","  inflating: data/classification/val/58/41964.jpg  \n","  inflating: data/classification/val/58/41972.jpg  \n","  inflating: data/classification/val/58/41979.jpg  \n","  inflating: data/classification/val/58/41980.jpg  \n","  inflating: data/classification/val/58/41996.jpg  \n","  inflating: data/classification/val/58/42000.jpg  \n","  inflating: data/classification/val/58/42020.jpg  \n","  inflating: data/classification/val/58/42027.jpg  \n","  inflating: data/classification/val/58/42036.jpg  \n","  inflating: data/classification/val/58/42052.jpg  \n","  inflating: data/classification/val/58/42060.jpg  \n","  inflating: data/classification/val/58/42066.jpg  \n","  inflating: data/classification/val/58/42078.jpg  \n","  inflating: data/classification/val/58/42085.jpg  \n","  inflating: data/classification/val/58/42086.jpg  \n","  inflating: data/classification/val/58/42091.jpg  \n","  inflating: data/classification/val/58/42099.jpg  \n","  inflating: data/classification/val/58/42103.jpg  \n","  inflating: data/classification/val/58/42110.jpg  \n","  inflating: data/classification/val/58/42125.jpg  \n","  inflating: data/classification/val/58/42129.jpg  \n","  inflating: data/classification/val/58/42167.jpg  \n","  inflating: data/classification/val/58/42168.jpg  \n","  inflating: data/classification/val/58/42175.jpg  \n","  inflating: data/classification/val/58/42183.jpg  \n","  inflating: data/classification/val/58/42193.jpg  \n","  inflating: data/classification/val/58/42200.jpg  \n","  inflating: data/classification/val/58/42212.jpg  \n","  inflating: data/classification/val/58/42222.jpg  \n","  inflating: data/classification/val/58/42233.jpg  \n","  inflating: data/classification/val/58/42243.jpg  \n","  inflating: data/classification/val/58/42250.jpg  \n","  inflating: data/classification/val/58/42256.jpg  \n","  inflating: data/classification/val/58/42298.jpg  \n","  inflating: data/classification/val/58/42303.jpg  \n","  inflating: data/classification/val/58/42337.jpg  \n","  inflating: data/classification/val/58/42348.jpg  \n","  inflating: data/classification/val/58/42359.jpg  \n","  inflating: data/classification/val/58/42361.jpg  \n","  inflating: data/classification/val/58/42362.jpg  \n","  inflating: data/classification/val/58/42366.jpg  \n","  inflating: data/classification/val/58/42378.jpg  \n","  inflating: data/classification/val/58/42382.jpg  \n","  inflating: data/classification/val/58/42386.jpg  \n","  inflating: data/classification/val/58/42388.jpg  \n","  inflating: data/classification/val/58/42393.jpg  \n","  inflating: data/classification/val/58/42407.jpg  \n","  inflating: data/classification/val/58/42409.jpg  \n","  inflating: data/classification/val/58/42437.jpg  \n","  inflating: data/classification/val/58/42439.jpg  \n","  inflating: data/classification/val/59/42447.jpg  \n","  inflating: data/classification/val/59/42448.jpg  \n","  inflating: data/classification/val/59/42475.jpg  \n","  inflating: data/classification/val/59/42476.jpg  \n","  inflating: data/classification/val/59/42477.jpg  \n","  inflating: data/classification/val/59/42492.jpg  \n","  inflating: data/classification/val/59/42497.jpg  \n","  inflating: data/classification/val/59/42505.jpg  \n","  inflating: data/classification/val/59/42528.jpg  \n","  inflating: data/classification/val/59/42533.jpg  \n","  inflating: data/classification/val/59/42560.jpg  \n","  inflating: data/classification/val/59/42592.jpg  \n","  inflating: data/classification/val/59/42601.jpg  \n","  inflating: data/classification/val/59/42627.jpg  \n","  inflating: data/classification/val/59/42629.jpg  \n","  inflating: data/classification/val/59/42634.jpg  \n","  inflating: data/classification/val/59/42635.jpg  \n","  inflating: data/classification/val/59/42643.jpg  \n","  inflating: data/classification/val/59/42646.jpg  \n","  inflating: data/classification/val/59/42664.jpg  \n","  inflating: data/classification/val/59/42667.jpg  \n","  inflating: data/classification/val/59/42669.jpg  \n","  inflating: data/classification/val/59/42673.jpg  \n","  inflating: data/classification/val/59/42694.jpg  \n","  inflating: data/classification/val/59/42702.jpg  \n","  inflating: data/classification/val/59/42711.jpg  \n","  inflating: data/classification/val/59/42724.jpg  \n","  inflating: data/classification/val/59/42732.jpg  \n","  inflating: data/classification/val/59/42744.jpg  \n","  inflating: data/classification/val/59/42746.jpg  \n","  inflating: data/classification/val/59/42748.jpg  \n","  inflating: data/classification/val/59/42761.jpg  \n","  inflating: data/classification/val/59/42769.jpg  \n","  inflating: data/classification/val/59/42772.jpg  \n","  inflating: data/classification/val/59/42786.jpg  \n","  inflating: data/classification/val/6/03933.jpg  \n","  inflating: data/classification/val/6/03941.jpg  \n","  inflating: data/classification/val/6/03946.jpg  \n","  inflating: data/classification/val/6/03948.jpg  \n","  inflating: data/classification/val/6/03957.jpg  \n","  inflating: data/classification/val/6/03974.jpg  \n","  inflating: data/classification/val/6/03976.jpg  \n","  inflating: data/classification/val/6/03978.jpg  \n","  inflating: data/classification/val/6/04024.jpg  \n","  inflating: data/classification/val/6/04031.jpg  \n","  inflating: data/classification/val/6/04036.jpg  \n","  inflating: data/classification/val/6/04050.jpg  \n","  inflating: data/classification/val/6/04067.jpg  \n","  inflating: data/classification/val/6/04070.jpg  \n","  inflating: data/classification/val/6/04075.jpg  \n","  inflating: data/classification/val/6/04080.jpg  \n","  inflating: data/classification/val/6/04095.jpg  \n","  inflating: data/classification/val/6/04111.jpg  \n","  inflating: data/classification/val/6/04145.jpg  \n","  inflating: data/classification/val/6/04150.jpg  \n","  inflating: data/classification/val/6/04157.jpg  \n","  inflating: data/classification/val/6/04168.jpg  \n","  inflating: data/classification/val/6/04173.jpg  \n","  inflating: data/classification/val/6/04175.jpg  \n","  inflating: data/classification/val/6/04179.jpg  \n","  inflating: data/classification/val/6/04196.jpg  \n","  inflating: data/classification/val/6/04219.jpg  \n","  inflating: data/classification/val/6/04221.jpg  \n","  inflating: data/classification/val/6/04223.jpg  \n","  inflating: data/classification/val/6/04236.jpg  \n","  inflating: data/classification/val/6/04241.jpg  \n","  inflating: data/classification/val/6/04252.jpg  \n","  inflating: data/classification/val/6/04258.jpg  \n","  inflating: data/classification/val/6/04260.jpg  \n","  inflating: data/classification/val/6/04279.jpg  \n","  inflating: data/classification/val/6/04289.jpg  \n","  inflating: data/classification/val/6/04293.jpg  \n","  inflating: data/classification/val/60/42826.jpg  \n","  inflating: data/classification/val/60/42830.jpg  \n","  inflating: data/classification/val/60/42832.jpg  \n","  inflating: data/classification/val/60/42834.jpg  \n","  inflating: data/classification/val/60/42840.jpg  \n","  inflating: data/classification/val/60/42856.jpg  \n","  inflating: data/classification/val/60/42875.jpg  \n","  inflating: data/classification/val/60/42881.jpg  \n","  inflating: data/classification/val/60/42882.jpg  \n","  inflating: data/classification/val/60/42883.jpg  \n","  inflating: data/classification/val/60/42885.jpg  \n","  inflating: data/classification/val/60/42892.jpg  \n","  inflating: data/classification/val/60/42904.jpg  \n","  inflating: data/classification/val/60/42906.jpg  \n","  inflating: data/classification/val/60/42908.jpg  \n","  inflating: data/classification/val/60/42931.jpg  \n","  inflating: data/classification/val/60/42944.jpg  \n","  inflating: data/classification/val/60/42969.jpg  \n","  inflating: data/classification/val/61/42975.jpg  \n","  inflating: data/classification/val/61/42976.jpg  \n","  inflating: data/classification/val/61/42980.jpg  \n","  inflating: data/classification/val/61/42982.jpg  \n","  inflating: data/classification/val/61/43033.jpg  \n","  inflating: data/classification/val/61/43035.jpg  \n","  inflating: data/classification/val/61/43042.jpg  \n","  inflating: data/classification/val/61/43044.jpg  \n","  inflating: data/classification/val/62/43053.jpg  \n","  inflating: data/classification/val/62/43064.jpg  \n","  inflating: data/classification/val/62/43068.jpg  \n","  inflating: data/classification/val/62/43092.jpg  \n","  inflating: data/classification/val/62/43096.jpg  \n","  inflating: data/classification/val/62/43104.jpg  \n","  inflating: data/classification/val/62/43111.jpg  \n","  inflating: data/classification/val/62/43112.jpg  \n","  inflating: data/classification/val/62/43122.jpg  \n","  inflating: data/classification/val/62/43125.jpg  \n","  inflating: data/classification/val/62/43131.jpg  \n","  inflating: data/classification/val/62/43145.jpg  \n","  inflating: data/classification/val/62/43147.jpg  \n","  inflating: data/classification/val/62/43150.jpg  \n","  inflating: data/classification/val/62/43164.jpg  \n","  inflating: data/classification/val/62/43172.jpg  \n","  inflating: data/classification/val/62/43199.jpg  \n","  inflating: data/classification/val/62/43206.jpg  \n","  inflating: data/classification/val/62/43220.jpg  \n","  inflating: data/classification/val/62/43221.jpg  \n","  inflating: data/classification/val/62/43233.jpg  \n","  inflating: data/classification/val/62/43237.jpg  \n","  inflating: data/classification/val/62/43247.jpg  \n","  inflating: data/classification/val/62/43257.jpg  \n","  inflating: data/classification/val/62/43281.jpg  \n","  inflating: data/classification/val/62/43306.jpg  \n","  inflating: data/classification/val/62/43309.jpg  \n","  inflating: data/classification/val/62/43313.jpg  \n","  inflating: data/classification/val/62/43325.jpg  \n","  inflating: data/classification/val/63/43352.jpg  \n","  inflating: data/classification/val/63/43362.jpg  \n","  inflating: data/classification/val/63/43383.jpg  \n","  inflating: data/classification/val/63/43387.jpg  \n","  inflating: data/classification/val/63/43392.jpg  \n","  inflating: data/classification/val/63/43401.jpg  \n","  inflating: data/classification/val/63/43410.jpg  \n","  inflating: data/classification/val/63/43414.jpg  \n","  inflating: data/classification/val/64/43417.jpg  \n","  inflating: data/classification/val/64/43470.jpg  \n","  inflating: data/classification/val/64/43476.jpg  \n","  inflating: data/classification/val/64/43489.jpg  \n","  inflating: data/classification/val/64/43491.jpg  \n","  inflating: data/classification/val/64/43492.jpg  \n","  inflating: data/classification/val/64/43500.jpg  \n","  inflating: data/classification/val/64/43510.jpg  \n","  inflating: data/classification/val/64/43521.jpg  \n","  inflating: data/classification/val/64/43523.jpg  \n","  inflating: data/classification/val/64/43534.jpg  \n","  inflating: data/classification/val/64/43536.jpg  \n","  inflating: data/classification/val/64/43548.jpg  \n","  inflating: data/classification/val/64/43563.jpg  \n","  inflating: data/classification/val/64/43575.jpg  \n","  inflating: data/classification/val/64/43590.jpg  \n","  inflating: data/classification/val/64/43617.jpg  \n","  inflating: data/classification/val/64/43618.jpg  \n","  inflating: data/classification/val/64/43621.jpg  \n","  inflating: data/classification/val/64/43649.jpg  \n","  inflating: data/classification/val/64/43650.jpg  \n","  inflating: data/classification/val/64/43661.jpg  \n","  inflating: data/classification/val/64/43670.jpg  \n","  inflating: data/classification/val/64/43671.jpg  \n","  inflating: data/classification/val/64/43690.jpg  \n","  inflating: data/classification/val/64/43691.jpg  \n","  inflating: data/classification/val/64/43693.jpg  \n","  inflating: data/classification/val/64/43694.jpg  \n","  inflating: data/classification/val/64/43695.jpg  \n","  inflating: data/classification/val/64/43697.jpg  \n","  inflating: data/classification/val/65/43730.jpg  \n","  inflating: data/classification/val/65/43735.jpg  \n","  inflating: data/classification/val/65/43742.jpg  \n","  inflating: data/classification/val/65/43743.jpg  \n","  inflating: data/classification/val/65/43744.jpg  \n","  inflating: data/classification/val/65/43755.jpg  \n","  inflating: data/classification/val/65/43756.jpg  \n","  inflating: data/classification/val/65/43760.jpg  \n","  inflating: data/classification/val/65/43774.jpg  \n","  inflating: data/classification/val/65/43778.jpg  \n","  inflating: data/classification/val/65/43796.jpg  \n","  inflating: data/classification/val/65/43814.jpg  \n","  inflating: data/classification/val/65/43837.jpg  \n","  inflating: data/classification/val/65/43858.jpg  \n","  inflating: data/classification/val/66/43865.jpg  \n","  inflating: data/classification/val/66/43869.jpg  \n","  inflating: data/classification/val/66/43878.jpg  \n","  inflating: data/classification/val/66/43880.jpg  \n","  inflating: data/classification/val/66/43881.jpg  \n","  inflating: data/classification/val/66/43885.jpg  \n","  inflating: data/classification/val/66/43895.jpg  \n","  inflating: data/classification/val/66/43896.jpg  \n","  inflating: data/classification/val/66/43898.jpg  \n","  inflating: data/classification/val/66/43899.jpg  \n","  inflating: data/classification/val/66/43902.jpg  \n","  inflating: data/classification/val/66/43914.jpg  \n","  inflating: data/classification/val/66/43918.jpg  \n","  inflating: data/classification/val/66/43924.jpg  \n","  inflating: data/classification/val/66/43943.jpg  \n","  inflating: data/classification/val/66/43952.jpg  \n","  inflating: data/classification/val/66/43971.jpg  \n","  inflating: data/classification/val/66/43972.jpg  \n","  inflating: data/classification/val/66/43981.jpg  \n","  inflating: data/classification/val/66/43985.jpg  \n","  inflating: data/classification/val/66/44022.jpg  \n","  inflating: data/classification/val/66/44028.jpg  \n","  inflating: data/classification/val/66/44029.jpg  \n","  inflating: data/classification/val/66/44037.jpg  \n","  inflating: data/classification/val/66/44044.jpg  \n","  inflating: data/classification/val/66/44048.jpg  \n","  inflating: data/classification/val/66/44054.jpg  \n","  inflating: data/classification/val/66/44056.jpg  \n","  inflating: data/classification/val/66/44069.jpg  \n","  inflating: data/classification/val/66/44073.jpg  \n","  inflating: data/classification/val/66/44084.jpg  \n","  inflating: data/classification/val/66/44101.jpg  \n","  inflating: data/classification/val/66/44118.jpg  \n","  inflating: data/classification/val/66/44122.jpg  \n","  inflating: data/classification/val/66/44135.jpg  \n","  inflating: data/classification/val/66/44137.jpg  \n","  inflating: data/classification/val/66/44148.jpg  \n","  inflating: data/classification/val/66/44149.jpg  \n","  inflating: data/classification/val/66/44152.jpg  \n","  inflating: data/classification/val/66/44161.jpg  \n","  inflating: data/classification/val/66/44174.jpg  \n","  inflating: data/classification/val/66/44180.jpg  \n","  inflating: data/classification/val/66/44182.jpg  \n","  inflating: data/classification/val/66/44190.jpg  \n","  inflating: data/classification/val/66/44200.jpg  \n","  inflating: data/classification/val/66/44209.jpg  \n","  inflating: data/classification/val/66/44214.jpg  \n","  inflating: data/classification/val/66/44227.jpg  \n","  inflating: data/classification/val/66/44230.jpg  \n","  inflating: data/classification/val/66/44231.jpg  \n","  inflating: data/classification/val/66/44245.jpg  \n","  inflating: data/classification/val/66/44249.jpg  \n","  inflating: data/classification/val/66/44255.jpg  \n","  inflating: data/classification/val/66/44280.jpg  \n","  inflating: data/classification/val/66/44294.jpg  \n","  inflating: data/classification/val/66/44301.jpg  \n","  inflating: data/classification/val/66/44302.jpg  \n","  inflating: data/classification/val/66/44317.jpg  \n","  inflating: data/classification/val/66/44319.jpg  \n","  inflating: data/classification/val/66/44339.jpg  \n","  inflating: data/classification/val/66/44342.jpg  \n","  inflating: data/classification/val/66/44363.jpg  \n","  inflating: data/classification/val/66/44382.jpg  \n","  inflating: data/classification/val/66/44387.jpg  \n","  inflating: data/classification/val/66/44409.jpg  \n","  inflating: data/classification/val/66/44505.jpg  \n","  inflating: data/classification/val/66/44516.jpg  \n","  inflating: data/classification/val/66/44521.jpg  \n","  inflating: data/classification/val/66/44528.jpg  \n","  inflating: data/classification/val/66/44529.jpg  \n","  inflating: data/classification/val/66/44545.jpg  \n","  inflating: data/classification/val/66/44551.jpg  \n","  inflating: data/classification/val/66/44588.jpg  \n","  inflating: data/classification/val/66/44597.jpg  \n","  inflating: data/classification/val/66/44614.jpg  \n","  inflating: data/classification/val/66/44623.jpg  \n","  inflating: data/classification/val/67/44642.jpg  \n","  inflating: data/classification/val/67/44651.jpg  \n","  inflating: data/classification/val/67/44654.jpg  \n","  inflating: data/classification/val/67/44668.jpg  \n","  inflating: data/classification/val/67/44673.jpg  \n","  inflating: data/classification/val/67/44679.jpg  \n","  inflating: data/classification/val/67/44684.jpg  \n","  inflating: data/classification/val/67/44687.jpg  \n","  inflating: data/classification/val/67/44696.jpg  \n","  inflating: data/classification/val/67/44732.jpg  \n","  inflating: data/classification/val/67/44735.jpg  \n","  inflating: data/classification/val/67/44742.jpg  \n","  inflating: data/classification/val/67/44746.jpg  \n","  inflating: data/classification/val/67/44748.jpg  \n","  inflating: data/classification/val/67/44752.jpg  \n","  inflating: data/classification/val/67/44755.jpg  \n","  inflating: data/classification/val/67/44774.jpg  \n","  inflating: data/classification/val/67/44785.jpg  \n","  inflating: data/classification/val/67/44789.jpg  \n","  inflating: data/classification/val/67/44790.jpg  \n","  inflating: data/classification/val/67/44791.jpg  \n","  inflating: data/classification/val/67/44811.jpg  \n","  inflating: data/classification/val/67/44815.jpg  \n","  inflating: data/classification/val/67/44821.jpg  \n","  inflating: data/classification/val/67/44853.jpg  \n","  inflating: data/classification/val/67/44859.jpg  \n","  inflating: data/classification/val/67/44873.jpg  \n","  inflating: data/classification/val/67/44891.jpg  \n","  inflating: data/classification/val/67/44896.jpg  \n","  inflating: data/classification/val/67/44917.jpg  \n","  inflating: data/classification/val/67/44923.jpg  \n","  inflating: data/classification/val/67/44925.jpg  \n","  inflating: data/classification/val/67/44929.jpg  \n","  inflating: data/classification/val/67/44936.jpg  \n","  inflating: data/classification/val/67/44940.jpg  \n","  inflating: data/classification/val/67/44954.jpg  \n","  inflating: data/classification/val/67/44965.jpg  \n","  inflating: data/classification/val/67/44966.jpg  \n","  inflating: data/classification/val/67/44977.jpg  \n","  inflating: data/classification/val/67/44981.jpg  \n","  inflating: data/classification/val/67/45008.jpg  \n","  inflating: data/classification/val/67/45015.jpg  \n","  inflating: data/classification/val/67/45037.jpg  \n","  inflating: data/classification/val/67/45048.jpg  \n","  inflating: data/classification/val/67/45049.jpg  \n","  inflating: data/classification/val/67/45068.jpg  \n","  inflating: data/classification/val/67/45073.jpg  \n","  inflating: data/classification/val/67/45075.jpg  \n","  inflating: data/classification/val/67/45100.jpg  \n","  inflating: data/classification/val/67/45109.jpg  \n","  inflating: data/classification/val/67/45118.jpg  \n","  inflating: data/classification/val/67/45144.jpg  \n","  inflating: data/classification/val/67/45145.jpg  \n","  inflating: data/classification/val/67/45147.jpg  \n","  inflating: data/classification/val/67/45155.jpg  \n","  inflating: data/classification/val/67/45175.jpg  \n","  inflating: data/classification/val/67/45176.jpg  \n","  inflating: data/classification/val/67/45193.jpg  \n","  inflating: data/classification/val/67/45194.jpg  \n","  inflating: data/classification/val/67/45218.jpg  \n","  inflating: data/classification/val/67/45232.jpg  \n","  inflating: data/classification/val/67/45235.jpg  \n","  inflating: data/classification/val/67/45245.jpg  \n","  inflating: data/classification/val/67/45248.jpg  \n","  inflating: data/classification/val/67/45261.jpg  \n","  inflating: data/classification/val/67/45263.jpg  \n","  inflating: data/classification/val/67/45264.jpg  \n","  inflating: data/classification/val/67/45288.jpg  \n","  inflating: data/classification/val/67/45297.jpg  \n","  inflating: data/classification/val/67/45307.jpg  \n","  inflating: data/classification/val/67/45309.jpg  \n","  inflating: data/classification/val/67/45332.jpg  \n","  inflating: data/classification/val/67/45335.jpg  \n","  inflating: data/classification/val/67/45337.jpg  \n","  inflating: data/classification/val/67/45354.jpg  \n","  inflating: data/classification/val/67/45362.jpg  \n","  inflating: data/classification/val/67/45377.jpg  \n","  inflating: data/classification/val/67/45387.jpg  \n","  inflating: data/classification/val/67/45391.jpg  \n","  inflating: data/classification/val/67/45410.jpg  \n","  inflating: data/classification/val/67/45435.jpg  \n","  inflating: data/classification/val/67/45443.jpg  \n","  inflating: data/classification/val/67/45450.jpg  \n","  inflating: data/classification/val/67/45456.jpg  \n","  inflating: data/classification/val/67/45480.jpg  \n","  inflating: data/classification/val/67/45509.jpg  \n","  inflating: data/classification/val/67/45514.jpg  \n","  inflating: data/classification/val/67/45521.jpg  \n","  inflating: data/classification/val/67/45524.jpg  \n","  inflating: data/classification/val/67/45525.jpg  \n","  inflating: data/classification/val/67/45533.jpg  \n","  inflating: data/classification/val/67/45542.jpg  \n","  inflating: data/classification/val/67/45545.jpg  \n","  inflating: data/classification/val/67/45546.jpg  \n","  inflating: data/classification/val/67/45590.jpg  \n","  inflating: data/classification/val/67/45595.jpg  \n","  inflating: data/classification/val/67/45643.jpg  \n","  inflating: data/classification/val/67/45648.jpg  \n","  inflating: data/classification/val/67/45657.jpg  \n","  inflating: data/classification/val/67/45660.jpg  \n","  inflating: data/classification/val/67/45677.jpg  \n","  inflating: data/classification/val/67/45712.jpg  \n","  inflating: data/classification/val/67/45724.jpg  \n","  inflating: data/classification/val/67/45732.jpg  \n","  inflating: data/classification/val/67/45735.jpg  \n","  inflating: data/classification/val/67/45751.jpg  \n","  inflating: data/classification/val/67/45758.jpg  \n","  inflating: data/classification/val/67/45768.jpg  \n","  inflating: data/classification/val/67/45771.jpg  \n","  inflating: data/classification/val/67/45789.jpg  \n","  inflating: data/classification/val/67/45798.jpg  \n","  inflating: data/classification/val/67/45799.jpg  \n","  inflating: data/classification/val/67/45816.jpg  \n","  inflating: data/classification/val/67/45818.jpg  \n","  inflating: data/classification/val/67/45835.jpg  \n","  inflating: data/classification/val/67/45839.jpg  \n","  inflating: data/classification/val/67/45842.jpg  \n","  inflating: data/classification/val/67/45847.jpg  \n","  inflating: data/classification/val/67/45852.jpg  \n","  inflating: data/classification/val/67/45854.jpg  \n","  inflating: data/classification/val/67/45858.jpg  \n","  inflating: data/classification/val/67/45861.jpg  \n","  inflating: data/classification/val/67/45864.jpg  \n","  inflating: data/classification/val/67/45867.jpg  \n","  inflating: data/classification/val/67/45868.jpg  \n","  inflating: data/classification/val/67/45875.jpg  \n","  inflating: data/classification/val/67/45885.jpg  \n","  inflating: data/classification/val/67/45906.jpg  \n","  inflating: data/classification/val/67/45909.jpg  \n","  inflating: data/classification/val/67/45913.jpg  \n","  inflating: data/classification/val/67/45919.jpg  \n","  inflating: data/classification/val/67/45921.jpg  \n","  inflating: data/classification/val/67/45924.jpg  \n","  inflating: data/classification/val/67/45950.jpg  \n","  inflating: data/classification/val/67/45966.jpg  \n","  inflating: data/classification/val/67/45984.jpg  \n","  inflating: data/classification/val/67/45992.jpg  \n","  inflating: data/classification/val/67/45993.jpg  \n","  inflating: data/classification/val/67/46013.jpg  \n","  inflating: data/classification/val/67/46043.jpg  \n","  inflating: data/classification/val/67/46046.jpg  \n","  inflating: data/classification/val/67/46056.jpg  \n","  inflating: data/classification/val/67/46060.jpg  \n","  inflating: data/classification/val/67/46061.jpg  \n","  inflating: data/classification/val/67/46073.jpg  \n","  inflating: data/classification/val/67/46098.jpg  \n","  inflating: data/classification/val/67/46106.jpg  \n","  inflating: data/classification/val/67/46118.jpg  \n","  inflating: data/classification/val/67/46121.jpg  \n","  inflating: data/classification/val/67/46123.jpg  \n","  inflating: data/classification/val/67/46129.jpg  \n","  inflating: data/classification/val/67/46133.jpg  \n","  inflating: data/classification/val/67/46141.jpg  \n","  inflating: data/classification/val/67/46166.jpg  \n","  inflating: data/classification/val/67/46172.jpg  \n","  inflating: data/classification/val/67/46181.jpg  \n","  inflating: data/classification/val/67/46196.jpg  \n","  inflating: data/classification/val/67/46205.jpg  \n","  inflating: data/classification/val/67/46208.jpg  \n","  inflating: data/classification/val/67/46213.jpg  \n","  inflating: data/classification/val/67/46215.jpg  \n","  inflating: data/classification/val/67/46246.jpg  \n","  inflating: data/classification/val/67/46270.jpg  \n","  inflating: data/classification/val/67/46271.jpg  \n","  inflating: data/classification/val/67/46279.jpg  \n","  inflating: data/classification/val/67/46280.jpg  \n","  inflating: data/classification/val/67/46281.jpg  \n","  inflating: data/classification/val/67/46284.jpg  \n","  inflating: data/classification/val/67/46288.jpg  \n","  inflating: data/classification/val/67/46297.jpg  \n","  inflating: data/classification/val/67/46301.jpg  \n","  inflating: data/classification/val/67/46303.jpg  \n","  inflating: data/classification/val/67/46326.jpg  \n","  inflating: data/classification/val/67/46335.jpg  \n","  inflating: data/classification/val/67/46346.jpg  \n","  inflating: data/classification/val/67/46350.jpg  \n","  inflating: data/classification/val/67/46356.jpg  \n","  inflating: data/classification/val/67/46358.jpg  \n","  inflating: data/classification/val/67/46374.jpg  \n","  inflating: data/classification/val/67/46382.jpg  \n","  inflating: data/classification/val/67/46388.jpg  \n","  inflating: data/classification/val/67/46393.jpg  \n","  inflating: data/classification/val/67/46407.jpg  \n","  inflating: data/classification/val/67/46411.jpg  \n","  inflating: data/classification/val/67/46412.jpg  \n","  inflating: data/classification/val/67/46422.jpg  \n","  inflating: data/classification/val/67/46441.jpg  \n","  inflating: data/classification/val/67/46450.jpg  \n","  inflating: data/classification/val/67/46451.jpg  \n","  inflating: data/classification/val/67/46460.jpg  \n","  inflating: data/classification/val/67/46461.jpg  \n","  inflating: data/classification/val/67/46463.jpg  \n","  inflating: data/classification/val/67/46491.jpg  \n","  inflating: data/classification/val/67/46519.jpg  \n","  inflating: data/classification/val/67/46530.jpg  \n","  inflating: data/classification/val/67/46553.jpg  \n","  inflating: data/classification/val/67/46567.jpg  \n","  inflating: data/classification/val/67/46573.jpg  \n","  inflating: data/classification/val/67/46579.jpg  \n","  inflating: data/classification/val/67/46596.jpg  \n","  inflating: data/classification/val/67/46604.jpg  \n","  inflating: data/classification/val/67/46605.jpg  \n","  inflating: data/classification/val/67/46616.jpg  \n","  inflating: data/classification/val/67/46633.jpg  \n","  inflating: data/classification/val/67/46636.jpg  \n","  inflating: data/classification/val/67/46643.jpg  \n","  inflating: data/classification/val/67/46678.jpg  \n","  inflating: data/classification/val/67/46689.jpg  \n","  inflating: data/classification/val/67/46691.jpg  \n","  inflating: data/classification/val/67/46698.jpg  \n","  inflating: data/classification/val/67/46720.jpg  \n","  inflating: data/classification/val/67/46730.jpg  \n","  inflating: data/classification/val/67/46731.jpg  \n","  inflating: data/classification/val/67/46736.jpg  \n","  inflating: data/classification/val/67/46753.jpg  \n","  inflating: data/classification/val/67/46759.jpg  \n","  inflating: data/classification/val/67/46763.jpg  \n","  inflating: data/classification/val/67/46770.jpg  \n","  inflating: data/classification/val/67/46774.jpg  \n","  inflating: data/classification/val/67/46776.jpg  \n","  inflating: data/classification/val/67/46777.jpg  \n","  inflating: data/classification/val/67/46780.jpg  \n","  inflating: data/classification/val/67/46781.jpg  \n","  inflating: data/classification/val/67/46791.jpg  \n","  inflating: data/classification/val/67/46797.jpg  \n","  inflating: data/classification/val/67/46814.jpg  \n","  inflating: data/classification/val/67/46821.jpg  \n","  inflating: data/classification/val/67/46826.jpg  \n","  inflating: data/classification/val/67/46844.jpg  \n","  inflating: data/classification/val/67/46850.jpg  \n","  inflating: data/classification/val/67/46856.jpg  \n","  inflating: data/classification/val/67/46860.jpg  \n","  inflating: data/classification/val/67/46868.jpg  \n","  inflating: data/classification/val/67/46872.jpg  \n","  inflating: data/classification/val/67/46874.jpg  \n","  inflating: data/classification/val/67/46875.jpg  \n","  inflating: data/classification/val/67/46881.jpg  \n","  inflating: data/classification/val/67/46884.jpg  \n","  inflating: data/classification/val/67/46912.jpg  \n","  inflating: data/classification/val/67/46931.jpg  \n","  inflating: data/classification/val/67/46943.jpg  \n","  inflating: data/classification/val/67/46953.jpg  \n","  inflating: data/classification/val/67/46954.jpg  \n","  inflating: data/classification/val/67/46964.jpg  \n","  inflating: data/classification/val/67/46976.jpg  \n","  inflating: data/classification/val/67/47021.jpg  \n","  inflating: data/classification/val/67/47040.jpg  \n","  inflating: data/classification/val/67/47055.jpg  \n","  inflating: data/classification/val/67/47066.jpg  \n","  inflating: data/classification/val/67/47067.jpg  \n","  inflating: data/classification/val/67/47079.jpg  \n","  inflating: data/classification/val/67/47104.jpg  \n","  inflating: data/classification/val/67/47105.jpg  \n","  inflating: data/classification/val/67/47132.jpg  \n","  inflating: data/classification/val/67/47135.jpg  \n","  inflating: data/classification/val/67/47156.jpg  \n","  inflating: data/classification/val/67/47159.jpg  \n","  inflating: data/classification/val/67/47163.jpg  \n","  inflating: data/classification/val/67/47178.jpg  \n","  inflating: data/classification/val/67/47184.jpg  \n","  inflating: data/classification/val/67/47187.jpg  \n","  inflating: data/classification/val/67/47196.jpg  \n","  inflating: data/classification/val/67/47205.jpg  \n","  inflating: data/classification/val/67/47209.jpg  \n","  inflating: data/classification/val/67/47231.jpg  \n","  inflating: data/classification/val/67/47244.jpg  \n","  inflating: data/classification/val/67/47250.jpg  \n","  inflating: data/classification/val/67/47254.jpg  \n","  inflating: data/classification/val/67/47268.jpg  \n","  inflating: data/classification/val/67/47284.jpg  \n","  inflating: data/classification/val/67/47290.jpg  \n","  inflating: data/classification/val/67/47294.jpg  \n","  inflating: data/classification/val/67/47298.jpg  \n","  inflating: data/classification/val/67/47309.jpg  \n","  inflating: data/classification/val/67/47311.jpg  \n","  inflating: data/classification/val/67/47313.jpg  \n","  inflating: data/classification/val/67/47314.jpg  \n","  inflating: data/classification/val/67/47317.jpg  \n","  inflating: data/classification/val/67/47327.jpg  \n","  inflating: data/classification/val/67/47334.jpg  \n","  inflating: data/classification/val/67/47342.jpg  \n","  inflating: data/classification/val/67/47354.jpg  \n","  inflating: data/classification/val/67/47357.jpg  \n","  inflating: data/classification/val/67/47378.jpg  \n","  inflating: data/classification/val/67/47380.jpg  \n","  inflating: data/classification/val/67/47388.jpg  \n","  inflating: data/classification/val/67/47404.jpg  \n","  inflating: data/classification/val/67/47459.jpg  \n","  inflating: data/classification/val/67/47480.jpg  \n","  inflating: data/classification/val/67/47508.jpg  \n","  inflating: data/classification/val/67/47517.jpg  \n","  inflating: data/classification/val/67/47538.jpg  \n","  inflating: data/classification/val/67/47543.jpg  \n","  inflating: data/classification/val/67/47551.jpg  \n","  inflating: data/classification/val/67/47553.jpg  \n","  inflating: data/classification/val/67/47579.jpg  \n","  inflating: data/classification/val/67/47600.jpg  \n","  inflating: data/classification/val/67/47608.jpg  \n","  inflating: data/classification/val/67/47618.jpg  \n","  inflating: data/classification/val/67/47620.jpg  \n","  inflating: data/classification/val/67/47636.jpg  \n","  inflating: data/classification/val/67/47645.jpg  \n","  inflating: data/classification/val/67/47648.jpg  \n","  inflating: data/classification/val/67/47655.jpg  \n","  inflating: data/classification/val/67/47685.jpg  \n","  inflating: data/classification/val/67/47690.jpg  \n","  inflating: data/classification/val/67/47700.jpg  \n","  inflating: data/classification/val/67/47710.jpg  \n","  inflating: data/classification/val/67/47726.jpg  \n","  inflating: data/classification/val/67/47744.jpg  \n","  inflating: data/classification/val/67/47745.jpg  \n","  inflating: data/classification/val/67/47746.jpg  \n","  inflating: data/classification/val/67/47750.jpg  \n","  inflating: data/classification/val/67/47751.jpg  \n","  inflating: data/classification/val/67/47759.jpg  \n","  inflating: data/classification/val/67/47767.jpg  \n","  inflating: data/classification/val/67/47788.jpg  \n","  inflating: data/classification/val/67/47789.jpg  \n","  inflating: data/classification/val/67/47793.jpg  \n","  inflating: data/classification/val/67/47829.jpg  \n","  inflating: data/classification/val/67/47840.jpg  \n","  inflating: data/classification/val/67/47854.jpg  \n","  inflating: data/classification/val/67/47863.jpg  \n","  inflating: data/classification/val/67/47864.jpg  \n","  inflating: data/classification/val/67/47891.jpg  \n","  inflating: data/classification/val/67/47900.jpg  \n","  inflating: data/classification/val/67/47915.jpg  \n","  inflating: data/classification/val/67/47926.jpg  \n","  inflating: data/classification/val/67/47928.jpg  \n","  inflating: data/classification/val/67/47932.jpg  \n","  inflating: data/classification/val/67/47938.jpg  \n","  inflating: data/classification/val/67/47940.jpg  \n","  inflating: data/classification/val/67/47952.jpg  \n","  inflating: data/classification/val/67/47955.jpg  \n","  inflating: data/classification/val/67/47963.jpg  \n","  inflating: data/classification/val/67/47968.jpg  \n","  inflating: data/classification/val/67/47969.jpg  \n","  inflating: data/classification/val/67/47978.jpg  \n","  inflating: data/classification/val/67/47980.jpg  \n","  inflating: data/classification/val/67/47983.jpg  \n","  inflating: data/classification/val/67/47988.jpg  \n","  inflating: data/classification/val/67/48000.jpg  \n","  inflating: data/classification/val/67/48017.jpg  \n","  inflating: data/classification/val/67/48028.jpg  \n","  inflating: data/classification/val/67/48037.jpg  \n","  inflating: data/classification/val/67/48044.jpg  \n","  inflating: data/classification/val/67/48048.jpg  \n","  inflating: data/classification/val/67/48062.jpg  \n","  inflating: data/classification/val/67/48088.jpg  \n","  inflating: data/classification/val/67/48090.jpg  \n","  inflating: data/classification/val/67/48095.jpg  \n","  inflating: data/classification/val/67/48108.jpg  \n","  inflating: data/classification/val/67/48115.jpg  \n","  inflating: data/classification/val/67/48124.jpg  \n","  inflating: data/classification/val/67/48130.jpg  \n","  inflating: data/classification/val/67/48132.jpg  \n","  inflating: data/classification/val/67/48135.jpg  \n","  inflating: data/classification/val/67/48150.jpg  \n","  inflating: data/classification/val/67/48173.jpg  \n","  inflating: data/classification/val/67/48176.jpg  \n","  inflating: data/classification/val/67/48195.jpg  \n","  inflating: data/classification/val/67/48206.jpg  \n","  inflating: data/classification/val/67/48212.jpg  \n","  inflating: data/classification/val/67/48214.jpg  \n","  inflating: data/classification/val/67/48216.jpg  \n","  inflating: data/classification/val/67/48229.jpg  \n","  inflating: data/classification/val/67/48240.jpg  \n","  inflating: data/classification/val/67/48243.jpg  \n","  inflating: data/classification/val/67/48251.jpg  \n","  inflating: data/classification/val/67/48264.jpg  \n","  inflating: data/classification/val/67/48265.jpg  \n","  inflating: data/classification/val/67/48270.jpg  \n","  inflating: data/classification/val/67/48272.jpg  \n","  inflating: data/classification/val/67/48280.jpg  \n","  inflating: data/classification/val/67/48291.jpg  \n","  inflating: data/classification/val/67/48307.jpg  \n","  inflating: data/classification/val/67/48324.jpg  \n","  inflating: data/classification/val/67/48325.jpg  \n","  inflating: data/classification/val/67/48328.jpg  \n","  inflating: data/classification/val/67/48332.jpg  \n","  inflating: data/classification/val/67/48334.jpg  \n","  inflating: data/classification/val/67/48342.jpg  \n","  inflating: data/classification/val/67/48364.jpg  \n","  inflating: data/classification/val/67/48377.jpg  \n","  inflating: data/classification/val/67/48384.jpg  \n","  inflating: data/classification/val/67/48392.jpg  \n","  inflating: data/classification/val/67/48396.jpg  \n","  inflating: data/classification/val/67/48398.jpg  \n","  inflating: data/classification/val/67/48400.jpg  \n","  inflating: data/classification/val/67/48401.jpg  \n","  inflating: data/classification/val/67/48418.jpg  \n","  inflating: data/classification/val/67/48422.jpg  \n","  inflating: data/classification/val/67/48424.jpg  \n","  inflating: data/classification/val/67/48426.jpg  \n","  inflating: data/classification/val/67/48435.jpg  \n","  inflating: data/classification/val/67/48445.jpg  \n","  inflating: data/classification/val/67/48454.jpg  \n","  inflating: data/classification/val/67/48458.jpg  \n","  inflating: data/classification/val/67/48462.jpg  \n","  inflating: data/classification/val/67/48464.jpg  \n","  inflating: data/classification/val/67/48467.jpg  \n","  inflating: data/classification/val/67/48475.jpg  \n","  inflating: data/classification/val/67/48485.jpg  \n","  inflating: data/classification/val/67/48497.jpg  \n","  inflating: data/classification/val/67/48498.jpg  \n","  inflating: data/classification/val/67/48505.jpg  \n","  inflating: data/classification/val/67/48537.jpg  \n","  inflating: data/classification/val/67/48539.jpg  \n","  inflating: data/classification/val/67/48547.jpg  \n","  inflating: data/classification/val/67/48565.jpg  \n","  inflating: data/classification/val/67/48570.jpg  \n","  inflating: data/classification/val/67/48578.jpg  \n","  inflating: data/classification/val/67/48579.jpg  \n","  inflating: data/classification/val/67/48581.jpg  \n","  inflating: data/classification/val/67/48587.jpg  \n","  inflating: data/classification/val/67/48599.jpg  \n","  inflating: data/classification/val/67/48612.jpg  \n","  inflating: data/classification/val/67/48637.jpg  \n","  inflating: data/classification/val/67/48648.jpg  \n","  inflating: data/classification/val/67/48658.jpg  \n","  inflating: data/classification/val/67/48666.jpg  \n","  inflating: data/classification/val/67/48683.jpg  \n","  inflating: data/classification/val/67/48684.jpg  \n","  inflating: data/classification/val/67/48714.jpg  \n","  inflating: data/classification/val/67/48718.jpg  \n","  inflating: data/classification/val/67/48720.jpg  \n","  inflating: data/classification/val/67/48721.jpg  \n","  inflating: data/classification/val/67/48726.jpg  \n","  inflating: data/classification/val/67/48732.jpg  \n","  inflating: data/classification/val/67/48734.jpg  \n","  inflating: data/classification/val/67/48741.jpg  \n","  inflating: data/classification/val/67/48751.jpg  \n","  inflating: data/classification/val/67/48753.jpg  \n","  inflating: data/classification/val/67/48755.jpg  \n","  inflating: data/classification/val/67/48762.jpg  \n","  inflating: data/classification/val/67/48767.jpg  \n","  inflating: data/classification/val/67/48768.jpg  \n","  inflating: data/classification/val/67/48779.jpg  \n","  inflating: data/classification/val/67/48781.jpg  \n","  inflating: data/classification/val/67/48784.jpg  \n","  inflating: data/classification/val/67/48785.jpg  \n","  inflating: data/classification/val/67/48788.jpg  \n","  inflating: data/classification/val/67/48809.jpg  \n","  inflating: data/classification/val/67/48839.jpg  \n","  inflating: data/classification/val/67/48840.jpg  \n","  inflating: data/classification/val/67/48848.jpg  \n","  inflating: data/classification/val/67/48854.jpg  \n","  inflating: data/classification/val/67/48862.jpg  \n","  inflating: data/classification/val/67/48865.jpg  \n","  inflating: data/classification/val/67/48867.jpg  \n","  inflating: data/classification/val/67/48875.jpg  \n","  inflating: data/classification/val/67/48886.jpg  \n","  inflating: data/classification/val/67/48894.jpg  \n","  inflating: data/classification/val/67/48896.jpg  \n","  inflating: data/classification/val/67/48915.jpg  \n","  inflating: data/classification/val/67/48926.jpg  \n","  inflating: data/classification/val/67/48934.jpg  \n","  inflating: data/classification/val/67/48935.jpg  \n","  inflating: data/classification/val/67/48939.jpg  \n","  inflating: data/classification/val/67/48968.jpg  \n","  inflating: data/classification/val/67/48976.jpg  \n","  inflating: data/classification/val/67/48989.jpg  \n","  inflating: data/classification/val/67/49000.jpg  \n","  inflating: data/classification/val/67/49055.jpg  \n","  inflating: data/classification/val/67/49057.jpg  \n","  inflating: data/classification/val/67/49076.jpg  \n","  inflating: data/classification/val/67/49078.jpg  \n","  inflating: data/classification/val/67/49093.jpg  \n","  inflating: data/classification/val/67/49121.jpg  \n","  inflating: data/classification/val/67/49125.jpg  \n","  inflating: data/classification/val/67/49135.jpg  \n","  inflating: data/classification/val/67/49137.jpg  \n","  inflating: data/classification/val/67/49142.jpg  \n","  inflating: data/classification/val/67/49150.jpg  \n","  inflating: data/classification/val/67/49155.jpg  \n","  inflating: data/classification/val/67/49166.jpg  \n","  inflating: data/classification/val/67/49185.jpg  \n","  inflating: data/classification/val/67/49193.jpg  \n","  inflating: data/classification/val/67/49197.jpg  \n","  inflating: data/classification/val/67/49205.jpg  \n","  inflating: data/classification/val/67/49208.jpg  \n","  inflating: data/classification/val/67/49214.jpg  \n","  inflating: data/classification/val/67/49216.jpg  \n","  inflating: data/classification/val/67/49240.jpg  \n","  inflating: data/classification/val/67/49244.jpg  \n","  inflating: data/classification/val/67/49247.jpg  \n","  inflating: data/classification/val/67/49255.jpg  \n","  inflating: data/classification/val/67/49273.jpg  \n","  inflating: data/classification/val/67/49293.jpg  \n","  inflating: data/classification/val/67/49307.jpg  \n","  inflating: data/classification/val/67/49339.jpg  \n","  inflating: data/classification/val/67/49353.jpg  \n","  inflating: data/classification/val/67/49354.jpg  \n","  inflating: data/classification/val/67/49364.jpg  \n","  inflating: data/classification/val/67/49400.jpg  \n","  inflating: data/classification/val/67/49403.jpg  \n","  inflating: data/classification/val/67/49428.jpg  \n","  inflating: data/classification/val/67/49430.jpg  \n","  inflating: data/classification/val/67/49435.jpg  \n","  inflating: data/classification/val/67/49465.jpg  \n","  inflating: data/classification/val/67/49467.jpg  \n","  inflating: data/classification/val/67/49482.jpg  \n","  inflating: data/classification/val/67/49483.jpg  \n","  inflating: data/classification/val/67/49486.jpg  \n","  inflating: data/classification/val/67/49514.jpg  \n","  inflating: data/classification/val/67/49521.jpg  \n","  inflating: data/classification/val/67/49553.jpg  \n","  inflating: data/classification/val/67/49557.jpg  \n","  inflating: data/classification/val/67/49579.jpg  \n","  inflating: data/classification/val/67/49594.jpg  \n","  inflating: data/classification/val/67/49608.jpg  \n","  inflating: data/classification/val/67/49626.jpg  \n","  inflating: data/classification/val/67/49633.jpg  \n","  inflating: data/classification/val/67/49643.jpg  \n","  inflating: data/classification/val/67/49653.jpg  \n","  inflating: data/classification/val/67/49654.jpg  \n","  inflating: data/classification/val/67/49709.jpg  \n","  inflating: data/classification/val/67/49726.jpg  \n","  inflating: data/classification/val/67/49729.jpg  \n","  inflating: data/classification/val/67/49765.jpg  \n","  inflating: data/classification/val/67/49774.jpg  \n","  inflating: data/classification/val/67/49790.jpg  \n","  inflating: data/classification/val/67/49794.jpg  \n","  inflating: data/classification/val/67/49799.jpg  \n","  inflating: data/classification/val/67/49836.jpg  \n","  inflating: data/classification/val/67/49837.jpg  \n","  inflating: data/classification/val/67/49840.jpg  \n","  inflating: data/classification/val/67/49850.jpg  \n","  inflating: data/classification/val/67/49860.jpg  \n","  inflating: data/classification/val/67/49900.jpg  \n","  inflating: data/classification/val/68/49958.jpg  \n","  inflating: data/classification/val/68/49962.jpg  \n","  inflating: data/classification/val/68/49963.jpg  \n","  inflating: data/classification/val/68/49973.jpg  \n","  inflating: data/classification/val/68/49976.jpg  \n","  inflating: data/classification/val/68/49999.jpg  \n","  inflating: data/classification/val/68/50002.jpg  \n","  inflating: data/classification/val/68/50022.jpg  \n","  inflating: data/classification/val/68/50023.jpg  \n","  inflating: data/classification/val/68/50035.jpg  \n","  inflating: data/classification/val/68/50060.jpg  \n","  inflating: data/classification/val/68/50086.jpg  \n","  inflating: data/classification/val/68/50109.jpg  \n","  inflating: data/classification/val/68/50113.jpg  \n","  inflating: data/classification/val/68/50123.jpg  \n","  inflating: data/classification/val/68/50134.jpg  \n","  inflating: data/classification/val/68/50136.jpg  \n","  inflating: data/classification/val/68/50142.jpg  \n","  inflating: data/classification/val/68/50153.jpg  \n","  inflating: data/classification/val/68/50180.jpg  \n","  inflating: data/classification/val/68/50201.jpg  \n","  inflating: data/classification/val/68/50206.jpg  \n","  inflating: data/classification/val/68/50236.jpg  \n","  inflating: data/classification/val/68/50242.jpg  \n","  inflating: data/classification/val/68/50251.jpg  \n","  inflating: data/classification/val/68/50264.jpg  \n","  inflating: data/classification/val/68/50298.jpg  \n","  inflating: data/classification/val/68/50305.jpg  \n","  inflating: data/classification/val/68/50308.jpg  \n","  inflating: data/classification/val/68/50314.jpg  \n","  inflating: data/classification/val/68/50362.jpg  \n","  inflating: data/classification/val/68/50370.jpg  \n","  inflating: data/classification/val/68/50390.jpg  \n","  inflating: data/classification/val/68/50391.jpg  \n","  inflating: data/classification/val/68/50395.jpg  \n","  inflating: data/classification/val/68/50398.jpg  \n","  inflating: data/classification/val/68/50410.jpg  \n","  inflating: data/classification/val/68/50433.jpg  \n","  inflating: data/classification/val/68/50440.jpg  \n","  inflating: data/classification/val/68/50472.jpg  \n","  inflating: data/classification/val/68/50474.jpg  \n","  inflating: data/classification/val/68/50483.jpg  \n","  inflating: data/classification/val/68/50487.jpg  \n","  inflating: data/classification/val/68/50490.jpg  \n","  inflating: data/classification/val/68/50527.jpg  \n","  inflating: data/classification/val/68/50544.jpg  \n","  inflating: data/classification/val/68/50546.jpg  \n","  inflating: data/classification/val/68/50583.jpg  \n","  inflating: data/classification/val/68/50587.jpg  \n","  inflating: data/classification/val/68/50594.jpg  \n","  inflating: data/classification/val/68/50599.jpg  \n","  inflating: data/classification/val/68/50620.jpg  \n","  inflating: data/classification/val/68/50640.jpg  \n","  inflating: data/classification/val/68/50644.jpg  \n","  inflating: data/classification/val/68/50671.jpg  \n","  inflating: data/classification/val/68/50679.jpg  \n","  inflating: data/classification/val/68/50688.jpg  \n","  inflating: data/classification/val/68/50711.jpg  \n","  inflating: data/classification/val/68/50715.jpg  \n","  inflating: data/classification/val/68/50723.jpg  \n","  inflating: data/classification/val/68/50725.jpg  \n","  inflating: data/classification/val/68/50726.jpg  \n","  inflating: data/classification/val/68/50748.jpg  \n","  inflating: data/classification/val/68/50749.jpg  \n","  inflating: data/classification/val/68/50754.jpg  \n","  inflating: data/classification/val/68/50759.jpg  \n","  inflating: data/classification/val/68/50762.jpg  \n","  inflating: data/classification/val/68/50764.jpg  \n","  inflating: data/classification/val/68/50804.jpg  \n","  inflating: data/classification/val/68/50806.jpg  \n","  inflating: data/classification/val/68/50813.jpg  \n","  inflating: data/classification/val/68/50823.jpg  \n","  inflating: data/classification/val/68/50824.jpg  \n","  inflating: data/classification/val/68/50825.jpg  \n","  inflating: data/classification/val/68/50827.jpg  \n","  inflating: data/classification/val/68/50828.jpg  \n","  inflating: data/classification/val/68/50829.jpg  \n","  inflating: data/classification/val/68/50830.jpg  \n","  inflating: data/classification/val/68/50842.jpg  \n","  inflating: data/classification/val/68/50847.jpg  \n","  inflating: data/classification/val/68/50859.jpg  \n","  inflating: data/classification/val/68/50862.jpg  \n","  inflating: data/classification/val/68/50863.jpg  \n","  inflating: data/classification/val/68/50865.jpg  \n","  inflating: data/classification/val/68/50871.jpg  \n","  inflating: data/classification/val/68/50879.jpg  \n","  inflating: data/classification/val/68/50892.jpg  \n","  inflating: data/classification/val/68/50895.jpg  \n","  inflating: data/classification/val/68/50901.jpg  \n","  inflating: data/classification/val/68/50910.jpg  \n","  inflating: data/classification/val/68/50929.jpg  \n","  inflating: data/classification/val/68/50931.jpg  \n","  inflating: data/classification/val/68/50939.jpg  \n","  inflating: data/classification/val/68/50948.jpg  \n","  inflating: data/classification/val/68/50949.jpg  \n","  inflating: data/classification/val/68/50956.jpg  \n","  inflating: data/classification/val/68/50967.jpg  \n","  inflating: data/classification/val/68/50973.jpg  \n","  inflating: data/classification/val/68/50999.jpg  \n","  inflating: data/classification/val/68/51005.jpg  \n","  inflating: data/classification/val/68/51007.jpg  \n","  inflating: data/classification/val/68/51012.jpg  \n","  inflating: data/classification/val/68/51015.jpg  \n","  inflating: data/classification/val/68/51026.jpg  \n","  inflating: data/classification/val/68/51027.jpg  \n","  inflating: data/classification/val/68/51029.jpg  \n","  inflating: data/classification/val/68/51036.jpg  \n","  inflating: data/classification/val/68/51042.jpg  \n","  inflating: data/classification/val/68/51047.jpg  \n","  inflating: data/classification/val/68/51054.jpg  \n","  inflating: data/classification/val/68/51063.jpg  \n","  inflating: data/classification/val/68/51073.jpg  \n","  inflating: data/classification/val/68/51081.jpg  \n","  inflating: data/classification/val/68/51082.jpg  \n","  inflating: data/classification/val/68/51086.jpg  \n","  inflating: data/classification/val/69/51139.jpg  \n","  inflating: data/classification/val/69/51142.jpg  \n","  inflating: data/classification/val/69/51149.jpg  \n","  inflating: data/classification/val/69/51152.jpg  \n","  inflating: data/classification/val/69/51163.jpg  \n","  inflating: data/classification/val/69/51164.jpg  \n","  inflating: data/classification/val/69/51180.jpg  \n","  inflating: data/classification/val/69/51229.jpg  \n","  inflating: data/classification/val/69/51241.jpg  \n","  inflating: data/classification/val/69/51249.jpg  \n","  inflating: data/classification/val/69/51253.jpg  \n","  inflating: data/classification/val/69/51263.jpg  \n","  inflating: data/classification/val/69/51270.jpg  \n","  inflating: data/classification/val/69/51279.jpg  \n","  inflating: data/classification/val/69/51288.jpg  \n","  inflating: data/classification/val/69/51307.jpg  \n","  inflating: data/classification/val/69/51330.jpg  \n","  inflating: data/classification/val/69/51332.jpg  \n","  inflating: data/classification/val/69/51335.jpg  \n","  inflating: data/classification/val/69/51343.jpg  \n","  inflating: data/classification/val/69/51344.jpg  \n","  inflating: data/classification/val/69/51366.jpg  \n","  inflating: data/classification/val/69/51380.jpg  \n","  inflating: data/classification/val/69/51387.jpg  \n","  inflating: data/classification/val/69/51390.jpg  \n","  inflating: data/classification/val/69/51407.jpg  \n","  inflating: data/classification/val/69/51410.jpg  \n","  inflating: data/classification/val/69/51414.jpg  \n","  inflating: data/classification/val/69/51422.jpg  \n","  inflating: data/classification/val/69/51424.jpg  \n","  inflating: data/classification/val/69/51440.jpg  \n","  inflating: data/classification/val/69/51450.jpg  \n","  inflating: data/classification/val/69/51459.jpg  \n","  inflating: data/classification/val/69/51470.jpg  \n","  inflating: data/classification/val/69/51478.jpg  \n","  inflating: data/classification/val/69/51487.jpg  \n","  inflating: data/classification/val/69/51499.jpg  \n","  inflating: data/classification/val/69/51508.jpg  \n","  inflating: data/classification/val/69/51510.jpg  \n","  inflating: data/classification/val/69/51538.jpg  \n","  inflating: data/classification/val/69/51542.jpg  \n","  inflating: data/classification/val/69/51543.jpg  \n","  inflating: data/classification/val/69/51554.jpg  \n","  inflating: data/classification/val/69/51574.jpg  \n","  inflating: data/classification/val/69/51582.jpg  \n","  inflating: data/classification/val/69/51589.jpg  \n","  inflating: data/classification/val/69/51598.jpg  \n","  inflating: data/classification/val/69/51599.jpg  \n","  inflating: data/classification/val/69/51605.jpg  \n","  inflating: data/classification/val/69/51606.jpg  \n","  inflating: data/classification/val/69/51617.jpg  \n","  inflating: data/classification/val/69/51652.jpg  \n","  inflating: data/classification/val/69/51653.jpg  \n","  inflating: data/classification/val/69/51695.jpg  \n","  inflating: data/classification/val/69/51701.jpg  \n","  inflating: data/classification/val/69/51702.jpg  \n","  inflating: data/classification/val/69/51705.jpg  \n","  inflating: data/classification/val/69/51748.jpg  \n","  inflating: data/classification/val/69/51749.jpg  \n","  inflating: data/classification/val/69/51750.jpg  \n","  inflating: data/classification/val/69/51759.jpg  \n","  inflating: data/classification/val/69/51776.jpg  \n","  inflating: data/classification/val/69/51784.jpg  \n","  inflating: data/classification/val/69/51789.jpg  \n","  inflating: data/classification/val/69/51792.jpg  \n","  inflating: data/classification/val/69/51793.jpg  \n","  inflating: data/classification/val/69/51814.jpg  \n","  inflating: data/classification/val/69/51817.jpg  \n","  inflating: data/classification/val/69/51824.jpg  \n","  inflating: data/classification/val/69/51835.jpg  \n","  inflating: data/classification/val/69/51837.jpg  \n","  inflating: data/classification/val/69/51838.jpg  \n","  inflating: data/classification/val/69/51839.jpg  \n","  inflating: data/classification/val/69/51842.jpg  \n","  inflating: data/classification/val/69/51845.jpg  \n","  inflating: data/classification/val/69/51851.jpg  \n","  inflating: data/classification/val/69/51880.jpg  \n","  inflating: data/classification/val/69/51887.jpg  \n","  inflating: data/classification/val/69/51890.jpg  \n","  inflating: data/classification/val/69/51897.jpg  \n","  inflating: data/classification/val/69/51900.jpg  \n","  inflating: data/classification/val/69/51916.jpg  \n","  inflating: data/classification/val/69/51921.jpg  \n","  inflating: data/classification/val/69/51932.jpg  \n","  inflating: data/classification/val/69/51933.jpg  \n","  inflating: data/classification/val/69/51948.jpg  \n","  inflating: data/classification/val/69/51951.jpg  \n","  inflating: data/classification/val/69/51955.jpg  \n","  inflating: data/classification/val/69/51958.jpg  \n","  inflating: data/classification/val/69/51963.jpg  \n","  inflating: data/classification/val/69/51970.jpg  \n","  inflating: data/classification/val/69/51982.jpg  \n","  inflating: data/classification/val/69/51984.jpg  \n","  inflating: data/classification/val/69/52008.jpg  \n","  inflating: data/classification/val/69/52018.jpg  \n","  inflating: data/classification/val/69/52023.jpg  \n","  inflating: data/classification/val/69/52059.jpg  \n","  inflating: data/classification/val/69/52060.jpg  \n","  inflating: data/classification/val/69/52092.jpg  \n","  inflating: data/classification/val/69/52115.jpg  \n","  inflating: data/classification/val/69/52129.jpg  \n","  inflating: data/classification/val/69/52133.jpg  \n","  inflating: data/classification/val/69/52156.jpg  \n","  inflating: data/classification/val/69/52160.jpg  \n","  inflating: data/classification/val/69/52172.jpg  \n","  inflating: data/classification/val/69/52174.jpg  \n","  inflating: data/classification/val/69/52183.jpg  \n","  inflating: data/classification/val/69/52214.jpg  \n","  inflating: data/classification/val/69/52232.jpg  \n","  inflating: data/classification/val/69/52235.jpg  \n","  inflating: data/classification/val/69/52236.jpg  \n","  inflating: data/classification/val/69/52246.jpg  \n","  inflating: data/classification/val/69/52260.jpg  \n","  inflating: data/classification/val/69/52267.jpg  \n","  inflating: data/classification/val/69/52272.jpg  \n","  inflating: data/classification/val/69/52276.jpg  \n","  inflating: data/classification/val/69/52294.jpg  \n","  inflating: data/classification/val/69/52296.jpg  \n","  inflating: data/classification/val/69/52313.jpg  \n","  inflating: data/classification/val/69/52314.jpg  \n","  inflating: data/classification/val/69/52319.jpg  \n","  inflating: data/classification/val/69/52328.jpg  \n","  inflating: data/classification/val/69/52330.jpg  \n","  inflating: data/classification/val/69/52340.jpg  \n","  inflating: data/classification/val/69/52348.jpg  \n","  inflating: data/classification/val/69/52349.jpg  \n","  inflating: data/classification/val/69/52352.jpg  \n","  inflating: data/classification/val/69/52356.jpg  \n","  inflating: data/classification/val/7/04298.jpg  \n","  inflating: data/classification/val/7/04332.jpg  \n","  inflating: data/classification/val/7/04335.jpg  \n","  inflating: data/classification/val/7/04339.jpg  \n","  inflating: data/classification/val/7/04348.jpg  \n","  inflating: data/classification/val/7/04357.jpg  \n","  inflating: data/classification/val/7/04368.jpg  \n","  inflating: data/classification/val/7/04394.jpg  \n","  inflating: data/classification/val/7/04395.jpg  \n","  inflating: data/classification/val/7/04411.jpg  \n","  inflating: data/classification/val/7/04422.jpg  \n","  inflating: data/classification/val/7/04430.jpg  \n","  inflating: data/classification/val/7/04436.jpg  \n","  inflating: data/classification/val/7/04453.jpg  \n","  inflating: data/classification/val/7/04457.jpg  \n","  inflating: data/classification/val/7/04463.jpg  \n","  inflating: data/classification/val/7/04470.jpg  \n","  inflating: data/classification/val/7/04480.jpg  \n","  inflating: data/classification/val/7/04485.jpg  \n","  inflating: data/classification/val/7/04489.jpg  \n","  inflating: data/classification/val/7/04490.jpg  \n","  inflating: data/classification/val/7/04492.jpg  \n","  inflating: data/classification/val/7/04497.jpg  \n","  inflating: data/classification/val/7/04521.jpg  \n","  inflating: data/classification/val/7/04522.jpg  \n","  inflating: data/classification/val/7/04552.jpg  \n","  inflating: data/classification/val/7/04554.jpg  \n","  inflating: data/classification/val/7/04555.jpg  \n","  inflating: data/classification/val/7/04561.jpg  \n","  inflating: data/classification/val/7/04570.jpg  \n","  inflating: data/classification/val/7/04571.jpg  \n","  inflating: data/classification/val/7/04578.jpg  \n","  inflating: data/classification/val/7/04586.jpg  \n","  inflating: data/classification/val/7/04588.jpg  \n","  inflating: data/classification/val/7/04600.jpg  \n","  inflating: data/classification/val/7/04604.jpg  \n","  inflating: data/classification/val/7/04650.jpg  \n","  inflating: data/classification/val/7/04651.jpg  \n","  inflating: data/classification/val/7/04688.jpg  \n","  inflating: data/classification/val/7/04692.jpg  \n","  inflating: data/classification/val/7/04697.jpg  \n","  inflating: data/classification/val/7/04709.jpg  \n","  inflating: data/classification/val/7/04721.jpg  \n","  inflating: data/classification/val/7/04738.jpg  \n","  inflating: data/classification/val/7/04743.jpg  \n","  inflating: data/classification/val/7/04751.jpg  \n","  inflating: data/classification/val/7/04754.jpg  \n","  inflating: data/classification/val/7/04759.jpg  \n","  inflating: data/classification/val/7/04772.jpg  \n","  inflating: data/classification/val/7/04773.jpg  \n","  inflating: data/classification/val/7/04784.jpg  \n","  inflating: data/classification/val/7/04789.jpg  \n","  inflating: data/classification/val/7/04799.jpg  \n","  inflating: data/classification/val/7/04831.jpg  \n","  inflating: data/classification/val/7/04838.jpg  \n","  inflating: data/classification/val/7/04851.jpg  \n","  inflating: data/classification/val/7/04862.jpg  \n","  inflating: data/classification/val/7/04877.jpg  \n","  inflating: data/classification/val/7/04901.jpg  \n","  inflating: data/classification/val/7/04913.jpg  \n","  inflating: data/classification/val/7/04927.jpg  \n","  inflating: data/classification/val/7/04928.jpg  \n","  inflating: data/classification/val/7/04929.jpg  \n","  inflating: data/classification/val/7/04936.jpg  \n","  inflating: data/classification/val/7/04937.jpg  \n","  inflating: data/classification/val/7/04978.jpg  \n","  inflating: data/classification/val/7/04979.jpg  \n","  inflating: data/classification/val/7/04982.jpg  \n","  inflating: data/classification/val/7/04984.jpg  \n","  inflating: data/classification/val/7/04990.jpg  \n","  inflating: data/classification/val/7/04997.jpg  \n","  inflating: data/classification/val/7/05003.jpg  \n","  inflating: data/classification/val/7/05019.jpg  \n","  inflating: data/classification/val/7/05020.jpg  \n","  inflating: data/classification/val/7/05035.jpg  \n","  inflating: data/classification/val/7/05038.jpg  \n","  inflating: data/classification/val/7/05044.jpg  \n","  inflating: data/classification/val/7/05071.jpg  \n","  inflating: data/classification/val/7/05072.jpg  \n","  inflating: data/classification/val/7/05090.jpg  \n","  inflating: data/classification/val/7/05096.jpg  \n","  inflating: data/classification/val/7/05102.jpg  \n","  inflating: data/classification/val/7/05116.jpg  \n","  inflating: data/classification/val/70/52378.jpg  \n","  inflating: data/classification/val/70/52390.jpg  \n","  inflating: data/classification/val/70/52402.jpg  \n","  inflating: data/classification/val/70/52431.jpg  \n","  inflating: data/classification/val/70/52454.jpg  \n","  inflating: data/classification/val/70/52456.jpg  \n","  inflating: data/classification/val/70/52462.jpg  \n","  inflating: data/classification/val/70/52473.jpg  \n","  inflating: data/classification/val/70/52477.jpg  \n","  inflating: data/classification/val/70/52502.jpg  \n","  inflating: data/classification/val/70/52525.jpg  \n","  inflating: data/classification/val/70/52531.jpg  \n","  inflating: data/classification/val/70/52536.jpg  \n","  inflating: data/classification/val/70/52619.jpg  \n","  inflating: data/classification/val/70/52621.jpg  \n","  inflating: data/classification/val/70/52625.jpg  \n","  inflating: data/classification/val/70/52636.jpg  \n","  inflating: data/classification/val/70/52644.jpg  \n","  inflating: data/classification/val/70/52651.jpg  \n","  inflating: data/classification/val/70/52673.jpg  \n","  inflating: data/classification/val/70/52675.jpg  \n","  inflating: data/classification/val/70/52676.jpg  \n","  inflating: data/classification/val/70/52682.jpg  \n","  inflating: data/classification/val/70/52683.jpg  \n","  inflating: data/classification/val/70/52684.jpg  \n","  inflating: data/classification/val/70/52709.jpg  \n","  inflating: data/classification/val/70/52720.jpg  \n","  inflating: data/classification/val/70/52732.jpg  \n","  inflating: data/classification/val/70/52747.jpg  \n","  inflating: data/classification/val/70/52756.jpg  \n","  inflating: data/classification/val/70/52774.jpg  \n","  inflating: data/classification/val/70/52783.jpg  \n","  inflating: data/classification/val/70/52802.jpg  \n","  inflating: data/classification/val/70/52809.jpg  \n","  inflating: data/classification/val/70/52821.jpg  \n","  inflating: data/classification/val/70/52840.jpg  \n","  inflating: data/classification/val/70/52842.jpg  \n","  inflating: data/classification/val/70/52853.jpg  \n","  inflating: data/classification/val/70/52854.jpg  \n","  inflating: data/classification/val/70/52866.jpg  \n","  inflating: data/classification/val/70/52868.jpg  \n","  inflating: data/classification/val/70/52870.jpg  \n","  inflating: data/classification/val/70/52877.jpg  \n","  inflating: data/classification/val/70/52878.jpg  \n","  inflating: data/classification/val/70/52883.jpg  \n","  inflating: data/classification/val/70/52889.jpg  \n","  inflating: data/classification/val/70/52898.jpg  \n","  inflating: data/classification/val/70/52902.jpg  \n","  inflating: data/classification/val/70/52912.jpg  \n","  inflating: data/classification/val/70/52913.jpg  \n","  inflating: data/classification/val/70/52921.jpg  \n","  inflating: data/classification/val/70/52955.jpg  \n","  inflating: data/classification/val/70/52956.jpg  \n","  inflating: data/classification/val/70/52958.jpg  \n","  inflating: data/classification/val/70/52964.jpg  \n","  inflating: data/classification/val/70/52976.jpg  \n","  inflating: data/classification/val/70/52986.jpg  \n","  inflating: data/classification/val/70/52990.jpg  \n","  inflating: data/classification/val/70/52994.jpg  \n","  inflating: data/classification/val/70/53012.jpg  \n","  inflating: data/classification/val/70/53016.jpg  \n","  inflating: data/classification/val/70/53023.jpg  \n","  inflating: data/classification/val/70/53057.jpg  \n","  inflating: data/classification/val/70/53067.jpg  \n","  inflating: data/classification/val/70/53069.jpg  \n","  inflating: data/classification/val/70/53074.jpg  \n","  inflating: data/classification/val/70/53076.jpg  \n","  inflating: data/classification/val/70/53092.jpg  \n","  inflating: data/classification/val/70/53098.jpg  \n","  inflating: data/classification/val/70/53129.jpg  \n","  inflating: data/classification/val/70/53135.jpg  \n","  inflating: data/classification/val/70/53137.jpg  \n","  inflating: data/classification/val/70/53141.jpg  \n","  inflating: data/classification/val/70/53153.jpg  \n","  inflating: data/classification/val/70/53165.jpg  \n","  inflating: data/classification/val/70/53169.jpg  \n","  inflating: data/classification/val/70/53209.jpg  \n","  inflating: data/classification/val/70/53229.jpg  \n","  inflating: data/classification/val/70/53230.jpg  \n","  inflating: data/classification/val/70/53251.jpg  \n","  inflating: data/classification/val/70/53269.jpg  \n","  inflating: data/classification/val/70/53316.jpg  \n","  inflating: data/classification/val/70/53319.jpg  \n","  inflating: data/classification/val/70/53321.jpg  \n","  inflating: data/classification/val/70/53323.jpg  \n","  inflating: data/classification/val/70/53324.jpg  \n","  inflating: data/classification/val/70/53327.jpg  \n","  inflating: data/classification/val/70/53339.jpg  \n","  inflating: data/classification/val/70/53352.jpg  \n","  inflating: data/classification/val/70/53354.jpg  \n","  inflating: data/classification/val/70/53356.jpg  \n","  inflating: data/classification/val/70/53357.jpg  \n","  inflating: data/classification/val/70/53369.jpg  \n","  inflating: data/classification/val/70/53370.jpg  \n","  inflating: data/classification/val/70/53382.jpg  \n","  inflating: data/classification/val/70/53383.jpg  \n","  inflating: data/classification/val/70/53384.jpg  \n","  inflating: data/classification/val/70/53427.jpg  \n","  inflating: data/classification/val/70/53453.jpg  \n","  inflating: data/classification/val/70/53462.jpg  \n","  inflating: data/classification/val/70/53463.jpg  \n","  inflating: data/classification/val/70/53465.jpg  \n","  inflating: data/classification/val/70/53468.jpg  \n","  inflating: data/classification/val/70/53470.jpg  \n","  inflating: data/classification/val/70/53485.jpg  \n","  inflating: data/classification/val/70/53491.jpg  \n","  inflating: data/classification/val/70/53513.jpg  \n","  inflating: data/classification/val/70/53514.jpg  \n","  inflating: data/classification/val/70/53521.jpg  \n","  inflating: data/classification/val/70/53522.jpg  \n","  inflating: data/classification/val/70/53536.jpg  \n","  inflating: data/classification/val/70/53542.jpg  \n","  inflating: data/classification/val/70/53559.jpg  \n","  inflating: data/classification/val/70/53573.jpg  \n","  inflating: data/classification/val/70/53602.jpg  \n","  inflating: data/classification/val/70/53616.jpg  \n","  inflating: data/classification/val/70/53617.jpg  \n","  inflating: data/classification/val/70/53626.jpg  \n","  inflating: data/classification/val/70/53643.jpg  \n","  inflating: data/classification/val/70/53670.jpg  \n","  inflating: data/classification/val/70/53689.jpg  \n","  inflating: data/classification/val/70/53691.jpg  \n","  inflating: data/classification/val/70/53703.jpg  \n","  inflating: data/classification/val/70/53712.jpg  \n","  inflating: data/classification/val/70/53725.jpg  \n","  inflating: data/classification/val/70/53728.jpg  \n","  inflating: data/classification/val/70/53741.jpg  \n","  inflating: data/classification/val/70/53747.jpg  \n","  inflating: data/classification/val/70/53752.jpg  \n","  inflating: data/classification/val/70/53754.jpg  \n","  inflating: data/classification/val/70/53782.jpg  \n","  inflating: data/classification/val/70/53789.jpg  \n","  inflating: data/classification/val/70/53790.jpg  \n","  inflating: data/classification/val/70/53797.jpg  \n","  inflating: data/classification/val/70/53799.jpg  \n","  inflating: data/classification/val/70/53803.jpg  \n","  inflating: data/classification/val/70/53810.jpg  \n","  inflating: data/classification/val/70/53813.jpg  \n","  inflating: data/classification/val/70/53829.jpg  \n","  inflating: data/classification/val/70/53830.jpg  \n","  inflating: data/classification/val/70/53832.jpg  \n","  inflating: data/classification/val/70/53835.jpg  \n","  inflating: data/classification/val/70/53862.jpg  \n","  inflating: data/classification/val/70/53872.jpg  \n","  inflating: data/classification/val/70/53877.jpg  \n","  inflating: data/classification/val/70/53883.jpg  \n","  inflating: data/classification/val/70/53889.jpg  \n","  inflating: data/classification/val/70/53908.jpg  \n","  inflating: data/classification/val/70/53909.jpg  \n","  inflating: data/classification/val/70/53914.jpg  \n","  inflating: data/classification/val/70/53922.jpg  \n","  inflating: data/classification/val/70/53939.jpg  \n","  inflating: data/classification/val/70/53940.jpg  \n","  inflating: data/classification/val/70/53947.jpg  \n","  inflating: data/classification/val/70/53949.jpg  \n","  inflating: data/classification/val/70/53961.jpg  \n","  inflating: data/classification/val/70/53978.jpg  \n","  inflating: data/classification/val/70/53980.jpg  \n","  inflating: data/classification/val/70/53991.jpg  \n","  inflating: data/classification/val/70/53992.jpg  \n","  inflating: data/classification/val/70/53994.jpg  \n","  inflating: data/classification/val/70/53998.jpg  \n","  inflating: data/classification/val/70/54025.jpg  \n","  inflating: data/classification/val/70/54041.jpg  \n","  inflating: data/classification/val/70/54044.jpg  \n","  inflating: data/classification/val/70/54051.jpg  \n","  inflating: data/classification/val/70/54057.jpg  \n","  inflating: data/classification/val/70/54064.jpg  \n","  inflating: data/classification/val/70/54067.jpg  \n","  inflating: data/classification/val/70/54082.jpg  \n","  inflating: data/classification/val/70/54090.jpg  \n","  inflating: data/classification/val/70/54098.jpg  \n","  inflating: data/classification/val/70/54106.jpg  \n","  inflating: data/classification/val/70/54113.jpg  \n","  inflating: data/classification/val/70/54126.jpg  \n","  inflating: data/classification/val/70/54170.jpg  \n","  inflating: data/classification/val/70/54188.jpg  \n","  inflating: data/classification/val/70/54189.jpg  \n","  inflating: data/classification/val/70/54190.jpg  \n","  inflating: data/classification/val/70/54224.jpg  \n","  inflating: data/classification/val/70/54241.jpg  \n","  inflating: data/classification/val/70/54250.jpg  \n","  inflating: data/classification/val/70/54259.jpg  \n","  inflating: data/classification/val/70/54263.jpg  \n","  inflating: data/classification/val/70/54268.jpg  \n","  inflating: data/classification/val/70/54284.jpg  \n","  inflating: data/classification/val/70/54285.jpg  \n","  inflating: data/classification/val/70/54288.jpg  \n","  inflating: data/classification/val/70/54292.jpg  \n","  inflating: data/classification/val/70/54299.jpg  \n","  inflating: data/classification/val/70/54329.jpg  \n","  inflating: data/classification/val/70/54334.jpg  \n","  inflating: data/classification/val/70/54342.jpg  \n","  inflating: data/classification/val/70/54358.jpg  \n","  inflating: data/classification/val/70/54368.jpg  \n","  inflating: data/classification/val/70/54377.jpg  \n","  inflating: data/classification/val/70/54378.jpg  \n","  inflating: data/classification/val/70/54390.jpg  \n","  inflating: data/classification/val/70/54393.jpg  \n","  inflating: data/classification/val/70/54423.jpg  \n","  inflating: data/classification/val/70/54425.jpg  \n","  inflating: data/classification/val/70/54426.jpg  \n","  inflating: data/classification/val/70/54430.jpg  \n","  inflating: data/classification/val/70/54441.jpg  \n","  inflating: data/classification/val/70/54442.jpg  \n","  inflating: data/classification/val/70/54451.jpg  \n","  inflating: data/classification/val/70/54455.jpg  \n","  inflating: data/classification/val/70/54460.jpg  \n","  inflating: data/classification/val/70/54470.jpg  \n","  inflating: data/classification/val/70/54475.jpg  \n","  inflating: data/classification/val/70/54479.jpg  \n","  inflating: data/classification/val/70/54482.jpg  \n","  inflating: data/classification/val/70/54513.jpg  \n","  inflating: data/classification/val/70/54517.jpg  \n","  inflating: data/classification/val/70/54524.jpg  \n","  inflating: data/classification/val/70/54537.jpg  \n","  inflating: data/classification/val/70/54539.jpg  \n","  inflating: data/classification/val/70/54545.jpg  \n","  inflating: data/classification/val/70/54555.jpg  \n","  inflating: data/classification/val/70/54570.jpg  \n","  inflating: data/classification/val/70/54583.jpg  \n","  inflating: data/classification/val/70/54609.jpg  \n","  inflating: data/classification/val/70/54614.jpg  \n","  inflating: data/classification/val/70/54626.jpg  \n","  inflating: data/classification/val/70/54628.jpg  \n","  inflating: data/classification/val/70/54634.jpg  \n","  inflating: data/classification/val/70/54653.jpg  \n","  inflating: data/classification/val/70/54669.jpg  \n","  inflating: data/classification/val/70/54681.jpg  \n","  inflating: data/classification/val/70/54682.jpg  \n","  inflating: data/classification/val/70/54700.jpg  \n","  inflating: data/classification/val/70/54723.jpg  \n","  inflating: data/classification/val/70/54727.jpg  \n","  inflating: data/classification/val/70/54731.jpg  \n","  inflating: data/classification/val/70/54733.jpg  \n","  inflating: data/classification/val/70/54734.jpg  \n","  inflating: data/classification/val/70/54740.jpg  \n","  inflating: data/classification/val/70/54760.jpg  \n","  inflating: data/classification/val/70/54766.jpg  \n","  inflating: data/classification/val/70/54771.jpg  \n","  inflating: data/classification/val/70/54773.jpg  \n","  inflating: data/classification/val/70/54774.jpg  \n","  inflating: data/classification/val/70/54781.jpg  \n","  inflating: data/classification/val/70/54793.jpg  \n","  inflating: data/classification/val/70/54809.jpg  \n","  inflating: data/classification/val/70/54833.jpg  \n","  inflating: data/classification/val/70/54845.jpg  \n","  inflating: data/classification/val/70/54860.jpg  \n","  inflating: data/classification/val/70/54862.jpg  \n","  inflating: data/classification/val/70/54875.jpg  \n","  inflating: data/classification/val/70/54881.jpg  \n","  inflating: data/classification/val/70/54884.jpg  \n","  inflating: data/classification/val/70/54907.jpg  \n","  inflating: data/classification/val/70/54912.jpg  \n","  inflating: data/classification/val/70/54919.jpg  \n","  inflating: data/classification/val/70/54941.jpg  \n","  inflating: data/classification/val/70/54955.jpg  \n","  inflating: data/classification/val/70/54974.jpg  \n","  inflating: data/classification/val/70/54981.jpg  \n","  inflating: data/classification/val/70/54985.jpg  \n","  inflating: data/classification/val/70/54986.jpg  \n","  inflating: data/classification/val/70/54994.jpg  \n","  inflating: data/classification/val/70/54996.jpg  \n","  inflating: data/classification/val/70/55002.jpg  \n","  inflating: data/classification/val/70/55005.jpg  \n","  inflating: data/classification/val/70/55038.jpg  \n","  inflating: data/classification/val/70/55043.jpg  \n","  inflating: data/classification/val/70/55049.jpg  \n","  inflating: data/classification/val/70/55051.jpg  \n","  inflating: data/classification/val/70/55088.jpg  \n","  inflating: data/classification/val/70/55091.jpg  \n","  inflating: data/classification/val/70/55114.jpg  \n","  inflating: data/classification/val/70/55130.jpg  \n","  inflating: data/classification/val/70/55142.jpg  \n","  inflating: data/classification/val/70/55168.jpg  \n","  inflating: data/classification/val/70/55170.jpg  \n","  inflating: data/classification/val/70/55192.jpg  \n","  inflating: data/classification/val/70/55193.jpg  \n","  inflating: data/classification/val/70/55216.jpg  \n","  inflating: data/classification/val/70/55219.jpg  \n","  inflating: data/classification/val/70/55223.jpg  \n","  inflating: data/classification/val/70/55242.jpg  \n","  inflating: data/classification/val/70/55256.jpg  \n","  inflating: data/classification/val/70/55265.jpg  \n","  inflating: data/classification/val/70/55278.jpg  \n","  inflating: data/classification/val/70/55284.jpg  \n","  inflating: data/classification/val/70/55286.jpg  \n","  inflating: data/classification/val/70/55308.jpg  \n","  inflating: data/classification/val/70/55344.jpg  \n","  inflating: data/classification/val/70/55353.jpg  \n","  inflating: data/classification/val/70/55366.jpg  \n","  inflating: data/classification/val/70/55368.jpg  \n","  inflating: data/classification/val/70/55375.jpg  \n","  inflating: data/classification/val/70/55387.jpg  \n","  inflating: data/classification/val/70/55406.jpg  \n","  inflating: data/classification/val/70/55408.jpg  \n","  inflating: data/classification/val/70/55414.jpg  \n","  inflating: data/classification/val/70/55436.jpg  \n","  inflating: data/classification/val/70/55442.jpg  \n","  inflating: data/classification/val/70/55445.jpg  \n","  inflating: data/classification/val/70/55458.jpg  \n","  inflating: data/classification/val/70/55492.jpg  \n","  inflating: data/classification/val/70/55500.jpg  \n","  inflating: data/classification/val/70/55507.jpg  \n","  inflating: data/classification/val/70/55514.jpg  \n","  inflating: data/classification/val/70/55516.jpg  \n","  inflating: data/classification/val/70/55520.jpg  \n","  inflating: data/classification/val/70/55529.jpg  \n","  inflating: data/classification/val/70/55532.jpg  \n","  inflating: data/classification/val/70/55541.jpg  \n","  inflating: data/classification/val/70/55545.jpg  \n","  inflating: data/classification/val/70/55562.jpg  \n","  inflating: data/classification/val/70/55590.jpg  \n","  inflating: data/classification/val/70/55596.jpg  \n","  inflating: data/classification/val/70/55597.jpg  \n","  inflating: data/classification/val/70/55603.jpg  \n","  inflating: data/classification/val/70/55604.jpg  \n","  inflating: data/classification/val/70/55605.jpg  \n","  inflating: data/classification/val/70/55668.jpg  \n","  inflating: data/classification/val/70/55675.jpg  \n","  inflating: data/classification/val/70/55684.jpg  \n","  inflating: data/classification/val/70/55687.jpg  \n","  inflating: data/classification/val/70/55691.jpg  \n","  inflating: data/classification/val/70/55703.jpg  \n","  inflating: data/classification/val/70/55707.jpg  \n","  inflating: data/classification/val/70/55709.jpg  \n","  inflating: data/classification/val/70/55728.jpg  \n","  inflating: data/classification/val/70/55732.jpg  \n","  inflating: data/classification/val/70/55777.jpg  \n","  inflating: data/classification/val/70/55784.jpg  \n","  inflating: data/classification/val/70/55816.jpg  \n","  inflating: data/classification/val/70/55817.jpg  \n","  inflating: data/classification/val/70/55818.jpg  \n","  inflating: data/classification/val/70/55867.jpg  \n","  inflating: data/classification/val/70/55873.jpg  \n","  inflating: data/classification/val/70/55883.jpg  \n","  inflating: data/classification/val/70/55906.jpg  \n","  inflating: data/classification/val/70/55914.jpg  \n","  inflating: data/classification/val/70/55924.jpg  \n","  inflating: data/classification/val/70/55928.jpg  \n","  inflating: data/classification/val/70/55932.jpg  \n","  inflating: data/classification/val/70/55933.jpg  \n","  inflating: data/classification/val/70/55942.jpg  \n","  inflating: data/classification/val/70/55944.jpg  \n","  inflating: data/classification/val/70/55951.jpg  \n","  inflating: data/classification/val/70/55953.jpg  \n","  inflating: data/classification/val/70/55992.jpg  \n","  inflating: data/classification/val/70/56019.jpg  \n","  inflating: data/classification/val/70/56024.jpg  \n","  inflating: data/classification/val/70/56026.jpg  \n","  inflating: data/classification/val/70/56029.jpg  \n","  inflating: data/classification/val/70/56036.jpg  \n","  inflating: data/classification/val/70/56049.jpg  \n","  inflating: data/classification/val/70/56070.jpg  \n","  inflating: data/classification/val/70/56072.jpg  \n","  inflating: data/classification/val/70/56073.jpg  \n","  inflating: data/classification/val/70/56075.jpg  \n","  inflating: data/classification/val/70/56081.jpg  \n","  inflating: data/classification/val/70/56086.jpg  \n","  inflating: data/classification/val/70/56095.jpg  \n","  inflating: data/classification/val/70/56101.jpg  \n","  inflating: data/classification/val/70/56134.jpg  \n","  inflating: data/classification/val/70/56141.jpg  \n","  inflating: data/classification/val/70/56145.jpg  \n","  inflating: data/classification/val/70/56156.jpg  \n","  inflating: data/classification/val/70/56166.jpg  \n","  inflating: data/classification/val/70/56170.jpg  \n","  inflating: data/classification/val/70/56174.jpg  \n","  inflating: data/classification/val/70/56179.jpg  \n","  inflating: data/classification/val/70/56185.jpg  \n","  inflating: data/classification/val/70/56194.jpg  \n","  inflating: data/classification/val/70/56205.jpg  \n","  inflating: data/classification/val/70/56221.jpg  \n","  inflating: data/classification/val/70/56235.jpg  \n","  inflating: data/classification/val/70/56241.jpg  \n","  inflating: data/classification/val/70/56243.jpg  \n","  inflating: data/classification/val/70/56250.jpg  \n","  inflating: data/classification/val/70/56261.jpg  \n","  inflating: data/classification/val/70/56266.jpg  \n","  inflating: data/classification/val/70/56267.jpg  \n","  inflating: data/classification/val/70/56275.jpg  \n","  inflating: data/classification/val/70/56297.jpg  \n","  inflating: data/classification/val/70/56302.jpg  \n","  inflating: data/classification/val/70/56303.jpg  \n","  inflating: data/classification/val/70/56313.jpg  \n","  inflating: data/classification/val/70/56318.jpg  \n","  inflating: data/classification/val/70/56319.jpg  \n","  inflating: data/classification/val/70/56326.jpg  \n","  inflating: data/classification/val/70/56330.jpg  \n","  inflating: data/classification/val/70/56336.jpg  \n","  inflating: data/classification/val/70/56339.jpg  \n","  inflating: data/classification/val/70/56362.jpg  \n","  inflating: data/classification/val/70/56369.jpg  \n","  inflating: data/classification/val/70/56381.jpg  \n","  inflating: data/classification/val/70/56412.jpg  \n","  inflating: data/classification/val/70/56416.jpg  \n","  inflating: data/classification/val/70/56428.jpg  \n","  inflating: data/classification/val/70/56435.jpg  \n","  inflating: data/classification/val/70/56437.jpg  \n","  inflating: data/classification/val/70/56462.jpg  \n","  inflating: data/classification/val/70/56470.jpg  \n","  inflating: data/classification/val/70/56500.jpg  \n","  inflating: data/classification/val/70/56504.jpg  \n","  inflating: data/classification/val/70/56523.jpg  \n","  inflating: data/classification/val/70/56527.jpg  \n","  inflating: data/classification/val/70/56529.jpg  \n","  inflating: data/classification/val/70/56534.jpg  \n","  inflating: data/classification/val/70/56537.jpg  \n","  inflating: data/classification/val/70/56539.jpg  \n","  inflating: data/classification/val/70/56553.jpg  \n","  inflating: data/classification/val/70/56567.jpg  \n","  inflating: data/classification/val/70/56568.jpg  \n","  inflating: data/classification/val/70/56573.jpg  \n","  inflating: data/classification/val/70/56583.jpg  \n","  inflating: data/classification/val/70/56590.jpg  \n","  inflating: data/classification/val/70/56600.jpg  \n","  inflating: data/classification/val/70/56635.jpg  \n","  inflating: data/classification/val/70/56653.jpg  \n","  inflating: data/classification/val/70/56655.jpg  \n","  inflating: data/classification/val/70/56667.jpg  \n","  inflating: data/classification/val/70/56672.jpg  \n","  inflating: data/classification/val/70/56698.jpg  \n","  inflating: data/classification/val/70/56715.jpg  \n","  inflating: data/classification/val/70/56723.jpg  \n","  inflating: data/classification/val/70/56725.jpg  \n","  inflating: data/classification/val/70/56727.jpg  \n","  inflating: data/classification/val/70/56731.jpg  \n","  inflating: data/classification/val/70/56746.jpg  \n","  inflating: data/classification/val/70/56751.jpg  \n","  inflating: data/classification/val/70/56755.jpg  \n","  inflating: data/classification/val/70/56773.jpg  \n","  inflating: data/classification/val/70/56776.jpg  \n","  inflating: data/classification/val/70/56779.jpg  \n","  inflating: data/classification/val/70/56790.jpg  \n","  inflating: data/classification/val/70/56797.jpg  \n","  inflating: data/classification/val/70/56803.jpg  \n","  inflating: data/classification/val/70/56805.jpg  \n","  inflating: data/classification/val/70/56807.jpg  \n","  inflating: data/classification/val/70/56821.jpg  \n","  inflating: data/classification/val/70/56822.jpg  \n","  inflating: data/classification/val/70/56838.jpg  \n","  inflating: data/classification/val/70/56862.jpg  \n","  inflating: data/classification/val/70/56864.jpg  \n","  inflating: data/classification/val/70/56866.jpg  \n","  inflating: data/classification/val/70/56874.jpg  \n","  inflating: data/classification/val/70/56876.jpg  \n","  inflating: data/classification/val/70/56900.jpg  \n","  inflating: data/classification/val/70/56901.jpg  \n","  inflating: data/classification/val/70/56909.jpg  \n","  inflating: data/classification/val/70/56915.jpg  \n","  inflating: data/classification/val/70/56935.jpg  \n","  inflating: data/classification/val/70/56953.jpg  \n","  inflating: data/classification/val/70/56955.jpg  \n","  inflating: data/classification/val/70/56965.jpg  \n","  inflating: data/classification/val/70/56966.jpg  \n","  inflating: data/classification/val/70/56985.jpg  \n","  inflating: data/classification/val/70/56986.jpg  \n","  inflating: data/classification/val/70/57000.jpg  \n","  inflating: data/classification/val/70/57001.jpg  \n","  inflating: data/classification/val/70/57034.jpg  \n","  inflating: data/classification/val/70/57035.jpg  \n","  inflating: data/classification/val/70/57051.jpg  \n","  inflating: data/classification/val/70/57053.jpg  \n","  inflating: data/classification/val/70/57062.jpg  \n","  inflating: data/classification/val/70/57063.jpg  \n","  inflating: data/classification/val/70/57074.jpg  \n","  inflating: data/classification/val/70/57092.jpg  \n","  inflating: data/classification/val/70/57134.jpg  \n","  inflating: data/classification/val/70/57136.jpg  \n","  inflating: data/classification/val/70/57175.jpg  \n","  inflating: data/classification/val/70/57184.jpg  \n","  inflating: data/classification/val/70/57185.jpg  \n","  inflating: data/classification/val/70/57192.jpg  \n","  inflating: data/classification/val/70/57196.jpg  \n","  inflating: data/classification/val/70/57197.jpg  \n","  inflating: data/classification/val/70/57202.jpg  \n","  inflating: data/classification/val/70/57211.jpg  \n","  inflating: data/classification/val/70/57217.jpg  \n","  inflating: data/classification/val/70/57225.jpg  \n","  inflating: data/classification/val/70/57226.jpg  \n","  inflating: data/classification/val/70/57227.jpg  \n","  inflating: data/classification/val/70/57242.jpg  \n","  inflating: data/classification/val/70/57255.jpg  \n","  inflating: data/classification/val/70/57259.jpg  \n","  inflating: data/classification/val/70/57269.jpg  \n","  inflating: data/classification/val/70/57278.jpg  \n","  inflating: data/classification/val/70/57282.jpg  \n","  inflating: data/classification/val/70/57311.jpg  \n","  inflating: data/classification/val/70/57335.jpg  \n","  inflating: data/classification/val/70/57337.jpg  \n","  inflating: data/classification/val/70/57354.jpg  \n","  inflating: data/classification/val/70/57361.jpg  \n","  inflating: data/classification/val/70/57365.jpg  \n","  inflating: data/classification/val/70/57366.jpg  \n","  inflating: data/classification/val/70/57375.jpg  \n","  inflating: data/classification/val/70/57382.jpg  \n","  inflating: data/classification/val/70/57383.jpg  \n","  inflating: data/classification/val/70/57389.jpg  \n","  inflating: data/classification/val/70/57391.jpg  \n","  inflating: data/classification/val/70/57393.jpg  \n","  inflating: data/classification/val/70/57397.jpg  \n","  inflating: data/classification/val/70/57403.jpg  \n","  inflating: data/classification/val/70/57405.jpg  \n","  inflating: data/classification/val/70/57407.jpg  \n","  inflating: data/classification/val/70/57415.jpg  \n","  inflating: data/classification/val/70/57425.jpg  \n","  inflating: data/classification/val/70/57440.jpg  \n","  inflating: data/classification/val/70/57441.jpg  \n","  inflating: data/classification/val/71/57448.jpg  \n","  inflating: data/classification/val/71/57452.jpg  \n","  inflating: data/classification/val/71/57466.jpg  \n","  inflating: data/classification/val/71/57467.jpg  \n","  inflating: data/classification/val/71/57469.jpg  \n","  inflating: data/classification/val/71/57470.jpg  \n","  inflating: data/classification/val/71/57471.jpg  \n","  inflating: data/classification/val/71/57473.jpg  \n","  inflating: data/classification/val/71/57478.jpg  \n","  inflating: data/classification/val/71/57494.jpg  \n","  inflating: data/classification/val/71/57508.jpg  \n","  inflating: data/classification/val/71/57510.jpg  \n","  inflating: data/classification/val/71/57526.jpg  \n","  inflating: data/classification/val/71/57541.jpg  \n","  inflating: data/classification/val/71/57552.jpg  \n","  inflating: data/classification/val/71/57571.jpg  \n","  inflating: data/classification/val/71/57580.jpg  \n","  inflating: data/classification/val/71/57606.jpg  \n","  inflating: data/classification/val/71/57607.jpg  \n","  inflating: data/classification/val/71/57623.jpg  \n","  inflating: data/classification/val/71/57624.jpg  \n","  inflating: data/classification/val/71/57629.jpg  \n","  inflating: data/classification/val/71/57633.jpg  \n","  inflating: data/classification/val/71/57698.jpg  \n","  inflating: data/classification/val/71/57707.jpg  \n","  inflating: data/classification/val/71/57711.jpg  \n","  inflating: data/classification/val/71/57741.jpg  \n","  inflating: data/classification/val/71/57752.jpg  \n","  inflating: data/classification/val/71/57759.jpg  \n","  inflating: data/classification/val/71/57763.jpg  \n","  inflating: data/classification/val/71/57768.jpg  \n","  inflating: data/classification/val/71/57777.jpg  \n","  inflating: data/classification/val/71/57780.jpg  \n","  inflating: data/classification/val/71/57783.jpg  \n","  inflating: data/classification/val/71/57802.jpg  \n","  inflating: data/classification/val/71/57804.jpg  \n","  inflating: data/classification/val/71/57807.jpg  \n","  inflating: data/classification/val/71/57818.jpg  \n","  inflating: data/classification/val/71/57825.jpg  \n","  inflating: data/classification/val/71/57850.jpg  \n","  inflating: data/classification/val/71/57851.jpg  \n","  inflating: data/classification/val/71/57856.jpg  \n","  inflating: data/classification/val/71/57864.jpg  \n","  inflating: data/classification/val/71/57867.jpg  \n","  inflating: data/classification/val/71/57872.jpg  \n","  inflating: data/classification/val/71/57883.jpg  \n","  inflating: data/classification/val/71/57892.jpg  \n","  inflating: data/classification/val/71/57900.jpg  \n","  inflating: data/classification/val/71/57906.jpg  \n","  inflating: data/classification/val/71/57911.jpg  \n","  inflating: data/classification/val/71/57918.jpg  \n","  inflating: data/classification/val/71/57923.jpg  \n","  inflating: data/classification/val/71/57935.jpg  \n","  inflating: data/classification/val/71/57942.jpg  \n","  inflating: data/classification/val/71/57954.jpg  \n","  inflating: data/classification/val/71/57962.jpg  \n","  inflating: data/classification/val/71/57981.jpg  \n","  inflating: data/classification/val/71/57983.jpg  \n","  inflating: data/classification/val/71/57995.jpg  \n","  inflating: data/classification/val/71/57998.jpg  \n","  inflating: data/classification/val/71/58012.jpg  \n","  inflating: data/classification/val/71/58041.jpg  \n","  inflating: data/classification/val/71/58056.jpg  \n","  inflating: data/classification/val/71/58096.jpg  \n","  inflating: data/classification/val/71/58106.jpg  \n","  inflating: data/classification/val/71/58107.jpg  \n","  inflating: data/classification/val/71/58108.jpg  \n","  inflating: data/classification/val/71/58112.jpg  \n","  inflating: data/classification/val/71/58138.jpg  \n","  inflating: data/classification/val/72/58142.jpg  \n","  inflating: data/classification/val/72/58163.jpg  \n","  inflating: data/classification/val/72/58167.jpg  \n","  inflating: data/classification/val/72/58169.jpg  \n","  inflating: data/classification/val/72/58171.jpg  \n","  inflating: data/classification/val/72/58173.jpg  \n","  inflating: data/classification/val/72/58197.jpg  \n","  inflating: data/classification/val/73/58219.jpg  \n","  inflating: data/classification/val/73/58220.jpg  \n","  inflating: data/classification/val/73/58238.jpg  \n","  inflating: data/classification/val/73/58241.jpg  \n","  inflating: data/classification/val/73/58258.jpg  \n","  inflating: data/classification/val/73/58263.jpg  \n","  inflating: data/classification/val/73/58273.jpg  \n","  inflating: data/classification/val/73/58295.jpg  \n","  inflating: data/classification/val/73/58308.jpg  \n","  inflating: data/classification/val/73/58321.jpg  \n","  inflating: data/classification/val/73/58323.jpg  \n","  inflating: data/classification/val/73/58329.jpg  \n","  inflating: data/classification/val/73/58330.jpg  \n","  inflating: data/classification/val/73/58335.jpg  \n","  inflating: data/classification/val/73/58341.jpg  \n","  inflating: data/classification/val/73/58367.jpg  \n","  inflating: data/classification/val/73/58370.jpg  \n","  inflating: data/classification/val/73/58378.jpg  \n","  inflating: data/classification/val/73/58383.jpg  \n","  inflating: data/classification/val/73/58388.jpg  \n","  inflating: data/classification/val/73/58389.jpg  \n","  inflating: data/classification/val/73/58400.jpg  \n","  inflating: data/classification/val/73/58404.jpg  \n","  inflating: data/classification/val/73/58414.jpg  \n","  inflating: data/classification/val/73/58419.jpg  \n","  inflating: data/classification/val/73/58439.jpg  \n","  inflating: data/classification/val/73/58449.jpg  \n","  inflating: data/classification/val/73/58455.jpg  \n","  inflating: data/classification/val/73/58456.jpg  \n","  inflating: data/classification/val/73/58461.jpg  \n","  inflating: data/classification/val/73/58476.jpg  \n","  inflating: data/classification/val/73/58490.jpg  \n","  inflating: data/classification/val/73/58492.jpg  \n","  inflating: data/classification/val/73/58529.jpg  \n","  inflating: data/classification/val/73/58534.jpg  \n","  inflating: data/classification/val/73/58543.jpg  \n","  inflating: data/classification/val/73/58550.jpg  \n","  inflating: data/classification/val/73/58551.jpg  \n","  inflating: data/classification/val/73/58552.jpg  \n","  inflating: data/classification/val/73/58569.jpg  \n","  inflating: data/classification/val/73/58592.jpg  \n","  inflating: data/classification/val/73/58605.jpg  \n","  inflating: data/classification/val/73/58613.jpg  \n","  inflating: data/classification/val/73/58631.jpg  \n","  inflating: data/classification/val/73/58651.jpg  \n","  inflating: data/classification/val/74/58667.jpg  \n","  inflating: data/classification/val/74/58674.jpg  \n","  inflating: data/classification/val/74/58692.jpg  \n","  inflating: data/classification/val/74/58726.jpg  \n","  inflating: data/classification/val/74/58727.jpg  \n","  inflating: data/classification/val/74/58734.jpg  \n","  inflating: data/classification/val/74/58741.jpg  \n","  inflating: data/classification/val/74/58746.jpg  \n","  inflating: data/classification/val/74/58757.jpg  \n","  inflating: data/classification/val/74/58764.jpg  \n","  inflating: data/classification/val/74/58767.jpg  \n","  inflating: data/classification/val/74/58773.jpg  \n","  inflating: data/classification/val/74/58781.jpg  \n","  inflating: data/classification/val/74/58796.jpg  \n","  inflating: data/classification/val/74/58829.jpg  \n","  inflating: data/classification/val/74/58841.jpg  \n","  inflating: data/classification/val/74/58850.jpg  \n","  inflating: data/classification/val/74/58874.jpg  \n","  inflating: data/classification/val/74/58882.jpg  \n","  inflating: data/classification/val/74/58901.jpg  \n","  inflating: data/classification/val/74/58911.jpg  \n","  inflating: data/classification/val/74/58934.jpg  \n","  inflating: data/classification/val/74/58943.jpg  \n","  inflating: data/classification/val/74/58949.jpg  \n","  inflating: data/classification/val/74/58962.jpg  \n","  inflating: data/classification/val/74/58966.jpg  \n","  inflating: data/classification/val/74/58969.jpg  \n","  inflating: data/classification/val/74/58971.jpg  \n","  inflating: data/classification/val/74/58977.jpg  \n","  inflating: data/classification/val/74/59000.jpg  \n","  inflating: data/classification/val/74/59004.jpg  \n","  inflating: data/classification/val/74/59009.jpg  \n","  inflating: data/classification/val/74/59025.jpg  \n","  inflating: data/classification/val/74/59028.jpg  \n","  inflating: data/classification/val/74/59030.jpg  \n","  inflating: data/classification/val/74/59039.jpg  \n","  inflating: data/classification/val/74/59041.jpg  \n","  inflating: data/classification/val/74/59044.jpg  \n","  inflating: data/classification/val/75/59046.jpg  \n","  inflating: data/classification/val/75/59049.jpg  \n","  inflating: data/classification/val/75/59050.jpg  \n","  inflating: data/classification/val/75/59063.jpg  \n","  inflating: data/classification/val/75/59071.jpg  \n","  inflating: data/classification/val/75/59078.jpg  \n","  inflating: data/classification/val/75/59095.jpg  \n","  inflating: data/classification/val/75/59096.jpg  \n","  inflating: data/classification/val/75/59111.jpg  \n","  inflating: data/classification/val/75/59115.jpg  \n","  inflating: data/classification/val/75/59118.jpg  \n","  inflating: data/classification/val/75/59119.jpg  \n","  inflating: data/classification/val/75/59139.jpg  \n","  inflating: data/classification/val/75/59181.jpg  \n","  inflating: data/classification/val/75/59191.jpg  \n","  inflating: data/classification/val/75/59192.jpg  \n","  inflating: data/classification/val/75/59212.jpg  \n","  inflating: data/classification/val/76/59217.jpg  \n","  inflating: data/classification/val/76/59221.jpg  \n","  inflating: data/classification/val/76/59227.jpg  \n","  inflating: data/classification/val/76/59240.jpg  \n","  inflating: data/classification/val/76/59254.jpg  \n","  inflating: data/classification/val/76/59255.jpg  \n","  inflating: data/classification/val/76/59260.jpg  \n","  inflating: data/classification/val/76/59269.jpg  \n","  inflating: data/classification/val/76/59310.jpg  \n","  inflating: data/classification/val/76/59317.jpg  \n","  inflating: data/classification/val/76/59332.jpg  \n","  inflating: data/classification/val/76/59333.jpg  \n","  inflating: data/classification/val/76/59338.jpg  \n","  inflating: data/classification/val/76/59341.jpg  \n","  inflating: data/classification/val/76/59343.jpg  \n","  inflating: data/classification/val/76/59361.jpg  \n","  inflating: data/classification/val/76/59379.jpg  \n","  inflating: data/classification/val/76/59381.jpg  \n","  inflating: data/classification/val/76/59382.jpg  \n","  inflating: data/classification/val/76/59386.jpg  \n","  inflating: data/classification/val/76/59410.jpg  \n","  inflating: data/classification/val/76/59434.jpg  \n","  inflating: data/classification/val/76/59436.jpg  \n","  inflating: data/classification/val/76/59449.jpg  \n","  inflating: data/classification/val/76/59459.jpg  \n","  inflating: data/classification/val/76/59470.jpg  \n","  inflating: data/classification/val/76/59477.jpg  \n","  inflating: data/classification/val/76/59481.jpg  \n","  inflating: data/classification/val/76/59488.jpg  \n","  inflating: data/classification/val/76/59498.jpg  \n","  inflating: data/classification/val/76/59520.jpg  \n","  inflating: data/classification/val/76/59526.jpg  \n","  inflating: data/classification/val/76/59530.jpg  \n","  inflating: data/classification/val/76/59533.jpg  \n","  inflating: data/classification/val/76/59534.jpg  \n","  inflating: data/classification/val/76/59536.jpg  \n","  inflating: data/classification/val/76/59550.jpg  \n","  inflating: data/classification/val/76/59563.jpg  \n","  inflating: data/classification/val/76/59565.jpg  \n","  inflating: data/classification/val/76/59571.jpg  \n","  inflating: data/classification/val/76/59598.jpg  \n","  inflating: data/classification/val/76/59599.jpg  \n","  inflating: data/classification/val/76/59602.jpg  \n","  inflating: data/classification/val/76/59629.jpg  \n","  inflating: data/classification/val/76/59630.jpg  \n","  inflating: data/classification/val/76/59634.jpg  \n","  inflating: data/classification/val/76/59640.jpg  \n","  inflating: data/classification/val/76/59681.jpg  \n","  inflating: data/classification/val/76/59684.jpg  \n","  inflating: data/classification/val/76/59694.jpg  \n","  inflating: data/classification/val/76/59708.jpg  \n","  inflating: data/classification/val/76/59709.jpg  \n","  inflating: data/classification/val/76/59723.jpg  \n","  inflating: data/classification/val/76/59729.jpg  \n","  inflating: data/classification/val/76/59759.jpg  \n","  inflating: data/classification/val/76/59760.jpg  \n","  inflating: data/classification/val/76/59768.jpg  \n","  inflating: data/classification/val/76/59803.jpg  \n","  inflating: data/classification/val/76/59822.jpg  \n","  inflating: data/classification/val/76/59824.jpg  \n","  inflating: data/classification/val/76/59830.jpg  \n","  inflating: data/classification/val/76/59853.jpg  \n","  inflating: data/classification/val/76/59866.jpg  \n","  inflating: data/classification/val/76/59879.jpg  \n","  inflating: data/classification/val/76/59885.jpg  \n","  inflating: data/classification/val/76/59891.jpg  \n","  inflating: data/classification/val/76/59896.jpg  \n","  inflating: data/classification/val/76/59898.jpg  \n","  inflating: data/classification/val/76/59913.jpg  \n","  inflating: data/classification/val/76/59918.jpg  \n","  inflating: data/classification/val/76/59933.jpg  \n","  inflating: data/classification/val/76/59938.jpg  \n","  inflating: data/classification/val/77/59948.jpg  \n","  inflating: data/classification/val/77/59950.jpg  \n","  inflating: data/classification/val/77/59961.jpg  \n","  inflating: data/classification/val/77/59984.jpg  \n","  inflating: data/classification/val/77/59998.jpg  \n","  inflating: data/classification/val/77/60001.jpg  \n","  inflating: data/classification/val/77/60015.jpg  \n","  inflating: data/classification/val/77/60016.jpg  \n","  inflating: data/classification/val/77/60027.jpg  \n","  inflating: data/classification/val/77/60029.jpg  \n","  inflating: data/classification/val/77/60033.jpg  \n","  inflating: data/classification/val/77/60042.jpg  \n","  inflating: data/classification/val/77/60050.jpg  \n","  inflating: data/classification/val/77/60060.jpg  \n","  inflating: data/classification/val/77/60063.jpg  \n","  inflating: data/classification/val/77/60072.jpg  \n","  inflating: data/classification/val/77/60090.jpg  \n","  inflating: data/classification/val/77/60093.jpg  \n","  inflating: data/classification/val/77/60096.jpg  \n","  inflating: data/classification/val/77/60109.jpg  \n","  inflating: data/classification/val/77/60116.jpg  \n","  inflating: data/classification/val/77/60143.jpg  \n","  inflating: data/classification/val/77/60145.jpg  \n","  inflating: data/classification/val/77/60155.jpg  \n","  inflating: data/classification/val/77/60159.jpg  \n","  inflating: data/classification/val/77/60169.jpg  \n","  inflating: data/classification/val/77/60174.jpg  \n","  inflating: data/classification/val/77/60183.jpg  \n","  inflating: data/classification/val/77/60186.jpg  \n","  inflating: data/classification/val/77/60190.jpg  \n","  inflating: data/classification/val/77/60199.jpg  \n","  inflating: data/classification/val/77/60203.jpg  \n","  inflating: data/classification/val/77/60209.jpg  \n","  inflating: data/classification/val/77/60224.jpg  \n","  inflating: data/classification/val/77/60251.jpg  \n","  inflating: data/classification/val/77/60275.jpg  \n","  inflating: data/classification/val/77/60286.jpg  \n","  inflating: data/classification/val/77/60296.jpg  \n","  inflating: data/classification/val/77/60302.jpg  \n","  inflating: data/classification/val/77/60319.jpg  \n","  inflating: data/classification/val/77/60333.jpg  \n","  inflating: data/classification/val/77/60339.jpg  \n","  inflating: data/classification/val/78/60363.jpg  \n","  inflating: data/classification/val/78/60377.jpg  \n","  inflating: data/classification/val/78/60380.jpg  \n","  inflating: data/classification/val/78/60385.jpg  \n","  inflating: data/classification/val/78/60403.jpg  \n","  inflating: data/classification/val/78/60421.jpg  \n","  inflating: data/classification/val/78/60428.jpg  \n","  inflating: data/classification/val/78/60452.jpg  \n","  inflating: data/classification/val/78/60456.jpg  \n","  inflating: data/classification/val/78/60478.jpg  \n","  inflating: data/classification/val/78/60483.jpg  \n","  inflating: data/classification/val/78/60491.jpg  \n","  inflating: data/classification/val/78/60493.jpg  \n","  inflating: data/classification/val/78/60498.jpg  \n","  inflating: data/classification/val/78/60502.jpg  \n","  inflating: data/classification/val/78/60503.jpg  \n","  inflating: data/classification/val/78/60536.jpg  \n","  inflating: data/classification/val/78/60540.jpg  \n","  inflating: data/classification/val/78/60543.jpg  \n","  inflating: data/classification/val/78/60565.jpg  \n","  inflating: data/classification/val/78/60567.jpg  \n","  inflating: data/classification/val/78/60572.jpg  \n","  inflating: data/classification/val/78/60573.jpg  \n","  inflating: data/classification/val/78/60579.jpg  \n","  inflating: data/classification/val/78/60585.jpg  \n","  inflating: data/classification/val/78/60592.jpg  \n","  inflating: data/classification/val/79/60625.jpg  \n","  inflating: data/classification/val/79/60631.jpg  \n","  inflating: data/classification/val/79/60658.jpg  \n","  inflating: data/classification/val/79/60674.jpg  \n","  inflating: data/classification/val/79/60680.jpg  \n","  inflating: data/classification/val/79/60683.jpg  \n","  inflating: data/classification/val/79/60685.jpg  \n","  inflating: data/classification/val/79/60696.jpg  \n","  inflating: data/classification/val/79/60699.jpg  \n","  inflating: data/classification/val/79/60710.jpg  \n","  inflating: data/classification/val/79/60717.jpg  \n","  inflating: data/classification/val/79/60738.jpg  \n","  inflating: data/classification/val/79/60761.jpg  \n","  inflating: data/classification/val/79/60785.jpg  \n","  inflating: data/classification/val/79/60788.jpg  \n","  inflating: data/classification/val/79/60799.jpg  \n","  inflating: data/classification/val/79/60800.jpg  \n","  inflating: data/classification/val/79/60802.jpg  \n","  inflating: data/classification/val/79/60816.jpg  \n","  inflating: data/classification/val/79/60825.jpg  \n","  inflating: data/classification/val/79/60832.jpg  \n","  inflating: data/classification/val/79/60840.jpg  \n","  inflating: data/classification/val/8/05143.jpg  \n","  inflating: data/classification/val/8/05148.jpg  \n","  inflating: data/classification/val/8/05160.jpg  \n","  inflating: data/classification/val/8/05167.jpg  \n","  inflating: data/classification/val/8/05194.jpg  \n","  inflating: data/classification/val/8/05203.jpg  \n","  inflating: data/classification/val/8/05205.jpg  \n","  inflating: data/classification/val/8/05218.jpg  \n","  inflating: data/classification/val/8/05230.jpg  \n","  inflating: data/classification/val/8/05234.jpg  \n","  inflating: data/classification/val/8/05239.jpg  \n","  inflating: data/classification/val/8/05244.jpg  \n","  inflating: data/classification/val/8/05245.jpg  \n","  inflating: data/classification/val/8/05255.jpg  \n","  inflating: data/classification/val/8/05261.jpg  \n","  inflating: data/classification/val/8/05277.jpg  \n","  inflating: data/classification/val/8/05285.jpg  \n","  inflating: data/classification/val/8/05317.jpg  \n","  inflating: data/classification/val/8/05326.jpg  \n","  inflating: data/classification/val/8/05332.jpg  \n","  inflating: data/classification/val/8/05359.jpg  \n","  inflating: data/classification/val/8/05371.jpg  \n","  inflating: data/classification/val/8/05389.jpg  \n","  inflating: data/classification/val/8/05406.jpg  \n","  inflating: data/classification/val/8/05411.jpg  \n","  inflating: data/classification/val/8/05412.jpg  \n","  inflating: data/classification/val/8/05413.jpg  \n","  inflating: data/classification/val/8/05417.jpg  \n","  inflating: data/classification/val/8/05425.jpg  \n","  inflating: data/classification/val/8/05431.jpg  \n","  inflating: data/classification/val/8/05439.jpg  \n","  inflating: data/classification/val/8/05443.jpg  \n","  inflating: data/classification/val/8/05450.jpg  \n","  inflating: data/classification/val/8/05452.jpg  \n","  inflating: data/classification/val/8/05457.jpg  \n","  inflating: data/classification/val/8/05459.jpg  \n","  inflating: data/classification/val/8/05462.jpg  \n","  inflating: data/classification/val/8/05493.jpg  \n","  inflating: data/classification/val/8/05497.jpg  \n","  inflating: data/classification/val/8/05503.jpg  \n","  inflating: data/classification/val/8/05518.jpg  \n","  inflating: data/classification/val/8/05531.jpg  \n","  inflating: data/classification/val/8/05548.jpg  \n","  inflating: data/classification/val/8/05560.jpg  \n","  inflating: data/classification/val/8/05565.jpg  \n","  inflating: data/classification/val/8/05573.jpg  \n","  inflating: data/classification/val/8/05586.jpg  \n","  inflating: data/classification/val/8/05589.jpg  \n","  inflating: data/classification/val/8/05592.jpg  \n","  inflating: data/classification/val/8/05601.jpg  \n","  inflating: data/classification/val/8/05604.jpg  \n","  inflating: data/classification/val/8/05605.jpg  \n","  inflating: data/classification/val/8/05616.jpg  \n","  inflating: data/classification/val/8/05620.jpg  \n","  inflating: data/classification/val/8/05632.jpg  \n","  inflating: data/classification/val/8/05636.jpg  \n","  inflating: data/classification/val/8/05639.jpg  \n","  inflating: data/classification/val/8/05653.jpg  \n","  inflating: data/classification/val/8/05661.jpg  \n","  inflating: data/classification/val/8/05699.jpg  \n","  inflating: data/classification/val/8/05715.jpg  \n","  inflating: data/classification/val/8/05717.jpg  \n","  inflating: data/classification/val/8/05725.jpg  \n","  inflating: data/classification/val/8/05727.jpg  \n","  inflating: data/classification/val/8/05737.jpg  \n","  inflating: data/classification/val/8/05750.jpg  \n","  inflating: data/classification/val/8/05751.jpg  \n","  inflating: data/classification/val/8/05767.jpg  \n","  inflating: data/classification/val/8/05769.jpg  \n","  inflating: data/classification/val/8/05773.jpg  \n","  inflating: data/classification/val/8/05790.jpg  \n","  inflating: data/classification/val/8/05794.jpg  \n","  inflating: data/classification/val/8/05807.jpg  \n","  inflating: data/classification/val/8/05839.jpg  \n","  inflating: data/classification/val/8/05844.jpg  \n","  inflating: data/classification/val/8/05845.jpg  \n","  inflating: data/classification/val/8/05848.jpg  \n","  inflating: data/classification/val/8/05854.jpg  \n","  inflating: data/classification/val/8/05858.jpg  \n","  inflating: data/classification/val/8/05869.jpg  \n","  inflating: data/classification/val/8/05890.jpg  \n","  inflating: data/classification/val/8/05898.jpg  \n","  inflating: data/classification/val/8/05913.jpg  \n","  inflating: data/classification/val/8/05918.jpg  \n","  inflating: data/classification/val/8/05943.jpg  \n","  inflating: data/classification/val/8/05968.jpg  \n","  inflating: data/classification/val/8/06011.jpg  \n","  inflating: data/classification/val/8/06012.jpg  \n","  inflating: data/classification/val/8/06015.jpg  \n","  inflating: data/classification/val/8/06020.jpg  \n","  inflating: data/classification/val/80/60848.jpg  \n","  inflating: data/classification/val/80/60855.jpg  \n","  inflating: data/classification/val/80/60861.jpg  \n","  inflating: data/classification/val/80/60864.jpg  \n","  inflating: data/classification/val/80/60887.jpg  \n","  inflating: data/classification/val/80/60900.jpg  \n","  inflating: data/classification/val/80/60907.jpg  \n","  inflating: data/classification/val/81/60936.jpg  \n","  inflating: data/classification/val/81/60938.jpg  \n","  inflating: data/classification/val/81/60944.jpg  \n","  inflating: data/classification/val/81/60958.jpg  \n","  inflating: data/classification/val/81/60960.jpg  \n","  inflating: data/classification/val/81/60963.jpg  \n","  inflating: data/classification/val/81/60989.jpg  \n","  inflating: data/classification/val/81/60998.jpg  \n","  inflating: data/classification/val/81/61005.jpg  \n","  inflating: data/classification/val/81/61010.jpg  \n","  inflating: data/classification/val/82/61024.jpg  \n","  inflating: data/classification/val/82/61032.jpg  \n","  inflating: data/classification/val/82/61045.jpg  \n","  inflating: data/classification/val/82/61051.jpg  \n","  inflating: data/classification/val/82/61075.jpg  \n","  inflating: data/classification/val/82/61081.jpg  \n","  inflating: data/classification/val/82/61084.jpg  \n","  inflating: data/classification/val/82/61089.jpg  \n","  inflating: data/classification/val/82/61108.jpg  \n","  inflating: data/classification/val/82/61112.jpg  \n","  inflating: data/classification/val/82/61147.jpg  \n","  inflating: data/classification/val/82/61148.jpg  \n","  inflating: data/classification/val/82/61152.jpg  \n","  inflating: data/classification/val/82/61168.jpg  \n","  inflating: data/classification/val/82/61170.jpg  \n","  inflating: data/classification/val/82/61174.jpg  \n","  inflating: data/classification/val/82/61187.jpg  \n","  inflating: data/classification/val/82/61199.jpg  \n","  inflating: data/classification/val/82/61201.jpg  \n","  inflating: data/classification/val/82/61204.jpg  \n","  inflating: data/classification/val/82/61229.jpg  \n","  inflating: data/classification/val/82/61233.jpg  \n","  inflating: data/classification/val/82/61238.jpg  \n","  inflating: data/classification/val/82/61250.jpg  \n","  inflating: data/classification/val/82/61251.jpg  \n","  inflating: data/classification/val/82/61288.jpg  \n","  inflating: data/classification/val/82/61291.jpg  \n","  inflating: data/classification/val/82/61309.jpg  \n","  inflating: data/classification/val/82/61311.jpg  \n","  inflating: data/classification/val/82/61320.jpg  \n","  inflating: data/classification/val/82/61327.jpg  \n","  inflating: data/classification/val/82/61328.jpg  \n","  inflating: data/classification/val/82/61330.jpg  \n","  inflating: data/classification/val/82/61331.jpg  \n","  inflating: data/classification/val/82/61341.jpg  \n","  inflating: data/classification/val/82/61344.jpg  \n","  inflating: data/classification/val/82/61346.jpg  \n","  inflating: data/classification/val/82/61356.jpg  \n","  inflating: data/classification/val/82/61397.jpg  \n","  inflating: data/classification/val/82/61411.jpg  \n","  inflating: data/classification/val/82/61419.jpg  \n","  inflating: data/classification/val/82/61421.jpg  \n","  inflating: data/classification/val/82/61442.jpg  \n","  inflating: data/classification/val/82/61453.jpg  \n","  inflating: data/classification/val/82/61456.jpg  \n","  inflating: data/classification/val/82/61463.jpg  \n","  inflating: data/classification/val/82/61468.jpg  \n","  inflating: data/classification/val/82/61477.jpg  \n","  inflating: data/classification/val/82/61496.jpg  \n","  inflating: data/classification/val/82/61530.jpg  \n","  inflating: data/classification/val/82/61532.jpg  \n","  inflating: data/classification/val/82/61542.jpg  \n","  inflating: data/classification/val/82/61555.jpg  \n","  inflating: data/classification/val/82/61560.jpg  \n","  inflating: data/classification/val/82/61577.jpg  \n","  inflating: data/classification/val/82/61604.jpg  \n","  inflating: data/classification/val/82/61608.jpg  \n","  inflating: data/classification/val/82/61616.jpg  \n","  inflating: data/classification/val/82/61627.jpg  \n","  inflating: data/classification/val/82/61639.jpg  \n","  inflating: data/classification/val/82/61649.jpg  \n","  inflating: data/classification/val/82/61650.jpg  \n","  inflating: data/classification/val/82/61651.jpg  \n","  inflating: data/classification/val/82/61656.jpg  \n","  inflating: data/classification/val/82/61669.jpg  \n","  inflating: data/classification/val/82/61685.jpg  \n","  inflating: data/classification/val/82/61695.jpg  \n","  inflating: data/classification/val/82/61701.jpg  \n","  inflating: data/classification/val/83/61715.jpg  \n","  inflating: data/classification/val/83/61728.jpg  \n","  inflating: data/classification/val/83/61730.jpg  \n","  inflating: data/classification/val/83/61734.jpg  \n","  inflating: data/classification/val/83/61738.jpg  \n","  inflating: data/classification/val/83/61746.jpg  \n","  inflating: data/classification/val/83/61749.jpg  \n","  inflating: data/classification/val/83/61758.jpg  \n","  inflating: data/classification/val/83/61761.jpg  \n","  inflating: data/classification/val/83/61780.jpg  \n","  inflating: data/classification/val/83/61794.jpg  \n","  inflating: data/classification/val/83/61804.jpg  \n","  inflating: data/classification/val/83/61816.jpg  \n","  inflating: data/classification/val/83/61852.jpg  \n","  inflating: data/classification/val/83/61913.jpg  \n","  inflating: data/classification/val/83/61923.jpg  \n","  inflating: data/classification/val/83/61926.jpg  \n","  inflating: data/classification/val/83/61931.jpg  \n","  inflating: data/classification/val/83/61936.jpg  \n","  inflating: data/classification/val/83/61949.jpg  \n","  inflating: data/classification/val/83/61958.jpg  \n","  inflating: data/classification/val/83/61960.jpg  \n","  inflating: data/classification/val/83/61965.jpg  \n","  inflating: data/classification/val/83/61982.jpg  \n","  inflating: data/classification/val/83/61984.jpg  \n","  inflating: data/classification/val/83/61988.jpg  \n","  inflating: data/classification/val/83/61997.jpg  \n","  inflating: data/classification/val/83/62010.jpg  \n","  inflating: data/classification/val/83/62012.jpg  \n","  inflating: data/classification/val/83/62026.jpg  \n","  inflating: data/classification/val/83/62034.jpg  \n","  inflating: data/classification/val/83/62037.jpg  \n","  inflating: data/classification/val/83/62040.jpg  \n","  inflating: data/classification/val/83/62042.jpg  \n","  inflating: data/classification/val/83/62048.jpg  \n","  inflating: data/classification/val/83/62053.jpg  \n","  inflating: data/classification/val/83/62070.jpg  \n","  inflating: data/classification/val/83/62083.jpg  \n","  inflating: data/classification/val/83/62087.jpg  \n","  inflating: data/classification/val/84/62101.jpg  \n","  inflating: data/classification/val/84/62120.jpg  \n","  inflating: data/classification/val/84/62129.jpg  \n","  inflating: data/classification/val/84/62138.jpg  \n","  inflating: data/classification/val/84/62151.jpg  \n","  inflating: data/classification/val/84/62153.jpg  \n","  inflating: data/classification/val/84/62158.jpg  \n","  inflating: data/classification/val/84/62161.jpg  \n","  inflating: data/classification/val/84/62171.jpg  \n","  inflating: data/classification/val/84/62184.jpg  \n","  inflating: data/classification/val/84/62194.jpg  \n","  inflating: data/classification/val/84/62202.jpg  \n","  inflating: data/classification/val/84/62206.jpg  \n","  inflating: data/classification/val/84/62217.jpg  \n","  inflating: data/classification/val/84/62219.jpg  \n","  inflating: data/classification/val/84/62227.jpg  \n","  inflating: data/classification/val/84/62230.jpg  \n","  inflating: data/classification/val/84/62240.jpg  \n","  inflating: data/classification/val/84/62259.jpg  \n","  inflating: data/classification/val/84/62262.jpg  \n","  inflating: data/classification/val/84/62278.jpg  \n","  inflating: data/classification/val/84/62298.jpg  \n","  inflating: data/classification/val/84/62300.jpg  \n","  inflating: data/classification/val/84/62307.jpg  \n","  inflating: data/classification/val/84/62308.jpg  \n","  inflating: data/classification/val/84/62330.jpg  \n","  inflating: data/classification/val/84/62336.jpg  \n","  inflating: data/classification/val/84/62341.jpg  \n","  inflating: data/classification/val/84/62346.jpg  \n","  inflating: data/classification/val/84/62351.jpg  \n","  inflating: data/classification/val/84/62368.jpg  \n","  inflating: data/classification/val/84/62382.jpg  \n","  inflating: data/classification/val/84/62383.jpg  \n","  inflating: data/classification/val/84/62386.jpg  \n","  inflating: data/classification/val/84/62398.jpg  \n","  inflating: data/classification/val/84/62400.jpg  \n","  inflating: data/classification/val/84/62407.jpg  \n","  inflating: data/classification/val/84/62411.jpg  \n","  inflating: data/classification/val/84/62440.jpg  \n","  inflating: data/classification/val/84/62442.jpg  \n","  inflating: data/classification/val/84/62473.jpg  \n","  inflating: data/classification/val/84/62477.jpg  \n","  inflating: data/classification/val/84/62508.jpg  \n","  inflating: data/classification/val/84/62530.jpg  \n","  inflating: data/classification/val/85/62534.jpg  \n","  inflating: data/classification/val/85/62540.jpg  \n","  inflating: data/classification/val/85/62560.jpg  \n","  inflating: data/classification/val/85/62564.jpg  \n","  inflating: data/classification/val/85/62569.jpg  \n","  inflating: data/classification/val/85/62580.jpg  \n","  inflating: data/classification/val/85/62590.jpg  \n","  inflating: data/classification/val/85/62594.jpg  \n","  inflating: data/classification/val/85/62598.jpg  \n","  inflating: data/classification/val/85/62611.jpg  \n","  inflating: data/classification/val/85/62617.jpg  \n","  inflating: data/classification/val/85/62623.jpg  \n","  inflating: data/classification/val/85/62642.jpg  \n","  inflating: data/classification/val/85/62668.jpg  \n","  inflating: data/classification/val/85/62671.jpg  \n","  inflating: data/classification/val/85/62697.jpg  \n","  inflating: data/classification/val/85/62698.jpg  \n","  inflating: data/classification/val/86/62702.jpg  \n","  inflating: data/classification/val/86/62703.jpg  \n","  inflating: data/classification/val/86/62708.jpg  \n","  inflating: data/classification/val/86/62721.jpg  \n","  inflating: data/classification/val/86/62724.jpg  \n","  inflating: data/classification/val/86/62752.jpg  \n","  inflating: data/classification/val/86/62762.jpg  \n","  inflating: data/classification/val/86/62767.jpg  \n","  inflating: data/classification/val/86/62782.jpg  \n","  inflating: data/classification/val/86/62796.jpg  \n","  inflating: data/classification/val/86/62823.jpg  \n","  inflating: data/classification/val/86/62829.jpg  \n","  inflating: data/classification/val/86/62837.jpg  \n","  inflating: data/classification/val/86/62854.jpg  \n","  inflating: data/classification/val/86/62863.jpg  \n","  inflating: data/classification/val/86/62876.jpg  \n","  inflating: data/classification/val/86/62877.jpg  \n","  inflating: data/classification/val/86/62892.jpg  \n","  inflating: data/classification/val/86/62902.jpg  \n","  inflating: data/classification/val/86/62911.jpg  \n","  inflating: data/classification/val/86/62917.jpg  \n","  inflating: data/classification/val/86/62935.jpg  \n","  inflating: data/classification/val/86/62966.jpg  \n","  inflating: data/classification/val/86/62968.jpg  \n","  inflating: data/classification/val/86/62980.jpg  \n","  inflating: data/classification/val/86/63036.jpg  \n","  inflating: data/classification/val/86/63042.jpg  \n","  inflating: data/classification/val/86/63050.jpg  \n","  inflating: data/classification/val/86/63063.jpg  \n","  inflating: data/classification/val/86/63081.jpg  \n","  inflating: data/classification/val/86/63086.jpg  \n","  inflating: data/classification/val/86/63089.jpg  \n","  inflating: data/classification/val/86/63097.jpg  \n","  inflating: data/classification/val/86/63120.jpg  \n","  inflating: data/classification/val/86/63122.jpg  \n","  inflating: data/classification/val/86/63123.jpg  \n","  inflating: data/classification/val/86/63130.jpg  \n","  inflating: data/classification/val/86/63134.jpg  \n","  inflating: data/classification/val/86/63136.jpg  \n","  inflating: data/classification/val/86/63148.jpg  \n","  inflating: data/classification/val/86/63151.jpg  \n","  inflating: data/classification/val/86/63152.jpg  \n","  inflating: data/classification/val/86/63160.jpg  \n","  inflating: data/classification/val/86/63166.jpg  \n","  inflating: data/classification/val/86/63168.jpg  \n","  inflating: data/classification/val/86/63173.jpg  \n","  inflating: data/classification/val/86/63178.jpg  \n","  inflating: data/classification/val/86/63180.jpg  \n","  inflating: data/classification/val/86/63182.jpg  \n","  inflating: data/classification/val/86/63194.jpg  \n","  inflating: data/classification/val/86/63221.jpg  \n","  inflating: data/classification/val/86/63222.jpg  \n","  inflating: data/classification/val/86/63227.jpg  \n","  inflating: data/classification/val/86/63231.jpg  \n","  inflating: data/classification/val/86/63241.jpg  \n","  inflating: data/classification/val/86/63248.jpg  \n","  inflating: data/classification/val/86/63250.jpg  \n","  inflating: data/classification/val/86/63258.jpg  \n","  inflating: data/classification/val/86/63265.jpg  \n","  inflating: data/classification/val/86/63281.jpg  \n","  inflating: data/classification/val/86/63284.jpg  \n","  inflating: data/classification/val/86/63301.jpg  \n","  inflating: data/classification/val/86/63304.jpg  \n","  inflating: data/classification/val/86/63322.jpg  \n","  inflating: data/classification/val/86/63345.jpg  \n","  inflating: data/classification/val/86/63346.jpg  \n","  inflating: data/classification/val/86/63360.jpg  \n","  inflating: data/classification/val/86/63365.jpg  \n","  inflating: data/classification/val/86/63382.jpg  \n","  inflating: data/classification/val/86/63389.jpg  \n","  inflating: data/classification/val/86/63417.jpg  \n","  inflating: data/classification/val/86/63439.jpg  \n","  inflating: data/classification/val/86/63443.jpg  \n","  inflating: data/classification/val/86/63445.jpg  \n","  inflating: data/classification/val/86/63453.jpg  \n","  inflating: data/classification/val/86/63454.jpg  \n","  inflating: data/classification/val/86/63461.jpg  \n","  inflating: data/classification/val/86/63462.jpg  \n","  inflating: data/classification/val/86/63467.jpg  \n","  inflating: data/classification/val/86/63474.jpg  \n","  inflating: data/classification/val/86/63485.jpg  \n","  inflating: data/classification/val/86/63505.jpg  \n","  inflating: data/classification/val/86/63517.jpg  \n","  inflating: data/classification/val/86/63542.jpg  \n","  inflating: data/classification/val/86/63546.jpg  \n","  inflating: data/classification/val/86/63553.jpg  \n","  inflating: data/classification/val/86/63578.jpg  \n","  inflating: data/classification/val/86/63594.jpg  \n","  inflating: data/classification/val/86/63606.jpg  \n","  inflating: data/classification/val/86/63612.jpg  \n","  inflating: data/classification/val/86/63614.jpg  \n","  inflating: data/classification/val/86/63616.jpg  \n","  inflating: data/classification/val/86/63617.jpg  \n","  inflating: data/classification/val/86/63621.jpg  \n","  inflating: data/classification/val/86/63628.jpg  \n","  inflating: data/classification/val/86/63629.jpg  \n","  inflating: data/classification/val/86/63656.jpg  \n","  inflating: data/classification/val/86/63667.jpg  \n","  inflating: data/classification/val/86/63669.jpg  \n","  inflating: data/classification/val/86/63670.jpg  \n","  inflating: data/classification/val/86/63686.jpg  \n","  inflating: data/classification/val/86/63695.jpg  \n","  inflating: data/classification/val/86/63699.jpg  \n","  inflating: data/classification/val/86/63712.jpg  \n","  inflating: data/classification/val/86/63728.jpg  \n","  inflating: data/classification/val/86/63732.jpg  \n","  inflating: data/classification/val/86/63752.jpg  \n","  inflating: data/classification/val/86/63761.jpg  \n","  inflating: data/classification/val/86/63767.jpg  \n","  inflating: data/classification/val/86/63773.jpg  \n","  inflating: data/classification/val/86/63800.jpg  \n","  inflating: data/classification/val/86/63809.jpg  \n","  inflating: data/classification/val/86/63813.jpg  \n","  inflating: data/classification/val/86/63841.jpg  \n","  inflating: data/classification/val/86/63842.jpg  \n","  inflating: data/classification/val/86/63845.jpg  \n","  inflating: data/classification/val/86/63853.jpg  \n","  inflating: data/classification/val/86/63860.jpg  \n","  inflating: data/classification/val/86/63883.jpg  \n","  inflating: data/classification/val/86/63884.jpg  \n","  inflating: data/classification/val/86/63895.jpg  \n","  inflating: data/classification/val/86/63901.jpg  \n","  inflating: data/classification/val/86/63909.jpg  \n","  inflating: data/classification/val/86/63950.jpg  \n","  inflating: data/classification/val/86/63965.jpg  \n","  inflating: data/classification/val/86/63966.jpg  \n","  inflating: data/classification/val/86/63970.jpg  \n","  inflating: data/classification/val/86/63975.jpg  \n","  inflating: data/classification/val/86/63982.jpg  \n","  inflating: data/classification/val/86/63996.jpg  \n","  inflating: data/classification/val/87/64011.jpg  \n","  inflating: data/classification/val/87/64012.jpg  \n","  inflating: data/classification/val/87/64023.jpg  \n","  inflating: data/classification/val/87/64030.jpg  \n","  inflating: data/classification/val/87/64055.jpg  \n","  inflating: data/classification/val/87/64066.jpg  \n","  inflating: data/classification/val/87/64082.jpg  \n","  inflating: data/classification/val/87/64086.jpg  \n","  inflating: data/classification/val/87/64093.jpg  \n","  inflating: data/classification/val/87/64102.jpg  \n","  inflating: data/classification/val/87/64105.jpg  \n","  inflating: data/classification/val/87/64115.jpg  \n","  inflating: data/classification/val/87/64135.jpg  \n","  inflating: data/classification/val/87/64138.jpg  \n","  inflating: data/classification/val/87/64144.jpg  \n","  inflating: data/classification/val/87/64147.jpg  \n","  inflating: data/classification/val/87/64150.jpg  \n","  inflating: data/classification/val/87/64169.jpg  \n","  inflating: data/classification/val/87/64173.jpg  \n","  inflating: data/classification/val/87/64175.jpg  \n","  inflating: data/classification/val/87/64176.jpg  \n","  inflating: data/classification/val/87/64184.jpg  \n","  inflating: data/classification/val/87/64212.jpg  \n","  inflating: data/classification/val/87/64216.jpg  \n","  inflating: data/classification/val/87/64233.jpg  \n","  inflating: data/classification/val/87/64256.jpg  \n","  inflating: data/classification/val/87/64267.jpg  \n","  inflating: data/classification/val/87/64281.jpg  \n","  inflating: data/classification/val/87/64294.jpg  \n","  inflating: data/classification/val/87/64305.jpg  \n","  inflating: data/classification/val/87/64313.jpg  \n","  inflating: data/classification/val/88/64321.jpg  \n","  inflating: data/classification/val/88/64324.jpg  \n","  inflating: data/classification/val/88/64335.jpg  \n","  inflating: data/classification/val/88/64352.jpg  \n","  inflating: data/classification/val/88/64354.jpg  \n","  inflating: data/classification/val/88/64394.jpg  \n","  inflating: data/classification/val/88/64397.jpg  \n","  inflating: data/classification/val/88/64402.jpg  \n","  inflating: data/classification/val/88/64407.jpg  \n","  inflating: data/classification/val/88/64409.jpg  \n","  inflating: data/classification/val/88/64423.jpg  \n","  inflating: data/classification/val/88/64428.jpg  \n","  inflating: data/classification/val/88/64432.jpg  \n","  inflating: data/classification/val/88/64460.jpg  \n","  inflating: data/classification/val/88/64490.jpg  \n","  inflating: data/classification/val/88/64495.jpg  \n","  inflating: data/classification/val/88/64496.jpg  \n","  inflating: data/classification/val/88/64500.jpg  \n","  inflating: data/classification/val/88/64501.jpg  \n","  inflating: data/classification/val/88/64506.jpg  \n","  inflating: data/classification/val/88/64514.jpg  \n","  inflating: data/classification/val/88/64535.jpg  \n","  inflating: data/classification/val/88/64547.jpg  \n","  inflating: data/classification/val/88/64566.jpg  \n","  inflating: data/classification/val/88/64573.jpg  \n","  inflating: data/classification/val/88/64577.jpg  \n","  inflating: data/classification/val/88/64585.jpg  \n","  inflating: data/classification/val/88/64588.jpg  \n","  inflating: data/classification/val/88/64598.jpg  \n","  inflating: data/classification/val/88/64614.jpg  \n","  inflating: data/classification/val/88/64619.jpg  \n","  inflating: data/classification/val/88/64630.jpg  \n","  inflating: data/classification/val/88/64631.jpg  \n","  inflating: data/classification/val/88/64639.jpg  \n","  inflating: data/classification/val/88/64646.jpg  \n","  inflating: data/classification/val/88/64652.jpg  \n","  inflating: data/classification/val/88/64661.jpg  \n","  inflating: data/classification/val/88/64682.jpg  \n","  inflating: data/classification/val/88/64708.jpg  \n","  inflating: data/classification/val/88/64712.jpg  \n","  inflating: data/classification/val/89/64720.jpg  \n","  inflating: data/classification/val/89/64728.jpg  \n","  inflating: data/classification/val/89/64743.jpg  \n","  inflating: data/classification/val/89/64748.jpg  \n","  inflating: data/classification/val/89/64775.jpg  \n","  inflating: data/classification/val/89/64777.jpg  \n","  inflating: data/classification/val/89/64790.jpg  \n","  inflating: data/classification/val/89/64794.jpg  \n","  inflating: data/classification/val/89/64815.jpg  \n","  inflating: data/classification/val/89/64821.jpg  \n","  inflating: data/classification/val/89/64829.jpg  \n","  inflating: data/classification/val/89/64850.jpg  \n","  inflating: data/classification/val/89/64852.jpg  \n","  inflating: data/classification/val/89/64866.jpg  \n","  inflating: data/classification/val/89/64876.jpg  \n","  inflating: data/classification/val/89/64877.jpg  \n","  inflating: data/classification/val/89/64882.jpg  \n","  inflating: data/classification/val/89/64896.jpg  \n","  inflating: data/classification/val/89/64898.jpg  \n","  inflating: data/classification/val/9/06037.jpg  \n","  inflating: data/classification/val/9/06041.jpg  \n","  inflating: data/classification/val/9/06047.jpg  \n","  inflating: data/classification/val/9/06053.jpg  \n","  inflating: data/classification/val/9/06065.jpg  \n","  inflating: data/classification/val/9/06081.jpg  \n","  inflating: data/classification/val/9/06084.jpg  \n","  inflating: data/classification/val/9/06094.jpg  \n","  inflating: data/classification/val/9/06108.jpg  \n","  inflating: data/classification/val/9/06110.jpg  \n","  inflating: data/classification/val/9/06136.jpg  \n","  inflating: data/classification/val/9/06137.jpg  \n","  inflating: data/classification/val/9/06138.jpg  \n","  inflating: data/classification/val/9/06142.jpg  \n","  inflating: data/classification/val/9/06155.jpg  \n","  inflating: data/classification/val/9/06156.jpg  \n","  inflating: data/classification/val/9/06165.jpg  \n","  inflating: data/classification/val/9/06182.jpg  \n","  inflating: data/classification/val/9/06183.jpg  \n","  inflating: data/classification/val/9/06195.jpg  \n","  inflating: data/classification/val/9/06198.jpg  \n","  inflating: data/classification/val/9/06211.jpg  \n","  inflating: data/classification/val/9/06226.jpg  \n","  inflating: data/classification/val/9/06236.jpg  \n","  inflating: data/classification/val/9/06237.jpg  \n","  inflating: data/classification/val/9/06241.jpg  \n","  inflating: data/classification/val/9/06246.jpg  \n","  inflating: data/classification/val/9/06247.jpg  \n","  inflating: data/classification/val/9/06249.jpg  \n","  inflating: data/classification/val/9/06251.jpg  \n","  inflating: data/classification/val/9/06256.jpg  \n","  inflating: data/classification/val/9/06270.jpg  \n","  inflating: data/classification/val/9/06309.jpg  \n","  inflating: data/classification/val/9/06310.jpg  \n","  inflating: data/classification/val/9/06314.jpg  \n","  inflating: data/classification/val/9/06315.jpg  \n","  inflating: data/classification/val/9/06332.jpg  \n","  inflating: data/classification/val/9/06358.jpg  \n","  inflating: data/classification/val/9/06360.jpg  \n","  inflating: data/classification/val/9/06379.jpg  \n","  inflating: data/classification/val/9/06381.jpg  \n","  inflating: data/classification/val/9/06388.jpg  \n","  inflating: data/classification/val/9/06392.jpg  \n","  inflating: data/classification/val/9/06403.jpg  \n","  inflating: data/classification/val/9/06441.jpg  \n","  inflating: data/classification/val/9/06442.jpg  \n","  inflating: data/classification/val/9/06479.jpg  \n","  inflating: data/classification/val/9/06485.jpg  \n","  inflating: data/classification/val/9/06493.jpg  \n","  inflating: data/classification/val/9/06520.jpg  \n","  inflating: data/classification/val/9/06521.jpg  \n","  inflating: data/classification/val/9/06528.jpg  \n","  inflating: data/classification/val/9/06540.jpg  \n","  inflating: data/classification/val/9/06555.jpg  \n","  inflating: data/classification/val/9/06565.jpg  \n","  inflating: data/classification/val/9/06568.jpg  \n","  inflating: data/classification/val/90/64934.jpg  \n","  inflating: data/classification/val/90/64954.jpg  \n","  inflating: data/classification/val/90/64970.jpg  \n","  inflating: data/classification/val/90/64974.jpg  \n","  inflating: data/classification/val/90/64992.jpg  \n","  inflating: data/classification/val/90/65001.jpg  \n","  inflating: data/classification/val/90/65041.jpg  \n","  inflating: data/classification/val/90/65043.jpg  \n","  inflating: data/classification/val/90/65048.jpg  \n","  inflating: data/classification/val/90/65055.jpg  \n","  inflating: data/classification/val/90/65058.jpg  \n","  inflating: data/classification/val/90/65060.jpg  \n","  inflating: data/classification/val/90/65065.jpg  \n","  inflating: data/classification/val/90/65066.jpg  \n","  inflating: data/classification/val/90/65077.jpg  \n","  inflating: data/classification/val/90/65086.jpg  \n","  inflating: data/classification/val/90/65088.jpg  \n","  inflating: data/classification/val/90/65092.jpg  \n","  inflating: data/classification/val/90/65099.jpg  \n","  inflating: data/classification/val/90/65120.jpg  \n","  inflating: data/classification/val/90/65125.jpg  \n","  inflating: data/classification/val/90/65127.jpg  \n","  inflating: data/classification/val/90/65129.jpg  \n","  inflating: data/classification/val/91/65143.jpg  \n","  inflating: data/classification/val/91/65173.jpg  \n","  inflating: data/classification/val/91/65180.jpg  \n","  inflating: data/classification/val/91/65184.jpg  \n","  inflating: data/classification/val/91/65192.jpg  \n","  inflating: data/classification/val/91/65241.jpg  \n","  inflating: data/classification/val/91/65245.jpg  \n","  inflating: data/classification/val/91/65246.jpg  \n","  inflating: data/classification/val/91/65252.jpg  \n","  inflating: data/classification/val/91/65266.jpg  \n","  inflating: data/classification/val/91/65278.jpg  \n","  inflating: data/classification/val/91/65291.jpg  \n","  inflating: data/classification/val/91/65298.jpg  \n","  inflating: data/classification/val/91/65308.jpg  \n","  inflating: data/classification/val/91/65320.jpg  \n","  inflating: data/classification/val/91/65350.jpg  \n","  inflating: data/classification/val/91/65356.jpg  \n","  inflating: data/classification/val/91/65363.jpg  \n","  inflating: data/classification/val/91/65365.jpg  \n","  inflating: data/classification/val/91/65367.jpg  \n","  inflating: data/classification/val/91/65368.jpg  \n","  inflating: data/classification/val/91/65370.jpg  \n","  inflating: data/classification/val/91/65378.jpg  \n","  inflating: data/classification/val/91/65385.jpg  \n","  inflating: data/classification/val/91/65404.jpg  \n","  inflating: data/classification/val/91/65418.jpg  \n","  inflating: data/classification/val/91/65425.jpg  \n","  inflating: data/classification/val/91/65430.jpg  \n","  inflating: data/classification/val/91/65436.jpg  \n","  inflating: data/classification/val/91/65441.jpg  \n","  inflating: data/classification/val/91/65453.jpg  \n","  inflating: data/classification/val/91/65463.jpg  \n","  inflating: data/classification/val/91/65465.jpg  \n","  inflating: data/classification/val/91/65469.jpg  \n","  inflating: data/classification/val/91/65483.jpg  \n","  inflating: data/classification/val/92/65492.jpg  \n","  inflating: data/classification/val/92/65494.jpg  \n","  inflating: data/classification/val/92/65495.jpg  \n","  inflating: data/classification/val/92/65504.jpg  \n","  inflating: data/classification/val/92/65510.jpg  \n","  inflating: data/classification/val/92/65525.jpg  \n","  inflating: data/classification/val/92/65544.jpg  \n","  inflating: data/classification/val/92/65549.jpg  \n","  inflating: data/classification/val/92/65557.jpg  \n","  inflating: data/classification/val/92/65559.jpg  \n","  inflating: data/classification/val/92/65563.jpg  \n","  inflating: data/classification/val/92/65589.jpg  \n","  inflating: data/classification/val/92/65591.jpg  \n","  inflating: data/classification/val/92/65592.jpg  \n","  inflating: data/classification/val/92/65603.jpg  \n","  inflating: data/classification/val/92/65604.jpg  \n","  inflating: data/classification/val/92/65608.jpg  \n","  inflating: data/classification/val/92/65613.jpg  \n","  inflating: data/classification/val/92/65639.jpg  \n","  inflating: data/classification/val/92/65673.jpg  \n","  inflating: data/classification/val/92/65679.jpg  \n","  inflating: data/classification/val/92/65707.jpg  \n","  inflating: data/classification/val/92/65710.jpg  \n","  inflating: data/classification/val/92/65712.jpg  \n","  inflating: data/classification/val/92/65724.jpg  \n","  inflating: data/classification/val/92/65740.jpg  \n","  inflating: data/classification/val/92/65747.jpg  \n","  inflating: data/classification/val/92/65749.jpg  \n","  inflating: data/classification/val/92/65755.jpg  \n","  inflating: data/classification/val/92/65765.jpg  \n","  inflating: data/classification/val/92/65767.jpg  \n","  inflating: data/classification/val/92/65772.jpg  \n","  inflating: data/classification/val/92/65778.jpg  \n","  inflating: data/classification/val/92/65787.jpg  \n","  inflating: data/classification/val/92/65791.jpg  \n","  inflating: data/classification/val/92/65800.jpg  \n","  inflating: data/classification/val/92/65802.jpg  \n","  inflating: data/classification/val/92/65808.jpg  \n","  inflating: data/classification/val/92/65816.jpg  \n","  inflating: data/classification/val/92/65833.jpg  \n","  inflating: data/classification/val/92/65839.jpg  \n","  inflating: data/classification/val/92/65845.jpg  \n","  inflating: data/classification/val/92/65866.jpg  \n","  inflating: data/classification/val/92/65882.jpg  \n","  inflating: data/classification/val/92/65891.jpg  \n","  inflating: data/classification/val/92/65893.jpg  \n","  inflating: data/classification/val/92/65902.jpg  \n","  inflating: data/classification/val/92/65903.jpg  \n","  inflating: data/classification/val/92/65927.jpg  \n","  inflating: data/classification/val/92/65929.jpg  \n","  inflating: data/classification/val/92/65944.jpg  \n","  inflating: data/classification/val/92/65952.jpg  \n","  inflating: data/classification/val/92/65959.jpg  \n","  inflating: data/classification/val/92/65972.jpg  \n","  inflating: data/classification/val/92/65977.jpg  \n","  inflating: data/classification/val/92/66001.jpg  \n","  inflating: data/classification/val/92/66011.jpg  \n","  inflating: data/classification/val/92/66013.jpg  \n","  inflating: data/classification/val/92/66017.jpg  \n","  inflating: data/classification/val/92/66021.jpg  \n","  inflating: data/classification/val/92/66024.jpg  \n","  inflating: data/classification/val/92/66047.jpg  \n","  inflating: data/classification/val/92/66065.jpg  \n","  inflating: data/classification/val/92/66072.jpg  \n","  inflating: data/classification/val/92/66075.jpg  \n","  inflating: data/classification/val/92/66079.jpg  \n","  inflating: data/classification/val/92/66129.jpg  \n","  inflating: data/classification/val/92/66133.jpg  \n","  inflating: data/classification/val/92/66150.jpg  \n","  inflating: data/classification/val/92/66162.jpg  \n","  inflating: data/classification/val/92/66186.jpg  \n","  inflating: data/classification/val/92/66196.jpg  \n","  inflating: data/classification/val/92/66206.jpg  \n","  inflating: data/classification/val/92/66218.jpg  \n","  inflating: data/classification/val/92/66224.jpg  \n","  inflating: data/classification/val/92/66225.jpg  \n","  inflating: data/classification/val/92/66236.jpg  \n","  inflating: data/classification/val/92/66241.jpg  \n","  inflating: data/classification/val/92/66266.jpg  \n","  inflating: data/classification/val/92/66284.jpg  \n","  inflating: data/classification/val/93/66291.jpg  \n","  inflating: data/classification/val/93/66293.jpg  \n","  inflating: data/classification/val/93/66299.jpg  \n","  inflating: data/classification/val/93/66305.jpg  \n","  inflating: data/classification/val/93/66313.jpg  \n","  inflating: data/classification/val/93/66336.jpg  \n","  inflating: data/classification/val/93/66347.jpg  \n","  inflating: data/classification/val/93/66350.jpg  \n","  inflating: data/classification/val/93/66382.jpg  \n","  inflating: data/classification/val/93/66389.jpg  \n","  inflating: data/classification/val/93/66395.jpg  \n","  inflating: data/classification/val/93/66405.jpg  \n","  inflating: data/classification/val/93/66411.jpg  \n","  inflating: data/classification/val/93/66434.jpg  \n","  inflating: data/classification/val/93/66447.jpg  \n","  inflating: data/classification/val/93/66460.jpg  \n","  inflating: data/classification/val/93/66463.jpg  \n","  inflating: data/classification/val/93/66474.jpg  \n","  inflating: data/classification/val/93/66478.jpg  \n","  inflating: data/classification/val/93/66482.jpg  \n","  inflating: data/classification/val/93/66514.jpg  \n","  inflating: data/classification/val/93/66516.jpg  \n","  inflating: data/classification/val/93/66544.jpg  \n","  inflating: data/classification/val/93/66548.jpg  \n","  inflating: data/classification/val/93/66550.jpg  \n","  inflating: data/classification/val/93/66569.jpg  \n","  inflating: data/classification/val/93/66581.jpg  \n","  inflating: data/classification/val/93/66615.jpg  \n","  inflating: data/classification/val/93/66629.jpg  \n","  inflating: data/classification/val/93/66636.jpg  \n","  inflating: data/classification/val/93/66644.jpg  \n","  inflating: data/classification/val/93/66651.jpg  \n","  inflating: data/classification/val/93/66658.jpg  \n","  inflating: data/classification/val/93/66665.jpg  \n","  inflating: data/classification/val/93/66674.jpg  \n","  inflating: data/classification/val/93/66679.jpg  \n","  inflating: data/classification/val/93/66688.jpg  \n","  inflating: data/classification/val/93/66692.jpg  \n","  inflating: data/classification/val/93/66694.jpg  \n","  inflating: data/classification/val/93/66705.jpg  \n","  inflating: data/classification/val/93/66710.jpg  \n","  inflating: data/classification/val/93/66717.jpg  \n","  inflating: data/classification/val/93/66721.jpg  \n","  inflating: data/classification/val/93/66728.jpg  \n","  inflating: data/classification/val/93/66747.jpg  \n","  inflating: data/classification/val/93/66757.jpg  \n","  inflating: data/classification/val/93/66770.jpg  \n","  inflating: data/classification/val/93/66786.jpg  \n","  inflating: data/classification/val/93/66789.jpg  \n","  inflating: data/classification/val/93/66793.jpg  \n","  inflating: data/classification/val/94/66797.jpg  \n","  inflating: data/classification/val/94/66799.jpg  \n","  inflating: data/classification/val/94/66803.jpg  \n","  inflating: data/classification/val/94/66809.jpg  \n","  inflating: data/classification/val/94/66816.jpg  \n","  inflating: data/classification/val/94/66821.jpg  \n","  inflating: data/classification/val/94/66824.jpg  \n","  inflating: data/classification/val/94/66843.jpg  \n","  inflating: data/classification/val/94/66856.jpg  \n","  inflating: data/classification/val/94/66857.jpg  \n","  inflating: data/classification/val/94/66862.jpg  \n","  inflating: data/classification/val/94/66866.jpg  \n","  inflating: data/classification/val/94/66869.jpg  \n","  inflating: data/classification/val/94/66878.jpg  \n","  inflating: data/classification/val/94/66885.jpg  \n","  inflating: data/classification/val/94/66894.jpg  \n","  inflating: data/classification/val/94/66897.jpg  \n","  inflating: data/classification/val/94/66929.jpg  \n","  inflating: data/classification/val/94/66938.jpg  \n","  inflating: data/classification/val/94/66942.jpg  \n","  inflating: data/classification/val/94/66945.jpg  \n","  inflating: data/classification/val/94/66958.jpg  \n","  inflating: data/classification/val/94/66996.jpg  \n","  inflating: data/classification/val/94/67003.jpg  \n","  inflating: data/classification/val/94/67009.jpg  \n","  inflating: data/classification/val/94/67019.jpg  \n","  inflating: data/classification/val/94/67034.jpg  \n","  inflating: data/classification/val/94/67040.jpg  \n","  inflating: data/classification/val/94/67057.jpg  \n","  inflating: data/classification/val/94/67059.jpg  \n","  inflating: data/classification/val/94/67062.jpg  \n","  inflating: data/classification/val/94/67063.jpg  \n","  inflating: data/classification/val/94/67070.jpg  \n","  inflating: data/classification/val/94/67080.jpg  \n","  inflating: data/classification/val/94/67091.jpg  \n","  inflating: data/classification/val/94/67109.jpg  \n","  inflating: data/classification/val/94/67132.jpg  \n","  inflating: data/classification/val/94/67135.jpg  \n","  inflating: data/classification/val/94/67143.jpg  \n","  inflating: data/classification/val/94/67150.jpg  \n","  inflating: data/classification/val/94/67158.jpg  \n","  inflating: data/classification/val/94/67167.jpg  \n","  inflating: data/classification/val/94/67183.jpg  \n","  inflating: data/classification/val/94/67188.jpg  \n","  inflating: data/classification/val/94/67216.jpg  \n","  inflating: data/classification/val/94/67257.jpg  \n","  inflating: data/classification/val/94/67277.jpg  \n","  inflating: data/classification/val/94/67280.jpg  \n","  inflating: data/classification/val/94/67285.jpg  \n","  inflating: data/classification/val/94/67292.jpg  \n","  inflating: data/classification/val/94/67312.jpg  \n","  inflating: data/classification/val/94/67313.jpg  \n","  inflating: data/classification/val/94/67323.jpg  \n","  inflating: data/classification/val/94/67331.jpg  \n","  inflating: data/classification/val/94/67342.jpg  \n","  inflating: data/classification/val/94/67356.jpg  \n","  inflating: data/classification/val/94/67364.jpg  \n","  inflating: data/classification/val/94/67366.jpg  \n","  inflating: data/classification/val/95/67383.jpg  \n","  inflating: data/classification/val/95/67391.jpg  \n","  inflating: data/classification/val/95/67394.jpg  \n","  inflating: data/classification/val/95/67399.jpg  \n","  inflating: data/classification/val/95/67403.jpg  \n","  inflating: data/classification/val/95/67416.jpg  \n","  inflating: data/classification/val/95/67453.jpg  \n","  inflating: data/classification/val/95/67456.jpg  \n","  inflating: data/classification/val/95/67458.jpg  \n","  inflating: data/classification/val/95/67462.jpg  \n","  inflating: data/classification/val/95/67464.jpg  \n","  inflating: data/classification/val/95/67466.jpg  \n","  inflating: data/classification/val/95/67469.jpg  \n","  inflating: data/classification/val/95/67473.jpg  \n","  inflating: data/classification/val/95/67496.jpg  \n","  inflating: data/classification/val/95/67526.jpg  \n","  inflating: data/classification/val/95/67537.jpg  \n","  inflating: data/classification/val/95/67544.jpg  \n","  inflating: data/classification/val/95/67557.jpg  \n","  inflating: data/classification/val/95/67559.jpg  \n","  inflating: data/classification/val/95/67563.jpg  \n","  inflating: data/classification/val/95/67565.jpg  \n","  inflating: data/classification/val/95/67607.jpg  \n","  inflating: data/classification/val/95/67616.jpg  \n","  inflating: data/classification/val/95/67630.jpg  \n","  inflating: data/classification/val/95/67643.jpg  \n","  inflating: data/classification/val/95/67645.jpg  \n","  inflating: data/classification/val/95/67647.jpg  \n","  inflating: data/classification/val/95/67648.jpg  \n","  inflating: data/classification/val/95/67667.jpg  \n","  inflating: data/classification/val/95/67682.jpg  \n","  inflating: data/classification/val/95/67688.jpg  \n","  inflating: data/classification/val/95/67689.jpg  \n","  inflating: data/classification/val/95/67702.jpg  \n","  inflating: data/classification/val/95/67716.jpg  \n","  inflating: data/classification/val/95/67723.jpg  \n","  inflating: data/classification/val/95/67729.jpg  \n","  inflating: data/classification/val/95/67730.jpg  \n","  inflating: data/classification/val/95/67731.jpg  \n","  inflating: data/classification/val/95/67768.jpg  \n","  inflating: data/classification/val/95/67781.jpg  \n","  inflating: data/classification/val/95/67797.jpg  \n","  inflating: data/classification/val/95/67809.jpg  \n","  inflating: data/classification/val/95/67812.jpg  \n","  inflating: data/classification/val/95/67818.jpg  \n","  inflating: data/classification/val/95/67837.jpg  \n","  inflating: data/classification/val/95/67841.jpg  \n","  inflating: data/classification/val/95/67848.jpg  \n","  inflating: data/classification/val/96/67863.jpg  \n","  inflating: data/classification/val/96/67880.jpg  \n","  inflating: data/classification/val/96/67882.jpg  \n","  inflating: data/classification/val/96/67892.jpg  \n","  inflating: data/classification/val/96/67914.jpg  \n","  inflating: data/classification/val/96/67930.jpg  \n","  inflating: data/classification/val/96/67936.jpg  \n","  inflating: data/classification/val/96/67943.jpg  \n","  inflating: data/classification/val/96/67968.jpg  \n","  inflating: data/classification/val/96/67970.jpg  \n","  inflating: data/classification/val/96/67975.jpg  \n","  inflating: data/classification/val/96/67978.jpg  \n","  inflating: data/classification/val/96/67988.jpg  \n","  inflating: data/classification/val/96/67997.jpg  \n","  inflating: data/classification/val/96/67998.jpg  \n","  inflating: data/classification/val/96/68021.jpg  \n","  inflating: data/classification/val/96/68028.jpg  \n","  inflating: data/classification/val/96/68033.jpg  \n","  inflating: data/classification/val/96/68050.jpg  \n","  inflating: data/classification/val/96/68055.jpg  \n","  inflating: data/classification/val/96/68060.jpg  \n","  inflating: data/classification/val/97/68105.jpg  \n","  inflating: data/classification/val/97/68116.jpg  \n","  inflating: data/classification/val/97/68118.jpg  \n","  inflating: data/classification/val/97/68121.jpg  \n","  inflating: data/classification/val/97/68134.jpg  \n","  inflating: data/classification/val/97/68137.jpg  \n","  inflating: data/classification/val/97/68140.jpg  \n","  inflating: data/classification/val/97/68142.jpg  \n","  inflating: data/classification/val/97/68145.jpg  \n","  inflating: data/classification/val/97/68158.jpg  \n","  inflating: data/classification/val/97/68168.jpg  \n","  inflating: data/classification/val/97/68174.jpg  \n","  inflating: data/classification/val/97/68178.jpg  \n","  inflating: data/classification/val/97/68180.jpg  \n","  inflating: data/classification/val/97/68204.jpg  \n","  inflating: data/classification/val/97/68234.jpg  \n","  inflating: data/classification/val/97/68238.jpg  \n","  inflating: data/classification/val/97/68239.jpg  \n","  inflating: data/classification/val/97/68240.jpg  \n","  inflating: data/classification/val/97/68246.jpg  \n","  inflating: data/classification/val/97/68264.jpg  \n","  inflating: data/classification/val/97/68269.jpg  \n","  inflating: data/classification/val/97/68286.jpg  \n","  inflating: data/classification/val/97/68303.jpg  \n","  inflating: data/classification/val/97/68307.jpg  \n","  inflating: data/classification/val/97/68323.jpg  \n","  inflating: data/classification/val/97/68336.jpg  \n","  inflating: data/classification/val/97/68342.jpg  \n","  inflating: data/classification/val/97/68364.jpg  \n","  inflating: data/classification/val/97/68370.jpg  \n","  inflating: data/classification/val/98/68389.jpg  \n","  inflating: data/classification/val/98/68394.jpg  \n","  inflating: data/classification/val/98/68407.jpg  \n","  inflating: data/classification/val/98/68416.jpg  \n","  inflating: data/classification/val/98/68443.jpg  \n","  inflating: data/classification/val/98/68447.jpg  \n","  inflating: data/classification/val/98/68453.jpg  \n","  inflating: data/classification/val/98/68457.jpg  \n","  inflating: data/classification/val/98/68465.jpg  \n","  inflating: data/classification/val/98/68466.jpg  \n","  inflating: data/classification/val/99/68503.jpg  \n","  inflating: data/classification/val/99/68518.jpg  \n","  inflating: data/classification/val/99/68528.jpg  \n","  inflating: data/classification/val/99/68564.jpg  \n","  inflating: data/classification/val/99/68587.jpg  \n","  inflating: data/classification/val/99/68599.jpg  \n","  inflating: data/classification/val/99/68604.jpg  \n","  inflating: data/classification/val/99/68605.jpg  \n","  inflating: data/classification/val/99/68608.jpg  \n","  inflating: data/classification/val/99/68629.jpg  \n","  inflating: data/classification/val/99/68636.jpg  \n","  inflating: data/classification/val/99/68664.jpg  \n","  inflating: data/classification/val/99/68672.jpg  \n","  inflating: data/classification/val/99/68673.jpg  \n","  inflating: data/classification/val/99/68682.jpg  \n","  inflating: data/classification/val/99/68694.jpg  \n","  inflating: data/classification/val/99/68712.jpg  \n","  inflating: data/classification/val/99/68714.jpg  \n","  inflating: data/classification/val/99/68716.jpg  \n","  inflating: data/classification/val/99/68732.jpg  \n","  inflating: data/classification/val/99/68747.jpg  \n","  inflating: data/classification/val/99/68749.jpg  \n","  inflating: data/classification/val/99/68751.jpg  \n","  inflating: data/classification/val/99/68754.jpg  \n","  inflating: data/classification/val/99/68757.jpg  \n","  inflating: data/classification/val/99/68763.jpg  \n","  inflating: data/classification/val/99/68767.jpg  \n","  inflating: data/classification/val/99/68782.jpg  \n","  inflating: data/classification/val/99/68786.jpg  \n","  inflating: data/classification/val/99/68797.jpg  \n","  inflating: data/classification/val/99/68798.jpg  \n","  inflating: data/classification/val/99/68812.jpg  \n","  inflating: data/classification/val/99/68817.jpg  \n","  inflating: data/classification/val/99/68828.jpg  \n","  inflating: data/classification/val/99/68831.jpg  \n","  inflating: data/classification/val/99/68856.jpg  \n","  inflating: data/classification/val/99/68867.jpg  \n","  inflating: data/classification/val/99/68868.jpg  \n","  inflating: data/classification/val/99/68869.jpg  \n","  inflating: data/classification/val/99/68880.jpg  \n","  inflating: data/classification/val/99/68904.jpg  \n","  inflating: data/classification/val/99/68927.jpg  \n","  inflating: data/classification/val/99/68931.jpg  \n","  inflating: data/classification/val/99/68934.jpg  \n","  inflating: data/classification/val/99/68937.jpg  \n","  inflating: data/classification/val/99/68939.jpg  \n","  inflating: data/classification/val/99/68946.jpg  \n","  inflating: data/classification/val/99/68948.jpg  \n","  inflating: data/classification/val/99/68951.jpg  \n","  inflating: data/classification/val/99/68956.jpg  \n","  inflating: data/classification/val/99/68977.jpg  \n","  inflating: data/classification/val/99/68979.jpg  \n","  inflating: data/classification/val/99/68996.jpg  \n","  inflating: data/classification/val/99/69013.jpg  \n","  inflating: data/classification/val/99/69014.jpg  \n","  inflating: data/test.txt           \n","  inflating: data/train.txt          \n","  inflating: data/val.txt            \n"]}],"source":["# Downlaod and extract ip102 data\n","!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1iuSUg2ULE8sDlVa17PCFLYqDrPaeY2Ps' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1iuSUg2ULE8sDlVa17PCFLYqDrPaeY2Ps\" -O ip102.zip && rm -rf /tmp/cookies.txt\n","\n","# https://drive.google.com/file/d/1iuSUg2ULE8sDlVa17PCFLYqDrPaeY2Ps/view?usp=sharing\n","!unzip ip102.zip -d data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":986,"status":"ok","timestamp":1694589616907,"user":{"displayName":"Andreas Louw","userId":"11183032721846533402"},"user_tz":-120},"id":"LkVR32jQqNjx","outputId":"d4579f56-b279-4dc2-fa42-95d714ff5ba1"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-09-13 07:20:15--  https://docs.google.com/uc?export=download&confirm=t&id=1RHCjl0B3hKDtftje-wzEJxkAkzF36GPo\n","Resolving docs.google.com (docs.google.com)... 142.251.12.100, 142.251.12.139, 142.251.12.138, ...\n","Connecting to docs.google.com (docs.google.com)|142.251.12.100|:443... connected.\n","HTTP request sent, awaiting response... 303 See Other\n","Location: https://doc-04-bk-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/o84c5q1s53poi4nvncu5qp8qt6f5l0v0/1694589600000/11183032721846533402/*/1RHCjl0B3hKDtftje-wzEJxkAkzF36GPo?e=download&uuid=83e4748e-8818-491e-8e91-aa745c1d719f [following]\n","Warning: wildcards not supported in HTTP.\n","--2023-09-13 07:20:16--  https://doc-04-bk-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/o84c5q1s53poi4nvncu5qp8qt6f5l0v0/1694589600000/11183032721846533402/*/1RHCjl0B3hKDtftje-wzEJxkAkzF36GPo?e=download&uuid=83e4748e-8818-491e-8e91-aa745c1d719f\n","Resolving doc-04-bk-docs.googleusercontent.com (doc-04-bk-docs.googleusercontent.com)... 74.125.24.132, 2404:6800:4003:c03::84\n","Connecting to doc-04-bk-docs.googleusercontent.com (doc-04-bk-docs.googleusercontent.com)|74.125.24.132|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 18135 (18K) [text/x-python]\n","Saving to: ‘cnn.py’\n","\n","cnn.py              100%[===================>]  17.71K  --.-KB/s    in 0s      \n","\n","2023-09-13 07:20:16 (84.4 MB/s) - ‘cnn.py’ saved [18135/18135]\n","\n"]}],"source":["# Downlaod cnn script\n","!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1RHCjl0B3hKDtftje-wzEJxkAkzF36GPo' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1RHCjl0B3hKDtftje-wzEJxkAkzF36GPo\" -O cnn.py && rm -rf /tmp/cookies.txt\n","\n","# https://drive.google.com/file/d/1RHCjl0B3hKDtftje-wzEJxkAkzF36GPo/view?usp=sharing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ej1I0zV6_yv8"},"outputs":[],"source":["\n","    # --dataset_name mnist \\\n","    # --output_dir output/cnn/mnist/mnistoutputs_1/ \\\n","\n","!python cnn.py \\\n","    --model_name microsoft/resnet-18 \\\n","    --model_type resnet \\\n","    --train_dir data/classification/train \\\n","    --validation_dir data/classification/test \\\n","    --output_dir drive/MyDrive/hons-research/output/cnn/ip102_outputs_2/ \\\n","    --remove_unused_columns False \\\n","    --do_train \\\n","    --do_eval \\\n","    --push_to_hub False \\\n","    --optim adamw_torch \\\n","    --learning_rate 0.001 \\\n","    --num_train_epochs 300 \\\n","    --per_device_train_batch_size 512 \\\n","    --per_device_eval_batch_size 512 \\\n","    --logging_strategy steps \\\n","    --logging_steps 10 \\\n","    --evaluation_strategy epoch \\\n","    --save_strategy epoch \\\n","    --load_best_model_at_end True \\\n","    --save_total_limit 3 \\\n","    --save_steps 500 \\\n","    --data_seed 2 \\\n","    --seed 2 \\\n","    --report_to wandb \\\n","    --ignore_mismatched_sizes"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29635,"status":"ok","timestamp":1693512598099,"user":{"displayName":"Andreas Louw","userId":"11183032721846533402"},"user_tz":-120},"id":"bDKpr2NrNr9G","outputId":"ac37880e-cb2e-4ae0-ceb0-d117ce7947b6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["#  from google.colab import drive\n","# drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":38},"executionInfo":{"elapsed":8544,"status":"ok","timestamp":1693512679329,"user":{"displayName":"Andreas Louw","userId":"11183032721846533402"},"user_tz":-120},"id":"bJkXn50NN0v3","outputId":"ad5f347b-f072-47d3-f25f-2a081f7dd6d3"},"outputs":[{"data":{"text/html":["\n","     <input type=\"file\" id=\"files-6f0d1028-6a50-4dac-b473-7b0510644801\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-6f0d1028-6a50-4dac-b473-7b0510644801\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["# from google.colab import files\n","# uploaded = files.upload()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-zKaGqsFPzD3"},"outputs":[],"source":["# !zip -r output.zip output"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mVEh0oiMOMdv"},"outputs":[],"source":["# import shutil\n","# shutil.move('output.zip','/content/drive/MyDrive/hons-research/output')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f2g0Ha4SQ0-G"},"outputs":[],"source":["# End run\n","\n","from google.colab import runtime\n","runtime.unassign()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"gAU8ZpJXhnFG","outputId":"9b3d6308-7daf-40ec-8b40-6bdb9c2c77c0"},"outputs":[{"name":"stdout","output_type":"stream","text":["2023-09-02 17:08:36.394819: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mu15048366\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.9\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20230902_170841-du19mtop\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mcharmed-dream-9\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/u15048366/colabCnnIp102Run1\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/u15048366/colabCnnIp102Run1/runs/du19mtop\u001b[0m\n","09/02/2023 17:08:41 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n","09/02/2023 17:08:41 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n","_n_gpu=1,\n","adafactor=False,\n","adam_beta1=0.9,\n","adam_beta2=0.999,\n","adam_epsilon=1e-08,\n","auto_find_batch_size=False,\n","bf16=False,\n","bf16_full_eval=False,\n","data_seed=3,\n","dataloader_drop_last=False,\n","dataloader_num_workers=0,\n","dataloader_pin_memory=True,\n","ddp_backend=None,\n","ddp_broadcast_buffers=None,\n","ddp_bucket_cap_mb=None,\n","ddp_find_unused_parameters=None,\n","ddp_timeout=1800,\n","debug=[],\n","deepspeed=None,\n","disable_tqdm=False,\n","dispatch_batches=None,\n","do_eval=True,\n","do_predict=False,\n","do_train=True,\n","eval_accumulation_steps=None,\n","eval_delay=0,\n","eval_steps=None,\n","evaluation_strategy=epoch,\n","fp16=False,\n","fp16_backend=auto,\n","fp16_full_eval=False,\n","fp16_opt_level=O1,\n","fsdp=[],\n","fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n","fsdp_min_num_params=0,\n","fsdp_transformer_layer_cls_to_wrap=None,\n","full_determinism=False,\n","gradient_accumulation_steps=1,\n","gradient_checkpointing=False,\n","greater_is_better=False,\n","group_by_length=False,\n","half_precision_backend=auto,\n","hub_always_push=False,\n","hub_model_id=None,\n","hub_private_repo=False,\n","hub_strategy=every_save,\n","hub_token=<HUB_TOKEN>,\n","ignore_data_skip=False,\n","include_inputs_for_metrics=False,\n","jit_mode_eval=False,\n","label_names=None,\n","label_smoothing_factor=0.0,\n","learning_rate=0.001,\n","length_column_name=length,\n","load_best_model_at_end=True,\n","local_rank=0,\n","log_level=passive,\n","log_level_replica=warning,\n","log_on_each_node=True,\n","logging_dir=drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/runs/Sep02_17-08-41_f10132d8a075,\n","logging_first_step=False,\n","logging_nan_inf_filter=True,\n","logging_steps=10,\n","logging_strategy=steps,\n","lr_scheduler_type=linear,\n","max_grad_norm=1.0,\n","max_steps=-1,\n","metric_for_best_model=loss,\n","mp_parameters=,\n","no_cuda=False,\n","num_train_epochs=300.0,\n","optim=adamw_torch,\n","optim_args=None,\n","output_dir=drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/,\n","overwrite_output_dir=False,\n","past_index=-1,\n","per_device_eval_batch_size=512,\n","per_device_train_batch_size=512,\n","prediction_loss_only=False,\n","push_to_hub=False,\n","push_to_hub_model_id=None,\n","push_to_hub_organization=None,\n","push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n","ray_scope=last,\n","remove_unused_columns=False,\n","report_to=['tensorboard', 'wandb'],\n","resume_from_checkpoint=None,\n","run_name=drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/,\n","save_on_each_node=False,\n","save_safetensors=False,\n","save_steps=500.0,\n","save_strategy=epoch,\n","save_total_limit=3,\n","seed=3,\n","sharded_ddp=[],\n","skip_memory_metrics=True,\n","tf32=None,\n","torch_compile=False,\n","torch_compile_backend=None,\n","torch_compile_mode=None,\n","torchdynamo=None,\n","tpu_metrics_debug=False,\n","tpu_num_cores=None,\n","use_cpu=False,\n","use_ipex=False,\n","use_legacy_prediction_loop=False,\n","use_mps_device=False,\n","warmup_ratio=0.0,\n","warmup_steps=0,\n","weight_decay=0.0,\n",")\n","/usr/local/lib/python3.10/dist-packages/datasets/load.py:2086: FutureWarning: 'task' was deprecated in version 2.13.0 and will be removed in 3.0.0.\n","\n","  warnings.warn(\n","Resolving data files: 100% 45095/45095 [00:00<00:00, 359923.84it/s]\n","Resolving data files: 100% 22619/22619 [00:00<00:00, 174930.55it/s]\n","Downloading data files: 100% 45095/45095 [00:00<00:00, 80799.62it/s]\n","Downloading data files: 0it [00:00, ?it/s]\n","Extracting data files: 0it [00:00, ?it/s]\n","Downloading data files: 100% 22619/22619 [00:00<00:00, 81171.84it/s]\n","Downloading data files: 0it [00:00, ?it/s]\n","Extracting data files: 0it [00:00, ?it/s]\n","Generating train split: 45095 examples [00:03, 12529.54 examples/s]\n","Generating validation split: 22619 examples [00:01, 12706.65 examples/s]\n","Casting the dataset: 100% 45095/45095 [00:00<00:00, 58179.89 examples/s] \n","Casting the dataset: 100% 22619/22619 [00:00<00:00, 29071.65 examples/s]\n","Downloading builder script: 100% 4.20k/4.20k [00:00<00:00, 10.9MB/s]\n","\n","\n","\n","None\n","\n","\n","\n","Downloading (…)lve/main/config.json: 100% 69.5k/69.5k [00:00<00:00, 5.78MB/s]\n","[INFO|configuration_utils.py:715] 2023-09-02 17:09:13,234 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--resnet-18/snapshots/f45a6faa12e0381f5620c5c8d7e916bca90f2c44/config.json\n","[INFO|configuration_utils.py:775] 2023-09-02 17:09:13,236 >> Model config ResNetConfig {\n","  \"_name_or_path\": \"microsoft/resnet-18\",\n","  \"architectures\": [\n","    \"ResNetForImageClassification\"\n","  ],\n","  \"depths\": [\n","    2,\n","    2,\n","    2,\n","    2\n","  ],\n","  \"downsample_in_first_stage\": false,\n","  \"embedding_size\": 64,\n","  \"finetuning_task\": \"image-classification\",\n","  \"hidden_act\": \"relu\",\n","  \"hidden_sizes\": [\n","    64,\n","    128,\n","    256,\n","    512\n","  ],\n","  \"id2label\": {\n","    \"0\": \"0\",\n","    \"1\": \"1\",\n","    \"10\": \"16\",\n","    \"100\": \"98\",\n","    \"101\": \"99\",\n","    \"11\": \"17\",\n","    \"12\": \"18\",\n","    \"13\": \"19\",\n","    \"14\": \"2\",\n","    \"15\": \"20\",\n","    \"16\": \"21\",\n","    \"17\": \"22\",\n","    \"18\": \"23\",\n","    \"19\": \"24\",\n","    \"2\": \"10\",\n","    \"20\": \"25\",\n","    \"21\": \"26\",\n","    \"22\": \"27\",\n","    \"23\": \"28\",\n","    \"24\": \"29\",\n","    \"25\": \"3\",\n","    \"26\": \"30\",\n","    \"27\": \"31\",\n","    \"28\": \"32\",\n","    \"29\": \"33\",\n","    \"3\": \"100\",\n","    \"30\": \"34\",\n","    \"31\": \"35\",\n","    \"32\": \"36\",\n","    \"33\": \"37\",\n","    \"34\": \"38\",\n","    \"35\": \"39\",\n","    \"36\": \"4\",\n","    \"37\": \"40\",\n","    \"38\": \"41\",\n","    \"39\": \"42\",\n","    \"4\": \"101\",\n","    \"40\": \"43\",\n","    \"41\": \"44\",\n","    \"42\": \"45\",\n","    \"43\": \"46\",\n","    \"44\": \"47\",\n","    \"45\": \"48\",\n","    \"46\": \"49\",\n","    \"47\": \"5\",\n","    \"48\": \"50\",\n","    \"49\": \"51\",\n","    \"5\": \"11\",\n","    \"50\": \"52\",\n","    \"51\": \"53\",\n","    \"52\": \"54\",\n","    \"53\": \"55\",\n","    \"54\": \"56\",\n","    \"55\": \"57\",\n","    \"56\": \"58\",\n","    \"57\": \"59\",\n","    \"58\": \"6\",\n","    \"59\": \"60\",\n","    \"6\": \"12\",\n","    \"60\": \"61\",\n","    \"61\": \"62\",\n","    \"62\": \"63\",\n","    \"63\": \"64\",\n","    \"64\": \"65\",\n","    \"65\": \"66\",\n","    \"66\": \"67\",\n","    \"67\": \"68\",\n","    \"68\": \"69\",\n","    \"69\": \"7\",\n","    \"7\": \"13\",\n","    \"70\": \"70\",\n","    \"71\": \"71\",\n","    \"72\": \"72\",\n","    \"73\": \"73\",\n","    \"74\": \"74\",\n","    \"75\": \"75\",\n","    \"76\": \"76\",\n","    \"77\": \"77\",\n","    \"78\": \"78\",\n","    \"79\": \"79\",\n","    \"8\": \"14\",\n","    \"80\": \"8\",\n","    \"81\": \"80\",\n","    \"82\": \"81\",\n","    \"83\": \"82\",\n","    \"84\": \"83\",\n","    \"85\": \"84\",\n","    \"86\": \"85\",\n","    \"87\": \"86\",\n","    \"88\": \"87\",\n","    \"89\": \"88\",\n","    \"9\": \"15\",\n","    \"90\": \"89\",\n","    \"91\": \"9\",\n","    \"92\": \"90\",\n","    \"93\": \"91\",\n","    \"94\": \"92\",\n","    \"95\": \"93\",\n","    \"96\": \"94\",\n","    \"97\": \"95\",\n","    \"98\": \"96\",\n","    \"99\": \"97\"\n","  },\n","  \"label2id\": {\n","    \"0\": \"0\",\n","    \"1\": \"1\",\n","    \"10\": \"2\",\n","    \"100\": \"3\",\n","    \"101\": \"4\",\n","    \"11\": \"5\",\n","    \"12\": \"6\",\n","    \"13\": \"7\",\n","    \"14\": \"8\",\n","    \"15\": \"9\",\n","    \"16\": \"10\",\n","    \"17\": \"11\",\n","    \"18\": \"12\",\n","    \"19\": \"13\",\n","    \"2\": \"14\",\n","    \"20\": \"15\",\n","    \"21\": \"16\",\n","    \"22\": \"17\",\n","    \"23\": \"18\",\n","    \"24\": \"19\",\n","    \"25\": \"20\",\n","    \"26\": \"21\",\n","    \"27\": \"22\",\n","    \"28\": \"23\",\n","    \"29\": \"24\",\n","    \"3\": \"25\",\n","    \"30\": \"26\",\n","    \"31\": \"27\",\n","    \"32\": \"28\",\n","    \"33\": \"29\",\n","    \"34\": \"30\",\n","    \"35\": \"31\",\n","    \"36\": \"32\",\n","    \"37\": \"33\",\n","    \"38\": \"34\",\n","    \"39\": \"35\",\n","    \"4\": \"36\",\n","    \"40\": \"37\",\n","    \"41\": \"38\",\n","    \"42\": \"39\",\n","    \"43\": \"40\",\n","    \"44\": \"41\",\n","    \"45\": \"42\",\n","    \"46\": \"43\",\n","    \"47\": \"44\",\n","    \"48\": \"45\",\n","    \"49\": \"46\",\n","    \"5\": \"47\",\n","    \"50\": \"48\",\n","    \"51\": \"49\",\n","    \"52\": \"50\",\n","    \"53\": \"51\",\n","    \"54\": \"52\",\n","    \"55\": \"53\",\n","    \"56\": \"54\",\n","    \"57\": \"55\",\n","    \"58\": \"56\",\n","    \"59\": \"57\",\n","    \"6\": \"58\",\n","    \"60\": \"59\",\n","    \"61\": \"60\",\n","    \"62\": \"61\",\n","    \"63\": \"62\",\n","    \"64\": \"63\",\n","    \"65\": \"64\",\n","    \"66\": \"65\",\n","    \"67\": \"66\",\n","    \"68\": \"67\",\n","    \"69\": \"68\",\n","    \"7\": \"69\",\n","    \"70\": \"70\",\n","    \"71\": \"71\",\n","    \"72\": \"72\",\n","    \"73\": \"73\",\n","    \"74\": \"74\",\n","    \"75\": \"75\",\n","    \"76\": \"76\",\n","    \"77\": \"77\",\n","    \"78\": \"78\",\n","    \"79\": \"79\",\n","    \"8\": \"80\",\n","    \"80\": \"81\",\n","    \"81\": \"82\",\n","    \"82\": \"83\",\n","    \"83\": \"84\",\n","    \"84\": \"85\",\n","    \"85\": \"86\",\n","    \"86\": \"87\",\n","    \"87\": \"88\",\n","    \"88\": \"89\",\n","    \"89\": \"90\",\n","    \"9\": \"91\",\n","    \"90\": \"92\",\n","    \"91\": \"93\",\n","    \"92\": \"94\",\n","    \"93\": \"95\",\n","    \"94\": \"96\",\n","    \"95\": \"97\",\n","    \"96\": \"98\",\n","    \"97\": \"99\",\n","    \"98\": \"100\",\n","    \"99\": \"101\"\n","  },\n","  \"layer_type\": \"basic\",\n","  \"model_type\": \"resnet\",\n","  \"num_channels\": 3,\n","  \"out_features\": [\n","    \"stage4\"\n","  ],\n","  \"out_indices\": [\n","    4\n","  ],\n","  \"stage_names\": [\n","    \"stem\",\n","    \"stage1\",\n","    \"stage2\",\n","    \"stage3\",\n","    \"stage4\"\n","  ],\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.33.0.dev0\"\n","}\n","\n","Downloading model.safetensors: 100% 46.8M/46.8M [00:00<00:00, 161MB/s]\n","[INFO|modeling_utils.py:2857] 2023-09-02 17:09:13,873 >> loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--microsoft--resnet-18/snapshots/f45a6faa12e0381f5620c5c8d7e916bca90f2c44/model.safetensors\n","[INFO|modeling_utils.py:3643] 2023-09-02 17:09:14,047 >> All model checkpoint weights were used when initializing ResNetForImageClassification.\n","\n","[WARNING|modeling_utils.py:3664] 2023-09-02 17:09:14,048 >> Some weights of ResNetForImageClassification were not initialized from the model checkpoint at microsoft/resnet-18 and are newly initialized because the shapes did not match:\n","- classifier.1.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([102]) in the model instantiated\n","- classifier.1.weight: found shape torch.Size([1000, 512]) in the checkpoint and torch.Size([102, 512]) in the model instantiated\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Downloading (…)rocessor_config.json: 100% 266/266 [00:00<00:00, 1.06MB/s]\n","[INFO|image_processing_utils.py:369] 2023-09-02 17:09:14,142 >> loading configuration file preprocessor_config.json from cache at /root/.cache/huggingface/hub/models--microsoft--resnet-18/snapshots/f45a6faa12e0381f5620c5c8d7e916bca90f2c44/preprocessor_config.json\n","[WARNING|image_processing_auto.py:355] 2023-09-02 17:09:14,142 >> Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n","[INFO|image_processing_utils.py:732] 2023-09-02 17:09:14,144 >> size should be a dictionary on of the following set of keys: ({'width', 'height'}, {'shortest_edge'}, {'shortest_edge', 'longest_edge'}, {'longest_edge'}), got 224. Converted to {'shortest_edge': 224}.\n","[INFO|image_processing_utils.py:419] 2023-09-02 17:09:14,144 >> Image processor ConvNextImageProcessor {\n","  \"crop_pct\": 0.875,\n","  \"do_normalize\": true,\n","  \"do_rescale\": true,\n","  \"do_resize\": true,\n","  \"image_mean\": [\n","    0.485,\n","    0.456,\n","    0.406\n","  ],\n","  \"image_processor_type\": \"ConvNextImageProcessor\",\n","  \"image_std\": [\n","    0.229,\n","    0.224,\n","    0.225\n","  ],\n","  \"resample\": 3,\n","  \"rescale_factor\": 0.00392156862745098,\n","  \"size\": {\n","    \"shortest_edge\": 224\n","  }\n","}\n","\n","[INFO|trainer.py:1712] 2023-09-02 17:09:18,942 >> ***** Running training *****\n","[INFO|trainer.py:1713] 2023-09-02 17:09:18,942 >>   Num examples = 45,095\n","[INFO|trainer.py:1714] 2023-09-02 17:09:18,942 >>   Num Epochs = 300\n","[INFO|trainer.py:1715] 2023-09-02 17:09:18,943 >>   Instantaneous batch size per device = 512\n","[INFO|trainer.py:1718] 2023-09-02 17:09:18,943 >>   Total train batch size (w. parallel, distributed & accumulation) = 512\n","[INFO|trainer.py:1719] 2023-09-02 17:09:18,943 >>   Gradient Accumulation steps = 1\n","[INFO|trainer.py:1720] 2023-09-02 17:09:18,943 >>   Total optimization steps = 26,700\n","[INFO|trainer.py:1721] 2023-09-02 17:09:18,943 >>   Number of trainable parameters = 11,228,838\n","[INFO|integration_utils.py:716] 2023-09-02 17:09:18,954 >> Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n","{'loss': 3.6445, 'learning_rate': 0.0009996254681647941, 'epoch': 0.11}\n","{'loss': 2.911, 'learning_rate': 0.000999250936329588, 'epoch': 0.22}\n","{'loss': 2.7448, 'learning_rate': 0.000998876404494382, 'epoch': 0.34}\n","{'loss': 2.5184, 'learning_rate': 0.000998501872659176, 'epoch': 0.45}\n","{'loss': 2.4341, 'learning_rate': 0.00099812734082397, 'epoch': 0.56}\n","{'loss': 2.3756, 'learning_rate': 0.0009977528089887642, 'epoch': 0.67}\n","{'loss': 2.2989, 'learning_rate': 0.000997378277153558, 'epoch': 0.79}\n","{'loss': 2.257, 'learning_rate': 0.000997003745318352, 'epoch': 0.9}\n","  0% 89/26700 [03:46<9:45:48,  1.32s/it] [INFO|trainer.py:3115] 2023-09-02 17:13:05,542 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3117] 2023-09-02 17:13:05,543 >>   Num examples = 22619\n","[INFO|trainer.py:3120] 2023-09-02 17:13:05,543 >>   Batch size = 512\n","\n","  0% 0/45 [00:00<?, ?it/s]\u001b[A\n","  4% 2/45 [00:02<00:53,  1.25s/it]\u001b[A\n","  7% 3/45 [00:05<01:19,  1.90s/it]\u001b[A\n","  9% 4/45 [00:07<01:26,  2.12s/it]\u001b[A\n"," 11% 5/45 [00:10<01:31,  2.29s/it]\u001b[A\n"," 13% 6/45 [00:13<01:39,  2.55s/it]\u001b[A\n"," 16% 7/45 [00:16<01:42,  2.70s/it]\u001b[A\n"," 18% 8/45 [00:19<01:44,  2.82s/it]\u001b[A\n"," 20% 9/45 [00:22<01:46,  2.95s/it]\u001b[A\n"," 22% 10/45 [00:26<01:47,  3.07s/it]\u001b[A\n"," 24% 11/45 [00:28<01:38,  2.89s/it]\u001b[A\n"," 27% 12/45 [00:31<01:32,  2.81s/it]\u001b[A\n"," 29% 13/45 [00:33<01:25,  2.66s/it]\u001b[A\n"," 31% 14/45 [00:36<01:23,  2.69s/it]\u001b[A\n"," 33% 15/45 [00:38<01:19,  2.64s/it]\u001b[A\n"," 36% 16/45 [00:41<01:18,  2.70s/it]\u001b[A\n"," 38% 17/45 [00:44<01:12,  2.59s/it]\u001b[A\n"," 40% 18/45 [00:46<01:05,  2.41s/it]\u001b[A\n"," 42% 19/45 [00:48<01:03,  2.44s/it]\u001b[A\n"," 44% 20/45 [00:51<01:03,  2.53s/it]\u001b[A\n"," 47% 21/45 [00:53<01:01,  2.57s/it]\u001b[A\n"," 49% 22/45 [00:56<00:58,  2.53s/it]\u001b[A\n"," 51% 23/45 [00:58<00:53,  2.43s/it]\u001b[A\n"," 53% 24/45 [01:01<00:53,  2.55s/it]\u001b[A\n"," 56% 25/45 [01:04<00:52,  2.61s/it]\u001b[A\n"," 58% 26/45 [01:06<00:45,  2.40s/it]\u001b[A\n"," 60% 27/45 [01:09<00:48,  2.72s/it]\u001b[A\n"," 62% 28/45 [01:12<00:48,  2.84s/it]\u001b[A\n"," 64% 29/45 [01:15<00:43,  2.70s/it]\u001b[A\n"," 67% 30/45 [01:17<00:40,  2.69s/it]\u001b[A\n"," 69% 31/45 [01:20<00:39,  2.84s/it]\u001b[A\n"," 71% 32/45 [01:23<00:37,  2.90s/it]\u001b[A\n"," 73% 33/45 [01:26<00:34,  2.85s/it]\u001b[A\n"," 76% 34/45 [01:29<00:31,  2.85s/it]\u001b[A\n"," 78% 35/45 [01:32<00:28,  2.85s/it]\u001b[A\n"," 80% 36/45 [01:35<00:25,  2.83s/it]\u001b[A\n"," 82% 37/45 [01:37<00:21,  2.64s/it]\u001b[A\n"," 84% 38/45 [01:39<00:17,  2.50s/it]\u001b[A\n"," 87% 39/45 [01:41<00:14,  2.42s/it]\u001b[A\n"," 89% 40/45 [01:44<00:12,  2.59s/it]\u001b[A\n"," 91% 41/45 [01:47<00:10,  2.52s/it]\u001b[A\n"," 93% 42/45 [01:49<00:07,  2.48s/it]\u001b[A\n"," 96% 43/45 [01:51<00:04,  2.41s/it]\u001b[A\n","                                        \n","\u001b[A{'eval_loss': 2.353001832962036, 'eval_accuracy': 0.41098191785666915, 'eval_runtime': 118.1064, 'eval_samples_per_second': 191.514, 'eval_steps_per_second': 0.381, 'epoch': 1.0}\n","  0% 89/26700 [05:44<9:45:48,  1.32s/it]\n","100% 45/45 [01:52<00:00,  1.88s/it]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2841] 2023-09-02 17:15:03,655 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-89\n","[INFO|configuration_utils.py:460] 2023-09-02 17:15:03,660 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-89/config.json\n","[INFO|modeling_utils.py:1992] 2023-09-02 17:15:03,772 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-89/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-02 17:15:03,776 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-89/preprocessor_config.json\n","{'loss': 2.2254, 'learning_rate': 0.000996629213483146, 'epoch': 1.01}\n","{'loss': 2.1058, 'learning_rate': 0.0009962546816479402, 'epoch': 1.12}\n","{'loss': 2.0457, 'learning_rate': 0.000995880149812734, 'epoch': 1.24}\n","{'loss': 2.0402, 'learning_rate': 0.0009955056179775281, 'epoch': 1.35}\n","{'loss': 1.9635, 'learning_rate': 0.0009951310861423222, 'epoch': 1.46}\n","{'loss': 1.9915, 'learning_rate': 0.0009947565543071161, 'epoch': 1.57}\n","{'loss': 1.9955, 'learning_rate': 0.0009943820224719102, 'epoch': 1.69}\n","{'loss': 1.905, 'learning_rate': 0.000994007490636704, 'epoch': 1.8}\n","{'loss': 1.9132, 'learning_rate': 0.0009936329588014982, 'epoch': 1.91}\n","  1% 177/26700 [09:22<13:37:43,  1.85s/it][INFO|trainer.py:3115] 2023-09-02 17:18:41,142 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3117] 2023-09-02 17:18:41,143 >>   Num examples = 22619\n","[INFO|trainer.py:3120] 2023-09-02 17:18:41,143 >>   Batch size = 512\n","\n","  0% 0/45 [00:00<?, ?it/s]\u001b[A\n","  4% 2/45 [00:02<00:53,  1.24s/it]\u001b[A\n","  7% 3/45 [00:05<01:19,  1.89s/it]\u001b[A\n","  9% 4/45 [00:07<01:26,  2.11s/it]\u001b[A\n"," 11% 5/45 [00:10<01:31,  2.29s/it]\u001b[A\n"," 13% 6/45 [00:13<01:39,  2.54s/it]\u001b[A\n"," 16% 7/45 [00:16<01:42,  2.70s/it]\u001b[A\n"," 18% 8/45 [00:19<01:46,  2.89s/it]\u001b[A\n"," 20% 9/45 [00:22<01:47,  2.99s/it]\u001b[A\n"," 22% 10/45 [00:26<01:48,  3.09s/it]\u001b[A\n"," 24% 11/45 [00:28<01:38,  2.89s/it]\u001b[A\n"," 27% 12/45 [00:31<01:32,  2.81s/it]\u001b[A\n"," 29% 13/45 [00:33<01:24,  2.65s/it]\u001b[A\n"," 31% 14/45 [00:36<01:23,  2.68s/it]\u001b[A\n"," 33% 15/45 [00:38<01:18,  2.62s/it]\u001b[A\n"," 36% 16/45 [00:41<01:16,  2.64s/it]\u001b[A\n"," 38% 17/45 [00:43<01:11,  2.56s/it]\u001b[A\n"," 40% 18/45 [00:45<01:04,  2.39s/it]\u001b[A\n"," 42% 19/45 [00:48<01:02,  2.42s/it]\u001b[A\n"," 44% 20/45 [00:51<01:02,  2.51s/it]\u001b[A\n"," 47% 21/45 [00:53<01:01,  2.55s/it]\u001b[A\n"," 49% 22/45 [00:56<00:57,  2.51s/it]\u001b[A\n"," 51% 23/45 [00:58<00:53,  2.41s/it]\u001b[A\n"," 53% 24/45 [01:01<00:53,  2.54s/it]\u001b[A\n"," 56% 25/45 [01:04<00:52,  2.61s/it]\u001b[A\n"," 58% 26/45 [01:05<00:45,  2.40s/it]\u001b[A\n"," 60% 27/45 [01:09<00:46,  2.61s/it]\u001b[A\n"," 62% 28/45 [01:12<00:46,  2.76s/it]\u001b[A\n"," 64% 29/45 [01:14<00:42,  2.65s/it]\u001b[A\n"," 67% 30/45 [01:17<00:39,  2.65s/it]\u001b[A\n"," 69% 31/45 [01:20<00:39,  2.80s/it]\u001b[A\n"," 71% 32/45 [01:23<00:37,  2.89s/it]\u001b[A\n"," 73% 33/45 [01:26<00:34,  2.86s/it]\u001b[A\n"," 76% 34/45 [01:29<00:31,  2.86s/it]\u001b[A\n"," 78% 35/45 [01:31<00:28,  2.85s/it]\u001b[A\n"," 80% 36/45 [01:34<00:25,  2.83s/it]\u001b[A\n"," 82% 37/45 [01:36<00:20,  2.62s/it]\u001b[A\n"," 84% 38/45 [01:38<00:17,  2.46s/it]\u001b[A\n"," 87% 39/45 [01:41<00:14,  2.44s/it]\u001b[A\n"," 89% 40/45 [01:44<00:13,  2.60s/it]\u001b[A\n"," 91% 41/45 [01:46<00:10,  2.52s/it]\u001b[A\n"," 93% 42/45 [01:49<00:07,  2.48s/it]\u001b[A\n"," 96% 43/45 [01:51<00:04,  2.39s/it]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 2.0028018951416016, 'eval_accuracy': 0.48048101153897166, 'eval_runtime': 117.5002, 'eval_samples_per_second': 192.502, 'eval_steps_per_second': 0.383, 'epoch': 2.0}\n","  1% 178/26700 [11:19<13:37:42,  1.85s/it]\n","100% 45/45 [01:51<00:00,  1.86s/it]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2841] 2023-09-02 17:20:38,651 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-178\n","[INFO|configuration_utils.py:460] 2023-09-02 17:20:38,656 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-178/config.json\n","[INFO|modeling_utils.py:1992] 2023-09-02 17:20:38,776 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-178/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-02 17:20:38,781 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-178/preprocessor_config.json\n","{'loss': 1.9238, 'learning_rate': 0.0009932584269662923, 'epoch': 2.02}\n","{'loss': 1.7846, 'learning_rate': 0.0009928838951310862, 'epoch': 2.13}\n","{'loss': 1.8068, 'learning_rate': 0.00099250936329588, 'epoch': 2.25}\n","{'loss': 1.7973, 'learning_rate': 0.0009921348314606742, 'epoch': 2.36}\n","{'loss': 1.771, 'learning_rate': 0.0009917602996254683, 'epoch': 2.47}\n","{'loss': 1.8428, 'learning_rate': 0.0009913857677902622, 'epoch': 2.58}\n","{'loss': 1.7779, 'learning_rate': 0.0009910112359550563, 'epoch': 2.7}\n","{'loss': 1.8005, 'learning_rate': 0.0009906367041198501, 'epoch': 2.81}\n","{'loss': 1.7738, 'learning_rate': 0.0009902621722846442, 'epoch': 2.92}\n","  1% 266/26700 [14:57<13:20:57,  1.82s/it][INFO|trainer.py:3115] 2023-09-02 17:24:16,677 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3117] 2023-09-02 17:24:16,677 >>   Num examples = 22619\n","[INFO|trainer.py:3120] 2023-09-02 17:24:16,678 >>   Batch size = 512\n","\n","  0% 0/45 [00:00<?, ?it/s]\u001b[A\n","  4% 2/45 [00:02<00:53,  1.24s/it]\u001b[A\n","  7% 3/45 [00:05<01:19,  1.89s/it]\u001b[A\n","  9% 4/45 [00:07<01:26,  2.11s/it]\u001b[A\n"," 11% 5/45 [00:10<01:32,  2.32s/it]\u001b[A\n"," 13% 6/45 [00:13<01:40,  2.58s/it]\u001b[A\n"," 16% 7/45 [00:16<01:43,  2.72s/it]\u001b[A\n"," 18% 8/45 [00:19<01:44,  2.82s/it]\u001b[A\n"," 20% 9/45 [00:22<01:46,  2.95s/it]\u001b[A\n"," 22% 10/45 [00:26<01:47,  3.07s/it]\u001b[A\n"," 24% 11/45 [00:28<01:38,  2.90s/it]\u001b[A\n"," 27% 12/45 [00:31<01:32,  2.81s/it]\u001b[A\n"," 29% 13/45 [00:33<01:25,  2.66s/it]\u001b[A\n"," 31% 14/45 [00:36<01:23,  2.68s/it]\u001b[A\n"," 33% 15/45 [00:38<01:18,  2.61s/it]\u001b[A\n"," 36% 16/45 [00:41<01:16,  2.65s/it]\u001b[A\n"," 38% 17/45 [00:43<01:11,  2.56s/it]\u001b[A\n"," 40% 18/45 [00:45<01:04,  2.40s/it]\u001b[A\n"," 42% 19/45 [00:48<01:03,  2.43s/it]\u001b[A\n"," 44% 20/45 [00:51<01:03,  2.52s/it]\u001b[A\n"," 47% 21/45 [00:53<01:01,  2.55s/it]\u001b[A\n"," 49% 22/45 [00:56<00:57,  2.51s/it]\u001b[A\n"," 51% 23/45 [00:58<00:53,  2.43s/it]\u001b[A\n"," 53% 24/45 [01:01<00:53,  2.56s/it]\u001b[A\n"," 56% 25/45 [01:04<00:52,  2.61s/it]\u001b[A\n"," 58% 26/45 [01:05<00:45,  2.40s/it]\u001b[A\n"," 60% 27/45 [01:08<00:46,  2.59s/it]\u001b[A\n"," 62% 28/45 [01:12<00:46,  2.75s/it]\u001b[A\n"," 64% 29/45 [01:14<00:42,  2.64s/it]\u001b[A\n"," 67% 30/45 [01:17<00:39,  2.64s/it]\u001b[A\n"," 69% 31/45 [01:20<00:39,  2.80s/it]\u001b[A\n"," 71% 32/45 [01:23<00:37,  2.87s/it]\u001b[A\n"," 73% 33/45 [01:26<00:34,  2.84s/it]\u001b[A\n"," 76% 34/45 [01:28<00:31,  2.84s/it]\u001b[A\n"," 78% 35/45 [01:31<00:28,  2.85s/it]\u001b[A\n"," 80% 36/45 [01:34<00:25,  2.82s/it]\u001b[A\n"," 82% 37/45 [01:36<00:20,  2.62s/it]\u001b[A\n"," 84% 38/45 [01:38<00:17,  2.46s/it]\u001b[A\n"," 87% 39/45 [01:41<00:14,  2.41s/it]\u001b[A\n"," 89% 40/45 [01:44<00:12,  2.59s/it]\u001b[A\n"," 91% 41/45 [01:46<00:10,  2.52s/it]\u001b[A\n"," 93% 42/45 [01:48<00:07,  2.48s/it]\u001b[A\n"," 96% 43/45 [01:50<00:04,  2.38s/it]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 1.813408374786377, 'eval_accuracy': 0.521375834475441, 'eval_runtime': 117.3625, 'eval_samples_per_second': 192.728, 'eval_steps_per_second': 0.383, 'epoch': 3.0}\n","  1% 267/26700 [16:55<13:20:56,  1.82s/it]\n","100% 45/45 [01:51<00:00,  1.84s/it]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2841] 2023-09-02 17:26:14,047 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-267\n","[INFO|configuration_utils.py:460] 2023-09-02 17:26:14,053 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-267/config.json\n","[INFO|modeling_utils.py:1992] 2023-09-02 17:26:14,164 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-267/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-02 17:26:14,169 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-267/preprocessor_config.json\n","{'loss': 1.743, 'learning_rate': 0.0009898876404494383, 'epoch': 3.03}\n","{'loss': 1.6544, 'learning_rate': 0.0009895131086142322, 'epoch': 3.15}\n","{'loss': 1.6342, 'learning_rate': 0.000989138576779026, 'epoch': 3.26}\n","{'loss': 1.6555, 'learning_rate': 0.0009887640449438202, 'epoch': 3.37}\n","{'loss': 1.633, 'learning_rate': 0.0009883895131086143, 'epoch': 3.48}\n","{'loss': 1.6443, 'learning_rate': 0.0009880149812734082, 'epoch': 3.6}\n","{'loss': 1.6848, 'learning_rate': 0.0009876404494382023, 'epoch': 3.71}\n","{'loss': 1.6497, 'learning_rate': 0.0009872659176029962, 'epoch': 3.82}\n","{'loss': 1.6275, 'learning_rate': 0.0009868913857677903, 'epoch': 3.93}\n","  1% 355/26700 [20:33<14:07:11,  1.93s/it][INFO|trainer.py:3115] 2023-09-02 17:29:52,460 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3117] 2023-09-02 17:29:52,461 >>   Num examples = 22619\n","[INFO|trainer.py:3120] 2023-09-02 17:29:52,461 >>   Batch size = 512\n","\n","  0% 0/45 [00:00<?, ?it/s]\u001b[A\n","  4% 2/45 [00:02<00:53,  1.24s/it]\u001b[A\n","  7% 3/45 [00:05<01:19,  1.88s/it]\u001b[A\n","  9% 4/45 [00:07<01:26,  2.10s/it]\u001b[A\n"," 11% 5/45 [00:10<01:30,  2.27s/it]\u001b[A\n"," 13% 6/45 [00:13<01:38,  2.53s/it]\u001b[A\n"," 16% 7/45 [00:16<01:42,  2.68s/it]\u001b[A\n"," 18% 8/45 [00:19<01:43,  2.80s/it]\u001b[A\n"," 20% 9/45 [00:22<01:45,  2.93s/it]\u001b[A\n"," 22% 10/45 [00:26<01:48,  3.09s/it]\u001b[A\n"," 24% 11/45 [00:28<01:38,  2.91s/it]\u001b[A\n"," 27% 12/45 [00:31<01:33,  2.82s/it]\u001b[A\n"," 29% 13/45 [00:33<01:25,  2.66s/it]\u001b[A\n"," 31% 14/45 [00:36<01:23,  2.68s/it]\u001b[A\n"," 33% 15/45 [00:38<01:18,  2.61s/it]\u001b[A\n"," 36% 16/45 [00:41<01:17,  2.66s/it]\u001b[A\n"," 38% 17/45 [00:43<01:12,  2.58s/it]\u001b[A\n"," 40% 18/45 [00:45<01:05,  2.41s/it]\u001b[A\n"," 42% 19/45 [00:48<01:03,  2.43s/it]\u001b[A\n"," 44% 20/45 [00:51<01:03,  2.52s/it]\u001b[A\n"," 47% 21/45 [00:53<01:01,  2.55s/it]\u001b[A\n"," 49% 22/45 [00:56<00:58,  2.54s/it]\u001b[A\n"," 51% 23/45 [00:58<00:54,  2.47s/it]\u001b[A\n"," 53% 24/45 [01:01<00:54,  2.58s/it]\u001b[A\n"," 56% 25/45 [01:04<00:52,  2.63s/it]\u001b[A\n"," 58% 26/45 [01:06<00:45,  2.41s/it]\u001b[A\n"," 60% 27/45 [01:09<00:46,  2.60s/it]\u001b[A\n"," 62% 28/45 [01:12<00:46,  2.74s/it]\u001b[A\n"," 64% 29/45 [01:14<00:42,  2.65s/it]\u001b[A\n"," 67% 30/45 [01:17<00:39,  2.64s/it]\u001b[A\n"," 69% 31/45 [01:20<00:39,  2.79s/it]\u001b[A\n"," 71% 32/45 [01:23<00:37,  2.87s/it]\u001b[A\n"," 73% 33/45 [01:26<00:34,  2.84s/it]\u001b[A\n"," 76% 34/45 [01:29<00:31,  2.85s/it]\u001b[A\n"," 78% 35/45 [01:31<00:28,  2.85s/it]\u001b[A\n"," 80% 36/45 [01:34<00:25,  2.82s/it]\u001b[A\n"," 82% 37/45 [01:36<00:20,  2.62s/it]\u001b[A\n"," 84% 38/45 [01:38<00:17,  2.49s/it]\u001b[A\n"," 87% 39/45 [01:41<00:14,  2.43s/it]\u001b[A\n"," 89% 40/45 [01:44<00:12,  2.60s/it]\u001b[A\n"," 91% 41/45 [01:46<00:10,  2.52s/it]\u001b[A\n"," 93% 42/45 [01:48<00:07,  2.48s/it]\u001b[A\n"," 96% 43/45 [01:51<00:04,  2.38s/it]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 1.7060071229934692, 'eval_accuracy': 0.5528095848622839, 'eval_runtime': 117.4587, 'eval_samples_per_second': 192.57, 'eval_steps_per_second': 0.383, 'epoch': 4.0}\n","  1% 356/26700 [22:30<14:07:09,  1.93s/it]\n","100% 45/45 [01:51<00:00,  1.85s/it]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2841] 2023-09-02 17:31:49,928 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-356\n","[INFO|configuration_utils.py:460] 2023-09-02 17:31:49,933 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-356/config.json\n","[INFO|modeling_utils.py:1992] 2023-09-02 17:31:50,041 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-356/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-02 17:31:50,045 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-356/preprocessor_config.json\n","[INFO|trainer.py:2928] 2023-09-02 17:31:50,265 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-89] due to args.save_total_limit\n","{'loss': 1.53, 'learning_rate': 0.0009865168539325844, 'epoch': 4.04}\n","{'loss': 1.5604, 'learning_rate': 0.0009861423220973782, 'epoch': 4.16}\n","{'loss': 1.5139, 'learning_rate': 0.0009857677902621723, 'epoch': 4.27}\n","{'loss': 1.5385, 'learning_rate': 0.0009853932584269664, 'epoch': 4.38}\n","{'loss': 1.5759, 'learning_rate': 0.0009850187265917603, 'epoch': 4.49}\n","{'loss': 1.5609, 'learning_rate': 0.0009846441947565542, 'epoch': 4.61}\n","{'loss': 1.5497, 'learning_rate': 0.0009842696629213483, 'epoch': 4.72}\n","{'loss': 1.5627, 'learning_rate': 0.0009838951310861424, 'epoch': 4.83}\n","{'loss': 1.5671, 'learning_rate': 0.0009835205992509363, 'epoch': 4.94}\n","  2% 444/26700 [26:08<14:20:41,  1.97s/it][INFO|trainer.py:3115] 2023-09-02 17:35:27,320 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3117] 2023-09-02 17:35:27,320 >>   Num examples = 22619\n","[INFO|trainer.py:3120] 2023-09-02 17:35:27,321 >>   Batch size = 512\n","\n","  0% 0/45 [00:00<?, ?it/s]\u001b[A\n","  4% 2/45 [00:02<00:54,  1.26s/it]\u001b[A\n","  7% 3/45 [00:05<01:19,  1.90s/it]\u001b[A\n","  9% 4/45 [00:07<01:27,  2.13s/it]\u001b[A\n"," 11% 5/45 [00:10<01:31,  2.29s/it]\u001b[A\n"," 13% 6/45 [00:13<01:42,  2.62s/it]\u001b[A\n"," 16% 7/45 [00:16<01:45,  2.77s/it]\u001b[A\n"," 18% 8/45 [00:19<01:45,  2.86s/it]\u001b[A\n"," 20% 9/45 [00:23<01:46,  2.97s/it]\u001b[A\n"," 22% 10/45 [00:26<01:47,  3.07s/it]\u001b[A\n"," 24% 11/45 [00:29<01:40,  2.96s/it]\u001b[A\n"," 27% 12/45 [00:31<01:35,  2.89s/it]\u001b[A\n"," 29% 13/45 [00:34<01:26,  2.72s/it]\u001b[A\n"," 31% 14/45 [00:36<01:24,  2.72s/it]\u001b[A\n"," 33% 15/45 [00:39<01:19,  2.64s/it]\u001b[A\n"," 36% 16/45 [00:41<01:16,  2.65s/it]\u001b[A\n"," 38% 17/45 [00:44<01:12,  2.57s/it]\u001b[A\n"," 40% 18/45 [00:46<01:05,  2.42s/it]\u001b[A\n"," 42% 19/45 [00:48<01:03,  2.44s/it]\u001b[A\n"," 44% 20/45 [00:51<01:03,  2.53s/it]\u001b[A\n"," 47% 21/45 [00:54<01:01,  2.54s/it]\u001b[A\n"," 49% 22/45 [00:56<00:57,  2.51s/it]\u001b[A\n"," 51% 23/45 [00:58<00:53,  2.43s/it]\u001b[A\n"," 53% 24/45 [01:01<00:53,  2.56s/it]\u001b[A\n"," 56% 25/45 [01:04<00:52,  2.62s/it]\u001b[A\n"," 58% 26/45 [01:06<00:45,  2.40s/it]\u001b[A\n"," 60% 27/45 [01:09<00:46,  2.59s/it]\u001b[A\n"," 62% 28/45 [01:12<00:46,  2.73s/it]\u001b[A\n"," 64% 29/45 [01:14<00:42,  2.65s/it]\u001b[A\n"," 67% 30/45 [01:17<00:39,  2.65s/it]\u001b[A\n"," 69% 31/45 [01:20<00:39,  2.79s/it]\u001b[A\n"," 71% 32/45 [01:23<00:37,  2.86s/it]\u001b[A\n"," 73% 33/45 [01:26<00:34,  2.84s/it]\u001b[A\n"," 76% 34/45 [01:29<00:31,  2.90s/it]\u001b[A\n"," 78% 35/45 [01:32<00:28,  2.88s/it]\u001b[A\n"," 80% 36/45 [01:35<00:25,  2.85s/it]\u001b[A\n"," 82% 37/45 [01:37<00:21,  2.64s/it]\u001b[A\n"," 84% 38/45 [01:39<00:17,  2.47s/it]\u001b[A\n"," 87% 39/45 [01:41<00:14,  2.40s/it]\u001b[A\n"," 89% 40/45 [01:44<00:13,  2.68s/it]\u001b[A\n"," 91% 41/45 [01:47<00:10,  2.58s/it]\u001b[A\n"," 93% 42/45 [01:49<00:07,  2.53s/it]\u001b[A\n"," 96% 43/45 [01:51<00:04,  2.43s/it]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 1.7519913911819458, 'eval_accuracy': 0.5447190415137716, 'eval_runtime': 118.2341, 'eval_samples_per_second': 191.307, 'eval_steps_per_second': 0.381, 'epoch': 5.0}\n","  2% 445/26700 [28:06<14:20:39,  1.97s/it]\n","100% 45/45 [01:52<00:00,  1.88s/it]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2841] 2023-09-02 17:37:25,560 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-445\n","[INFO|configuration_utils.py:460] 2023-09-02 17:37:25,566 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-445/config.json\n","[INFO|modeling_utils.py:1992] 2023-09-02 17:37:25,681 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-445/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-02 17:37:25,686 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-445/preprocessor_config.json\n","[INFO|trainer.py:2928] 2023-09-02 17:37:25,897 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-178] due to args.save_total_limit\n","{'loss': 1.5277, 'learning_rate': 0.0009831460674157304, 'epoch': 5.06}\n","{'loss': 1.4014, 'learning_rate': 0.0009827715355805243, 'epoch': 5.17}\n","{'loss': 1.482, 'learning_rate': 0.0009823970037453184, 'epoch': 5.28}\n","{'loss': 1.4849, 'learning_rate': 0.0009820224719101125, 'epoch': 5.39}\n","{'loss': 1.4652, 'learning_rate': 0.0009816479400749064, 'epoch': 5.51}\n","{'loss': 1.452, 'learning_rate': 0.0009812734082397002, 'epoch': 5.62}\n","{'loss': 1.4614, 'learning_rate': 0.0009808988764044943, 'epoch': 5.73}\n","{'loss': 1.4394, 'learning_rate': 0.0009805243445692884, 'epoch': 5.84}\n","{'loss': 1.4819, 'learning_rate': 0.0009801498127340823, 'epoch': 5.96}\n","  2% 533/26700 [31:44<13:43:50,  1.89s/it][INFO|trainer.py:3115] 2023-09-02 17:41:03,189 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3117] 2023-09-02 17:41:03,189 >>   Num examples = 22619\n","[INFO|trainer.py:3120] 2023-09-02 17:41:03,190 >>   Batch size = 512\n","\n","  0% 0/45 [00:00<?, ?it/s]\u001b[A\n","  4% 2/45 [00:02<00:55,  1.29s/it]\u001b[A\n","  7% 3/45 [00:05<01:20,  1.92s/it]\u001b[A\n","  9% 4/45 [00:07<01:27,  2.13s/it]\u001b[A\n"," 11% 5/45 [00:10<01:31,  2.29s/it]\u001b[A\n"," 13% 6/45 [00:13<01:39,  2.55s/it]\u001b[A\n"," 16% 7/45 [00:16<01:45,  2.77s/it]\u001b[A\n"," 18% 8/45 [00:19<01:46,  2.87s/it]\u001b[A\n"," 20% 9/45 [00:23<01:47,  2.97s/it]\u001b[A\n"," 22% 10/45 [00:26<01:47,  3.07s/it]\u001b[A\n"," 24% 11/45 [00:28<01:38,  2.90s/it]\u001b[A\n"," 27% 12/45 [00:31<01:34,  2.85s/it]\u001b[A\n"," 29% 13/45 [00:33<01:25,  2.68s/it]\u001b[A\n"," 31% 14/45 [00:36<01:23,  2.70s/it]\u001b[A\n"," 33% 15/45 [00:39<01:18,  2.62s/it]\u001b[A\n"," 36% 16/45 [00:41<01:16,  2.63s/it]\u001b[A\n"," 38% 17/45 [00:44<01:11,  2.54s/it]\u001b[A\n"," 40% 18/45 [00:46<01:05,  2.41s/it]\u001b[A\n"," 42% 19/45 [00:48<01:03,  2.43s/it]\u001b[A\n"," 44% 20/45 [00:51<01:03,  2.53s/it]\u001b[A\n"," 47% 21/45 [00:53<01:00,  2.54s/it]\u001b[A\n"," 49% 22/45 [00:56<00:57,  2.49s/it]\u001b[A\n"," 51% 23/45 [00:58<00:52,  2.40s/it]\u001b[A\n"," 53% 24/45 [01:01<00:53,  2.56s/it]\u001b[A\n"," 56% 25/45 [01:04<00:52,  2.61s/it]\u001b[A\n"," 58% 26/45 [01:06<00:45,  2.40s/it]\u001b[A\n"," 60% 27/45 [01:09<00:46,  2.59s/it]\u001b[A\n"," 62% 28/45 [01:12<00:46,  2.72s/it]\u001b[A\n"," 64% 29/45 [01:14<00:42,  2.65s/it]\u001b[A\n"," 67% 30/45 [01:17<00:39,  2.65s/it]\u001b[A\n"," 69% 31/45 [01:20<00:39,  2.80s/it]\u001b[A\n"," 71% 32/45 [01:23<00:37,  2.87s/it]\u001b[A\n"," 73% 33/45 [01:26<00:33,  2.82s/it]\u001b[A\n"," 76% 34/45 [01:29<00:32,  2.95s/it]\u001b[A\n"," 78% 35/45 [01:32<00:29,  2.92s/it]\u001b[A\n"," 80% 36/45 [01:34<00:25,  2.87s/it]\u001b[A\n"," 82% 37/45 [01:37<00:21,  2.66s/it]\u001b[A\n"," 84% 38/45 [01:39<00:17,  2.48s/it]\u001b[A\n"," 87% 39/45 [01:41<00:14,  2.41s/it]\u001b[A\n"," 89% 40/45 [01:44<00:13,  2.63s/it]\u001b[A\n"," 91% 41/45 [01:46<00:10,  2.54s/it]\u001b[A\n"," 93% 42/45 [01:49<00:07,  2.50s/it]\u001b[A\n"," 96% 43/45 [01:51<00:04,  2.40s/it]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 1.6655635833740234, 'eval_accuracy': 0.5596622308678545, 'eval_runtime': 117.7553, 'eval_samples_per_second': 192.085, 'eval_steps_per_second': 0.382, 'epoch': 6.0}\n","  2% 534/26700 [33:41<13:43:48,  1.89s/it]\n","100% 45/45 [01:52<00:00,  1.86s/it]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2841] 2023-09-02 17:43:00,951 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-534\n","[INFO|configuration_utils.py:460] 2023-09-02 17:43:00,956 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-534/config.json\n","[INFO|modeling_utils.py:1992] 2023-09-02 17:43:01,065 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-534/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-02 17:43:01,069 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-534/preprocessor_config.json\n","[INFO|trainer.py:2928] 2023-09-02 17:43:01,279 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-267] due to args.save_total_limit\n","{'loss': 1.3953, 'learning_rate': 0.0009797752808988764, 'epoch': 6.07}\n","{'loss': 1.3588, 'learning_rate': 0.0009794007490636703, 'epoch': 6.18}\n","{'loss': 1.4017, 'learning_rate': 0.0009790262172284644, 'epoch': 6.29}\n","{'loss': 1.3602, 'learning_rate': 0.0009786516853932585, 'epoch': 6.4}\n","{'loss': 1.3765, 'learning_rate': 0.0009782771535580524, 'epoch': 6.52}\n","{'loss': 1.4041, 'learning_rate': 0.0009779026217228465, 'epoch': 6.63}\n","{'loss': 1.3953, 'learning_rate': 0.0009775280898876404, 'epoch': 6.74}\n","{'loss': 1.4185, 'learning_rate': 0.0009771535580524345, 'epoch': 6.85}\n","{'loss': 1.3605, 'learning_rate': 0.0009767790262172286, 'epoch': 6.97}\n","  2% 622/26700 [37:19<13:46:50,  1.90s/it][INFO|trainer.py:3115] 2023-09-02 17:46:38,784 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3117] 2023-09-02 17:46:38,784 >>   Num examples = 22619\n","[INFO|trainer.py:3120] 2023-09-02 17:46:38,784 >>   Batch size = 512\n","\n","  0% 0/45 [00:00<?, ?it/s]\u001b[A\n","  4% 2/45 [00:02<00:58,  1.37s/it]\u001b[A\n","  7% 3/45 [00:05<01:22,  1.95s/it]\u001b[A\n","  9% 4/45 [00:07<01:28,  2.15s/it]\u001b[A\n"," 11% 5/45 [00:10<01:32,  2.30s/it]\u001b[A\n"," 13% 6/45 [00:13<01:39,  2.55s/it]\u001b[A\n"," 16% 7/45 [00:16<01:43,  2.72s/it]\u001b[A\n"," 18% 8/45 [00:19<01:44,  2.83s/it]\u001b[A\n"," 20% 9/45 [00:22<01:45,  2.94s/it]\u001b[A\n"," 22% 10/45 [00:26<01:46,  3.05s/it]\u001b[A\n"," 24% 11/45 [00:28<01:39,  2.92s/it]\u001b[A\n"," 27% 12/45 [00:31<01:34,  2.85s/it]\u001b[A\n"," 29% 13/45 [00:33<01:25,  2.69s/it]\u001b[A\n"," 31% 14/45 [00:36<01:23,  2.71s/it]\u001b[A\n"," 33% 15/45 [00:39<01:18,  2.63s/it]\u001b[A\n"," 36% 16/45 [00:41<01:16,  2.63s/it]\u001b[A\n"," 38% 17/45 [00:44<01:11,  2.55s/it]\u001b[A\n"," 40% 18/45 [00:46<01:05,  2.41s/it]\u001b[A\n"," 42% 19/45 [00:48<01:03,  2.44s/it]\u001b[A\n"," 44% 20/45 [00:51<01:03,  2.54s/it]\u001b[A\n"," 47% 21/45 [00:54<01:01,  2.57s/it]\u001b[A\n"," 49% 22/45 [00:56<00:57,  2.51s/it]\u001b[A\n"," 51% 23/45 [00:58<00:53,  2.41s/it]\u001b[A\n"," 53% 24/45 [01:01<00:53,  2.56s/it]\u001b[A\n"," 56% 25/45 [01:04<00:52,  2.62s/it]\u001b[A\n"," 58% 26/45 [01:06<00:45,  2.41s/it]\u001b[A\n"," 60% 27/45 [01:09<00:46,  2.59s/it]\u001b[A\n"," 62% 28/45 [01:12<00:46,  2.73s/it]\u001b[A\n"," 64% 29/45 [01:14<00:42,  2.64s/it]\u001b[A\n"," 67% 30/45 [01:17<00:39,  2.66s/it]\u001b[A\n"," 69% 31/45 [01:20<00:39,  2.82s/it]\u001b[A\n"," 71% 32/45 [01:23<00:37,  2.88s/it]\u001b[A\n"," 73% 33/45 [01:26<00:34,  2.83s/it]\u001b[A\n"," 76% 34/45 [01:29<00:31,  2.89s/it]\u001b[A\n"," 78% 35/45 [01:32<00:28,  2.89s/it]\u001b[A\n"," 80% 36/45 [01:35<00:25,  2.86s/it]\u001b[A\n"," 82% 37/45 [01:37<00:21,  2.65s/it]\u001b[A\n"," 84% 38/45 [01:39<00:17,  2.48s/it]\u001b[A\n"," 87% 39/45 [01:41<00:14,  2.42s/it]\u001b[A\n"," 89% 40/45 [01:44<00:13,  2.62s/it]\u001b[A\n"," 91% 41/45 [01:47<00:10,  2.54s/it]\u001b[A\n"," 93% 42/45 [01:49<00:07,  2.49s/it]\u001b[A\n"," 96% 43/45 [01:51<00:04,  2.39s/it]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 1.647548794746399, 'eval_accuracy': 0.5791149033997967, 'eval_runtime': 117.8034, 'eval_samples_per_second': 192.006, 'eval_steps_per_second': 0.382, 'epoch': 7.0}\n","  2% 623/26700 [39:17<13:46:48,  1.90s/it]\n","100% 45/45 [01:52<00:00,  1.85s/it]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2841] 2023-09-02 17:48:36,593 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-623\n","[INFO|configuration_utils.py:460] 2023-09-02 17:48:36,599 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-623/config.json\n","[INFO|modeling_utils.py:1992] 2023-09-02 17:48:36,706 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-623/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-02 17:48:36,709 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-623/preprocessor_config.json\n","[INFO|trainer.py:2928] 2023-09-02 17:48:36,919 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-356] due to args.save_total_limit\n","{'loss': 1.2837, 'learning_rate': 0.0009764044943820225, 'epoch': 7.08}\n","{'loss': 1.333, 'learning_rate': 0.0009760299625468166, 'epoch': 7.19}\n","{'loss': 1.289, 'learning_rate': 0.0009756554307116106, 'epoch': 7.3}\n","{'loss': 1.2688, 'learning_rate': 0.0009752808988764044, 'epoch': 7.42}\n","{'loss': 1.3031, 'learning_rate': 0.0009749063670411985, 'epoch': 7.53}\n","{'loss': 1.3128, 'learning_rate': 0.0009745318352059925, 'epoch': 7.64}\n","{'loss': 1.337, 'learning_rate': 0.0009741573033707865, 'epoch': 7.75}\n","{'loss': 1.3442, 'learning_rate': 0.0009737827715355806, 'epoch': 7.87}\n","{'loss': 1.3727, 'learning_rate': 0.0009734082397003745, 'epoch': 7.98}\n","  3% 711/26700 [42:55<12:55:19,  1.79s/it][INFO|trainer.py:3115] 2023-09-02 17:52:14,902 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3117] 2023-09-02 17:52:14,902 >>   Num examples = 22619\n","[INFO|trainer.py:3120] 2023-09-02 17:52:14,902 >>   Batch size = 512\n","\n","  0% 0/45 [00:00<?, ?it/s]\u001b[A\n","  4% 2/45 [00:02<00:57,  1.34s/it]\u001b[A\n","  7% 3/45 [00:05<01:22,  1.96s/it]\u001b[A\n","  9% 4/45 [00:07<01:28,  2.16s/it]\u001b[A\n"," 11% 5/45 [00:10<01:32,  2.31s/it]\u001b[A\n"," 13% 6/45 [00:13<01:39,  2.55s/it]\u001b[A\n"," 16% 7/45 [00:16<01:44,  2.74s/it]\u001b[A\n"," 18% 8/45 [00:19<01:46,  2.87s/it]\u001b[A\n"," 20% 9/45 [00:23<01:47,  2.98s/it]\u001b[A\n"," 22% 10/45 [00:26<01:47,  3.08s/it]\u001b[A\n"," 24% 11/45 [00:28<01:37,  2.87s/it]\u001b[A\n"," 27% 12/45 [00:31<01:33,  2.82s/it]\u001b[A\n"," 29% 13/45 [00:33<01:25,  2.68s/it]\u001b[A\n"," 31% 14/45 [00:36<01:23,  2.70s/it]\u001b[A\n"," 33% 15/45 [00:39<01:18,  2.63s/it]\u001b[A\n"," 36% 16/45 [00:41<01:16,  2.64s/it]\u001b[A\n"," 38% 17/45 [00:44<01:11,  2.56s/it]\u001b[A\n"," 40% 18/45 [00:46<01:05,  2.42s/it]\u001b[A\n"," 42% 19/45 [00:48<01:04,  2.47s/it]\u001b[A\n"," 44% 20/45 [00:51<01:03,  2.56s/it]\u001b[A\n"," 47% 21/45 [00:54<01:01,  2.57s/it]\u001b[A\n"," 49% 22/45 [00:56<00:57,  2.51s/it]\u001b[A\n"," 51% 23/45 [00:58<00:53,  2.42s/it]\u001b[A\n"," 53% 24/45 [01:01<00:53,  2.57s/it]\u001b[A\n"," 56% 25/45 [01:04<00:52,  2.64s/it]\u001b[A\n"," 58% 26/45 [01:06<00:46,  2.43s/it]\u001b[A\n"," 60% 27/45 [01:09<00:46,  2.61s/it]\u001b[A\n"," 62% 28/45 [01:12<00:46,  2.74s/it]\u001b[A\n"," 64% 29/45 [01:14<00:42,  2.65s/it]\u001b[A\n"," 67% 30/45 [01:17<00:40,  2.68s/it]\u001b[A\n"," 69% 31/45 [01:20<00:39,  2.82s/it]\u001b[A\n"," 71% 32/45 [01:23<00:37,  2.89s/it]\u001b[A\n"," 73% 33/45 [01:26<00:34,  2.84s/it]\u001b[A\n"," 76% 34/45 [01:29<00:31,  2.86s/it]\u001b[A\n"," 78% 35/45 [01:32<00:28,  2.88s/it]\u001b[A\n"," 80% 36/45 [01:35<00:25,  2.86s/it]\u001b[A\n"," 82% 37/45 [01:37<00:21,  2.65s/it]\u001b[A\n"," 84% 38/45 [01:39<00:17,  2.48s/it]\u001b[A\n"," 87% 39/45 [01:41<00:14,  2.42s/it]\u001b[A\n"," 89% 40/45 [01:44<00:13,  2.62s/it]\u001b[A\n"," 91% 41/45 [01:47<00:10,  2.57s/it]\u001b[A\n"," 93% 42/45 [01:49<00:07,  2.54s/it]\u001b[A\n"," 96% 43/45 [01:52<00:04,  2.44s/it]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 1.6742361783981323, 'eval_accuracy': 0.5787612184446704, 'eval_runtime': 118.2831, 'eval_samples_per_second': 191.228, 'eval_steps_per_second': 0.38, 'epoch': 8.0}\n","  3% 712/26700 [44:54<12:55:17,  1.79s/it]\n","100% 45/45 [01:52<00:00,  1.89s/it]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2841] 2023-09-02 17:54:13,192 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-712\n","[INFO|configuration_utils.py:460] 2023-09-02 17:54:13,198 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-712/config.json\n","[INFO|modeling_utils.py:1992] 2023-09-02 17:54:13,314 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-712/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-02 17:54:13,318 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-712/preprocessor_config.json\n","[INFO|trainer.py:2928] 2023-09-02 17:54:13,544 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-445] due to args.save_total_limit\n","{'loss': 1.2302, 'learning_rate': 0.0009730337078651685, 'epoch': 8.09}\n","{'loss': 1.2193, 'learning_rate': 0.0009726591760299626, 'epoch': 8.2}\n","{'loss': 1.2428, 'learning_rate': 0.0009722846441947566, 'epoch': 8.31}\n","{'loss': 1.2745, 'learning_rate': 0.0009719101123595506, 'epoch': 8.43}\n","{'loss': 1.2799, 'learning_rate': 0.0009715355805243446, 'epoch': 8.54}\n","{'loss': 1.3038, 'learning_rate': 0.0009711610486891386, 'epoch': 8.65}\n","{'loss': 1.2671, 'learning_rate': 0.0009707865168539325, 'epoch': 8.76}\n","{'loss': 1.3009, 'learning_rate': 0.0009704119850187266, 'epoch': 8.88}\n","{'loss': 1.2828, 'learning_rate': 0.0009700374531835206, 'epoch': 8.99}\n","  3% 800/26700 [48:33<12:40:13,  1.76s/it][INFO|trainer.py:3115] 2023-09-02 17:57:52,028 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3117] 2023-09-02 17:57:52,029 >>   Num examples = 22619\n","[INFO|trainer.py:3120] 2023-09-02 17:57:52,029 >>   Batch size = 512\n","\n","  0% 0/45 [00:00<?, ?it/s]\u001b[A\n","  4% 2/45 [00:02<00:57,  1.34s/it]\u001b[A\n","  7% 3/45 [00:05<01:21,  1.94s/it]\u001b[A\n","  9% 4/45 [00:07<01:27,  2.14s/it]\u001b[A\n"," 11% 5/45 [00:10<01:31,  2.30s/it]\u001b[A\n"," 13% 6/45 [00:13<01:38,  2.54s/it]\u001b[A\n"," 16% 7/45 [00:16<01:43,  2.71s/it]\u001b[A\n"," 18% 8/45 [00:19<01:44,  2.83s/it]\u001b[A\n"," 20% 9/45 [00:22<01:45,  2.94s/it]\u001b[A\n"," 22% 10/45 [00:26<01:46,  3.05s/it]\u001b[A\n"," 24% 11/45 [00:28<01:36,  2.85s/it]\u001b[A\n"," 27% 12/45 [00:31<01:32,  2.79s/it]\u001b[A\n"," 29% 13/45 [00:33<01:24,  2.65s/it]\u001b[A\n"," 31% 14/45 [00:36<01:23,  2.68s/it]\u001b[A\n"," 33% 15/45 [00:38<01:18,  2.61s/it]\u001b[A\n"," 36% 16/45 [00:41<01:15,  2.62s/it]\u001b[A\n"," 38% 17/45 [00:43<01:10,  2.53s/it]\u001b[A\n"," 40% 18/45 [00:45<01:05,  2.41s/it]\u001b[A\n"," 42% 19/45 [00:48<01:03,  2.46s/it]\u001b[A\n"," 44% 20/45 [00:51<01:03,  2.55s/it]\u001b[A\n"," 47% 21/45 [00:53<01:01,  2.56s/it]\u001b[A\n"," 49% 22/45 [00:56<00:57,  2.50s/it]\u001b[A\n"," 51% 23/45 [00:58<00:52,  2.41s/it]\u001b[A\n"," 53% 24/45 [01:01<00:53,  2.57s/it]\u001b[A\n"," 56% 25/45 [01:04<00:52,  2.63s/it]\u001b[A\n"," 58% 26/45 [01:05<00:45,  2.41s/it]\u001b[A\n"," 60% 27/45 [01:08<00:46,  2.59s/it]\u001b[A\n"," 62% 28/45 [01:11<00:46,  2.71s/it]\u001b[A\n"," 64% 29/45 [01:14<00:42,  2.63s/it]\u001b[A\n"," 67% 30/45 [01:17<00:39,  2.64s/it]\u001b[A\n"," 69% 31/45 [01:20<00:38,  2.78s/it]\u001b[A\n"," 71% 32/45 [01:23<00:37,  2.86s/it]\u001b[A\n"," 73% 33/45 [01:25<00:33,  2.82s/it]\u001b[A\n"," 76% 34/45 [01:28<00:31,  2.86s/it]\u001b[A\n"," 78% 35/45 [01:32<00:29,  2.94s/it]\u001b[A\n"," 80% 36/45 [01:34<00:25,  2.89s/it]\u001b[A\n"," 82% 37/45 [01:36<00:21,  2.67s/it]\u001b[A\n"," 84% 38/45 [01:39<00:17,  2.50s/it]\u001b[A\n"," 87% 39/45 [01:41<00:14,  2.42s/it]\u001b[A\n"," 89% 40/45 [01:44<00:13,  2.62s/it]\u001b[A\n"," 91% 41/45 [01:46<00:10,  2.56s/it]\u001b[A\n"," 93% 42/45 [01:49<00:07,  2.51s/it]\u001b[A\n"," 96% 43/45 [01:51<00:04,  2.40s/it]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 1.5698353052139282, 'eval_accuracy': 0.6012644237145762, 'eval_runtime': 117.6699, 'eval_samples_per_second': 192.224, 'eval_steps_per_second': 0.382, 'epoch': 9.0}\n","  3% 801/26700 [50:30<12:40:12,  1.76s/it]\n","100% 45/45 [01:52<00:00,  1.86s/it]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2841] 2023-09-02 17:59:49,706 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-801\n","[INFO|configuration_utils.py:460] 2023-09-02 17:59:49,712 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-801/config.json\n","[INFO|modeling_utils.py:1992] 2023-09-02 17:59:49,821 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-801/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-02 17:59:49,826 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-801/preprocessor_config.json\n","[INFO|trainer.py:2928] 2023-09-02 17:59:50,053 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-534] due to args.save_total_limit\n","{'loss': 1.1847, 'learning_rate': 0.0009696629213483145, 'epoch': 9.1}\n","{'loss': 1.1782, 'learning_rate': 0.0009692883895131086, 'epoch': 9.21}\n","{'loss': 1.1829, 'learning_rate': 0.0009689138576779026, 'epoch': 9.33}\n","{'loss': 1.1722, 'learning_rate': 0.0009685393258426967, 'epoch': 9.44}\n","{'loss': 1.182, 'learning_rate': 0.0009681647940074907, 'epoch': 9.55}\n","{'loss': 1.2279, 'learning_rate': 0.0009677902621722847, 'epoch': 9.66}\n","{'loss': 1.2098, 'learning_rate': 0.0009674157303370787, 'epoch': 9.78}\n","{'loss': 1.2402, 'learning_rate': 0.0009670411985018727, 'epoch': 9.89}\n","{'loss': 1.2707, 'learning_rate': 0.0009666666666666667, 'epoch': 10.0}\n","  3% 890/26700 [54:08<12:54:01,  1.80s/it][INFO|trainer.py:3115] 2023-09-02 18:03:27,690 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3117] 2023-09-02 18:03:27,690 >>   Num examples = 22619\n","[INFO|trainer.py:3120] 2023-09-02 18:03:27,690 >>   Batch size = 512\n","\n","  0% 0/45 [00:00<?, ?it/s]\u001b[A\n","  4% 2/45 [00:02<00:54,  1.27s/it]\u001b[A\n","  7% 3/45 [00:05<01:21,  1.93s/it]\u001b[A\n","  9% 4/45 [00:07<01:28,  2.15s/it]\u001b[A\n"," 11% 5/45 [00:10<01:31,  2.30s/it]\u001b[A\n"," 13% 6/45 [00:13<01:39,  2.56s/it]\u001b[A\n"," 16% 7/45 [00:16<01:43,  2.73s/it]\u001b[A\n"," 18% 8/45 [00:19<01:45,  2.85s/it]\u001b[A\n"," 20% 9/45 [00:23<01:47,  2.98s/it]\u001b[A\n"," 22% 10/45 [00:26<01:47,  3.08s/it]\u001b[A\n"," 24% 11/45 [00:28<01:37,  2.86s/it]\u001b[A\n"," 27% 12/45 [00:31<01:32,  2.79s/it]\u001b[A\n"," 29% 13/45 [00:33<01:25,  2.67s/it]\u001b[A\n"," 31% 14/45 [00:36<01:23,  2.69s/it]\u001b[A\n"," 33% 15/45 [00:38<01:18,  2.62s/it]\u001b[A\n"," 36% 16/45 [00:41<01:16,  2.62s/it]\u001b[A\n"," 38% 17/45 [00:43<01:10,  2.53s/it]\u001b[A\n"," 40% 18/45 [00:45<01:04,  2.39s/it]\u001b[A\n"," 42% 19/45 [00:48<01:03,  2.44s/it]\u001b[A\n"," 44% 20/45 [00:51<01:03,  2.54s/it]\u001b[A\n"," 47% 21/45 [00:53<01:01,  2.56s/it]\u001b[A\n"," 49% 22/45 [00:56<00:57,  2.50s/it]\u001b[A\n"," 51% 23/45 [00:58<00:52,  2.40s/it]\u001b[A\n"," 53% 24/45 [01:01<00:53,  2.55s/it]\u001b[A\n"," 56% 25/45 [01:04<00:52,  2.63s/it]\u001b[A\n"," 58% 26/45 [01:05<00:45,  2.41s/it]\u001b[A\n"," 60% 27/45 [01:09<00:46,  2.59s/it]\u001b[A\n"," 62% 28/45 [01:12<00:46,  2.71s/it]\u001b[A\n"," 64% 29/45 [01:14<00:41,  2.62s/it]\u001b[A\n"," 67% 30/45 [01:17<00:39,  2.64s/it]\u001b[A\n"," 69% 31/45 [01:20<00:39,  2.81s/it]\u001b[A\n"," 71% 32/45 [01:23<00:37,  2.87s/it]\u001b[A\n"," 73% 33/45 [01:26<00:33,  2.83s/it]\u001b[A\n"," 76% 34/45 [01:28<00:31,  2.84s/it]\u001b[A\n"," 78% 35/45 [01:31<00:28,  2.87s/it]\u001b[A\n"," 80% 36/45 [01:34<00:25,  2.85s/it]\u001b[A\n"," 82% 37/45 [01:36<00:21,  2.64s/it]\u001b[A\n"," 84% 38/45 [01:38<00:17,  2.48s/it]\u001b[A\n"," 87% 39/45 [01:41<00:14,  2.48s/it]\u001b[A\n"," 89% 40/45 [01:44<00:13,  2.64s/it]\u001b[A\n"," 91% 41/45 [01:46<00:10,  2.56s/it]\u001b[A\n"," 93% 42/45 [01:49<00:07,  2.52s/it]\u001b[A\n"," 96% 43/45 [01:51<00:04,  2.42s/it]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 1.6441526412963867, 'eval_accuracy': 0.5868959724125735, 'eval_runtime': 117.5957, 'eval_samples_per_second': 192.346, 'eval_steps_per_second': 0.383, 'epoch': 10.0}\n","  3% 890/26700 [56:06<12:54:01,  1.80s/it]\n","100% 45/45 [01:52<00:00,  1.87s/it]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2841] 2023-09-02 18:05:25,293 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-890\n","[INFO|configuration_utils.py:460] 2023-09-02 18:05:25,299 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-890/config.json\n","[INFO|modeling_utils.py:1992] 2023-09-02 18:05:25,409 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-890/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-02 18:05:25,413 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-890/preprocessor_config.json\n","[INFO|trainer.py:2928] 2023-09-02 18:05:25,625 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-623] due to args.save_total_limit\n","{'loss': 1.1342, 'learning_rate': 0.0009662921348314608, 'epoch': 10.11}\n","{'loss': 1.1579, 'learning_rate': 0.0009659176029962548, 'epoch': 10.22}\n","{'loss': 1.1163, 'learning_rate': 0.0009655430711610486, 'epoch': 10.34}\n","{'loss': 1.1148, 'learning_rate': 0.0009651685393258427, 'epoch': 10.45}\n","{'loss': 1.1712, 'learning_rate': 0.0009647940074906367, 'epoch': 10.56}\n","{'loss': 1.2023, 'learning_rate': 0.0009644194756554307, 'epoch': 10.67}\n","{'loss': 1.1683, 'learning_rate': 0.0009640449438202248, 'epoch': 10.79}\n","{'loss': 1.1607, 'learning_rate': 0.0009636704119850187, 'epoch': 10.9}\n","  4% 978/26700 [59:43<13:07:35,  1.84s/it][INFO|trainer.py:3115] 2023-09-02 18:09:02,827 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3117] 2023-09-02 18:09:02,827 >>   Num examples = 22619\n","[INFO|trainer.py:3120] 2023-09-02 18:09:02,827 >>   Batch size = 512\n","\n","  0% 0/45 [00:00<?, ?it/s]\u001b[A\n","  4% 2/45 [00:02<00:54,  1.26s/it]\u001b[A\n","  7% 3/45 [00:05<01:20,  1.93s/it]\u001b[A\n","  9% 4/45 [00:07<01:27,  2.14s/it]\u001b[A\n"," 11% 5/45 [00:10<01:31,  2.29s/it]\u001b[A\n"," 13% 6/45 [00:13<01:38,  2.53s/it]\u001b[A\n"," 16% 7/45 [00:16<01:42,  2.69s/it]\u001b[A\n"," 18% 8/45 [00:19<01:44,  2.83s/it]\u001b[A\n"," 20% 9/45 [00:22<01:46,  2.94s/it]\u001b[A\n"," 22% 10/45 [00:26<01:46,  3.05s/it]\u001b[A\n"," 24% 11/45 [00:28<01:36,  2.84s/it]\u001b[A\n"," 27% 12/45 [00:31<01:31,  2.77s/it]\u001b[A\n"," 29% 13/45 [00:33<01:24,  2.64s/it]\u001b[A\n"," 31% 14/45 [00:36<01:22,  2.68s/it]\u001b[A\n"," 33% 15/45 [00:38<01:18,  2.61s/it]\u001b[A\n"," 36% 16/45 [00:41<01:15,  2.62s/it]\u001b[A\n"," 38% 17/45 [00:43<01:10,  2.53s/it]\u001b[A\n"," 40% 18/45 [00:45<01:04,  2.38s/it]\u001b[A\n"," 42% 19/45 [00:48<01:03,  2.46s/it]\u001b[A\n"," 44% 20/45 [00:51<01:05,  2.62s/it]\u001b[A\n"," 47% 21/45 [00:53<01:02,  2.62s/it]\u001b[A\n"," 49% 22/45 [00:56<00:58,  2.54s/it]\u001b[A\n"," 51% 23/45 [00:58<00:53,  2.43s/it]\u001b[A\n"," 53% 24/45 [01:01<00:53,  2.57s/it]\u001b[A\n"," 56% 25/45 [01:04<00:54,  2.72s/it]\u001b[A\n"," 58% 26/45 [01:06<00:47,  2.48s/it]\u001b[A\n"," 60% 27/45 [01:09<00:47,  2.65s/it]\u001b[A\n"," 62% 28/45 [01:12<00:46,  2.75s/it]\u001b[A\n"," 64% 29/45 [01:14<00:42,  2.65s/it]\u001b[A\n"," 67% 30/45 [01:17<00:40,  2.67s/it]\u001b[A\n"," 69% 31/45 [01:20<00:39,  2.85s/it]\u001b[A\n"," 71% 32/45 [01:23<00:37,  2.90s/it]\u001b[A\n"," 73% 33/45 [01:26<00:34,  2.84s/it]\u001b[A\n"," 76% 34/45 [01:29<00:31,  2.85s/it]\u001b[A\n"," 78% 35/45 [01:32<00:28,  2.87s/it]\u001b[A\n"," 80% 36/45 [01:35<00:25,  2.85s/it]\u001b[A\n"," 82% 37/45 [01:37<00:21,  2.63s/it]\u001b[A\n"," 84% 38/45 [01:39<00:17,  2.47s/it]\u001b[A\n"," 87% 39/45 [01:41<00:14,  2.39s/it]\u001b[A\n"," 89% 40/45 [01:44<00:12,  2.59s/it]\u001b[A\n"," 91% 41/45 [01:47<00:10,  2.59s/it]\u001b[A\n"," 93% 42/45 [01:49<00:07,  2.55s/it]\u001b[A\n"," 96% 43/45 [01:51<00:04,  2.44s/it]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 1.5694068670272827, 'eval_accuracy': 0.6059065387506078, 'eval_runtime': 117.9229, 'eval_samples_per_second': 191.812, 'eval_steps_per_second': 0.382, 'epoch': 11.0}\n","  4% 979/26700 [1:01:41<13:07:33,  1.84s/it]\n","100% 45/45 [01:52<00:00,  1.88s/it]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2841] 2023-09-02 18:11:00,756 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-979\n","[INFO|configuration_utils.py:460] 2023-09-02 18:11:00,762 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-979/config.json\n","[INFO|modeling_utils.py:1992] 2023-09-02 18:11:00,870 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-979/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-02 18:11:00,874 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-979/preprocessor_config.json\n","[INFO|trainer.py:2928] 2023-09-02 18:11:01,085 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-712] due to args.save_total_limit\n","{'loss': 1.1836, 'learning_rate': 0.0009632958801498127, 'epoch': 11.01}\n","{'loss': 1.064, 'learning_rate': 0.0009629213483146068, 'epoch': 11.12}\n","{'loss': 1.1136, 'learning_rate': 0.0009625468164794008, 'epoch': 11.24}\n","{'loss': 1.0875, 'learning_rate': 0.0009621722846441948, 'epoch': 11.35}\n","{'loss': 1.0861, 'learning_rate': 0.0009617977528089888, 'epoch': 11.46}\n","{'loss': 1.1371, 'learning_rate': 0.0009614232209737828, 'epoch': 11.57}\n","{'loss': 1.1086, 'learning_rate': 0.0009610486891385768, 'epoch': 11.69}\n","{'loss': 1.129, 'learning_rate': 0.0009606741573033709, 'epoch': 11.8}\n","{'loss': 1.1419, 'learning_rate': 0.0009602996254681649, 'epoch': 11.91}\n","  4% 1067/26700 [1:05:19<12:57:28,  1.82s/it][INFO|trainer.py:3115] 2023-09-02 18:14:38,053 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3117] 2023-09-02 18:14:38,053 >>   Num examples = 22619\n","[INFO|trainer.py:3120] 2023-09-02 18:14:38,053 >>   Batch size = 512\n","\n","  0% 0/45 [00:00<?, ?it/s]\u001b[A\n","  4% 2/45 [00:02<00:56,  1.31s/it]\u001b[A\n","  7% 3/45 [00:05<01:20,  1.93s/it]\u001b[A\n","  9% 4/45 [00:07<01:27,  2.13s/it]\u001b[A\n"," 11% 5/45 [00:10<01:31,  2.29s/it]\u001b[A\n"," 13% 6/45 [00:13<01:39,  2.55s/it]\u001b[A\n"," 16% 7/45 [00:16<01:43,  2.73s/it]\u001b[A\n"," 18% 8/45 [00:19<01:45,  2.84s/it]\u001b[A\n"," 20% 9/45 [00:22<01:46,  2.96s/it]\u001b[A\n"," 22% 10/45 [00:26<01:47,  3.07s/it]\u001b[A\n"," 24% 11/45 [00:28<01:38,  2.88s/it]\u001b[A\n"," 27% 12/45 [00:31<01:33,  2.83s/it]\u001b[A\n"," 29% 13/45 [00:33<01:25,  2.66s/it]\u001b[A\n"," 31% 14/45 [00:36<01:23,  2.68s/it]\u001b[A\n"," 33% 15/45 [00:38<01:18,  2.62s/it]\u001b[A\n"," 36% 16/45 [00:41<01:16,  2.64s/it]\u001b[A\n"," 38% 17/45 [00:43<01:11,  2.57s/it]\u001b[A\n"," 40% 18/45 [00:46<01:04,  2.40s/it]\u001b[A\n"," 42% 19/45 [00:48<01:03,  2.43s/it]\u001b[A\n"," 44% 20/45 [00:51<01:04,  2.59s/it]\u001b[A\n"," 47% 21/45 [00:54<01:02,  2.59s/it]\u001b[A\n"," 49% 22/45 [00:56<00:58,  2.53s/it]\u001b[A\n"," 51% 23/45 [00:58<00:53,  2.44s/it]\u001b[A\n"," 53% 24/45 [01:01<00:53,  2.56s/it]\u001b[A\n"," 56% 25/45 [01:04<00:52,  2.62s/it]\u001b[A\n"," 58% 26/45 [01:06<00:45,  2.41s/it]\u001b[A\n"," 60% 27/45 [01:09<00:46,  2.60s/it]\u001b[A\n"," 62% 28/45 [01:12<00:46,  2.75s/it]\u001b[A\n"," 64% 29/45 [01:14<00:42,  2.64s/it]\u001b[A\n"," 67% 30/45 [01:17<00:39,  2.64s/it]\u001b[A\n"," 69% 31/45 [01:20<00:39,  2.79s/it]\u001b[A\n"," 71% 32/45 [01:23<00:37,  2.88s/it]\u001b[A\n"," 73% 33/45 [01:26<00:34,  2.88s/it]\u001b[A\n"," 76% 34/45 [01:29<00:31,  2.87s/it]\u001b[A\n"," 78% 35/45 [01:32<00:28,  2.87s/it]\u001b[A\n"," 80% 36/45 [01:34<00:25,  2.84s/it]\u001b[A\n"," 82% 37/45 [01:37<00:21,  2.64s/it]\u001b[A\n"," 84% 38/45 [01:39<00:17,  2.50s/it]\u001b[A\n"," 87% 39/45 [01:41<00:14,  2.42s/it]\u001b[A\n"," 89% 40/45 [01:44<00:12,  2.59s/it]\u001b[A\n"," 91% 41/45 [01:46<00:10,  2.51s/it]\u001b[A\n"," 93% 42/45 [01:49<00:07,  2.48s/it]\u001b[A\n"," 96% 43/45 [01:51<00:04,  2.39s/it]\u001b[A\n","                                             \n","\u001b[A{'eval_loss': 1.6596189737319946, 'eval_accuracy': 0.5886643971882046, 'eval_runtime': 117.6623, 'eval_samples_per_second': 192.237, 'eval_steps_per_second': 0.382, 'epoch': 12.0}\n","  4% 1068/26700 [1:07:16<12:57:26,  1.82s/it]\n","100% 45/45 [01:52<00:00,  1.85s/it]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2841] 2023-09-02 18:16:35,723 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-1068\n","[INFO|configuration_utils.py:460] 2023-09-02 18:16:35,729 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-1068/config.json\n","[INFO|modeling_utils.py:1992] 2023-09-02 18:16:35,846 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-1068/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-02 18:16:35,851 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-1068/preprocessor_config.json\n","[INFO|trainer.py:2928] 2023-09-02 18:16:36,074 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-801] due to args.save_total_limit\n","{'loss': 1.1193, 'learning_rate': 0.0009599250936329587, 'epoch': 12.02}\n","{'loss': 0.9908, 'learning_rate': 0.0009595505617977528, 'epoch': 12.13}\n","{'loss': 1.0684, 'learning_rate': 0.0009591760299625468, 'epoch': 12.25}\n","{'loss': 1.0569, 'learning_rate': 0.0009588014981273408, 'epoch': 12.36}\n","{'loss': 1.0532, 'learning_rate': 0.0009584269662921349, 'epoch': 12.47}\n","{'loss': 1.0789, 'learning_rate': 0.0009580524344569289, 'epoch': 12.58}\n","{'loss': 1.0607, 'learning_rate': 0.0009576779026217228, 'epoch': 12.7}\n","{'loss': 1.0877, 'learning_rate': 0.0009573033707865169, 'epoch': 12.81}\n","{'loss': 1.1066, 'learning_rate': 0.0009569288389513109, 'epoch': 12.92}\n","  4% 1156/26700 [1:10:54<13:06:39,  1.85s/it][INFO|trainer.py:3115] 2023-09-02 18:20:13,234 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3117] 2023-09-02 18:20:13,235 >>   Num examples = 22619\n","[INFO|trainer.py:3120] 2023-09-02 18:20:13,235 >>   Batch size = 512\n","\n","  0% 0/45 [00:00<?, ?it/s]\u001b[A\n","  4% 2/45 [00:02<00:54,  1.26s/it]\u001b[A\n","  7% 3/45 [00:05<01:21,  1.94s/it]\u001b[A\n","  9% 4/45 [00:07<01:27,  2.14s/it]\u001b[A\n"," 11% 5/45 [00:10<01:31,  2.29s/it]\u001b[A\n"," 13% 6/45 [00:13<01:38,  2.53s/it]\u001b[A\n"," 16% 7/45 [00:16<01:42,  2.69s/it]\u001b[A\n"," 18% 8/45 [00:19<01:44,  2.82s/it]\u001b[A\n"," 20% 9/45 [00:22<01:45,  2.94s/it]\u001b[A\n"," 22% 10/45 [00:26<01:46,  3.05s/it]\u001b[A\n"," 24% 11/45 [00:28<01:36,  2.84s/it]\u001b[A\n"," 27% 12/45 [00:31<01:31,  2.78s/it]\u001b[A\n"," 29% 13/45 [00:33<01:25,  2.66s/it]\u001b[A\n"," 31% 14/45 [00:36<01:23,  2.69s/it]\u001b[A\n"," 33% 15/45 [00:38<01:18,  2.62s/it]\u001b[A\n"," 36% 16/45 [00:41<01:16,  2.63s/it]\u001b[A\n"," 38% 17/45 [00:43<01:10,  2.53s/it]\u001b[A\n"," 40% 18/45 [00:45<01:04,  2.39s/it]\u001b[A\n"," 42% 19/45 [00:48<01:03,  2.45s/it]\u001b[A\n"," 44% 20/45 [00:51<01:03,  2.54s/it]\u001b[A\n"," 47% 21/45 [00:53<01:01,  2.55s/it]\u001b[A\n"," 49% 22/45 [00:56<00:57,  2.50s/it]\u001b[A\n"," 51% 23/45 [00:58<00:52,  2.39s/it]\u001b[A\n"," 53% 24/45 [01:01<00:53,  2.54s/it]\u001b[A\n"," 56% 25/45 [01:03<00:52,  2.61s/it]\u001b[A\n"," 58% 26/45 [01:05<00:45,  2.40s/it]\u001b[A\n"," 60% 27/45 [01:08<00:46,  2.59s/it]\u001b[A\n"," 62% 28/45 [01:11<00:46,  2.71s/it]\u001b[A\n"," 64% 29/45 [01:14<00:42,  2.64s/it]\u001b[A\n"," 67% 30/45 [01:16<00:39,  2.66s/it]\u001b[A\n"," 69% 31/45 [01:20<00:39,  2.81s/it]\u001b[A\n"," 71% 32/45 [01:23<00:37,  2.88s/it]\u001b[A\n"," 73% 33/45 [01:25<00:33,  2.83s/it]\u001b[A\n"," 76% 34/45 [01:28<00:31,  2.84s/it]\u001b[A\n"," 78% 35/45 [01:31<00:28,  2.86s/it]\u001b[A\n"," 80% 36/45 [01:34<00:25,  2.83s/it]\u001b[A\n"," 82% 37/45 [01:36<00:21,  2.63s/it]\u001b[A\n"," 84% 38/45 [01:38<00:17,  2.47s/it]\u001b[A\n"," 87% 39/45 [01:40<00:14,  2.41s/it]\u001b[A\n"," 89% 40/45 [01:43<00:13,  2.60s/it]\u001b[A\n"," 91% 41/45 [01:46<00:10,  2.52s/it]\u001b[A\n"," 93% 42/45 [01:48<00:07,  2.48s/it]\u001b[A\n"," 96% 43/45 [01:50<00:04,  2.39s/it]\u001b[A\n","                                             \n","\u001b[A{'eval_loss': 1.492159366607666, 'eval_accuracy': 0.622794995357885, 'eval_runtime': 117.2748, 'eval_samples_per_second': 192.872, 'eval_steps_per_second': 0.384, 'epoch': 13.0}\n","  4% 1157/26700 [1:12:51<13:06:37,  1.85s/it]\n","100% 45/45 [01:51<00:00,  1.85s/it]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2841] 2023-09-02 18:22:10,516 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-1157\n","[INFO|configuration_utils.py:460] 2023-09-02 18:22:10,521 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-1157/config.json\n","[INFO|modeling_utils.py:1992] 2023-09-02 18:22:10,629 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-1157/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-02 18:22:10,633 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-1157/preprocessor_config.json\n","[INFO|trainer.py:2928] 2023-09-02 18:22:10,867 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-890] due to args.save_total_limit\n","{'loss': 1.087, 'learning_rate': 0.0009565543071161049, 'epoch': 13.03}\n","{'loss': 1.0164, 'learning_rate': 0.000956179775280899, 'epoch': 13.15}\n","{'loss': 1.0003, 'learning_rate': 0.0009558052434456929, 'epoch': 13.26}\n","{'loss': 0.9917, 'learning_rate': 0.0009554307116104869, 'epoch': 13.37}\n","{'loss': 1.0445, 'learning_rate': 0.000955056179775281, 'epoch': 13.48}\n","{'loss': 1.0066, 'learning_rate': 0.0009546816479400749, 'epoch': 13.6}\n","{'loss': 1.0619, 'learning_rate': 0.0009543071161048689, 'epoch': 13.71}\n","{'loss': 1.0787, 'learning_rate': 0.0009539325842696629, 'epoch': 13.82}\n","{'loss': 1.0813, 'learning_rate': 0.0009535580524344569, 'epoch': 13.93}\n","  5% 1245/26700 [1:16:28<13:10:19,  1.86s/it][INFO|trainer.py:3115] 2023-09-02 18:25:47,796 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3117] 2023-09-02 18:25:47,796 >>   Num examples = 22619\n","[INFO|trainer.py:3120] 2023-09-02 18:25:47,796 >>   Batch size = 512\n","\n","  0% 0/45 [00:00<?, ?it/s]\u001b[A\n","  4% 2/45 [00:02<00:53,  1.23s/it]\u001b[A\n","  7% 3/45 [00:05<01:19,  1.89s/it]\u001b[A\n","  9% 4/45 [00:07<01:26,  2.12s/it]\u001b[A\n"," 11% 5/45 [00:10<01:31,  2.29s/it]\u001b[A\n"," 13% 6/45 [00:13<01:38,  2.54s/it]\u001b[A\n"," 16% 7/45 [00:16<01:42,  2.69s/it]\u001b[A\n"," 18% 8/45 [00:19<01:43,  2.81s/it]\u001b[A\n"," 20% 9/45 [00:22<01:46,  2.95s/it]\u001b[A\n"," 22% 10/45 [00:26<01:47,  3.06s/it]\u001b[A\n"," 24% 11/45 [00:28<01:36,  2.85s/it]\u001b[A\n"," 27% 12/45 [00:31<01:31,  2.78s/it]\u001b[A\n"," 29% 13/45 [00:33<01:24,  2.63s/it]\u001b[A\n"," 31% 14/45 [00:36<01:23,  2.68s/it]\u001b[A\n"," 33% 15/45 [00:38<01:19,  2.65s/it]\u001b[A\n"," 36% 16/45 [00:41<01:16,  2.64s/it]\u001b[A\n"," 38% 17/45 [00:43<01:11,  2.55s/it]\u001b[A\n"," 40% 18/45 [00:45<01:04,  2.39s/it]\u001b[A\n"," 42% 19/45 [00:48<01:04,  2.50s/it]\u001b[A\n"," 44% 20/45 [00:51<01:05,  2.61s/it]\u001b[A\n"," 47% 21/45 [00:53<01:02,  2.62s/it]\u001b[A\n"," 49% 22/45 [00:56<00:58,  2.55s/it]\u001b[A\n"," 51% 23/45 [00:58<00:53,  2.43s/it]\u001b[A\n"," 53% 24/45 [01:01<00:53,  2.56s/it]\u001b[A\n"," 56% 25/45 [01:04<00:52,  2.64s/it]\u001b[A\n"," 58% 26/45 [01:06<00:46,  2.43s/it]\u001b[A\n"," 60% 27/45 [01:09<00:46,  2.61s/it]\u001b[A\n"," 62% 28/45 [01:12<00:46,  2.73s/it]\u001b[A\n"," 64% 29/45 [01:14<00:42,  2.63s/it]\u001b[A\n"," 67% 30/45 [01:17<00:40,  2.69s/it]\u001b[A\n"," 69% 31/45 [01:20<00:40,  2.88s/it]\u001b[A\n"," 71% 32/45 [01:23<00:38,  2.93s/it]\u001b[A\n"," 73% 33/45 [01:26<00:34,  2.87s/it]\u001b[A\n"," 76% 34/45 [01:29<00:31,  2.87s/it]\u001b[A\n"," 78% 35/45 [01:32<00:29,  2.91s/it]\u001b[A\n"," 80% 36/45 [01:35<00:26,  2.89s/it]\u001b[A\n"," 82% 37/45 [01:37<00:21,  2.67s/it]\u001b[A\n"," 84% 38/45 [01:39<00:17,  2.49s/it]\u001b[A\n"," 87% 39/45 [01:41<00:14,  2.41s/it]\u001b[A\n"," 89% 40/45 [01:44<00:12,  2.58s/it]\u001b[A\n"," 91% 41/45 [01:47<00:10,  2.52s/it]\u001b[A\n"," 93% 42/45 [01:49<00:07,  2.48s/it]\u001b[A\n"," 96% 43/45 [01:51<00:04,  2.39s/it]\u001b[A\n","                                             \n","\u001b[A{'eval_loss': 1.584754467010498, 'eval_accuracy': 0.6114770767938459, 'eval_runtime': 117.8272, 'eval_samples_per_second': 191.968, 'eval_steps_per_second': 0.382, 'epoch': 14.0}\n","  5% 1246/26700 [1:18:26<13:10:17,  1.86s/it]\n","100% 45/45 [01:52<00:00,  1.85s/it]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2841] 2023-09-02 18:27:45,629 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-1246\n","[INFO|configuration_utils.py:460] 2023-09-02 18:27:45,634 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-1246/config.json\n","[INFO|modeling_utils.py:1992] 2023-09-02 18:27:45,741 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-1246/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-02 18:27:45,745 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-1246/preprocessor_config.json\n","[INFO|trainer.py:2928] 2023-09-02 18:27:45,965 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-979] due to args.save_total_limit\n","{'loss': 1.0658, 'learning_rate': 0.0009531835205992509, 'epoch': 14.04}\n","{'loss': 0.9616, 'learning_rate': 0.000952808988764045, 'epoch': 14.16}\n","{'loss': 0.9817, 'learning_rate': 0.000952434456928839, 'epoch': 14.27}\n","{'loss': 0.9524, 'learning_rate': 0.0009520599250936329, 'epoch': 14.38}\n","{'loss': 1.0131, 'learning_rate': 0.000951685393258427, 'epoch': 14.49}\n","{'loss': 1.0101, 'learning_rate': 0.000951310861423221, 'epoch': 14.61}\n","{'loss': 1.0048, 'learning_rate': 0.000950936329588015, 'epoch': 14.72}\n","{'loss': 1.0018, 'learning_rate': 0.0009505617977528091, 'epoch': 14.83}\n","{'loss': 0.9947, 'learning_rate': 0.000950187265917603, 'epoch': 14.94}\n","  5% 1334/26700 [1:22:04<13:02:08,  1.85s/it][INFO|trainer.py:3115] 2023-09-02 18:31:23,243 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3117] 2023-09-02 18:31:23,243 >>   Num examples = 22619\n","[INFO|trainer.py:3120] 2023-09-02 18:31:23,244 >>   Batch size = 512\n","\n","  0% 0/45 [00:00<?, ?it/s]\u001b[A\n","  4% 2/45 [00:02<00:53,  1.25s/it]\u001b[A\n","  7% 3/45 [00:05<01:19,  1.88s/it]\u001b[A\n","  9% 4/45 [00:07<01:26,  2.11s/it]\u001b[A\n"," 11% 5/45 [00:10<01:31,  2.28s/it]\u001b[A\n"," 13% 6/45 [00:13<01:39,  2.54s/it]\u001b[A\n"," 16% 7/45 [00:16<01:42,  2.68s/it]\u001b[A\n"," 18% 8/45 [00:19<01:43,  2.81s/it]\u001b[A\n"," 20% 9/45 [00:22<01:45,  2.94s/it]\u001b[A\n"," 22% 10/45 [00:26<01:49,  3.13s/it]\u001b[A\n"," 24% 11/45 [00:28<01:38,  2.90s/it]\u001b[A\n"," 27% 12/45 [00:31<01:32,  2.82s/it]\u001b[A\n"," 29% 13/45 [00:33<01:25,  2.66s/it]\u001b[A\n"," 31% 14/45 [00:36<01:23,  2.68s/it]\u001b[A\n"," 33% 15/45 [00:38<01:18,  2.63s/it]\u001b[A\n"," 36% 16/45 [00:41<01:16,  2.65s/it]\u001b[A\n"," 38% 17/45 [00:43<01:11,  2.55s/it]\u001b[A\n"," 40% 18/45 [00:45<01:04,  2.39s/it]\u001b[A\n"," 42% 19/45 [00:48<01:03,  2.43s/it]\u001b[A\n"," 44% 20/45 [00:51<01:03,  2.53s/it]\u001b[A\n"," 47% 21/45 [00:53<01:01,  2.55s/it]\u001b[A\n"," 49% 22/45 [00:56<00:57,  2.50s/it]\u001b[A\n"," 51% 23/45 [00:58<00:52,  2.40s/it]\u001b[A\n"," 53% 24/45 [01:01<00:53,  2.53s/it]\u001b[A\n"," 56% 25/45 [01:03<00:51,  2.59s/it]\u001b[A\n"," 58% 26/45 [01:05<00:45,  2.41s/it]\u001b[A\n"," 60% 27/45 [01:08<00:47,  2.63s/it]\u001b[A\n"," 62% 28/45 [01:11<00:46,  2.73s/it]\u001b[A\n"," 64% 29/45 [01:14<00:42,  2.63s/it]\u001b[A\n"," 67% 30/45 [01:16<00:39,  2.63s/it]\u001b[A\n"," 69% 31/45 [01:20<00:39,  2.79s/it]\u001b[A\n"," 71% 32/45 [01:23<00:37,  2.90s/it]\u001b[A\n"," 73% 33/45 [01:26<00:34,  2.84s/it]\u001b[A\n"," 76% 34/45 [01:28<00:31,  2.84s/it]\u001b[A\n"," 78% 35/45 [01:31<00:28,  2.85s/it]\u001b[A\n"," 80% 36/45 [01:34<00:25,  2.84s/it]\u001b[A\n"," 82% 37/45 [01:36<00:21,  2.67s/it]\u001b[A\n"," 84% 38/45 [01:38<00:17,  2.50s/it]\u001b[A\n"," 87% 39/45 [01:41<00:14,  2.41s/it]\u001b[A\n"," 89% 40/45 [01:44<00:12,  2.58s/it]\u001b[A\n"," 91% 41/45 [01:46<00:10,  2.51s/it]\u001b[A\n"," 93% 42/45 [01:48<00:07,  2.48s/it]\u001b[A\n"," 96% 43/45 [01:51<00:04,  2.40s/it]\u001b[A\n","                                             \n","\u001b[A{'eval_loss': 1.5517334938049316, 'eval_accuracy': 0.6249171050886423, 'eval_runtime': 117.9544, 'eval_samples_per_second': 191.761, 'eval_steps_per_second': 0.382, 'epoch': 15.0}\n","  5% 1335/26700 [1:24:02<13:02:06,  1.85s/it]\n","100% 45/45 [01:51<00:00,  1.86s/it]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2841] 2023-09-02 18:33:21,203 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-1335\n","[INFO|configuration_utils.py:460] 2023-09-02 18:33:21,209 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-1335/config.json\n","[INFO|modeling_utils.py:1992] 2023-09-02 18:33:21,317 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-1335/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-02 18:33:21,321 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-1335/preprocessor_config.json\n","[INFO|trainer.py:2928] 2023-09-02 18:33:21,534 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-1068] due to args.save_total_limit\n","{'loss': 0.9968, 'learning_rate': 0.0009498127340823969, 'epoch': 15.06}\n","{'loss': 0.9154, 'learning_rate': 0.000949438202247191, 'epoch': 15.17}\n","{'loss': 0.9076, 'learning_rate': 0.000949063670411985, 'epoch': 15.28}\n","{'loss': 0.9275, 'learning_rate': 0.000948689138576779, 'epoch': 15.39}\n","{'loss': 0.9586, 'learning_rate': 0.0009483146067415731, 'epoch': 15.51}\n","{'loss': 0.9708, 'learning_rate': 0.000947940074906367, 'epoch': 15.62}\n","{'loss': 0.9745, 'learning_rate': 0.0009475655430711611, 'epoch': 15.73}\n","{'loss': 0.9991, 'learning_rate': 0.0009471910112359551, 'epoch': 15.84}\n","{'loss': 0.9843, 'learning_rate': 0.0009468164794007491, 'epoch': 15.96}\n","  5% 1423/26700 [1:27:39<13:21:41,  1.90s/it][INFO|trainer.py:3115] 2023-09-02 18:36:58,988 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3117] 2023-09-02 18:36:58,988 >>   Num examples = 22619\n","[INFO|trainer.py:3120] 2023-09-02 18:36:58,989 >>   Batch size = 512\n","\n","  0% 0/45 [00:00<?, ?it/s]\u001b[A\n","  4% 2/45 [00:02<00:54,  1.28s/it]\u001b[A\n","  7% 3/45 [00:05<01:19,  1.90s/it]\u001b[A\n","  9% 4/45 [00:07<01:26,  2.12s/it]\u001b[A\n"," 11% 5/45 [00:10<01:31,  2.28s/it]\u001b[A\n"," 13% 6/45 [00:13<01:39,  2.54s/it]\u001b[A\n"," 16% 7/45 [00:16<01:45,  2.79s/it]\u001b[A\n"," 18% 8/45 [00:19<01:46,  2.88s/it]\u001b[A\n"," 20% 9/45 [00:23<01:47,  2.98s/it]\u001b[A\n"," 22% 10/45 [00:26<01:47,  3.08s/it]\u001b[A\n"," 24% 11/45 [00:28<01:38,  2.89s/it]\u001b[A\n"," 27% 12/45 [00:31<01:33,  2.82s/it]\u001b[A\n"," 29% 13/45 [00:33<01:25,  2.66s/it]\u001b[A\n"," 31% 14/45 [00:36<01:23,  2.69s/it]\u001b[A\n"," 33% 15/45 [00:38<01:18,  2.62s/it]\u001b[A\n"," 36% 16/45 [00:41<01:17,  2.69s/it]\u001b[A\n"," 38% 17/45 [00:44<01:13,  2.62s/it]\u001b[A\n"," 40% 18/45 [00:46<01:06,  2.45s/it]\u001b[A\n"," 42% 19/45 [00:48<01:04,  2.46s/it]\u001b[A\n"," 44% 20/45 [00:51<01:03,  2.54s/it]\u001b[A\n"," 47% 21/45 [00:54<01:01,  2.56s/it]\u001b[A\n"," 49% 22/45 [00:56<00:57,  2.51s/it]\u001b[A\n"," 51% 23/45 [00:58<00:53,  2.44s/it]\u001b[A\n"," 53% 24/45 [01:01<00:53,  2.56s/it]\u001b[A\n"," 56% 25/45 [01:04<00:52,  2.62s/it]\u001b[A\n"," 58% 26/45 [01:06<00:45,  2.41s/it]\u001b[A\n"," 60% 27/45 [01:09<00:46,  2.59s/it]\u001b[A\n"," 62% 28/45 [01:12<00:46,  2.75s/it]\u001b[A\n"," 64% 29/45 [01:14<00:42,  2.65s/it]\u001b[A\n"," 67% 30/45 [01:17<00:39,  2.64s/it]\u001b[A\n"," 69% 31/45 [01:20<00:39,  2.79s/it]\u001b[A\n"," 71% 32/45 [01:23<00:37,  2.87s/it]\u001b[A\n"," 73% 33/45 [01:26<00:34,  2.84s/it]\u001b[A\n"," 76% 34/45 [01:29<00:32,  2.91s/it]\u001b[A\n"," 78% 35/45 [01:32<00:28,  2.89s/it]\u001b[A\n"," 80% 36/45 [01:35<00:25,  2.86s/it]\u001b[A\n"," 82% 37/45 [01:37<00:21,  2.66s/it]\u001b[A\n"," 84% 38/45 [01:39<00:17,  2.51s/it]\u001b[A\n"," 87% 39/45 [01:41<00:14,  2.43s/it]\u001b[A\n"," 89% 40/45 [01:44<00:12,  2.59s/it]\u001b[A\n"," 91% 41/45 [01:47<00:10,  2.51s/it]\u001b[A\n"," 93% 42/45 [01:49<00:07,  2.48s/it]\u001b[A\n"," 96% 43/45 [01:51<00:04,  2.40s/it]\u001b[A\n","                                             \n","\u001b[A{'eval_loss': 1.5166242122650146, 'eval_accuracy': 0.6269065829612273, 'eval_runtime': 118.0457, 'eval_samples_per_second': 191.612, 'eval_steps_per_second': 0.381, 'epoch': 16.0}\n","  5% 1424/26700 [1:29:38<13:21:39,  1.90s/it]\n","100% 45/45 [01:52<00:00,  1.86s/it]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2841] 2023-09-02 18:38:57,040 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-1424\n","[INFO|configuration_utils.py:460] 2023-09-02 18:38:57,046 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-1424/config.json\n","[INFO|modeling_utils.py:1992] 2023-09-02 18:38:57,157 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-1424/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-02 18:38:57,162 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-1424/preprocessor_config.json\n","[INFO|trainer.py:2928] 2023-09-02 18:38:57,383 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-1246] due to args.save_total_limit\n","{'loss': 1.0229, 'learning_rate': 0.0009464419475655432, 'epoch': 16.07}\n","{'loss': 0.8647, 'learning_rate': 0.0009460674157303371, 'epoch': 16.18}\n","{'loss': 0.8898, 'learning_rate': 0.0009456928838951311, 'epoch': 16.29}\n","{'loss': 0.9238, 'learning_rate': 0.0009453183520599252, 'epoch': 16.4}\n","{'loss': 0.8968, 'learning_rate': 0.0009449438202247192, 'epoch': 16.52}\n","{'loss': 0.9344, 'learning_rate': 0.0009445692883895131, 'epoch': 16.63}\n","{'loss': 0.9572, 'learning_rate': 0.0009441947565543071, 'epoch': 16.74}\n","{'loss': 0.983, 'learning_rate': 0.0009438202247191011, 'epoch': 16.85}\n","{'loss': 0.9388, 'learning_rate': 0.0009434456928838951, 'epoch': 16.97}\n","  6% 1512/26700 [1:33:15<13:23:24,  1.91s/it][INFO|trainer.py:3115] 2023-09-02 18:42:34,537 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3117] 2023-09-02 18:42:34,537 >>   Num examples = 22619\n","[INFO|trainer.py:3120] 2023-09-02 18:42:34,537 >>   Batch size = 512\n","\n","  0% 0/45 [00:00<?, ?it/s]\u001b[A\n","  4% 2/45 [00:02<00:54,  1.26s/it]\u001b[A\n","  7% 3/45 [00:05<01:21,  1.93s/it]\u001b[A\n","  9% 4/45 [00:07<01:27,  2.14s/it]\u001b[A\n"," 11% 5/45 [00:10<01:31,  2.29s/it]\u001b[A\n"," 13% 6/45 [00:13<01:38,  2.53s/it]\u001b[A\n"," 16% 7/45 [00:16<01:42,  2.71s/it]\u001b[A\n"," 18% 8/45 [00:19<01:45,  2.86s/it]\u001b[A\n"," 20% 9/45 [00:22<01:46,  2.97s/it]\u001b[A\n"," 22% 10/45 [00:26<01:47,  3.07s/it]\u001b[A\n"," 24% 11/45 [00:28<01:37,  2.86s/it]\u001b[A\n"," 27% 12/45 [00:31<01:32,  2.82s/it]\u001b[A\n"," 29% 13/45 [00:33<01:26,  2.71s/it]\u001b[A\n"," 31% 14/45 [00:36<01:24,  2.73s/it]\u001b[A\n"," 33% 15/45 [00:39<01:20,  2.67s/it]\u001b[A\n"," 36% 16/45 [00:41<01:17,  2.68s/it]\u001b[A\n"," 38% 17/45 [00:44<01:12,  2.57s/it]\u001b[A\n"," 40% 18/45 [00:46<01:05,  2.43s/it]\u001b[A\n"," 42% 19/45 [00:48<01:04,  2.46s/it]\u001b[A\n"," 44% 20/45 [00:51<01:03,  2.55s/it]\u001b[A\n"," 47% 21/45 [00:54<01:01,  2.56s/it]\u001b[A\n"," 49% 22/45 [00:56<00:57,  2.49s/it]\u001b[A\n"," 51% 23/45 [00:58<00:52,  2.40s/it]\u001b[A\n"," 53% 24/45 [01:01<00:54,  2.58s/it]\u001b[A\n"," 56% 25/45 [01:04<00:52,  2.63s/it]\u001b[A\n"," 58% 26/45 [01:06<00:45,  2.41s/it]\u001b[A\n"," 60% 27/45 [01:09<00:46,  2.60s/it]\u001b[A\n"," 62% 28/45 [01:12<00:46,  2.71s/it]\u001b[A\n"," 64% 29/45 [01:14<00:43,  2.71s/it]\u001b[A\n"," 67% 30/45 [01:17<00:40,  2.69s/it]\u001b[A\n"," 69% 31/45 [01:20<00:39,  2.83s/it]\u001b[A\n"," 71% 32/45 [01:23<00:37,  2.89s/it]\u001b[A\n"," 73% 33/45 [01:26<00:34,  2.84s/it]\u001b[A\n"," 76% 34/45 [01:29<00:31,  2.87s/it]\u001b[A\n"," 78% 35/45 [01:32<00:28,  2.88s/it]\u001b[A\n"," 80% 36/45 [01:35<00:25,  2.85s/it]\u001b[A\n"," 82% 37/45 [01:37<00:21,  2.63s/it]\u001b[A\n"," 84% 38/45 [01:39<00:17,  2.47s/it]\u001b[A\n"," 87% 39/45 [01:41<00:14,  2.40s/it]\u001b[A\n"," 89% 40/45 [01:44<00:12,  2.58s/it]\u001b[A\n"," 91% 41/45 [01:46<00:10,  2.51s/it]\u001b[A\n"," 93% 42/45 [01:49<00:07,  2.48s/it]\u001b[A\n"," 96% 43/45 [01:51<00:04,  2.39s/it]\u001b[A\n","                                             \n","\u001b[A{'eval_loss': 1.5836589336395264, 'eval_accuracy': 0.6244307882753437, 'eval_runtime': 117.7455, 'eval_samples_per_second': 192.101, 'eval_steps_per_second': 0.382, 'epoch': 17.0}\n","  6% 1513/26700 [1:35:13<13:23:22,  1.91s/it]\n","100% 45/45 [01:52<00:00,  1.85s/it]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2841] 2023-09-02 18:44:32,288 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-1513\n","[INFO|configuration_utils.py:460] 2023-09-02 18:44:32,294 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-1513/config.json\n","[INFO|modeling_utils.py:1992] 2023-09-02 18:44:32,402 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-1513/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-02 18:44:32,407 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-1513/preprocessor_config.json\n","[INFO|trainer.py:2928] 2023-09-02 18:44:32,640 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-1335] due to args.save_total_limit\n","{'loss': 0.941, 'learning_rate': 0.0009430711610486892, 'epoch': 17.08}\n","{'loss': 0.8412, 'learning_rate': 0.0009426966292134832, 'epoch': 17.19}\n","{'loss': 0.8482, 'learning_rate': 0.0009423220973782771, 'epoch': 17.3}\n","{'loss': 0.8798, 'learning_rate': 0.0009419475655430712, 'epoch': 17.42}\n","{'loss': 0.907, 'learning_rate': 0.0009415730337078652, 'epoch': 17.53}\n","{'loss': 0.8986, 'learning_rate': 0.0009411985018726592, 'epoch': 17.64}\n","{'loss': 0.9103, 'learning_rate': 0.0009408239700374533, 'epoch': 17.75}\n","{'loss': 0.9454, 'learning_rate': 0.0009404494382022473, 'epoch': 17.87}\n","{'loss': 0.9703, 'learning_rate': 0.0009400749063670412, 'epoch': 17.98}\n","  6% 1601/26700 [1:38:50<12:44:33,  1.83s/it][INFO|trainer.py:3115] 2023-09-02 18:48:09,217 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3117] 2023-09-02 18:48:09,218 >>   Num examples = 22619\n","[INFO|trainer.py:3120] 2023-09-02 18:48:09,218 >>   Batch size = 512\n","\n","  0% 0/45 [00:00<?, ?it/s]\u001b[A\n","  4% 2/45 [00:02<00:53,  1.24s/it]\u001b[A\n","  7% 3/45 [00:05<01:19,  1.88s/it]\u001b[A\n","  9% 4/45 [00:07<01:27,  2.13s/it]\u001b[A\n"," 11% 5/45 [00:10<01:32,  2.31s/it]\u001b[A\n"," 13% 6/45 [00:13<01:39,  2.54s/it]\u001b[A\n"," 16% 7/45 [00:16<01:42,  2.70s/it]\u001b[A\n"," 18% 8/45 [00:19<01:43,  2.81s/it]\u001b[A\n"," 20% 9/45 [00:22<01:46,  2.97s/it]\u001b[A\n"," 22% 10/45 [00:26<01:47,  3.07s/it]\u001b[A\n"," 24% 11/45 [00:28<01:36,  2.85s/it]\u001b[A\n"," 27% 12/45 [00:31<01:31,  2.78s/it]\u001b[A\n"," 29% 13/45 [00:33<01:24,  2.63s/it]\u001b[A\n"," 31% 14/45 [00:36<01:24,  2.71s/it]\u001b[A\n"," 33% 15/45 [00:38<01:19,  2.65s/it]\u001b[A\n"," 36% 16/45 [00:41<01:16,  2.65s/it]\u001b[A\n"," 38% 17/45 [00:43<01:11,  2.55s/it]\u001b[A\n"," 40% 18/45 [00:45<01:04,  2.39s/it]\u001b[A\n"," 42% 19/45 [00:48<01:03,  2.43s/it]\u001b[A\n"," 44% 20/45 [00:51<01:03,  2.54s/it]\u001b[A\n"," 47% 21/45 [00:53<01:01,  2.56s/it]\u001b[A\n"," 49% 22/45 [00:56<00:59,  2.58s/it]\u001b[A\n"," 51% 23/45 [00:58<00:54,  2.46s/it]\u001b[A\n"," 53% 24/45 [01:01<00:54,  2.59s/it]\u001b[A\n"," 56% 25/45 [01:04<00:53,  2.69s/it]\u001b[A\n"," 58% 26/45 [01:06<00:47,  2.50s/it]\u001b[A\n"," 60% 27/45 [01:09<00:47,  2.66s/it]\u001b[A\n"," 62% 28/45 [01:12<00:46,  2.76s/it]\u001b[A\n"," 64% 29/45 [01:14<00:42,  2.65s/it]\u001b[A\n"," 67% 30/45 [01:17<00:39,  2.66s/it]\u001b[A\n"," 69% 31/45 [01:20<00:39,  2.84s/it]\u001b[A\n"," 71% 32/45 [01:23<00:37,  2.89s/it]\u001b[A\n"," 73% 33/45 [01:26<00:34,  2.84s/it]\u001b[A\n"," 76% 34/45 [01:29<00:31,  2.84s/it]\u001b[A\n"," 78% 35/45 [01:32<00:28,  2.88s/it]\u001b[A\n"," 80% 36/45 [01:35<00:25,  2.88s/it]\u001b[A\n"," 82% 37/45 [01:37<00:21,  2.66s/it]\u001b[A\n"," 84% 38/45 [01:39<00:17,  2.48s/it]\u001b[A\n"," 87% 39/45 [01:41<00:14,  2.40s/it]\u001b[A\n"," 89% 40/45 [01:44<00:12,  2.58s/it]\u001b[A\n"," 91% 41/45 [01:47<00:10,  2.56s/it]\u001b[A\n"," 93% 42/45 [01:49<00:07,  2.52s/it]\u001b[A\n"," 96% 43/45 [01:51<00:04,  2.41s/it]\u001b[A\n","                                             \n","\u001b[A{'eval_loss': 1.5312849283218384, 'eval_accuracy': 0.6366329192271983, 'eval_runtime': 117.8953, 'eval_samples_per_second': 191.857, 'eval_steps_per_second': 0.382, 'epoch': 18.0}\n","  6% 1602/26700 [1:40:48<12:44:31,  1.83s/it]\n","100% 45/45 [01:52<00:00,  1.86s/it]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2841] 2023-09-02 18:50:07,119 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-1602\n","[INFO|configuration_utils.py:460] 2023-09-02 18:50:07,125 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-1602/config.json\n","[INFO|modeling_utils.py:1992] 2023-09-02 18:50:07,237 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-1602/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-02 18:50:07,241 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-1602/preprocessor_config.json\n","[INFO|trainer.py:2928] 2023-09-02 18:50:07,456 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-1424] due to args.save_total_limit\n","{'loss': 0.8547, 'learning_rate': 0.0009397003745318353, 'epoch': 18.09}\n","{'loss': 0.8087, 'learning_rate': 0.0009393258426966292, 'epoch': 18.2}\n","{'loss': 0.8331, 'learning_rate': 0.0009389513108614232, 'epoch': 18.31}\n","{'loss': 0.8147, 'learning_rate': 0.0009385767790262173, 'epoch': 18.43}\n","{'loss': 0.8578, 'learning_rate': 0.0009382022471910112, 'epoch': 18.54}\n","{'loss': 0.8932, 'learning_rate': 0.0009378277153558052, 'epoch': 18.65}\n","{'loss': 0.883, 'learning_rate': 0.0009374531835205993, 'epoch': 18.76}\n","{'loss': 0.8697, 'learning_rate': 0.0009370786516853933, 'epoch': 18.88}\n","{'loss': 0.9275, 'learning_rate': 0.0009367041198501873, 'epoch': 18.99}\n","  6% 1690/26700 [1:44:25<12:52:33,  1.85s/it][INFO|trainer.py:3115] 2023-09-02 18:53:44,300 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3117] 2023-09-02 18:53:44,301 >>   Num examples = 22619\n","[INFO|trainer.py:3120] 2023-09-02 18:53:44,301 >>   Batch size = 512\n","\n","  0% 0/45 [00:00<?, ?it/s]\u001b[A\n","  4% 2/45 [00:02<00:53,  1.24s/it]\u001b[A\n","  7% 3/45 [00:05<01:19,  1.89s/it]\u001b[A\n","  9% 4/45 [00:07<01:26,  2.11s/it]\u001b[A\n"," 11% 5/45 [00:10<01:31,  2.29s/it]\u001b[A\n"," 13% 6/45 [00:13<01:39,  2.56s/it]\u001b[A\n"," 16% 7/45 [00:16<01:42,  2.70s/it]\u001b[A\n"," 18% 8/45 [00:19<01:44,  2.82s/it]\u001b[A\n"," 20% 9/45 [00:22<01:45,  2.94s/it]\u001b[A\n"," 22% 10/45 [00:26<01:47,  3.07s/it]\u001b[A\n"," 24% 11/45 [00:28<01:37,  2.86s/it]\u001b[A\n"," 27% 12/45 [00:31<01:31,  2.79s/it]\u001b[A\n"," 29% 13/45 [00:33<01:26,  2.71s/it]\u001b[A\n"," 31% 14/45 [00:36<01:24,  2.72s/it]\u001b[A\n"," 33% 15/45 [00:38<01:19,  2.66s/it]\u001b[A\n"," 36% 16/45 [00:41<01:17,  2.67s/it]\u001b[A\n"," 38% 17/45 [00:43<01:11,  2.56s/it]\u001b[A\n"," 40% 18/45 [00:45<01:04,  2.40s/it]\u001b[A\n"," 42% 19/45 [00:48<01:03,  2.42s/it]\u001b[A\n"," 44% 20/45 [00:51<01:02,  2.52s/it]\u001b[A\n"," 47% 21/45 [00:53<01:01,  2.56s/it]\u001b[A\n"," 49% 22/45 [00:56<00:58,  2.53s/it]\u001b[A\n"," 51% 23/45 [00:58<00:53,  2.42s/it]\u001b[A\n"," 53% 24/45 [01:01<00:53,  2.54s/it]\u001b[A\n"," 56% 25/45 [01:04<00:52,  2.60s/it]\u001b[A\n"," 58% 26/45 [01:05<00:45,  2.40s/it]\u001b[A\n"," 60% 27/45 [01:09<00:47,  2.64s/it]\u001b[A\n"," 62% 28/45 [01:12<00:46,  2.76s/it]\u001b[A\n"," 64% 29/45 [01:14<00:42,  2.65s/it]\u001b[A\n"," 67% 30/45 [01:17<00:39,  2.65s/it]\u001b[A\n"," 69% 31/45 [01:20<00:40,  2.87s/it]\u001b[A\n"," 71% 32/45 [01:23<00:38,  2.96s/it]\u001b[A\n"," 73% 33/45 [01:26<00:34,  2.89s/it]\u001b[A\n"," 76% 34/45 [01:29<00:31,  2.89s/it]\u001b[A\n"," 78% 35/45 [01:32<00:28,  2.89s/it]\u001b[A\n"," 80% 36/45 [01:35<00:25,  2.87s/it]\u001b[A\n"," 82% 37/45 [01:37<00:21,  2.67s/it]\u001b[A\n"," 84% 38/45 [01:39<00:17,  2.50s/it]\u001b[A\n"," 87% 39/45 [01:41<00:14,  2.42s/it]\u001b[A\n"," 89% 40/45 [01:44<00:12,  2.60s/it]\u001b[A\n"," 91% 41/45 [01:47<00:10,  2.53s/it]\u001b[A\n"," 93% 42/45 [01:49<00:07,  2.51s/it]\u001b[A\n"," 96% 43/45 [01:51<00:04,  2.43s/it]\u001b[A\n","                                             \n","\u001b[A{'eval_loss': 1.5799789428710938, 'eval_accuracy': 0.6316371192360405, 'eval_runtime': 118.089, 'eval_samples_per_second': 191.542, 'eval_steps_per_second': 0.381, 'epoch': 19.0}\n","  6% 1691/26700 [1:46:23<12:52:31,  1.85s/it]\n","100% 45/45 [01:52<00:00,  1.88s/it]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2841] 2023-09-02 18:55:42,395 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-1691\n","[INFO|configuration_utils.py:460] 2023-09-02 18:55:42,401 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-1691/config.json\n","[INFO|modeling_utils.py:1992] 2023-09-02 18:55:42,507 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-1691/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-02 18:55:42,511 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-1691/preprocessor_config.json\n","[INFO|trainer.py:2928] 2023-09-02 18:55:42,727 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-1513] due to args.save_total_limit\n","{'loss': 0.8519, 'learning_rate': 0.0009363295880149813, 'epoch': 19.1}\n","{'loss': 0.8051, 'learning_rate': 0.0009359550561797753, 'epoch': 19.21}\n","{'loss': 0.8097, 'learning_rate': 0.0009355805243445693, 'epoch': 19.33}\n","{'loss': 0.8339, 'learning_rate': 0.0009352059925093634, 'epoch': 19.44}\n","{'loss': 0.8664, 'learning_rate': 0.0009348314606741574, 'epoch': 19.55}\n","{'loss': 0.8562, 'learning_rate': 0.0009344569288389512, 'epoch': 19.66}\n","{'loss': 0.8805, 'learning_rate': 0.0009340823970037453, 'epoch': 19.78}\n","{'loss': 0.8815, 'learning_rate': 0.0009337078651685393, 'epoch': 19.89}\n","{'loss': 0.8444, 'learning_rate': 0.0009333333333333333, 'epoch': 20.0}\n","  7% 1780/26700 [1:50:00<12:52:21,  1.86s/it][INFO|trainer.py:3115] 2023-09-02 18:59:19,812 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3117] 2023-09-02 18:59:19,812 >>   Num examples = 22619\n","[INFO|trainer.py:3120] 2023-09-02 18:59:19,812 >>   Batch size = 512\n","\n","  0% 0/45 [00:00<?, ?it/s]\u001b[A\n","  4% 2/45 [00:02<00:54,  1.28s/it]\u001b[A\n","  7% 3/45 [00:05<01:19,  1.90s/it]\u001b[A\n","  9% 4/45 [00:07<01:26,  2.12s/it]\u001b[A\n"," 11% 5/45 [00:10<01:31,  2.28s/it]\u001b[A\n"," 13% 6/45 [00:13<01:38,  2.54s/it]\u001b[A\n"," 16% 7/45 [00:16<01:42,  2.71s/it]\u001b[A\n"," 18% 8/45 [00:19<01:44,  2.82s/it]\u001b[A\n"," 20% 9/45 [00:22<01:45,  2.94s/it]\u001b[A\n"," 22% 10/45 [00:26<01:46,  3.05s/it]\u001b[A\n"," 24% 11/45 [00:28<01:39,  2.92s/it]\u001b[A\n"," 27% 12/45 [00:31<01:33,  2.85s/it]\u001b[A\n"," 29% 13/45 [00:33<01:25,  2.68s/it]\u001b[A\n"," 31% 14/45 [00:36<01:23,  2.70s/it]\u001b[A\n"," 33% 15/45 [00:38<01:18,  2.63s/it]\u001b[A\n"," 36% 16/45 [00:41<01:16,  2.65s/it]\u001b[A\n"," 38% 17/45 [00:43<01:12,  2.58s/it]\u001b[A\n"," 40% 18/45 [00:46<01:05,  2.41s/it]\u001b[A\n"," 42% 19/45 [00:48<01:03,  2.44s/it]\u001b[A\n"," 44% 20/45 [00:51<01:03,  2.53s/it]\u001b[A\n"," 47% 21/45 [00:53<01:01,  2.55s/it]\u001b[A\n"," 49% 22/45 [00:56<00:57,  2.51s/it]\u001b[A\n"," 51% 23/45 [00:58<00:53,  2.44s/it]\u001b[A\n"," 53% 24/45 [01:01<00:53,  2.56s/it]\u001b[A\n"," 56% 25/45 [01:04<00:52,  2.61s/it]\u001b[A\n"," 58% 26/45 [01:06<00:45,  2.41s/it]\u001b[A\n"," 60% 27/45 [01:09<00:46,  2.60s/it]\u001b[A\n"," 62% 28/45 [01:12<00:47,  2.77s/it]\u001b[A\n"," 64% 29/45 [01:14<00:42,  2.66s/it]\u001b[A\n"," 67% 30/45 [01:17<00:39,  2.66s/it]\u001b[A\n"," 69% 31/45 [01:20<00:39,  2.80s/it]\u001b[A\n"," 71% 32/45 [01:23<00:37,  2.88s/it]\u001b[A\n"," 73% 33/45 [01:26<00:34,  2.88s/it]\u001b[A\n"," 76% 34/45 [01:29<00:31,  2.87s/it]\u001b[A\n"," 78% 35/45 [01:32<00:28,  2.87s/it]\u001b[A\n"," 80% 36/45 [01:34<00:25,  2.84s/it]\u001b[A\n"," 82% 37/45 [01:37<00:21,  2.65s/it]\u001b[A\n"," 84% 38/45 [01:39<00:17,  2.54s/it]\u001b[A\n"," 87% 39/45 [01:41<00:14,  2.47s/it]\u001b[A\n"," 89% 40/45 [01:44<00:13,  2.63s/it]\u001b[A\n"," 91% 41/45 [01:47<00:10,  2.54s/it]\u001b[A\n"," 93% 42/45 [01:49<00:07,  2.50s/it]\u001b[A\n"," 96% 43/45 [01:51<00:04,  2.41s/it]\u001b[A\n","                                             \n","\u001b[A{'eval_loss': 1.5202339887619019, 'eval_accuracy': 0.6480834696494098, 'eval_runtime': 117.9622, 'eval_samples_per_second': 191.748, 'eval_steps_per_second': 0.381, 'epoch': 20.0}\n","  7% 1780/26700 [1:51:58<12:52:21,  1.86s/it]\n","100% 45/45 [01:52<00:00,  1.87s/it]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2841] 2023-09-02 19:01:17,780 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-1780\n","[INFO|configuration_utils.py:460] 2023-09-02 19:01:17,787 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-1780/config.json\n","[INFO|modeling_utils.py:1992] 2023-09-02 19:01:17,900 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-1780/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-02 19:01:17,904 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-1780/preprocessor_config.json\n","[INFO|trainer.py:2928] 2023-09-02 19:01:18,125 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-1602] due to args.save_total_limit\n","{'loss': 0.7568, 'learning_rate': 0.0009329588014981274, 'epoch': 20.11}\n","{'loss': 0.7661, 'learning_rate': 0.0009325842696629213, 'epoch': 20.22}\n","{'loss': 0.7833, 'learning_rate': 0.0009322097378277153, 'epoch': 20.34}\n","{'loss': 0.8072, 'learning_rate': 0.0009318352059925094, 'epoch': 20.45}\n","{'loss': 0.8431, 'learning_rate': 0.0009314606741573034, 'epoch': 20.56}\n","{'loss': 0.8561, 'learning_rate': 0.0009310861423220974, 'epoch': 20.67}\n","{'loss': 0.8554, 'learning_rate': 0.0009307116104868915, 'epoch': 20.79}\n","{'loss': 0.8295, 'learning_rate': 0.0009303370786516854, 'epoch': 20.9}\n","  7% 1868/26700 [1:55:35<12:36:58,  1.83s/it][INFO|trainer.py:3115] 2023-09-02 19:04:54,894 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3117] 2023-09-02 19:04:54,894 >>   Num examples = 22619\n","[INFO|trainer.py:3120] 2023-09-02 19:04:54,895 >>   Batch size = 512\n","\n","  0% 0/45 [00:00<?, ?it/s]\u001b[A\n","  4% 2/45 [00:02<00:54,  1.26s/it]\u001b[A\n","  7% 3/45 [00:05<01:21,  1.94s/it]\u001b[A\n","  9% 4/45 [00:07<01:27,  2.14s/it]\u001b[A\n"," 11% 5/45 [00:10<01:31,  2.29s/it]\u001b[A\n"," 13% 6/45 [00:13<01:38,  2.53s/it]\u001b[A\n"," 16% 7/45 [00:16<01:42,  2.69s/it]\u001b[A\n"," 18% 8/45 [00:19<01:44,  2.83s/it]\u001b[A\n"," 20% 9/45 [00:22<01:45,  2.94s/it]\u001b[A\n"," 22% 10/45 [00:26<01:46,  3.05s/it]\u001b[A\n"," 24% 11/45 [00:28<01:36,  2.84s/it]\u001b[A\n"," 27% 12/45 [00:31<01:31,  2.78s/it]\u001b[A\n"," 29% 13/45 [00:33<01:25,  2.66s/it]\u001b[A\n"," 31% 14/45 [00:36<01:23,  2.69s/it]\u001b[A\n"," 33% 15/45 [00:38<01:18,  2.62s/it]\u001b[A\n"," 36% 16/45 [00:41<01:16,  2.63s/it]\u001b[A\n"," 38% 17/45 [00:43<01:10,  2.53s/it]\u001b[A\n"," 40% 18/45 [00:45<01:04,  2.38s/it]\u001b[A\n"," 42% 19/45 [00:48<01:03,  2.45s/it]\u001b[A\n"," 44% 20/45 [00:51<01:03,  2.53s/it]\u001b[A\n"," 47% 21/45 [00:53<01:01,  2.55s/it]\u001b[A\n"," 49% 22/45 [00:56<00:57,  2.50s/it]\u001b[A\n"," 51% 23/45 [00:58<00:52,  2.39s/it]\u001b[A\n"," 53% 24/45 [01:01<00:53,  2.55s/it]\u001b[A\n"," 56% 25/45 [01:03<00:52,  2.62s/it]\u001b[A\n"," 58% 26/45 [01:05<00:45,  2.41s/it]\u001b[A\n"," 60% 27/45 [01:08<00:46,  2.59s/it]\u001b[A\n"," 62% 28/45 [01:11<00:46,  2.72s/it]\u001b[A\n"," 64% 29/45 [01:14<00:42,  2.64s/it]\u001b[A\n"," 67% 30/45 [01:16<00:39,  2.66s/it]\u001b[A\n"," 69% 31/45 [01:20<00:39,  2.81s/it]\u001b[A\n"," 71% 32/45 [01:23<00:37,  2.88s/it]\u001b[A\n"," 73% 33/45 [01:25<00:33,  2.83s/it]\u001b[A\n"," 76% 34/45 [01:28<00:31,  2.86s/it]\u001b[A\n"," 78% 35/45 [01:31<00:28,  2.88s/it]\u001b[A\n"," 80% 36/45 [01:34<00:25,  2.84s/it]\u001b[A\n"," 82% 37/45 [01:36<00:21,  2.63s/it]\u001b[A\n"," 84% 38/45 [01:38<00:17,  2.47s/it]\u001b[A\n"," 87% 39/45 [01:40<00:14,  2.40s/it]\u001b[A\n"," 89% 40/45 [01:43<00:12,  2.59s/it]\u001b[A\n"," 91% 41/45 [01:46<00:10,  2.51s/it]\u001b[A\n"," 93% 42/45 [01:48<00:07,  2.48s/it]\u001b[A\n"," 96% 43/45 [01:50<00:04,  2.39s/it]\u001b[A\n","                                             \n","\u001b[A{'eval_loss': 1.6438030004501343, 'eval_accuracy': 0.6396392413457712, 'eval_runtime': 117.1051, 'eval_samples_per_second': 193.151, 'eval_steps_per_second': 0.384, 'epoch': 21.0}\n","  7% 1869/26700 [1:57:33<12:36:57,  1.83s/it]\n","100% 45/45 [01:51<00:00,  1.85s/it]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2841] 2023-09-02 19:06:52,006 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-1869\n","[INFO|configuration_utils.py:460] 2023-09-02 19:06:52,011 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-1869/config.json\n","[INFO|modeling_utils.py:1992] 2023-09-02 19:06:52,136 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-1869/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-02 19:06:52,140 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-1869/preprocessor_config.json\n","[INFO|trainer.py:2928] 2023-09-02 19:06:52,362 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-1691] due to args.save_total_limit\n","{'loss': 0.8817, 'learning_rate': 0.0009299625468164794, 'epoch': 21.01}\n","{'loss': 0.7463, 'learning_rate': 0.0009295880149812735, 'epoch': 21.12}\n","{'loss': 0.7559, 'learning_rate': 0.0009292134831460674, 'epoch': 21.24}\n","{'loss': 0.7447, 'learning_rate': 0.0009288389513108614, 'epoch': 21.35}\n","{'loss': 0.778, 'learning_rate': 0.0009284644194756554, 'epoch': 21.46}\n","{'loss': 0.7993, 'learning_rate': 0.0009280898876404494, 'epoch': 21.57}\n","{'loss': 0.8029, 'learning_rate': 0.0009277153558052434, 'epoch': 21.69}\n","{'loss': 0.8174, 'learning_rate': 0.0009273408239700375, 'epoch': 21.8}\n","{'loss': 0.7961, 'learning_rate': 0.0009269662921348315, 'epoch': 21.91}\n","  7% 1957/26700 [2:01:10<12:21:31,  1.80s/it][INFO|trainer.py:3115] 2023-09-02 19:10:29,187 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3117] 2023-09-02 19:10:29,187 >>   Num examples = 22619\n","[INFO|trainer.py:3120] 2023-09-02 19:10:29,188 >>   Batch size = 512\n","\n","  0% 0/45 [00:00<?, ?it/s]\u001b[A\n","  4% 2/45 [00:02<00:53,  1.24s/it]\u001b[A\n","  7% 3/45 [00:05<01:18,  1.88s/it]\u001b[A\n","  9% 4/45 [00:07<01:26,  2.12s/it]\u001b[A\n"," 11% 5/45 [00:10<01:31,  2.30s/it]\u001b[A\n"," 13% 6/45 [00:13<01:38,  2.54s/it]\u001b[A\n"," 16% 7/45 [00:16<01:42,  2.69s/it]\u001b[A\n"," 18% 8/45 [00:19<01:43,  2.81s/it]\u001b[A\n"," 20% 9/45 [00:22<01:46,  2.95s/it]\u001b[A\n"," 22% 10/45 [00:26<01:47,  3.07s/it]\u001b[A\n"," 24% 11/45 [00:28<01:37,  2.86s/it]\u001b[A\n"," 27% 12/45 [00:31<01:31,  2.78s/it]\u001b[A\n"," 29% 13/45 [00:33<01:24,  2.64s/it]\u001b[A\n"," 31% 14/45 [00:36<01:24,  2.73s/it]\u001b[A\n"," 33% 15/45 [00:38<01:20,  2.68s/it]\u001b[A\n"," 36% 16/45 [00:41<01:17,  2.67s/it]\u001b[A\n"," 38% 17/45 [00:43<01:11,  2.57s/it]\u001b[A\n"," 40% 18/45 [00:45<01:04,  2.40s/it]\u001b[A\n"," 42% 19/45 [00:48<01:03,  2.44s/it]\u001b[A\n"," 44% 20/45 [00:51<01:04,  2.59s/it]\u001b[A\n"," 47% 21/45 [00:53<01:02,  2.59s/it]\u001b[A\n"," 49% 22/45 [00:56<00:58,  2.53s/it]\u001b[A\n"," 51% 23/45 [00:58<00:53,  2.42s/it]\u001b[A\n"," 53% 24/45 [01:01<00:53,  2.55s/it]\u001b[A\n"," 56% 25/45 [01:04<00:52,  2.63s/it]\u001b[A\n"," 58% 26/45 [01:06<00:46,  2.44s/it]\u001b[A\n"," 60% 27/45 [01:09<00:47,  2.62s/it]\u001b[A\n"," 62% 28/45 [01:12<00:46,  2.74s/it]\u001b[A\n"," 64% 29/45 [01:14<00:42,  2.64s/it]\u001b[A\n"," 67% 30/45 [01:17<00:39,  2.65s/it]\u001b[A\n"," 69% 31/45 [01:20<00:39,  2.81s/it]\u001b[A\n"," 71% 32/45 [01:23<00:37,  2.88s/it]\u001b[A\n"," 73% 33/45 [01:26<00:34,  2.83s/it]\u001b[A\n"," 76% 34/45 [01:29<00:31,  2.85s/it]\u001b[A\n"," 78% 35/45 [01:32<00:28,  2.86s/it]\u001b[A\n"," 80% 36/45 [01:34<00:25,  2.87s/it]\u001b[A\n"," 82% 37/45 [01:37<00:21,  2.73s/it]\u001b[A\n"," 84% 38/45 [01:39<00:17,  2.54s/it]\u001b[A\n"," 87% 39/45 [01:41<00:14,  2.45s/it]\u001b[A\n"," 89% 40/45 [01:44<00:13,  2.61s/it]\u001b[A\n"," 91% 41/45 [01:47<00:10,  2.56s/it]\u001b[A\n"," 93% 42/45 [01:49<00:07,  2.51s/it]\u001b[A\n"," 96% 43/45 [01:51<00:04,  2.41s/it]\u001b[A\n","                                             \n","\u001b[A{'eval_loss': 1.6009589433670044, 'eval_accuracy': 0.6415402979795747, 'eval_runtime': 117.8442, 'eval_samples_per_second': 191.94, 'eval_steps_per_second': 0.382, 'epoch': 22.0}\n","  7% 1958/26700 [2:03:08<12:21:29,  1.80s/it]\n","100% 45/45 [01:52<00:00,  1.86s/it]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2841] 2023-09-02 19:12:27,037 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-1958\n","[INFO|configuration_utils.py:460] 2023-09-02 19:12:27,042 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-1958/config.json\n","[INFO|modeling_utils.py:1992] 2023-09-02 19:12:27,152 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-1958/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-02 19:12:27,156 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-1958/preprocessor_config.json\n","[INFO|trainer.py:2928] 2023-09-02 19:12:27,385 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-1780] due to args.save_total_limit\n","{'loss': 0.8385, 'learning_rate': 0.0009265917602996254, 'epoch': 22.02}\n","{'loss': 0.7619, 'learning_rate': 0.0009262172284644195, 'epoch': 22.13}\n","{'loss': 0.7413, 'learning_rate': 0.0009258426966292135, 'epoch': 22.25}\n","{'loss': 0.7673, 'learning_rate': 0.0009254681647940076, 'epoch': 22.36}\n","{'loss': 0.8194, 'learning_rate': 0.0009250936329588016, 'epoch': 22.47}\n","{'loss': 0.7709, 'learning_rate': 0.0009247191011235955, 'epoch': 22.58}\n","{'loss': 0.7993, 'learning_rate': 0.0009243445692883896, 'epoch': 22.7}\n","{'loss': 0.8063, 'learning_rate': 0.0009239700374531835, 'epoch': 22.81}\n","{'loss': 0.8155, 'learning_rate': 0.0009235955056179775, 'epoch': 22.92}\n","  8% 2046/26700 [2:06:45<12:33:53,  1.83s/it][INFO|trainer.py:3115] 2023-09-02 19:16:04,716 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3117] 2023-09-02 19:16:04,716 >>   Num examples = 22619\n","[INFO|trainer.py:3120] 2023-09-02 19:16:04,716 >>   Batch size = 512\n","\n","  0% 0/45 [00:00<?, ?it/s]\u001b[A\n","  4% 2/45 [00:02<00:53,  1.25s/it]\u001b[A\n","  7% 3/45 [00:05<01:19,  1.90s/it]\u001b[A\n","  9% 4/45 [00:07<01:27,  2.13s/it]\u001b[A\n"," 11% 5/45 [00:10<01:32,  2.30s/it]\u001b[A\n"," 13% 6/45 [00:13<01:40,  2.57s/it]\u001b[A\n"," 16% 7/45 [00:16<01:43,  2.72s/it]\u001b[A\n"," 18% 8/45 [00:19<01:44,  2.83s/it]\u001b[A\n"," 20% 9/45 [00:22<01:46,  2.96s/it]\u001b[A\n"," 22% 10/45 [00:26<01:48,  3.10s/it]\u001b[A\n"," 24% 11/45 [00:28<01:38,  2.89s/it]\u001b[A\n"," 27% 12/45 [00:31<01:32,  2.81s/it]\u001b[A\n"," 29% 13/45 [00:33<01:25,  2.66s/it]\u001b[A\n"," 31% 14/45 [00:36<01:23,  2.69s/it]\u001b[A\n"," 33% 15/45 [00:38<01:19,  2.64s/it]\u001b[A\n"," 36% 16/45 [00:41<01:16,  2.65s/it]\u001b[A\n"," 38% 17/45 [00:43<01:11,  2.56s/it]\u001b[A\n"," 40% 18/45 [00:46<01:04,  2.40s/it]\u001b[A\n"," 42% 19/45 [00:48<01:03,  2.43s/it]\u001b[A\n"," 44% 20/45 [00:51<01:03,  2.55s/it]\u001b[A\n"," 47% 21/45 [00:54<01:02,  2.59s/it]\u001b[A\n"," 49% 22/45 [00:56<00:58,  2.53s/it]\u001b[A\n"," 51% 23/45 [00:58<00:53,  2.42s/it]\u001b[A\n"," 53% 24/45 [01:01<00:53,  2.55s/it]\u001b[A\n"," 56% 25/45 [01:04<00:52,  2.62s/it]\u001b[A\n"," 58% 26/45 [01:06<00:46,  2.42s/it]\u001b[A\n"," 60% 27/45 [01:09<00:47,  2.63s/it]\u001b[A\n"," 62% 28/45 [01:12<00:46,  2.75s/it]\u001b[A\n"," 64% 29/45 [01:14<00:42,  2.65s/it]\u001b[A\n"," 67% 30/45 [01:17<00:40,  2.72s/it]\u001b[A\n"," 69% 31/45 [01:20<00:40,  2.87s/it]\u001b[A\n"," 71% 32/45 [01:23<00:38,  2.94s/it]\u001b[A\n"," 73% 33/45 [01:26<00:34,  2.88s/it]\u001b[A\n"," 76% 34/45 [01:29<00:31,  2.87s/it]\u001b[A\n"," 78% 35/45 [01:32<00:28,  2.87s/it]\u001b[A\n"," 80% 36/45 [01:35<00:25,  2.89s/it]\u001b[A\n"," 82% 37/45 [01:37<00:21,  2.68s/it]\u001b[A\n"," 84% 38/45 [01:39<00:17,  2.51s/it]\u001b[A\n"," 87% 39/45 [01:41<00:14,  2.42s/it]\u001b[A\n"," 89% 40/45 [01:44<00:12,  2.59s/it]\u001b[A\n"," 91% 41/45 [01:47<00:10,  2.52s/it]\u001b[A\n"," 93% 42/45 [01:49<00:07,  2.50s/it]\u001b[A\n"," 96% 43/45 [01:51<00:04,  2.41s/it]\u001b[A\n","                                             \n","\u001b[A{'eval_loss': 1.5816941261291504, 'eval_accuracy': 0.641672929837747, 'eval_runtime': 118.207, 'eval_samples_per_second': 191.351, 'eval_steps_per_second': 0.381, 'epoch': 23.0}\n","  8% 2047/26700 [2:08:43<12:33:51,  1.83s/it]\n","100% 45/45 [01:52<00:00,  1.87s/it]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2841] 2023-09-02 19:18:02,930 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-2047\n","[INFO|configuration_utils.py:460] 2023-09-02 19:18:02,936 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-2047/config.json\n","[INFO|modeling_utils.py:1992] 2023-09-02 19:18:03,048 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-2047/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-02 19:18:03,052 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-2047/preprocessor_config.json\n","[INFO|trainer.py:2928] 2023-09-02 19:18:03,267 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-1869] due to args.save_total_limit\n","[INFO|trainer.py:1960] 2023-09-02 19:18:03,287 >> \n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","[INFO|trainer.py:2122] 2023-09-02 19:18:03,288 >> Loading best model from drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/checkpoint-1157 (score: 1.492159366607666).\n","{'train_runtime': 7724.404, 'train_samples_per_second': 1751.397, 'train_steps_per_second': 3.457, 'train_loss': 1.2379271526364624, 'epoch': 23.0}\n","  8% 2047/26700 [2:08:44<25:50:28,  3.77s/it]\n","[INFO|trainer.py:2841] 2023-09-02 19:18:03,355 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/\n","[INFO|configuration_utils.py:460] 2023-09-02 19:18:03,377 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/config.json\n","[INFO|modeling_utils.py:1992] 2023-09-02 19:18:03,485 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-02 19:18:03,489 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/preprocessor_config.json\n","***** train metrics *****\n","  epoch                    =       23.0\n","  train_loss               =     1.2379\n","  train_runtime            = 2:08:44.40\n","  train_samples_per_second =   1751.397\n","  train_steps_per_second   =      3.457\n","[INFO|trainer.py:3115] 2023-09-02 19:18:03,508 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3117] 2023-09-02 19:18:03,508 >>   Num examples = 22619\n","[INFO|trainer.py:3120] 2023-09-02 19:18:03,508 >>   Batch size = 512\n","100% 45/45 [01:52<00:00,  2.51s/it]\n","***** eval metrics *****\n","  epoch                   =       23.0\n","  eval_accuracy           =     0.6228\n","  eval_loss               =     1.4922\n","  eval_runtime            = 0:01:58.37\n","  eval_samples_per_second =    191.074\n","  eval_steps_per_second   =       0.38\n","\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n","\u001b[34m\u001b[1mwandb\u001b[0m:                  eval/accuracy ▁▃▄▅▅▅▆▆▇▆▇▆▇▇▇▇▇██████▇\n","\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/loss █▅▄▃▃▂▂▂▂▂▂▂▁▂▁▁▂▁▂▁▂▂▂▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/runtime ▇▃▂▃▇▅▅▇▄▄▅▄▂▅▆▆▅▅▆▆▁▅▇█\n","\u001b[34m\u001b[1mwandb\u001b[0m:        eval/samples_per_second ▂▆▇▆▂▄▄▂▅▅▃▅▇▄▃▃▄▄▃▃█▄▂▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:          eval/steps_per_second ▃▆▆▆▃▅▅▁▅▆▅▅█▅▅▃▅▅▃▃█▅▃▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\n","\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\n","\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate ████▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss █▆▅▅▄▄▄▃▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n","\u001b[34m\u001b[1mwandb\u001b[0m:                  eval/accuracy 0.62279\n","\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/loss 1.49216\n","\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/runtime 118.3784\n","\u001b[34m\u001b[1mwandb\u001b[0m:        eval/samples_per_second 191.074\n","\u001b[34m\u001b[1mwandb\u001b[0m:          eval/steps_per_second 0.38\n","\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch 23.0\n","\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step 2047\n","\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate 0.00092\n","\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss 0.8155\n","\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos 1.0518639846183383e+19\n","\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss 1.23793\n","\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime 7724.404\n","\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second 1751.397\n","\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second 3.457\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mcharmed-dream-9\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/u15048366/colabCnnIp102Run1/runs/du19mtop\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n","\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230902_170841-du19mtop/logs\u001b[0m\n"]}],"source":["# --train_dir drive/MyDrive/hons-research/data/ip102/train \\\n","#     --validation_dir drive/MyDrive/hons-research/data/ip102/val \\\n","#     --output_dir drive/MyDrive/hons-research/output/cnn/ip102/ip102outputs_1/ \\\n","\n","# drive/MyDrive/hons-research/script/cnn-run1.py \\\n","\n","!python cnn.py \\\n","    --model_name microsoft/resnet-18 \\\n","    --model_type resnet \\\n","    --train_dir data/classification/train \\\n","    --validation_dir data/classification/test \\\n","    --output_dir drive/MyDrive/hons-research/output/cnn/ip102_outputs_3/ \\\n","    --remove_unused_columns False \\\n","    --do_train \\\n","    --do_eval \\\n","    --push_to_hub False \\\n","    --optim adamw_torch \\\n","    --learning_rate 0.001 \\\n","    --num_train_epochs 300 \\\n","    --per_device_train_batch_size 512 \\\n","    --per_device_eval_batch_size 512 \\\n","    --logging_strategy steps \\\n","    --logging_steps 10 \\\n","    --evaluation_strategy epoch \\\n","    --save_strategy epoch \\\n","    --load_best_model_at_end True \\\n","    --save_total_limit 3 \\\n","    --save_steps 500 \\\n","    --data_seed 3 \\\n","    --seed 3 \\\n","    --ignore_mismatched_sizes\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"EuAxN-9TFIeO","outputId":"f3bed8a2-cc6e-4031-98f3-64cf98a8810e"},"outputs":[{"name":"stdout","output_type":"stream","text":["2023-09-02 19:20:14.157357: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mu15048366\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.9\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20230902_192017-tgd6yq20\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mavid-water-10\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/u15048366/colabCnnIp102Run1\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/u15048366/colabCnnIp102Run1/runs/tgd6yq20\u001b[0m\n","09/02/2023 19:20:18 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n","09/02/2023 19:20:18 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n","_n_gpu=1,\n","adafactor=False,\n","adam_beta1=0.9,\n","adam_beta2=0.999,\n","adam_epsilon=1e-08,\n","auto_find_batch_size=False,\n","bf16=False,\n","bf16_full_eval=False,\n","data_seed=4,\n","dataloader_drop_last=False,\n","dataloader_num_workers=0,\n","dataloader_pin_memory=True,\n","ddp_backend=None,\n","ddp_broadcast_buffers=None,\n","ddp_bucket_cap_mb=None,\n","ddp_find_unused_parameters=None,\n","ddp_timeout=1800,\n","debug=[],\n","deepspeed=None,\n","disable_tqdm=False,\n","dispatch_batches=None,\n","do_eval=True,\n","do_predict=False,\n","do_train=True,\n","eval_accumulation_steps=None,\n","eval_delay=0,\n","eval_steps=None,\n","evaluation_strategy=epoch,\n","fp16=False,\n","fp16_backend=auto,\n","fp16_full_eval=False,\n","fp16_opt_level=O1,\n","fsdp=[],\n","fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n","fsdp_min_num_params=0,\n","fsdp_transformer_layer_cls_to_wrap=None,\n","full_determinism=False,\n","gradient_accumulation_steps=1,\n","gradient_checkpointing=False,\n","greater_is_better=False,\n","group_by_length=False,\n","half_precision_backend=auto,\n","hub_always_push=False,\n","hub_model_id=None,\n","hub_private_repo=False,\n","hub_strategy=every_save,\n","hub_token=<HUB_TOKEN>,\n","ignore_data_skip=False,\n","include_inputs_for_metrics=False,\n","jit_mode_eval=False,\n","label_names=None,\n","label_smoothing_factor=0.0,\n","learning_rate=0.001,\n","length_column_name=length,\n","load_best_model_at_end=True,\n","local_rank=0,\n","log_level=passive,\n","log_level_replica=warning,\n","log_on_each_node=True,\n","logging_dir=drive/MyDrive/hons-research/output/cnn/ip102_outputs_4/runs/Sep02_19-20-18_f10132d8a075,\n","logging_first_step=False,\n","logging_nan_inf_filter=True,\n","logging_steps=10,\n","logging_strategy=steps,\n","lr_scheduler_type=linear,\n","max_grad_norm=1.0,\n","max_steps=-1,\n","metric_for_best_model=loss,\n","mp_parameters=,\n","no_cuda=False,\n","num_train_epochs=300.0,\n","optim=adamw_torch,\n","optim_args=None,\n","output_dir=drive/MyDrive/hons-research/output/cnn/ip102_outputs_4/,\n","overwrite_output_dir=False,\n","past_index=-1,\n","per_device_eval_batch_size=512,\n","per_device_train_batch_size=512,\n","prediction_loss_only=False,\n","push_to_hub=False,\n","push_to_hub_model_id=None,\n","push_to_hub_organization=None,\n","push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n","ray_scope=last,\n","remove_unused_columns=False,\n","report_to=['tensorboard', 'wandb'],\n","resume_from_checkpoint=None,\n","run_name=drive/MyDrive/hons-research/output/cnn/ip102_outputs_4/,\n","save_on_each_node=False,\n","save_safetensors=False,\n","save_steps=500.0,\n","save_strategy=epoch,\n","save_total_limit=3,\n","seed=4,\n","sharded_ddp=[],\n","skip_memory_metrics=True,\n","tf32=None,\n","torch_compile=False,\n","torch_compile_backend=None,\n","torch_compile_mode=None,\n","torchdynamo=None,\n","tpu_metrics_debug=False,\n","tpu_num_cores=None,\n","use_cpu=False,\n","use_ipex=False,\n","use_legacy_prediction_loop=False,\n","use_mps_device=False,\n","warmup_ratio=0.0,\n","warmup_steps=0,\n","weight_decay=0.0,\n",")\n","/usr/local/lib/python3.10/dist-packages/datasets/load.py:2086: FutureWarning: 'task' was deprecated in version 2.13.0 and will be removed in 3.0.0.\n","\n","  warnings.warn(\n","Resolving data files: 100% 45095/45095 [00:00<00:00, 266993.04it/s]\n","Resolving data files: 100% 22619/22619 [00:00<00:00, 102943.26it/s]\n","\n","\n","\n","None\n","\n","\n","\n","[INFO|configuration_utils.py:715] 2023-09-02 19:20:37,672 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--resnet-18/snapshots/f45a6faa12e0381f5620c5c8d7e916bca90f2c44/config.json\n","[INFO|configuration_utils.py:775] 2023-09-02 19:20:37,674 >> Model config ResNetConfig {\n","  \"_name_or_path\": \"microsoft/resnet-18\",\n","  \"architectures\": [\n","    \"ResNetForImageClassification\"\n","  ],\n","  \"depths\": [\n","    2,\n","    2,\n","    2,\n","    2\n","  ],\n","  \"downsample_in_first_stage\": false,\n","  \"embedding_size\": 64,\n","  \"finetuning_task\": \"image-classification\",\n","  \"hidden_act\": \"relu\",\n","  \"hidden_sizes\": [\n","    64,\n","    128,\n","    256,\n","    512\n","  ],\n","  \"id2label\": {\n","    \"0\": \"0\",\n","    \"1\": \"1\",\n","    \"10\": \"16\",\n","    \"100\": \"98\",\n","    \"101\": \"99\",\n","    \"11\": \"17\",\n","    \"12\": \"18\",\n","    \"13\": \"19\",\n","    \"14\": \"2\",\n","    \"15\": \"20\",\n","    \"16\": \"21\",\n","    \"17\": \"22\",\n","    \"18\": \"23\",\n","    \"19\": \"24\",\n","    \"2\": \"10\",\n","    \"20\": \"25\",\n","    \"21\": \"26\",\n","    \"22\": \"27\",\n","    \"23\": \"28\",\n","    \"24\": \"29\",\n","    \"25\": \"3\",\n","    \"26\": \"30\",\n","    \"27\": \"31\",\n","    \"28\": \"32\",\n","    \"29\": \"33\",\n","    \"3\": \"100\",\n","    \"30\": \"34\",\n","    \"31\": \"35\",\n","    \"32\": \"36\",\n","    \"33\": \"37\",\n","    \"34\": \"38\",\n","    \"35\": \"39\",\n","    \"36\": \"4\",\n","    \"37\": \"40\",\n","    \"38\": \"41\",\n","    \"39\": \"42\",\n","    \"4\": \"101\",\n","    \"40\": \"43\",\n","    \"41\": \"44\",\n","    \"42\": \"45\",\n","    \"43\": \"46\",\n","    \"44\": \"47\",\n","    \"45\": \"48\",\n","    \"46\": \"49\",\n","    \"47\": \"5\",\n","    \"48\": \"50\",\n","    \"49\": \"51\",\n","    \"5\": \"11\",\n","    \"50\": \"52\",\n","    \"51\": \"53\",\n","    \"52\": \"54\",\n","    \"53\": \"55\",\n","    \"54\": \"56\",\n","    \"55\": \"57\",\n","    \"56\": \"58\",\n","    \"57\": \"59\",\n","    \"58\": \"6\",\n","    \"59\": \"60\",\n","    \"6\": \"12\",\n","    \"60\": \"61\",\n","    \"61\": \"62\",\n","    \"62\": \"63\",\n","    \"63\": \"64\",\n","    \"64\": \"65\",\n","    \"65\": \"66\",\n","    \"66\": \"67\",\n","    \"67\": \"68\",\n","    \"68\": \"69\",\n","    \"69\": \"7\",\n","    \"7\": \"13\",\n","    \"70\": \"70\",\n","    \"71\": \"71\",\n","    \"72\": \"72\",\n","    \"73\": \"73\",\n","    \"74\": \"74\",\n","    \"75\": \"75\",\n","    \"76\": \"76\",\n","    \"77\": \"77\",\n","    \"78\": \"78\",\n","    \"79\": \"79\",\n","    \"8\": \"14\",\n","    \"80\": \"8\",\n","    \"81\": \"80\",\n","    \"82\": \"81\",\n","    \"83\": \"82\",\n","    \"84\": \"83\",\n","    \"85\": \"84\",\n","    \"86\": \"85\",\n","    \"87\": \"86\",\n","    \"88\": \"87\",\n","    \"89\": \"88\",\n","    \"9\": \"15\",\n","    \"90\": \"89\",\n","    \"91\": \"9\",\n","    \"92\": \"90\",\n","    \"93\": \"91\",\n","    \"94\": \"92\",\n","    \"95\": \"93\",\n","    \"96\": \"94\",\n","    \"97\": \"95\",\n","    \"98\": \"96\",\n","    \"99\": \"97\"\n","  },\n","  \"label2id\": {\n","    \"0\": \"0\",\n","    \"1\": \"1\",\n","    \"10\": \"2\",\n","    \"100\": \"3\",\n","    \"101\": \"4\",\n","    \"11\": \"5\",\n","    \"12\": \"6\",\n","    \"13\": \"7\",\n","    \"14\": \"8\",\n","    \"15\": \"9\",\n","    \"16\": \"10\",\n","    \"17\": \"11\",\n","    \"18\": \"12\",\n","    \"19\": \"13\",\n","    \"2\": \"14\",\n","    \"20\": \"15\",\n","    \"21\": \"16\",\n","    \"22\": \"17\",\n","    \"23\": \"18\",\n","    \"24\": \"19\",\n","    \"25\": \"20\",\n","    \"26\": \"21\",\n","    \"27\": \"22\",\n","    \"28\": \"23\",\n","    \"29\": \"24\",\n","    \"3\": \"25\",\n","    \"30\": \"26\",\n","    \"31\": \"27\",\n","    \"32\": \"28\",\n","    \"33\": \"29\",\n","    \"34\": \"30\",\n","    \"35\": \"31\",\n","    \"36\": \"32\",\n","    \"37\": \"33\",\n","    \"38\": \"34\",\n","    \"39\": \"35\",\n","    \"4\": \"36\",\n","    \"40\": \"37\",\n","    \"41\": \"38\",\n","    \"42\": \"39\",\n","    \"43\": \"40\",\n","    \"44\": \"41\",\n","    \"45\": \"42\",\n","    \"46\": \"43\",\n","    \"47\": \"44\",\n","    \"48\": \"45\",\n","    \"49\": \"46\",\n","    \"5\": \"47\",\n","    \"50\": \"48\",\n","    \"51\": \"49\",\n","    \"52\": \"50\",\n","    \"53\": \"51\",\n","    \"54\": \"52\",\n","    \"55\": \"53\",\n","    \"56\": \"54\",\n","    \"57\": \"55\",\n","    \"58\": \"56\",\n","    \"59\": \"57\",\n","    \"6\": \"58\",\n","    \"60\": \"59\",\n","    \"61\": \"60\",\n","    \"62\": \"61\",\n","    \"63\": \"62\",\n","    \"64\": \"63\",\n","    \"65\": \"64\",\n","    \"66\": \"65\",\n","    \"67\": \"66\",\n","    \"68\": \"67\",\n","    \"69\": \"68\",\n","    \"7\": \"69\",\n","    \"70\": \"70\",\n","    \"71\": \"71\",\n","    \"72\": \"72\",\n","    \"73\": \"73\",\n","    \"74\": \"74\",\n","    \"75\": \"75\",\n","    \"76\": \"76\",\n","    \"77\": \"77\",\n","    \"78\": \"78\",\n","    \"79\": \"79\",\n","    \"8\": \"80\",\n","    \"80\": \"81\",\n","    \"81\": \"82\",\n","    \"82\": \"83\",\n","    \"83\": \"84\",\n","    \"84\": \"85\",\n","    \"85\": \"86\",\n","    \"86\": \"87\",\n","    \"87\": \"88\",\n","    \"88\": \"89\",\n","    \"89\": \"90\",\n","    \"9\": \"91\",\n","    \"90\": \"92\",\n","    \"91\": \"93\",\n","    \"92\": \"94\",\n","    \"93\": \"95\",\n","    \"94\": \"96\",\n","    \"95\": \"97\",\n","    \"96\": \"98\",\n","    \"97\": \"99\",\n","    \"98\": \"100\",\n","    \"99\": \"101\"\n","  },\n","  \"layer_type\": \"basic\",\n","  \"model_type\": \"resnet\",\n","  \"num_channels\": 3,\n","  \"out_features\": [\n","    \"stage4\"\n","  ],\n","  \"out_indices\": [\n","    4\n","  ],\n","  \"stage_names\": [\n","    \"stem\",\n","    \"stage1\",\n","    \"stage2\",\n","    \"stage3\",\n","    \"stage4\"\n","  ],\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.33.0.dev0\"\n","}\n","\n","[INFO|modeling_utils.py:2857] 2023-09-02 19:20:37,677 >> loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--microsoft--resnet-18/snapshots/f45a6faa12e0381f5620c5c8d7e916bca90f2c44/model.safetensors\n","\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mavid-water-10\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/u15048366/colabCnnIp102Run1/runs/tgd6yq20\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n","\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230902_192017-tgd6yq20/logs\u001b[0m\n"]}],"source":["!python cnn.py \\\n","    --model_name microsoft/resnet-18 \\\n","    --model_type resnet \\\n","    --train_dir data/classification/train \\\n","    --validation_dir data/classification/test \\\n","    --output_dir drive/MyDrive/hons-research/output/cnn/ip102_outputs_4/ \\\n","    --remove_unused_columns False \\\n","    --do_train \\\n","    --do_eval \\\n","    --push_to_hub False \\\n","    --learning_rate 0.001 \\\n","    --num_train_epochs 300 \\\n","    --per_device_train_batch_size 512 \\\n","    --per_device_eval_batch_size 512 \\\n","    --logging_strategy steps \\\n","    --logging_steps 10 \\\n","    --evaluation_strategy epoch \\\n","    --save_strategy epoch \\\n","    --load_best_model_at_end True \\\n","    --save_total_limit 3 \\\n","    --save_steps 500 \\\n","    --data_seed 4 \\\n","    --seed 4\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"hw_zqhJyFKun","outputId":"7b7930d9-4581-474a-9288-b28fd5900e06"},"outputs":[{"name":"stdout","output_type":"stream","text":["2023-09-02 19:20:46.943148: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mu15048366\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.9\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20230902_192050-8m17agql\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmild-bee-11\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/u15048366/colabCnnIp102Run1\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/u15048366/colabCnnIp102Run1/runs/8m17agql\u001b[0m\n","09/02/2023 19:20:51 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n","09/02/2023 19:20:51 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n","_n_gpu=1,\n","adafactor=False,\n","adam_beta1=0.9,\n","adam_beta2=0.999,\n","adam_epsilon=1e-08,\n","auto_find_batch_size=False,\n","bf16=False,\n","bf16_full_eval=False,\n","data_seed=5,\n","dataloader_drop_last=False,\n","dataloader_num_workers=0,\n","dataloader_pin_memory=True,\n","ddp_backend=None,\n","ddp_broadcast_buffers=None,\n","ddp_bucket_cap_mb=None,\n","ddp_find_unused_parameters=None,\n","ddp_timeout=1800,\n","debug=[],\n","deepspeed=None,\n","disable_tqdm=False,\n","dispatch_batches=None,\n","do_eval=True,\n","do_predict=False,\n","do_train=True,\n","eval_accumulation_steps=None,\n","eval_delay=0,\n","eval_steps=None,\n","evaluation_strategy=epoch,\n","fp16=False,\n","fp16_backend=auto,\n","fp16_full_eval=False,\n","fp16_opt_level=O1,\n","fsdp=[],\n","fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n","fsdp_min_num_params=0,\n","fsdp_transformer_layer_cls_to_wrap=None,\n","full_determinism=False,\n","gradient_accumulation_steps=1,\n","gradient_checkpointing=False,\n","greater_is_better=False,\n","group_by_length=False,\n","half_precision_backend=auto,\n","hub_always_push=False,\n","hub_model_id=None,\n","hub_private_repo=False,\n","hub_strategy=every_save,\n","hub_token=<HUB_TOKEN>,\n","ignore_data_skip=False,\n","include_inputs_for_metrics=False,\n","jit_mode_eval=False,\n","label_names=None,\n","label_smoothing_factor=0.0,\n","learning_rate=0.001,\n","length_column_name=length,\n","load_best_model_at_end=True,\n","local_rank=0,\n","log_level=passive,\n","log_level_replica=warning,\n","log_on_each_node=True,\n","logging_dir=drive/MyDrive/hons-research/output/cnn/ip102_outputs_5/runs/Sep02_19-20-51_f10132d8a075,\n","logging_first_step=False,\n","logging_nan_inf_filter=True,\n","logging_steps=10,\n","logging_strategy=steps,\n","lr_scheduler_type=linear,\n","max_grad_norm=1.0,\n","max_steps=-1,\n","metric_for_best_model=loss,\n","mp_parameters=,\n","no_cuda=False,\n","num_train_epochs=300.0,\n","optim=adamw_torch,\n","optim_args=None,\n","output_dir=drive/MyDrive/hons-research/output/cnn/ip102_outputs_5/,\n","overwrite_output_dir=False,\n","past_index=-1,\n","per_device_eval_batch_size=512,\n","per_device_train_batch_size=512,\n","prediction_loss_only=False,\n","push_to_hub=False,\n","push_to_hub_model_id=None,\n","push_to_hub_organization=None,\n","push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n","ray_scope=last,\n","remove_unused_columns=False,\n","report_to=['tensorboard', 'wandb'],\n","resume_from_checkpoint=None,\n","run_name=drive/MyDrive/hons-research/output/cnn/ip102_outputs_5/,\n","save_on_each_node=False,\n","save_safetensors=False,\n","save_steps=500.0,\n","save_strategy=epoch,\n","save_total_limit=3,\n","seed=5,\n","sharded_ddp=[],\n","skip_memory_metrics=True,\n","tf32=None,\n","torch_compile=False,\n","torch_compile_backend=None,\n","torch_compile_mode=None,\n","torchdynamo=None,\n","tpu_metrics_debug=False,\n","tpu_num_cores=None,\n","use_cpu=False,\n","use_ipex=False,\n","use_legacy_prediction_loop=False,\n","use_mps_device=False,\n","warmup_ratio=0.0,\n","warmup_steps=0,\n","weight_decay=0.0,\n",")\n","/usr/local/lib/python3.10/dist-packages/datasets/load.py:2086: FutureWarning: 'task' was deprecated in version 2.13.0 and will be removed in 3.0.0.\n","\n","  warnings.warn(\n","Resolving data files: 100% 45095/45095 [00:00<00:00, 391662.69it/s]\n","Resolving data files: 100% 22619/22619 [00:00<00:00, 44270.39it/s]\n","\n","\n","\n","None\n","\n","\n","\n","[INFO|configuration_utils.py:715] 2023-09-02 19:21:10,883 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--resnet-18/snapshots/f45a6faa12e0381f5620c5c8d7e916bca90f2c44/config.json\n","[INFO|configuration_utils.py:775] 2023-09-02 19:21:10,884 >> Model config ResNetConfig {\n","  \"_name_or_path\": \"microsoft/resnet-18\",\n","  \"architectures\": [\n","    \"ResNetForImageClassification\"\n","  ],\n","  \"depths\": [\n","    2,\n","    2,\n","    2,\n","    2\n","  ],\n","  \"downsample_in_first_stage\": false,\n","  \"embedding_size\": 64,\n","  \"finetuning_task\": \"image-classification\",\n","  \"hidden_act\": \"relu\",\n","  \"hidden_sizes\": [\n","    64,\n","    128,\n","    256,\n","    512\n","  ],\n","  \"id2label\": {\n","    \"0\": \"0\",\n","    \"1\": \"1\",\n","    \"10\": \"16\",\n","    \"100\": \"98\",\n","    \"101\": \"99\",\n","    \"11\": \"17\",\n","    \"12\": \"18\",\n","    \"13\": \"19\",\n","    \"14\": \"2\",\n","    \"15\": \"20\",\n","    \"16\": \"21\",\n","    \"17\": \"22\",\n","    \"18\": \"23\",\n","    \"19\": \"24\",\n","    \"2\": \"10\",\n","    \"20\": \"25\",\n","    \"21\": \"26\",\n","    \"22\": \"27\",\n","    \"23\": \"28\",\n","    \"24\": \"29\",\n","    \"25\": \"3\",\n","    \"26\": \"30\",\n","    \"27\": \"31\",\n","    \"28\": \"32\",\n","    \"29\": \"33\",\n","    \"3\": \"100\",\n","    \"30\": \"34\",\n","    \"31\": \"35\",\n","    \"32\": \"36\",\n","    \"33\": \"37\",\n","    \"34\": \"38\",\n","    \"35\": \"39\",\n","    \"36\": \"4\",\n","    \"37\": \"40\",\n","    \"38\": \"41\",\n","    \"39\": \"42\",\n","    \"4\": \"101\",\n","    \"40\": \"43\",\n","    \"41\": \"44\",\n","    \"42\": \"45\",\n","    \"43\": \"46\",\n","    \"44\": \"47\",\n","    \"45\": \"48\",\n","    \"46\": \"49\",\n","    \"47\": \"5\",\n","    \"48\": \"50\",\n","    \"49\": \"51\",\n","    \"5\": \"11\",\n","    \"50\": \"52\",\n","    \"51\": \"53\",\n","    \"52\": \"54\",\n","    \"53\": \"55\",\n","    \"54\": \"56\",\n","    \"55\": \"57\",\n","    \"56\": \"58\",\n","    \"57\": \"59\",\n","    \"58\": \"6\",\n","    \"59\": \"60\",\n","    \"6\": \"12\",\n","    \"60\": \"61\",\n","    \"61\": \"62\",\n","    \"62\": \"63\",\n","    \"63\": \"64\",\n","    \"64\": \"65\",\n","    \"65\": \"66\",\n","    \"66\": \"67\",\n","    \"67\": \"68\",\n","    \"68\": \"69\",\n","    \"69\": \"7\",\n","    \"7\": \"13\",\n","    \"70\": \"70\",\n","    \"71\": \"71\",\n","    \"72\": \"72\",\n","    \"73\": \"73\",\n","    \"74\": \"74\",\n","    \"75\": \"75\",\n","    \"76\": \"76\",\n","    \"77\": \"77\",\n","    \"78\": \"78\",\n","    \"79\": \"79\",\n","    \"8\": \"14\",\n","    \"80\": \"8\",\n","    \"81\": \"80\",\n","    \"82\": \"81\",\n","    \"83\": \"82\",\n","    \"84\": \"83\",\n","    \"85\": \"84\",\n","    \"86\": \"85\",\n","    \"87\": \"86\",\n","    \"88\": \"87\",\n","    \"89\": \"88\",\n","    \"9\": \"15\",\n","    \"90\": \"89\",\n","    \"91\": \"9\",\n","    \"92\": \"90\",\n","    \"93\": \"91\",\n","    \"94\": \"92\",\n","    \"95\": \"93\",\n","    \"96\": \"94\",\n","    \"97\": \"95\",\n","    \"98\": \"96\",\n","    \"99\": \"97\"\n","  },\n","  \"label2id\": {\n","    \"0\": \"0\",\n","    \"1\": \"1\",\n","    \"10\": \"2\",\n","    \"100\": \"3\",\n","    \"101\": \"4\",\n","    \"11\": \"5\",\n","    \"12\": \"6\",\n","    \"13\": \"7\",\n","    \"14\": \"8\",\n","    \"15\": \"9\",\n","    \"16\": \"10\",\n","    \"17\": \"11\",\n","    \"18\": \"12\",\n","    \"19\": \"13\",\n","    \"2\": \"14\",\n","    \"20\": \"15\",\n","    \"21\": \"16\",\n","    \"22\": \"17\",\n","    \"23\": \"18\",\n","    \"24\": \"19\",\n","    \"25\": \"20\",\n","    \"26\": \"21\",\n","    \"27\": \"22\",\n","    \"28\": \"23\",\n","    \"29\": \"24\",\n","    \"3\": \"25\",\n","    \"30\": \"26\",\n","    \"31\": \"27\",\n","    \"32\": \"28\",\n","    \"33\": \"29\",\n","    \"34\": \"30\",\n","    \"35\": \"31\",\n","    \"36\": \"32\",\n","    \"37\": \"33\",\n","    \"38\": \"34\",\n","    \"39\": \"35\",\n","    \"4\": \"36\",\n","    \"40\": \"37\",\n","    \"41\": \"38\",\n","    \"42\": \"39\",\n","    \"43\": \"40\",\n","    \"44\": \"41\",\n","    \"45\": \"42\",\n","    \"46\": \"43\",\n","    \"47\": \"44\",\n","    \"48\": \"45\",\n","    \"49\": \"46\",\n","    \"5\": \"47\",\n","    \"50\": \"48\",\n","    \"51\": \"49\",\n","    \"52\": \"50\",\n","    \"53\": \"51\",\n","    \"54\": \"52\",\n","    \"55\": \"53\",\n","    \"56\": \"54\",\n","    \"57\": \"55\",\n","    \"58\": \"56\",\n","    \"59\": \"57\",\n","    \"6\": \"58\",\n","    \"60\": \"59\",\n","    \"61\": \"60\",\n","    \"62\": \"61\",\n","    \"63\": \"62\",\n","    \"64\": \"63\",\n","    \"65\": \"64\",\n","    \"66\": \"65\",\n","    \"67\": \"66\",\n","    \"68\": \"67\",\n","    \"69\": \"68\",\n","    \"7\": \"69\",\n","    \"70\": \"70\",\n","    \"71\": \"71\",\n","    \"72\": \"72\",\n","    \"73\": \"73\",\n","    \"74\": \"74\",\n","    \"75\": \"75\",\n","    \"76\": \"76\",\n","    \"77\": \"77\",\n","    \"78\": \"78\",\n","    \"79\": \"79\",\n","    \"8\": \"80\",\n","    \"80\": \"81\",\n","    \"81\": \"82\",\n","    \"82\": \"83\",\n","    \"83\": \"84\",\n","    \"84\": \"85\",\n","    \"85\": \"86\",\n","    \"86\": \"87\",\n","    \"87\": \"88\",\n","    \"88\": \"89\",\n","    \"89\": \"90\",\n","    \"9\": \"91\",\n","    \"90\": \"92\",\n","    \"91\": \"93\",\n","    \"92\": \"94\",\n","    \"93\": \"95\",\n","    \"94\": \"96\",\n","    \"95\": \"97\",\n","    \"96\": \"98\",\n","    \"97\": \"99\",\n","    \"98\": \"100\",\n","    \"99\": \"101\"\n","  },\n","  \"layer_type\": \"basic\",\n","  \"model_type\": \"resnet\",\n","  \"num_channels\": 3,\n","  \"out_features\": [\n","    \"stage4\"\n","  ],\n","  \"out_indices\": [\n","    4\n","  ],\n","  \"stage_names\": [\n","    \"stem\",\n","    \"stage1\",\n","    \"stage2\",\n","    \"stage3\",\n","    \"stage4\"\n","  ],\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.33.0.dev0\"\n","}\n","\n","[INFO|modeling_utils.py:2857] 2023-09-02 19:21:10,887 >> loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--microsoft--resnet-18/snapshots/f45a6faa12e0381f5620c5c8d7e916bca90f2c44/model.safetensors\n","\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mmild-bee-11\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/u15048366/colabCnnIp102Run1/runs/8m17agql\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n","\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230902_192050-8m17agql/logs\u001b[0m\n"]}],"source":["!python cnn.py \\\n","    --model_name microsoft/resnet-18 \\\n","    --model_type resnet \\\n","    --train_dir data/classification/train \\\n","    --validation_dir data/classification/test \\\n","    --output_dir drive/MyDrive/hons-research/output/cnn/ip102_outputs_5/ \\\n","    --remove_unused_columns False \\\n","    --do_train \\\n","    --do_eval \\\n","    --push_to_hub False \\\n","    --learning_rate 0.001 \\\n","    --num_train_epochs 300 \\\n","    --per_device_train_batch_size 512 \\\n","    --per_device_eval_batch_size 512 \\\n","    --logging_strategy steps \\\n","    --logging_steps 10 \\\n","    --evaluation_strategy epoch \\\n","    --save_strategy epoch \\\n","    --load_best_model_at_end True \\\n","    --save_total_limit 3 \\\n","    --save_steps 500 \\\n","    --data_seed 5 \\\n","    --seed 5\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lGabtHrcFOTk","outputId":"7f46de65-b03b-4e46-e3d0-483542a7ffc5"},"outputs":[{"output_type":"stream","name":"stdout","text":["2023-09-13 07:22:59.832424: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mu15048366\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.10\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20230913_072304-ktr8vaof\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mrosy-frog-22\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/u15048366/colabCnnIp102Run1\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/u15048366/colabCnnIp102Run1/runs/ktr8vaof\u001b[0m\n","09/13/2023 07:23:05 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n","09/13/2023 07:23:05 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n","_n_gpu=1,\n","adafactor=False,\n","adam_beta1=0.9,\n","adam_beta2=0.999,\n","adam_epsilon=1e-08,\n","auto_find_batch_size=False,\n","bf16=False,\n","bf16_full_eval=False,\n","data_seed=6,\n","dataloader_drop_last=False,\n","dataloader_num_workers=0,\n","dataloader_pin_memory=True,\n","ddp_backend=None,\n","ddp_broadcast_buffers=None,\n","ddp_bucket_cap_mb=None,\n","ddp_find_unused_parameters=None,\n","ddp_timeout=1800,\n","debug=[],\n","deepspeed=None,\n","disable_tqdm=False,\n","dispatch_batches=None,\n","do_eval=True,\n","do_predict=False,\n","do_train=True,\n","eval_accumulation_steps=None,\n","eval_delay=0,\n","eval_steps=None,\n","evaluation_strategy=epoch,\n","fp16=False,\n","fp16_backend=auto,\n","fp16_full_eval=False,\n","fp16_opt_level=O1,\n","fsdp=[],\n","fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n","fsdp_min_num_params=0,\n","fsdp_transformer_layer_cls_to_wrap=None,\n","full_determinism=False,\n","gradient_accumulation_steps=1,\n","gradient_checkpointing=False,\n","greater_is_better=False,\n","group_by_length=False,\n","half_precision_backend=auto,\n","hub_always_push=False,\n","hub_model_id=None,\n","hub_private_repo=False,\n","hub_strategy=every_save,\n","hub_token=<HUB_TOKEN>,\n","ignore_data_skip=False,\n","include_inputs_for_metrics=False,\n","include_tokens_per_second=False,\n","jit_mode_eval=False,\n","label_names=None,\n","label_smoothing_factor=0.0,\n","learning_rate=0.001,\n","length_column_name=length,\n","load_best_model_at_end=True,\n","local_rank=0,\n","log_level=passive,\n","log_level_replica=warning,\n","log_on_each_node=True,\n","logging_dir=drive/MyDrive/hons-research/output/cnn/ip102_outputs_6/runs/Sep13_07-23-04_b7df1b119eb1,\n","logging_first_step=False,\n","logging_nan_inf_filter=True,\n","logging_steps=10,\n","logging_strategy=steps,\n","lr_scheduler_type=linear,\n","max_grad_norm=1.0,\n","max_steps=-1,\n","metric_for_best_model=loss,\n","mp_parameters=,\n","no_cuda=False,\n","num_train_epochs=300.0,\n","optim=adamw_torch,\n","optim_args=None,\n","output_dir=drive/MyDrive/hons-research/output/cnn/ip102_outputs_6/,\n","overwrite_output_dir=False,\n","past_index=-1,\n","per_device_eval_batch_size=512,\n","per_device_train_batch_size=512,\n","prediction_loss_only=False,\n","push_to_hub=False,\n","push_to_hub_model_id=None,\n","push_to_hub_organization=None,\n","push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n","ray_scope=last,\n","remove_unused_columns=False,\n","report_to=['tensorboard', 'wandb'],\n","resume_from_checkpoint=None,\n","run_name=drive/MyDrive/hons-research/output/cnn/ip102_outputs_6/,\n","save_on_each_node=False,\n","save_safetensors=False,\n","save_steps=500.0,\n","save_strategy=epoch,\n","save_total_limit=3,\n","seed=6,\n","sharded_ddp=[],\n","skip_memory_metrics=True,\n","tf32=None,\n","torch_compile=False,\n","torch_compile_backend=None,\n","torch_compile_mode=None,\n","torchdynamo=None,\n","tpu_metrics_debug=False,\n","tpu_num_cores=None,\n","use_cpu=False,\n","use_ipex=False,\n","use_legacy_prediction_loop=False,\n","use_mps_device=False,\n","warmup_ratio=0.0,\n","warmup_steps=0,\n","weight_decay=0.0,\n",")\n","/usr/local/lib/python3.10/dist-packages/datasets/load.py:2103: FutureWarning: 'task' was deprecated in version 2.13.0 and will be removed in 3.0.0.\n","\n","  warnings.warn(\n","Resolving data files: 100% 45095/45095 [00:00<00:00, 309862.34it/s]\n","Resolving data files: 100% 22619/22619 [00:00<00:00, 95072.04it/s]\n","\n","\n","\n","None\n","\n","\n","\n","[INFO|configuration_utils.py:715] 2023-09-13 07:23:26,374 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--resnet-18/snapshots/f45a6faa12e0381f5620c5c8d7e916bca90f2c44/config.json\n","[INFO|configuration_utils.py:775] 2023-09-13 07:23:26,376 >> Model config ResNetConfig {\n","  \"_name_or_path\": \"microsoft/resnet-18\",\n","  \"architectures\": [\n","    \"ResNetForImageClassification\"\n","  ],\n","  \"depths\": [\n","    2,\n","    2,\n","    2,\n","    2\n","  ],\n","  \"downsample_in_first_stage\": false,\n","  \"embedding_size\": 64,\n","  \"finetuning_task\": \"image-classification\",\n","  \"hidden_act\": \"relu\",\n","  \"hidden_sizes\": [\n","    64,\n","    128,\n","    256,\n","    512\n","  ],\n","  \"id2label\": {\n","    \"0\": \"0\",\n","    \"1\": \"1\",\n","    \"10\": \"16\",\n","    \"100\": \"98\",\n","    \"101\": \"99\",\n","    \"11\": \"17\",\n","    \"12\": \"18\",\n","    \"13\": \"19\",\n","    \"14\": \"2\",\n","    \"15\": \"20\",\n","    \"16\": \"21\",\n","    \"17\": \"22\",\n","    \"18\": \"23\",\n","    \"19\": \"24\",\n","    \"2\": \"10\",\n","    \"20\": \"25\",\n","    \"21\": \"26\",\n","    \"22\": \"27\",\n","    \"23\": \"28\",\n","    \"24\": \"29\",\n","    \"25\": \"3\",\n","    \"26\": \"30\",\n","    \"27\": \"31\",\n","    \"28\": \"32\",\n","    \"29\": \"33\",\n","    \"3\": \"100\",\n","    \"30\": \"34\",\n","    \"31\": \"35\",\n","    \"32\": \"36\",\n","    \"33\": \"37\",\n","    \"34\": \"38\",\n","    \"35\": \"39\",\n","    \"36\": \"4\",\n","    \"37\": \"40\",\n","    \"38\": \"41\",\n","    \"39\": \"42\",\n","    \"4\": \"101\",\n","    \"40\": \"43\",\n","    \"41\": \"44\",\n","    \"42\": \"45\",\n","    \"43\": \"46\",\n","    \"44\": \"47\",\n","    \"45\": \"48\",\n","    \"46\": \"49\",\n","    \"47\": \"5\",\n","    \"48\": \"50\",\n","    \"49\": \"51\",\n","    \"5\": \"11\",\n","    \"50\": \"52\",\n","    \"51\": \"53\",\n","    \"52\": \"54\",\n","    \"53\": \"55\",\n","    \"54\": \"56\",\n","    \"55\": \"57\",\n","    \"56\": \"58\",\n","    \"57\": \"59\",\n","    \"58\": \"6\",\n","    \"59\": \"60\",\n","    \"6\": \"12\",\n","    \"60\": \"61\",\n","    \"61\": \"62\",\n","    \"62\": \"63\",\n","    \"63\": \"64\",\n","    \"64\": \"65\",\n","    \"65\": \"66\",\n","    \"66\": \"67\",\n","    \"67\": \"68\",\n","    \"68\": \"69\",\n","    \"69\": \"7\",\n","    \"7\": \"13\",\n","    \"70\": \"70\",\n","    \"71\": \"71\",\n","    \"72\": \"72\",\n","    \"73\": \"73\",\n","    \"74\": \"74\",\n","    \"75\": \"75\",\n","    \"76\": \"76\",\n","    \"77\": \"77\",\n","    \"78\": \"78\",\n","    \"79\": \"79\",\n","    \"8\": \"14\",\n","    \"80\": \"8\",\n","    \"81\": \"80\",\n","    \"82\": \"81\",\n","    \"83\": \"82\",\n","    \"84\": \"83\",\n","    \"85\": \"84\",\n","    \"86\": \"85\",\n","    \"87\": \"86\",\n","    \"88\": \"87\",\n","    \"89\": \"88\",\n","    \"9\": \"15\",\n","    \"90\": \"89\",\n","    \"91\": \"9\",\n","    \"92\": \"90\",\n","    \"93\": \"91\",\n","    \"94\": \"92\",\n","    \"95\": \"93\",\n","    \"96\": \"94\",\n","    \"97\": \"95\",\n","    \"98\": \"96\",\n","    \"99\": \"97\"\n","  },\n","  \"label2id\": {\n","    \"0\": \"0\",\n","    \"1\": \"1\",\n","    \"10\": \"2\",\n","    \"100\": \"3\",\n","    \"101\": \"4\",\n","    \"11\": \"5\",\n","    \"12\": \"6\",\n","    \"13\": \"7\",\n","    \"14\": \"8\",\n","    \"15\": \"9\",\n","    \"16\": \"10\",\n","    \"17\": \"11\",\n","    \"18\": \"12\",\n","    \"19\": \"13\",\n","    \"2\": \"14\",\n","    \"20\": \"15\",\n","    \"21\": \"16\",\n","    \"22\": \"17\",\n","    \"23\": \"18\",\n","    \"24\": \"19\",\n","    \"25\": \"20\",\n","    \"26\": \"21\",\n","    \"27\": \"22\",\n","    \"28\": \"23\",\n","    \"29\": \"24\",\n","    \"3\": \"25\",\n","    \"30\": \"26\",\n","    \"31\": \"27\",\n","    \"32\": \"28\",\n","    \"33\": \"29\",\n","    \"34\": \"30\",\n","    \"35\": \"31\",\n","    \"36\": \"32\",\n","    \"37\": \"33\",\n","    \"38\": \"34\",\n","    \"39\": \"35\",\n","    \"4\": \"36\",\n","    \"40\": \"37\",\n","    \"41\": \"38\",\n","    \"42\": \"39\",\n","    \"43\": \"40\",\n","    \"44\": \"41\",\n","    \"45\": \"42\",\n","    \"46\": \"43\",\n","    \"47\": \"44\",\n","    \"48\": \"45\",\n","    \"49\": \"46\",\n","    \"5\": \"47\",\n","    \"50\": \"48\",\n","    \"51\": \"49\",\n","    \"52\": \"50\",\n","    \"53\": \"51\",\n","    \"54\": \"52\",\n","    \"55\": \"53\",\n","    \"56\": \"54\",\n","    \"57\": \"55\",\n","    \"58\": \"56\",\n","    \"59\": \"57\",\n","    \"6\": \"58\",\n","    \"60\": \"59\",\n","    \"61\": \"60\",\n","    \"62\": \"61\",\n","    \"63\": \"62\",\n","    \"64\": \"63\",\n","    \"65\": \"64\",\n","    \"66\": \"65\",\n","    \"67\": \"66\",\n","    \"68\": \"67\",\n","    \"69\": \"68\",\n","    \"7\": \"69\",\n","    \"70\": \"70\",\n","    \"71\": \"71\",\n","    \"72\": \"72\",\n","    \"73\": \"73\",\n","    \"74\": \"74\",\n","    \"75\": \"75\",\n","    \"76\": \"76\",\n","    \"77\": \"77\",\n","    \"78\": \"78\",\n","    \"79\": \"79\",\n","    \"8\": \"80\",\n","    \"80\": \"81\",\n","    \"81\": \"82\",\n","    \"82\": \"83\",\n","    \"83\": \"84\",\n","    \"84\": \"85\",\n","    \"85\": \"86\",\n","    \"86\": \"87\",\n","    \"87\": \"88\",\n","    \"88\": \"89\",\n","    \"89\": \"90\",\n","    \"9\": \"91\",\n","    \"90\": \"92\",\n","    \"91\": \"93\",\n","    \"92\": \"94\",\n","    \"93\": \"95\",\n","    \"94\": \"96\",\n","    \"95\": \"97\",\n","    \"96\": \"98\",\n","    \"97\": \"99\",\n","    \"98\": \"100\",\n","    \"99\": \"101\"\n","  },\n","  \"layer_type\": \"basic\",\n","  \"model_type\": \"resnet\",\n","  \"num_channels\": 3,\n","  \"out_features\": [\n","    \"stage4\"\n","  ],\n","  \"out_indices\": [\n","    4\n","  ],\n","  \"stage_names\": [\n","    \"stem\",\n","    \"stage1\",\n","    \"stage2\",\n","    \"stage3\",\n","    \"stage4\"\n","  ],\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.34.0.dev0\"\n","}\n","\n","[INFO|modeling_utils.py:2866] 2023-09-13 07:23:26,378 >> loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--microsoft--resnet-18/snapshots/f45a6faa12e0381f5620c5c8d7e916bca90f2c44/model.safetensors\n","[INFO|modeling_utils.py:3652] 2023-09-13 07:23:26,492 >> All model checkpoint weights were used when initializing ResNetForImageClassification.\n","\n","[WARNING|modeling_utils.py:3673] 2023-09-13 07:23:26,492 >> Some weights of ResNetForImageClassification were not initialized from the model checkpoint at microsoft/resnet-18 and are newly initialized because the shapes did not match:\n","- classifier.1.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([102]) in the model instantiated\n","- classifier.1.weight: found shape torch.Size([1000, 512]) in the checkpoint and torch.Size([102, 512]) in the model instantiated\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Downloading (…)rocessor_config.json: 100% 266/266 [00:00<00:00, 898kB/s]\n","[INFO|image_processing_utils.py:369] 2023-09-13 07:23:26,995 >> loading configuration file preprocessor_config.json from cache at /root/.cache/huggingface/hub/models--microsoft--resnet-18/snapshots/f45a6faa12e0381f5620c5c8d7e916bca90f2c44/preprocessor_config.json\n","[WARNING|image_processing_auto.py:355] 2023-09-13 07:23:26,995 >> Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n","[INFO|image_processing_utils.py:732] 2023-09-13 07:23:26,997 >> size should be a dictionary on of the following set of keys: ({'width', 'height'}, {'shortest_edge'}, {'shortest_edge', 'longest_edge'}, {'longest_edge'}), got 224. Converted to {'shortest_edge': 224}.\n","[INFO|image_processing_utils.py:419] 2023-09-13 07:23:26,997 >> Image processor ConvNextImageProcessor {\n","  \"crop_pct\": 0.875,\n","  \"do_normalize\": true,\n","  \"do_rescale\": true,\n","  \"do_resize\": true,\n","  \"image_mean\": [\n","    0.485,\n","    0.456,\n","    0.406\n","  ],\n","  \"image_processor_type\": \"ConvNextImageProcessor\",\n","  \"image_std\": [\n","    0.229,\n","    0.224,\n","    0.225\n","  ],\n","  \"resample\": 3,\n","  \"rescale_factor\": 0.00392156862745098,\n","  \"size\": {\n","    \"shortest_edge\": 224\n","  }\n","}\n","\n","[INFO|trainer.py:1743] 2023-09-13 07:23:31,674 >> ***** Running training *****\n","[INFO|trainer.py:1744] 2023-09-13 07:23:31,674 >>   Num examples = 45,095\n","[INFO|trainer.py:1745] 2023-09-13 07:23:31,674 >>   Num Epochs = 300\n","[INFO|trainer.py:1746] 2023-09-13 07:23:31,675 >>   Instantaneous batch size per device = 512\n","[INFO|trainer.py:1749] 2023-09-13 07:23:31,675 >>   Total train batch size (w. parallel, distributed & accumulation) = 512\n","[INFO|trainer.py:1750] 2023-09-13 07:23:31,675 >>   Gradient Accumulation steps = 1\n","[INFO|trainer.py:1751] 2023-09-13 07:23:31,675 >>   Total optimization steps = 26,700\n","[INFO|trainer.py:1752] 2023-09-13 07:23:31,675 >>   Number of trainable parameters = 11,228,838\n","[INFO|integration_utils.py:722] 2023-09-13 07:23:31,685 >> Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n","{'loss': 3.5505, 'learning_rate': 0.0009996254681647941, 'epoch': 0.11}\n","{'loss': 2.8735, 'learning_rate': 0.000999250936329588, 'epoch': 0.22}\n","{'loss': 2.7271, 'learning_rate': 0.000998876404494382, 'epoch': 0.34}\n","{'loss': 2.536, 'learning_rate': 0.000998501872659176, 'epoch': 0.45}\n","{'loss': 2.4663, 'learning_rate': 0.00099812734082397, 'epoch': 0.56}\n","{'loss': 2.3537, 'learning_rate': 0.0009977528089887642, 'epoch': 0.67}\n","{'loss': 2.3263, 'learning_rate': 0.000997378277153558, 'epoch': 0.79}\n","{'loss': 2.2519, 'learning_rate': 0.000997003745318352, 'epoch': 0.9}\n","  0% 88/26700 [03:43<13:46:26,  1.86s/it][INFO|trainer.py:3177] 2023-09-13 07:27:15,623 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3179] 2023-09-13 07:27:15,623 >>   Num examples = 22619\n","[INFO|trainer.py:3182] 2023-09-13 07:27:15,623 >>   Batch size = 512\n","\n","  0% 0/45 [00:00<?, ?it/s]\u001b[A\n","  4% 2/45 [00:02<00:53,  1.24s/it]\u001b[A\n","  7% 3/45 [00:05<01:19,  1.88s/it]\u001b[A\n","  9% 4/45 [00:07<01:26,  2.12s/it]\u001b[A\n"," 11% 5/45 [00:10<01:32,  2.31s/it]\u001b[A\n"," 13% 6/45 [00:13<01:39,  2.55s/it]\u001b[A\n"," 16% 7/45 [00:16<01:41,  2.68s/it]\u001b[A\n"," 18% 8/45 [00:19<01:43,  2.80s/it]\u001b[A\n"," 20% 9/45 [00:22<01:45,  2.92s/it]\u001b[A\n"," 22% 10/45 [00:26<01:47,  3.07s/it]\u001b[A\n"," 24% 11/45 [00:28<01:37,  2.86s/it]\u001b[A\n"," 27% 12/45 [00:31<01:31,  2.79s/it]\u001b[A\n"," 29% 13/45 [00:33<01:24,  2.63s/it]\u001b[A\n"," 31% 14/45 [00:36<01:22,  2.67s/it]\u001b[A\n"," 33% 15/45 [00:38<01:18,  2.61s/it]\u001b[A\n"," 36% 16/45 [00:41<01:16,  2.63s/it]\u001b[A\n"," 38% 17/45 [00:43<01:10,  2.53s/it]\u001b[A\n"," 40% 18/45 [00:45<01:04,  2.38s/it]\u001b[A\n"," 42% 19/45 [00:48<01:02,  2.42s/it]\u001b[A\n"," 44% 20/45 [00:50<01:03,  2.52s/it]\u001b[A\n"," 47% 21/45 [00:53<01:01,  2.55s/it]\u001b[A\n"," 49% 22/45 [00:55<00:57,  2.50s/it]\u001b[A\n"," 51% 23/45 [00:57<00:52,  2.39s/it]\u001b[A\n"," 53% 24/45 [01:00<00:52,  2.52s/it]\u001b[A\n"," 56% 25/45 [01:03<00:51,  2.59s/it]\u001b[A\n"," 58% 26/45 [01:05<00:45,  2.40s/it]\u001b[A\n"," 60% 27/45 [01:08<00:47,  2.61s/it]\u001b[A\n"," 62% 28/45 [01:11<00:46,  2.73s/it]\u001b[A\n"," 64% 29/45 [01:14<00:42,  2.63s/it]\u001b[A\n"," 67% 30/45 [01:16<00:39,  2.63s/it]\u001b[A\n"," 69% 31/45 [01:20<00:39,  2.85s/it]\u001b[A\n"," 71% 32/45 [01:23<00:37,  2.92s/it]\u001b[A\n"," 73% 33/45 [01:25<00:34,  2.86s/it]\u001b[A\n"," 76% 34/45 [01:28<00:31,  2.86s/it]\u001b[A\n"," 78% 35/45 [01:31<00:28,  2.86s/it]\u001b[A\n"," 80% 36/45 [01:34<00:25,  2.84s/it]\u001b[A\n"," 82% 37/45 [01:36<00:21,  2.64s/it]\u001b[A\n"," 84% 38/45 [01:38<00:17,  2.52s/it]\u001b[A\n"," 87% 39/45 [01:40<00:14,  2.42s/it]\u001b[A\n"," 89% 40/45 [01:43<00:12,  2.58s/it]\u001b[A\n"," 91% 41/45 [01:46<00:10,  2.51s/it]\u001b[A\n"," 93% 42/45 [01:48<00:07,  2.47s/it]\u001b[A\n"," 96% 43/45 [01:50<00:04,  2.40s/it]\u001b[A\n","                                         \n","\u001b[A{'eval_loss': 2.487842559814453, 'eval_accuracy': 0.3932976701003581, 'eval_runtime': 117.125, 'eval_samples_per_second': 193.119, 'eval_steps_per_second': 0.384, 'epoch': 1.0}\n","  0% 89/26700 [05:41<13:46:24,  1.86s/it]\n","100% 45/45 [01:51<00:00,  1.85s/it]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2903] 2023-09-13 07:29:12,754 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_6/checkpoint-89\n","[INFO|configuration_utils.py:460] 2023-09-13 07:29:12,759 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_6/checkpoint-89/config.json\n","[INFO|modeling_utils.py:1997] 2023-09-13 07:29:12,874 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_6/checkpoint-89/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-13 07:29:12,878 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_6/checkpoint-89/preprocessor_config.json\n","{'loss': 2.1998, 'learning_rate': 0.000996629213483146, 'epoch': 1.01}\n","{'loss': 2.0843, 'learning_rate': 0.0009962546816479402, 'epoch': 1.12}\n","{'loss': 2.0229, 'learning_rate': 0.000995880149812734, 'epoch': 1.24}\n","{'loss': 2.0277, 'learning_rate': 0.0009955056179775281, 'epoch': 1.35}\n","{'loss': 1.992, 'learning_rate': 0.0009951310861423222, 'epoch': 1.46}\n","{'loss': 1.9929, 'learning_rate': 0.0009947565543071161, 'epoch': 1.57}\n","{'loss': 1.9533, 'learning_rate': 0.0009943820224719102, 'epoch': 1.69}\n","{'loss': 1.9378, 'learning_rate': 0.000994007490636704, 'epoch': 1.8}\n","{'loss': 1.9105, 'learning_rate': 0.0009936329588014982, 'epoch': 1.91}\n","  1% 177/26700 [09:14<13:48:27,  1.87s/it][INFO|trainer.py:3177] 2023-09-13 07:32:46,538 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3179] 2023-09-13 07:32:46,539 >>   Num examples = 22619\n","[INFO|trainer.py:3182] 2023-09-13 07:32:46,539 >>   Batch size = 512\n","\n","  0% 0/45 [00:00<?, ?it/s]\u001b[A\n","  4% 2/45 [00:02<00:55,  1.30s/it]\u001b[A\n","  7% 3/45 [00:05<01:20,  1.91s/it]\u001b[A\n","  9% 4/45 [00:07<01:26,  2.11s/it]\u001b[A\n"," 11% 5/45 [00:10<01:30,  2.27s/it]\u001b[A\n"," 13% 6/45 [00:13<01:38,  2.53s/it]\u001b[A\n"," 16% 7/45 [00:16<01:42,  2.69s/it]\u001b[A\n"," 18% 8/45 [00:19<01:44,  2.81s/it]\u001b[A\n"," 20% 9/45 [00:22<01:44,  2.92s/it]\u001b[A\n"," 22% 10/45 [00:25<01:45,  3.03s/it]\u001b[A\n"," 24% 11/45 [00:28<01:36,  2.84s/it]\u001b[A\n"," 27% 12/45 [00:31<01:32,  2.79s/it]\u001b[A\n"," 29% 13/45 [00:33<01:24,  2.64s/it]\u001b[A\n"," 31% 14/45 [00:36<01:22,  2.67s/it]\u001b[A\n"," 33% 15/45 [00:38<01:17,  2.59s/it]\u001b[A\n"," 36% 16/45 [00:41<01:15,  2.60s/it]\u001b[A\n"," 38% 17/45 [00:43<01:10,  2.53s/it]\u001b[A\n"," 40% 18/45 [00:45<01:04,  2.40s/it]\u001b[A\n"," 42% 19/45 [00:48<01:02,  2.42s/it]\u001b[A\n"," 44% 20/45 [00:50<01:02,  2.51s/it]\u001b[A\n"," 47% 21/45 [00:53<01:02,  2.60s/it]\u001b[A\n"," 49% 22/45 [00:55<00:58,  2.53s/it]\u001b[A\n"," 51% 23/45 [00:58<00:53,  2.42s/it]\u001b[A\n"," 53% 24/45 [01:00<00:53,  2.56s/it]\u001b[A\n"," 56% 25/45 [01:03<00:52,  2.62s/it]\u001b[A\n"," 58% 26/45 [01:05<00:45,  2.40s/it]\u001b[A\n"," 60% 27/45 [01:08<00:46,  2.59s/it]\u001b[A\n"," 62% 28/45 [01:11<00:46,  2.72s/it]\u001b[A\n"," 64% 29/45 [01:14<00:42,  2.63s/it]\u001b[A\n"," 67% 30/45 [01:16<00:39,  2.64s/it]\u001b[A\n"," 69% 31/45 [01:19<00:38,  2.78s/it]\u001b[A\n"," 71% 32/45 [01:22<00:37,  2.86s/it]\u001b[A\n"," 73% 33/45 [01:25<00:33,  2.82s/it]\u001b[A\n"," 76% 34/45 [01:28<00:31,  2.83s/it]\u001b[A\n"," 78% 35/45 [01:31<00:28,  2.84s/it]\u001b[A\n"," 80% 36/45 [01:34<00:25,  2.82s/it]\u001b[A\n"," 82% 37/45 [01:36<00:20,  2.61s/it]\u001b[A\n"," 84% 38/45 [01:38<00:17,  2.45s/it]\u001b[A\n"," 87% 39/45 [01:40<00:14,  2.38s/it]\u001b[A\n"," 89% 40/45 [01:43<00:12,  2.59s/it]\u001b[A\n"," 91% 41/45 [01:45<00:10,  2.52s/it]\u001b[A\n"," 93% 42/45 [01:48<00:07,  2.48s/it]\u001b[A\n"," 96% 43/45 [01:50<00:04,  2.38s/it]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 2.15993595123291, 'eval_accuracy': 0.45161147707679383, 'eval_runtime': 116.7175, 'eval_samples_per_second': 193.793, 'eval_steps_per_second': 0.386, 'epoch': 2.0}\n","  1% 178/26700 [11:11<13:48:25,  1.87s/it]\n","100% 45/45 [01:51<00:00,  1.84s/it]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2903] 2023-09-13 07:34:43,261 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_6/checkpoint-178\n","[INFO|configuration_utils.py:460] 2023-09-13 07:34:43,268 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_6/checkpoint-178/config.json\n","[INFO|modeling_utils.py:1997] 2023-09-13 07:34:43,382 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_6/checkpoint-178/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-13 07:34:43,386 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_6/checkpoint-178/preprocessor_config.json\n","{'loss': 1.9766, 'learning_rate': 0.0009932584269662923, 'epoch': 2.02}\n","{'loss': 1.8255, 'learning_rate': 0.0009928838951310862, 'epoch': 2.13}\n","{'loss': 1.7631, 'learning_rate': 0.00099250936329588, 'epoch': 2.25}\n","{'loss': 1.7827, 'learning_rate': 0.0009921348314606742, 'epoch': 2.36}\n","{'loss': 1.8316, 'learning_rate': 0.0009917602996254683, 'epoch': 2.47}\n","{'loss': 1.7945, 'learning_rate': 0.0009913857677902622, 'epoch': 2.58}\n","{'loss': 1.8027, 'learning_rate': 0.0009910112359550563, 'epoch': 2.7}\n","{'loss': 1.7904, 'learning_rate': 0.0009906367041198501, 'epoch': 2.81}\n","{'loss': 1.776, 'learning_rate': 0.0009902621722846442, 'epoch': 2.92}\n","  1% 266/26700 [14:47<13:11:45,  1.80s/it][INFO|trainer.py:3177] 2023-09-13 07:38:19,045 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3179] 2023-09-13 07:38:19,046 >>   Num examples = 22619\n","[INFO|trainer.py:3182] 2023-09-13 07:38:19,046 >>   Batch size = 512\n","\n","  0% 0/45 [00:00<?, ?it/s]\u001b[A\n","  4% 2/45 [00:02<00:53,  1.24s/it]\u001b[A\n","  7% 3/45 [00:05<01:20,  1.91s/it]\u001b[A\n","  9% 4/45 [00:07<01:27,  2.13s/it]\u001b[A\n"," 11% 5/45 [00:10<01:31,  2.29s/it]\u001b[A\n"," 13% 6/45 [00:13<01:38,  2.53s/it]\u001b[A\n"," 16% 7/45 [00:16<01:41,  2.68s/it]\u001b[A\n"," 18% 8/45 [00:19<01:44,  2.82s/it]\u001b[A\n"," 20% 9/45 [00:22<01:46,  2.95s/it]\u001b[A\n"," 22% 10/45 [00:26<01:46,  3.04s/it]\u001b[A\n"," 24% 11/45 [00:28<01:36,  2.83s/it]\u001b[A\n"," 27% 12/45 [00:30<01:31,  2.76s/it]\u001b[A\n"," 29% 13/45 [00:33<01:24,  2.64s/it]\u001b[A\n"," 31% 14/45 [00:36<01:25,  2.75s/it]\u001b[A\n"," 33% 15/45 [00:38<01:19,  2.65s/it]\u001b[A\n"," 36% 16/45 [00:41<01:16,  2.64s/it]\u001b[A\n"," 38% 17/45 [00:43<01:11,  2.54s/it]\u001b[A\n"," 40% 18/45 [00:45<01:04,  2.37s/it]\u001b[A\n"," 42% 19/45 [00:48<01:04,  2.46s/it]\u001b[A\n"," 44% 20/45 [00:51<01:03,  2.56s/it]\u001b[A\n"," 47% 21/45 [00:53<01:01,  2.56s/it]\u001b[A\n"," 49% 22/45 [00:56<00:57,  2.49s/it]\u001b[A\n"," 51% 23/45 [00:58<00:52,  2.38s/it]\u001b[A\n"," 53% 24/45 [01:00<00:52,  2.51s/it]\u001b[A\n"," 56% 25/45 [01:03<00:51,  2.59s/it]\u001b[A\n"," 58% 26/45 [01:05<00:45,  2.42s/it]\u001b[A\n"," 60% 27/45 [01:08<00:46,  2.59s/it]\u001b[A\n"," 62% 28/45 [01:11<00:46,  2.71s/it]\u001b[A\n"," 64% 29/45 [01:14<00:41,  2.60s/it]\u001b[A\n"," 67% 30/45 [01:16<00:39,  2.62s/it]\u001b[A\n"," 69% 31/45 [01:19<00:38,  2.79s/it]\u001b[A\n"," 71% 32/45 [01:22<00:37,  2.85s/it]\u001b[A\n"," 73% 33/45 [01:25<00:33,  2.81s/it]\u001b[A\n"," 76% 34/45 [01:28<00:31,  2.82s/it]\u001b[A\n"," 78% 35/45 [01:31<00:28,  2.85s/it]\u001b[A\n"," 80% 36/45 [01:34<00:25,  2.85s/it]\u001b[A\n"," 82% 37/45 [01:36<00:21,  2.63s/it]\u001b[A\n"," 84% 38/45 [01:38<00:17,  2.46s/it]\u001b[A\n"," 87% 39/45 [01:40<00:14,  2.38s/it]\u001b[A\n"," 89% 40/45 [01:43<00:12,  2.55s/it]\u001b[A\n"," 91% 41/45 [01:45<00:09,  2.49s/it]\u001b[A\n"," 93% 42/45 [01:48<00:07,  2.49s/it]\u001b[A\n"," 96% 43/45 [01:50<00:04,  2.40s/it]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 1.9565232992172241, 'eval_accuracy': 0.4891462929395641, 'eval_runtime': 116.7491, 'eval_samples_per_second': 193.74, 'eval_steps_per_second': 0.385, 'epoch': 3.0}\n","  1% 267/26700 [16:44<13:11:43,  1.80s/it]\n","100% 45/45 [01:51<00:00,  1.85s/it]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2903] 2023-09-13 07:40:15,800 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_6/checkpoint-267\n","[INFO|configuration_utils.py:460] 2023-09-13 07:40:15,806 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_6/checkpoint-267/config.json\n","[INFO|modeling_utils.py:1997] 2023-09-13 07:40:15,914 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_6/checkpoint-267/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-13 07:40:15,918 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_6/checkpoint-267/preprocessor_config.json\n","{'loss': 1.7023, 'learning_rate': 0.0009898876404494383, 'epoch': 3.03}\n","{'loss': 1.6996, 'learning_rate': 0.0009895131086142322, 'epoch': 3.15}\n","{'loss': 1.6881, 'learning_rate': 0.000989138576779026, 'epoch': 3.26}\n","{'loss': 1.6247, 'learning_rate': 0.0009887640449438202, 'epoch': 3.37}\n","{'loss': 1.6296, 'learning_rate': 0.0009883895131086143, 'epoch': 3.48}\n","{'loss': 1.6637, 'learning_rate': 0.0009880149812734082, 'epoch': 3.6}\n","{'loss': 1.6513, 'learning_rate': 0.0009876404494382023, 'epoch': 3.71}\n","{'loss': 1.6673, 'learning_rate': 0.0009872659176029962, 'epoch': 3.82}\n","{'loss': 1.6672, 'learning_rate': 0.0009868913857677903, 'epoch': 3.93}\n","  1% 355/26700 [20:18<12:59:26,  1.78s/it][INFO|trainer.py:3177] 2023-09-13 07:43:50,023 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3179] 2023-09-13 07:43:50,024 >>   Num examples = 22619\n","[INFO|trainer.py:3182] 2023-09-13 07:43:50,024 >>   Batch size = 512\n","\n","  0% 0/45 [00:00<?, ?it/s]\u001b[A\n","  4% 2/45 [00:02<00:52,  1.23s/it]\u001b[A\n","  7% 3/45 [00:05<01:18,  1.87s/it]\u001b[A\n","  9% 4/45 [00:07<01:29,  2.17s/it]\u001b[A\n"," 11% 5/45 [00:10<01:36,  2.42s/it]\u001b[A\n"," 13% 6/45 [00:13<01:42,  2.62s/it]\u001b[A\n"," 16% 7/45 [00:16<01:44,  2.74s/it]\u001b[A\n"," 18% 8/45 [00:19<01:44,  2.83s/it]\u001b[A\n"," 20% 9/45 [00:22<01:45,  2.93s/it]\u001b[A\n"," 22% 10/45 [00:26<01:47,  3.06s/it]\u001b[A\n"," 24% 11/45 [00:28<01:37,  2.85s/it]\u001b[A\n"," 27% 12/45 [00:31<01:31,  2.77s/it]\u001b[A\n"," 29% 13/45 [00:33<01:23,  2.62s/it]\u001b[A\n"," 31% 14/45 [00:36<01:22,  2.65s/it]\u001b[A\n"," 33% 15/45 [00:38<01:17,  2.59s/it]\u001b[A\n"," 36% 16/45 [00:41<01:15,  2.62s/it]\u001b[A\n"," 38% 17/45 [00:43<01:10,  2.53s/it]\u001b[A\n"," 40% 18/45 [00:45<01:04,  2.37s/it]\u001b[A\n"," 42% 19/45 [00:48<01:02,  2.41s/it]\u001b[A\n"," 44% 20/45 [00:50<01:02,  2.51s/it]\u001b[A\n"," 47% 21/45 [00:53<01:00,  2.54s/it]\u001b[A\n"," 49% 22/45 [00:56<00:57,  2.50s/it]\u001b[A\n"," 51% 23/45 [00:58<00:52,  2.40s/it]\u001b[A\n"," 53% 24/45 [01:00<00:52,  2.52s/it]\u001b[A\n"," 56% 25/45 [01:03<00:51,  2.59s/it]\u001b[A\n"," 58% 26/45 [01:05<00:45,  2.38s/it]\u001b[A\n"," 60% 27/45 [01:08<00:46,  2.57s/it]\u001b[A\n"," 62% 28/45 [01:11<00:46,  2.71s/it]\u001b[A\n"," 64% 29/45 [01:14<00:41,  2.61s/it]\u001b[A\n"," 67% 30/45 [01:16<00:39,  2.62s/it]\u001b[A\n"," 69% 31/45 [01:19<00:38,  2.76s/it]\u001b[A\n"," 71% 32/45 [01:22<00:36,  2.84s/it]\u001b[A\n"," 73% 33/45 [01:25<00:33,  2.83s/it]\u001b[A\n"," 76% 34/45 [01:28<00:31,  2.83s/it]\u001b[A\n"," 78% 35/45 [01:31<00:28,  2.83s/it]\u001b[A\n"," 80% 36/45 [01:34<00:25,  2.80s/it]\u001b[A\n"," 82% 37/45 [01:36<00:20,  2.60s/it]\u001b[A\n"," 84% 38/45 [01:38<00:17,  2.45s/it]\u001b[A\n"," 87% 39/45 [01:40<00:14,  2.40s/it]\u001b[ATraceback (most recent call last):\n","  File \"/content/cnn.py\", line 464, in <module>\n","    main()\n","  File \"/content/cnn.py\", line 432, in main\n","    train_result = trainer.train(resume_from_checkpoint=checkpoint)\n","  File \"/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\", line 1575, in train\n","    return inner_training_loop(\n","  File \"/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\", line 1982, in _inner_training_loop\n","    self._maybe_log_save_evaluate(tr_loss, model, trial, epoch, ignore_keys_for_eval)\n","  File \"/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\", line 2300, in _maybe_log_save_evaluate\n","    metrics = self.evaluate(ignore_keys=ignore_keys_for_eval)\n","  File \"/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\", line 3030, in evaluate\n","    output = eval_loop(\n","  File \"/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\", line 3209, in evaluation_loop\n","    for step, inputs in enumerate(dataloader):\n","  File \"/usr/local/lib/python3.10/dist-packages/accelerate/data_loader.py\", line 394, in __iter__\n","    next_batch = next(dataloader_iter)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 633, in __next__\n","    data = self._next_data()\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 677, in _next_data\n","    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n","    data = self.dataset.__getitems__(possibly_batched_index)\n","  File \"/usr/local/lib/python3.10/dist-packages/datasets/arrow_dataset.py\", line 2807, in __getitems__\n","    batch = self.__getitem__(keys)\n","  File \"/usr/local/lib/python3.10/dist-packages/datasets/arrow_dataset.py\", line 2803, in __getitem__\n","    return self._getitem(key)\n","  File \"/usr/local/lib/python3.10/dist-packages/datasets/arrow_dataset.py\", line 2788, in _getitem\n","    formatted_output = format_table(\n","  File \"/usr/local/lib/python3.10/dist-packages/datasets/formatting/formatting.py\", line 629, in format_table\n","    return formatter(pa_table, query_type=query_type)\n","  File \"/usr/local/lib/python3.10/dist-packages/datasets/formatting/formatting.py\", line 400, in __call__\n","    return self.format_batch(pa_table)\n","  File \"/usr/local/lib/python3.10/dist-packages/datasets/formatting/formatting.py\", line 515, in format_batch\n","    return self.transform(batch)\n","  File \"/content/cnn.py\", line 387, in val_transforms\n","    example_batch[\"pixel_values\"] = [_val_transforms(\n","  File \"/content/cnn.py\", line 387, in <listcomp>\n","    example_batch[\"pixel_values\"] = [_val_transforms(\n","  File \"/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\", line 95, in __call__\n","    img = t(img)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n","    return forward_call(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\", line 361, in forward\n","    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)\n","  File \"/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py\", line 490, in resize\n","    return F_pil.resize(img, size=output_size, interpolation=pil_interpolation)\n","  File \"/usr/local/lib/python3.10/dist-packages/torchvision/transforms/_functional_pil.py\", line 250, in resize\n","    return img.resize(tuple(size[::-1]), interpolation)\n","  File \"/usr/local/lib/python3.10/dist-packages/PIL/Image.py\", line 2192, in resize\n","    return self._new(self.im.resize(size, resample, box))\n","KeyboardInterrupt\n","\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[31m(failed 255).\u001b[0m Press Control-C to abort syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n","\u001b[34m\u001b[1mwandb\u001b[0m:           eval/accuracy ▁▅█\n","\u001b[34m\u001b[1mwandb\u001b[0m:               eval/loss █▄▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:            eval/runtime █▁▂\n","\u001b[34m\u001b[1mwandb\u001b[0m: eval/samples_per_second ▁█▇\n","\u001b[34m\u001b[1mwandb\u001b[0m:   eval/steps_per_second ▁█▄\n","\u001b[34m\u001b[1mwandb\u001b[0m:             train/epoch ▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███\n","\u001b[34m\u001b[1mwandb\u001b[0m:       train/global_step ▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███\n","\u001b[34m\u001b[1mwandb\u001b[0m:     train/learning_rate ███▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:              train/loss █▆▅▄▄▄▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n","\u001b[34m\u001b[1mwandb\u001b[0m:           eval/accuracy 0.48915\n","\u001b[34m\u001b[1mwandb\u001b[0m:               eval/loss 1.95652\n","\u001b[34m\u001b[1mwandb\u001b[0m:            eval/runtime 116.7491\n","\u001b[34m\u001b[1mwandb\u001b[0m: eval/samples_per_second 193.74\n","\u001b[34m\u001b[1mwandb\u001b[0m:   eval/steps_per_second 0.385\n","\u001b[34m\u001b[1mwandb\u001b[0m:             train/epoch 3.93\n","\u001b[34m\u001b[1mwandb\u001b[0m:       train/global_step 350\n","\u001b[34m\u001b[1mwandb\u001b[0m:     train/learning_rate 0.00099\n","\u001b[34m\u001b[1mwandb\u001b[0m:              train/loss 1.6672\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mrosy-frog-22\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/u15048366/colabCnnIp102Run1/runs/ktr8vaof\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n","\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230913_072304-ktr8vaof/logs\u001b[0m\n"]}],"source":["!python cnn.py \\\n","    --model_name microsoft/resnet-18 \\\n","    --model_type resnet \\\n","    --train_dir data/classification/train \\\n","    --validation_dir data/classification/test \\\n","    --output_dir drive/MyDrive/hons-research/output/cnn/ip102_outputs_6/ \\\n","    --remove_unused_columns False \\\n","    --do_train \\\n","    --do_eval \\\n","    --push_to_hub False \\\n","    --learning_rate 0.001 \\\n","    --num_train_epochs 300 \\\n","    --per_device_train_batch_size 512 \\\n","    --per_device_eval_batch_size 512 \\\n","    --logging_strategy steps \\\n","    --logging_steps 10 \\\n","    --evaluation_strategy epoch \\\n","    --save_strategy epoch \\\n","    --load_best_model_at_end True \\\n","    --save_total_limit 3 \\\n","    --save_steps 500 \\\n","    --data_seed 6 \\\n","    --seed 6 \\\n","    --ignore_mismatched_sizes\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uWs01trKFRid"},"outputs":[],"source":["!python cnn.py \\\n","    --model_name microsoft/resnet-18 \\\n","    --model_type resnet \\\n","    --train_dir data/classification/train \\\n","    --validation_dir data/classification/test \\\n","    --output_dir drive/MyDrive/hons-research/output/cnn/ip102_outputs_7/ \\\n","    --remove_unused_columns False \\\n","    --do_train \\\n","    --do_eval \\\n","    --push_to_hub False \\\n","    --learning_rate 0.001 \\\n","    --num_train_epochs 300 \\\n","    --per_device_train_batch_size 512 \\\n","    --per_device_eval_batch_size 512 \\\n","    --logging_strategy steps \\\n","    --logging_steps 10 \\\n","    --evaluation_strategy epoch \\\n","    --save_strategy epoch \\\n","    --load_best_model_at_end True \\\n","    --save_total_limit 3 \\\n","    --save_steps 500 \\\n","    --data_seed 7 \\\n","    --seed 7\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sNaUt6MIxv9z"},"outputs":[],"source":["# End run\n","\n","from google.colab import runtime\n","runtime.unassign()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28,"status":"ok","timestamp":1693166189326,"user":{"displayName":"Andreas Louw","userId":"11183032721846533402"},"user_tz":-120},"id":"C5cP8uzzFVIB","outputId":"4a39d9f6-960b-493f-94c8-90a060375e95"},"outputs":[{"name":"stdout","output_type":"stream","text":["2023-09-03 13:51:54.560761: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mu15048366\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.9\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20230903_135200-ljj5bzs6\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdark-disco-18\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/u15048366/colabCnnIp102Run1\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/u15048366/colabCnnIp102Run1/runs/ljj5bzs6\u001b[0m\n","09/03/2023 13:52:01 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n","09/03/2023 13:52:01 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n","_n_gpu=1,\n","adafactor=False,\n","adam_beta1=0.9,\n","adam_beta2=0.999,\n","adam_epsilon=1e-08,\n","auto_find_batch_size=False,\n","bf16=False,\n","bf16_full_eval=False,\n","data_seed=8,\n","dataloader_drop_last=False,\n","dataloader_num_workers=0,\n","dataloader_pin_memory=True,\n","ddp_backend=None,\n","ddp_broadcast_buffers=None,\n","ddp_bucket_cap_mb=None,\n","ddp_find_unused_parameters=None,\n","ddp_timeout=1800,\n","debug=[],\n","deepspeed=None,\n","disable_tqdm=False,\n","dispatch_batches=None,\n","do_eval=True,\n","do_predict=False,\n","do_train=True,\n","eval_accumulation_steps=None,\n","eval_delay=0,\n","eval_steps=None,\n","evaluation_strategy=epoch,\n","fp16=False,\n","fp16_backend=auto,\n","fp16_full_eval=False,\n","fp16_opt_level=O1,\n","fsdp=[],\n","fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n","fsdp_min_num_params=0,\n","fsdp_transformer_layer_cls_to_wrap=None,\n","full_determinism=False,\n","gradient_accumulation_steps=1,\n","gradient_checkpointing=False,\n","greater_is_better=False,\n","group_by_length=False,\n","half_precision_backend=auto,\n","hub_always_push=False,\n","hub_model_id=None,\n","hub_private_repo=False,\n","hub_strategy=every_save,\n","hub_token=<HUB_TOKEN>,\n","ignore_data_skip=False,\n","include_inputs_for_metrics=False,\n","jit_mode_eval=False,\n","label_names=None,\n","label_smoothing_factor=0.0,\n","learning_rate=0.001,\n","length_column_name=length,\n","load_best_model_at_end=True,\n","local_rank=0,\n","log_level=passive,\n","log_level_replica=warning,\n","log_on_each_node=True,\n","logging_dir=drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/runs/Sep03_13-52-00_ad494e439e78,\n","logging_first_step=False,\n","logging_nan_inf_filter=True,\n","logging_steps=10,\n","logging_strategy=steps,\n","lr_scheduler_type=linear,\n","max_grad_norm=1.0,\n","max_steps=-1,\n","metric_for_best_model=loss,\n","mp_parameters=,\n","no_cuda=False,\n","num_train_epochs=300.0,\n","optim=adamw_torch,\n","optim_args=None,\n","output_dir=drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/,\n","overwrite_output_dir=False,\n","past_index=-1,\n","per_device_eval_batch_size=512,\n","per_device_train_batch_size=512,\n","prediction_loss_only=False,\n","push_to_hub=False,\n","push_to_hub_model_id=None,\n","push_to_hub_organization=None,\n","push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n","ray_scope=last,\n","remove_unused_columns=False,\n","report_to=['wandb'],\n","resume_from_checkpoint=None,\n","run_name=drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/,\n","save_on_each_node=False,\n","save_safetensors=False,\n","save_steps=500.0,\n","save_strategy=epoch,\n","save_total_limit=3,\n","seed=8,\n","sharded_ddp=[],\n","skip_memory_metrics=True,\n","tf32=None,\n","torch_compile=False,\n","torch_compile_backend=None,\n","torch_compile_mode=None,\n","torchdynamo=None,\n","tpu_metrics_debug=False,\n","tpu_num_cores=None,\n","use_cpu=False,\n","use_ipex=False,\n","use_legacy_prediction_loop=False,\n","use_mps_device=False,\n","warmup_ratio=0.0,\n","warmup_steps=0,\n","weight_decay=0.0,\n",")\n","/usr/local/lib/python3.10/dist-packages/datasets/load.py:2086: FutureWarning: 'task' was deprecated in version 2.13.0 and will be removed in 3.0.0.\n","\n","  warnings.warn(\n","Resolving data files: 100% 45095/45095 [00:00<00:00, 352981.83it/s]\n","Resolving data files: 100% 22619/22619 [00:00<00:00, 208311.20it/s]\n","Downloading data files: 100% 45095/45095 [00:00<00:00, 80572.62it/s]\n","Downloading data files: 0it [00:00, ?it/s]\n","Extracting data files: 0it [00:00, ?it/s]\n","Downloading data files: 100% 22619/22619 [00:00<00:00, 80473.52it/s]\n","Downloading data files: 0it [00:00, ?it/s]\n","Extracting data files: 0it [00:00, ?it/s]\n","Generating train split: 45095 examples [00:03, 12521.01 examples/s]\n","Generating validation split: 22619 examples [00:01, 12782.03 examples/s]\n","Casting the dataset: 100% 45095/45095 [00:00<00:00, 58112.38 examples/s] \n","Casting the dataset: 100% 22619/22619 [00:00<00:00, 29113.99 examples/s]\n","Downloading builder script: 100% 4.20k/4.20k [00:00<00:00, 10.7MB/s]\n","\n","\n","\n","None\n","\n","\n","\n","Downloading (…)lve/main/config.json: 100% 69.5k/69.5k [00:00<00:00, 357kB/s]\n","[INFO|configuration_utils.py:715] 2023-09-03 13:52:35,790 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--resnet-18/snapshots/f45a6faa12e0381f5620c5c8d7e916bca90f2c44/config.json\n","[INFO|configuration_utils.py:775] 2023-09-03 13:52:35,792 >> Model config ResNetConfig {\n","  \"_name_or_path\": \"microsoft/resnet-18\",\n","  \"architectures\": [\n","    \"ResNetForImageClassification\"\n","  ],\n","  \"depths\": [\n","    2,\n","    2,\n","    2,\n","    2\n","  ],\n","  \"downsample_in_first_stage\": false,\n","  \"embedding_size\": 64,\n","  \"finetuning_task\": \"image-classification\",\n","  \"hidden_act\": \"relu\",\n","  \"hidden_sizes\": [\n","    64,\n","    128,\n","    256,\n","    512\n","  ],\n","  \"id2label\": {\n","    \"0\": \"0\",\n","    \"1\": \"1\",\n","    \"10\": \"16\",\n","    \"100\": \"98\",\n","    \"101\": \"99\",\n","    \"11\": \"17\",\n","    \"12\": \"18\",\n","    \"13\": \"19\",\n","    \"14\": \"2\",\n","    \"15\": \"20\",\n","    \"16\": \"21\",\n","    \"17\": \"22\",\n","    \"18\": \"23\",\n","    \"19\": \"24\",\n","    \"2\": \"10\",\n","    \"20\": \"25\",\n","    \"21\": \"26\",\n","    \"22\": \"27\",\n","    \"23\": \"28\",\n","    \"24\": \"29\",\n","    \"25\": \"3\",\n","    \"26\": \"30\",\n","    \"27\": \"31\",\n","    \"28\": \"32\",\n","    \"29\": \"33\",\n","    \"3\": \"100\",\n","    \"30\": \"34\",\n","    \"31\": \"35\",\n","    \"32\": \"36\",\n","    \"33\": \"37\",\n","    \"34\": \"38\",\n","    \"35\": \"39\",\n","    \"36\": \"4\",\n","    \"37\": \"40\",\n","    \"38\": \"41\",\n","    \"39\": \"42\",\n","    \"4\": \"101\",\n","    \"40\": \"43\",\n","    \"41\": \"44\",\n","    \"42\": \"45\",\n","    \"43\": \"46\",\n","    \"44\": \"47\",\n","    \"45\": \"48\",\n","    \"46\": \"49\",\n","    \"47\": \"5\",\n","    \"48\": \"50\",\n","    \"49\": \"51\",\n","    \"5\": \"11\",\n","    \"50\": \"52\",\n","    \"51\": \"53\",\n","    \"52\": \"54\",\n","    \"53\": \"55\",\n","    \"54\": \"56\",\n","    \"55\": \"57\",\n","    \"56\": \"58\",\n","    \"57\": \"59\",\n","    \"58\": \"6\",\n","    \"59\": \"60\",\n","    \"6\": \"12\",\n","    \"60\": \"61\",\n","    \"61\": \"62\",\n","    \"62\": \"63\",\n","    \"63\": \"64\",\n","    \"64\": \"65\",\n","    \"65\": \"66\",\n","    \"66\": \"67\",\n","    \"67\": \"68\",\n","    \"68\": \"69\",\n","    \"69\": \"7\",\n","    \"7\": \"13\",\n","    \"70\": \"70\",\n","    \"71\": \"71\",\n","    \"72\": \"72\",\n","    \"73\": \"73\",\n","    \"74\": \"74\",\n","    \"75\": \"75\",\n","    \"76\": \"76\",\n","    \"77\": \"77\",\n","    \"78\": \"78\",\n","    \"79\": \"79\",\n","    \"8\": \"14\",\n","    \"80\": \"8\",\n","    \"81\": \"80\",\n","    \"82\": \"81\",\n","    \"83\": \"82\",\n","    \"84\": \"83\",\n","    \"85\": \"84\",\n","    \"86\": \"85\",\n","    \"87\": \"86\",\n","    \"88\": \"87\",\n","    \"89\": \"88\",\n","    \"9\": \"15\",\n","    \"90\": \"89\",\n","    \"91\": \"9\",\n","    \"92\": \"90\",\n","    \"93\": \"91\",\n","    \"94\": \"92\",\n","    \"95\": \"93\",\n","    \"96\": \"94\",\n","    \"97\": \"95\",\n","    \"98\": \"96\",\n","    \"99\": \"97\"\n","  },\n","  \"label2id\": {\n","    \"0\": \"0\",\n","    \"1\": \"1\",\n","    \"10\": \"2\",\n","    \"100\": \"3\",\n","    \"101\": \"4\",\n","    \"11\": \"5\",\n","    \"12\": \"6\",\n","    \"13\": \"7\",\n","    \"14\": \"8\",\n","    \"15\": \"9\",\n","    \"16\": \"10\",\n","    \"17\": \"11\",\n","    \"18\": \"12\",\n","    \"19\": \"13\",\n","    \"2\": \"14\",\n","    \"20\": \"15\",\n","    \"21\": \"16\",\n","    \"22\": \"17\",\n","    \"23\": \"18\",\n","    \"24\": \"19\",\n","    \"25\": \"20\",\n","    \"26\": \"21\",\n","    \"27\": \"22\",\n","    \"28\": \"23\",\n","    \"29\": \"24\",\n","    \"3\": \"25\",\n","    \"30\": \"26\",\n","    \"31\": \"27\",\n","    \"32\": \"28\",\n","    \"33\": \"29\",\n","    \"34\": \"30\",\n","    \"35\": \"31\",\n","    \"36\": \"32\",\n","    \"37\": \"33\",\n","    \"38\": \"34\",\n","    \"39\": \"35\",\n","    \"4\": \"36\",\n","    \"40\": \"37\",\n","    \"41\": \"38\",\n","    \"42\": \"39\",\n","    \"43\": \"40\",\n","    \"44\": \"41\",\n","    \"45\": \"42\",\n","    \"46\": \"43\",\n","    \"47\": \"44\",\n","    \"48\": \"45\",\n","    \"49\": \"46\",\n","    \"5\": \"47\",\n","    \"50\": \"48\",\n","    \"51\": \"49\",\n","    \"52\": \"50\",\n","    \"53\": \"51\",\n","    \"54\": \"52\",\n","    \"55\": \"53\",\n","    \"56\": \"54\",\n","    \"57\": \"55\",\n","    \"58\": \"56\",\n","    \"59\": \"57\",\n","    \"6\": \"58\",\n","    \"60\": \"59\",\n","    \"61\": \"60\",\n","    \"62\": \"61\",\n","    \"63\": \"62\",\n","    \"64\": \"63\",\n","    \"65\": \"64\",\n","    \"66\": \"65\",\n","    \"67\": \"66\",\n","    \"68\": \"67\",\n","    \"69\": \"68\",\n","    \"7\": \"69\",\n","    \"70\": \"70\",\n","    \"71\": \"71\",\n","    \"72\": \"72\",\n","    \"73\": \"73\",\n","    \"74\": \"74\",\n","    \"75\": \"75\",\n","    \"76\": \"76\",\n","    \"77\": \"77\",\n","    \"78\": \"78\",\n","    \"79\": \"79\",\n","    \"8\": \"80\",\n","    \"80\": \"81\",\n","    \"81\": \"82\",\n","    \"82\": \"83\",\n","    \"83\": \"84\",\n","    \"84\": \"85\",\n","    \"85\": \"86\",\n","    \"86\": \"87\",\n","    \"87\": \"88\",\n","    \"88\": \"89\",\n","    \"89\": \"90\",\n","    \"9\": \"91\",\n","    \"90\": \"92\",\n","    \"91\": \"93\",\n","    \"92\": \"94\",\n","    \"93\": \"95\",\n","    \"94\": \"96\",\n","    \"95\": \"97\",\n","    \"96\": \"98\",\n","    \"97\": \"99\",\n","    \"98\": \"100\",\n","    \"99\": \"101\"\n","  },\n","  \"layer_type\": \"basic\",\n","  \"model_type\": \"resnet\",\n","  \"num_channels\": 3,\n","  \"out_features\": [\n","    \"stage4\"\n","  ],\n","  \"out_indices\": [\n","    4\n","  ],\n","  \"stage_names\": [\n","    \"stem\",\n","    \"stage1\",\n","    \"stage2\",\n","    \"stage3\",\n","    \"stage4\"\n","  ],\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.33.0.dev0\"\n","}\n","\n","Downloading model.safetensors: 100% 46.8M/46.8M [00:04<00:00, 11.2MB/s]\n","[INFO|modeling_utils.py:2857] 2023-09-03 13:52:42,079 >> loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--microsoft--resnet-18/snapshots/f45a6faa12e0381f5620c5c8d7e916bca90f2c44/model.safetensors\n","[INFO|modeling_utils.py:3643] 2023-09-03 13:52:42,276 >> All model checkpoint weights were used when initializing ResNetForImageClassification.\n","\n","[WARNING|modeling_utils.py:3664] 2023-09-03 13:52:42,277 >> Some weights of ResNetForImageClassification were not initialized from the model checkpoint at microsoft/resnet-18 and are newly initialized because the shapes did not match:\n","- classifier.1.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([102]) in the model instantiated\n","- classifier.1.weight: found shape torch.Size([1000, 512]) in the checkpoint and torch.Size([102, 512]) in the model instantiated\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Downloading (…)rocessor_config.json: 100% 266/266 [00:00<00:00, 746kB/s]\n","[INFO|image_processing_utils.py:369] 2023-09-03 13:52:43,180 >> loading configuration file preprocessor_config.json from cache at /root/.cache/huggingface/hub/models--microsoft--resnet-18/snapshots/f45a6faa12e0381f5620c5c8d7e916bca90f2c44/preprocessor_config.json\n","[WARNING|image_processing_auto.py:355] 2023-09-03 13:52:43,180 >> Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n","[INFO|image_processing_utils.py:732] 2023-09-03 13:52:43,182 >> size should be a dictionary on of the following set of keys: ({'height', 'width'}, {'shortest_edge'}, {'longest_edge', 'shortest_edge'}, {'longest_edge'}), got 224. Converted to {'shortest_edge': 224}.\n","[INFO|image_processing_utils.py:419] 2023-09-03 13:52:43,182 >> Image processor ConvNextImageProcessor {\n","  \"crop_pct\": 0.875,\n","  \"do_normalize\": true,\n","  \"do_rescale\": true,\n","  \"do_resize\": true,\n","  \"image_mean\": [\n","    0.485,\n","    0.456,\n","    0.406\n","  ],\n","  \"image_processor_type\": \"ConvNextImageProcessor\",\n","  \"image_std\": [\n","    0.229,\n","    0.224,\n","    0.225\n","  ],\n","  \"resample\": 3,\n","  \"rescale_factor\": 0.00392156862745098,\n","  \"size\": {\n","    \"shortest_edge\": 224\n","  }\n","}\n","\n","[INFO|trainer.py:1712] 2023-09-03 13:52:48,747 >> ***** Running training *****\n","[INFO|trainer.py:1713] 2023-09-03 13:52:48,747 >>   Num examples = 45,095\n","[INFO|trainer.py:1714] 2023-09-03 13:52:48,747 >>   Num Epochs = 300\n","[INFO|trainer.py:1715] 2023-09-03 13:52:48,748 >>   Instantaneous batch size per device = 512\n","[INFO|trainer.py:1718] 2023-09-03 13:52:48,748 >>   Total train batch size (w. parallel, distributed & accumulation) = 512\n","[INFO|trainer.py:1719] 2023-09-03 13:52:48,748 >>   Gradient Accumulation steps = 1\n","[INFO|trainer.py:1720] 2023-09-03 13:52:48,748 >>   Total optimization steps = 26,700\n","[INFO|trainer.py:1721] 2023-09-03 13:52:48,748 >>   Number of trainable parameters = 11,228,838\n","[INFO|integration_utils.py:716] 2023-09-03 13:52:48,749 >> Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n","{'loss': 3.5648, 'learning_rate': 0.0009996254681647941, 'epoch': 0.11}\n","{'loss': 2.9655, 'learning_rate': 0.000999250936329588, 'epoch': 0.22}\n","{'loss': 2.7072, 'learning_rate': 0.000998876404494382, 'epoch': 0.34}\n","{'loss': 2.5419, 'learning_rate': 0.000998501872659176, 'epoch': 0.45}\n","{'loss': 2.4347, 'learning_rate': 0.00099812734082397, 'epoch': 0.56}\n","{'loss': 2.347, 'learning_rate': 0.0009977528089887642, 'epoch': 0.67}\n","{'loss': 2.2759, 'learning_rate': 0.000997378277153558, 'epoch': 0.79}\n","{'loss': 2.2534, 'learning_rate': 0.000997003745318352, 'epoch': 0.9}\n","  0% 89/26700 [03:49<9:52:02,  1.33s/it] [INFO|trainer.py:3115] 2023-09-03 13:56:38,102 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3117] 2023-09-03 13:56:38,102 >>   Num examples = 22619\n","[INFO|trainer.py:3120] 2023-09-03 13:56:38,102 >>   Batch size = 512\n","\n","  0% 0/45 [00:00<?, ?it/s]\u001b[A\n","  4% 2/45 [00:02<00:55,  1.28s/it]\u001b[A\n","  7% 3/45 [00:05<01:20,  1.92s/it]\u001b[A\n","  9% 4/45 [00:07<01:27,  2.13s/it]\u001b[A\n"," 11% 5/45 [00:10<01:31,  2.28s/it]\u001b[A\n"," 13% 6/45 [00:13<01:38,  2.53s/it]\u001b[A\n"," 16% 7/45 [00:16<01:43,  2.72s/it]\u001b[A\n"," 18% 8/45 [00:19<01:45,  2.85s/it]\u001b[A\n"," 20% 9/45 [00:22<01:46,  2.97s/it]\u001b[A\n"," 22% 10/45 [00:26<01:47,  3.08s/it]\u001b[A\n"," 24% 11/45 [00:28<01:38,  2.88s/it]\u001b[A\n"," 27% 12/45 [00:31<01:33,  2.83s/it]\u001b[A\n"," 29% 13/45 [00:33<01:26,  2.69s/it]\u001b[A\n"," 31% 14/45 [00:36<01:24,  2.71s/it]\u001b[A\n"," 33% 15/45 [00:39<01:19,  2.64s/it]\u001b[A\n"," 36% 16/45 [00:41<01:16,  2.65s/it]\u001b[A\n"," 38% 17/45 [00:44<01:12,  2.59s/it]\u001b[A\n"," 40% 18/45 [00:46<01:06,  2.47s/it]\u001b[A\n"," 42% 19/45 [00:48<01:04,  2.49s/it]\u001b[A\n"," 44% 20/45 [00:51<01:04,  2.57s/it]\u001b[A\n"," 47% 21/45 [00:54<01:02,  2.59s/it]\u001b[A\n"," 49% 22/45 [00:56<00:58,  2.53s/it]\u001b[A\n"," 51% 23/45 [00:58<00:53,  2.43s/it]\u001b[A\n"," 53% 24/45 [01:01<00:54,  2.58s/it]\u001b[A\n"," 56% 25/45 [01:04<00:52,  2.63s/it]\u001b[A\n"," 58% 26/45 [01:06<00:45,  2.42s/it]\u001b[A\n"," 60% 27/45 [01:09<00:46,  2.61s/it]\u001b[A\n"," 62% 28/45 [01:12<00:46,  2.74s/it]\u001b[A\n"," 64% 29/45 [01:15<00:43,  2.70s/it]\u001b[A\n"," 67% 30/45 [01:17<00:40,  2.70s/it]\u001b[A\n"," 69% 31/45 [01:21<00:40,  2.91s/it]\u001b[A\n"," 71% 32/45 [01:24<00:38,  2.95s/it]\u001b[A\n"," 73% 33/45 [01:27<00:34,  2.90s/it]\u001b[A\n"," 76% 34/45 [01:30<00:32,  2.92s/it]\u001b[A\n"," 78% 35/45 [01:32<00:29,  2.91s/it]\u001b[A\n"," 80% 36/45 [01:35<00:25,  2.87s/it]\u001b[A\n"," 82% 37/45 [01:37<00:21,  2.65s/it]\u001b[A\n"," 84% 38/45 [01:39<00:17,  2.49s/it]\u001b[A\n"," 87% 39/45 [01:42<00:14,  2.43s/it]\u001b[A\n"," 89% 40/45 [01:45<00:13,  2.62s/it]\u001b[A\n"," 91% 41/45 [01:47<00:10,  2.54s/it]\u001b[A\n"," 93% 42/45 [01:50<00:07,  2.50s/it]\u001b[A\n"," 96% 43/45 [01:52<00:04,  2.40s/it]\u001b[A\n","                                        \n","\u001b[A{'eval_loss': 2.6203293800354004, 'eval_accuracy': 0.36296918519828464, 'eval_runtime': 118.5312, 'eval_samples_per_second': 190.827, 'eval_steps_per_second': 0.38, 'epoch': 1.0}\n","  0% 89/26700 [05:47<9:52:02,  1.33s/it]\n","100% 45/45 [01:53<00:00,  1.86s/it]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2841] 2023-09-03 13:58:36,638 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-89\n","[INFO|configuration_utils.py:460] 2023-09-03 13:58:36,644 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-89/config.json\n","[INFO|modeling_utils.py:1992] 2023-09-03 13:58:36,753 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-89/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-03 13:58:36,758 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-89/preprocessor_config.json\n","{'loss': 2.163, 'learning_rate': 0.000996629213483146, 'epoch': 1.01}\n","{'loss': 2.1028, 'learning_rate': 0.0009962546816479402, 'epoch': 1.12}\n","{'loss': 2.0438, 'learning_rate': 0.000995880149812734, 'epoch': 1.24}\n","{'loss': 2.0059, 'learning_rate': 0.0009955056179775281, 'epoch': 1.35}\n","{'loss': 1.9858, 'learning_rate': 0.0009951310861423222, 'epoch': 1.46}\n","{'loss': 1.9392, 'learning_rate': 0.0009947565543071161, 'epoch': 1.57}\n","{'loss': 2.0188, 'learning_rate': 0.0009943820224719102, 'epoch': 1.69}\n","{'loss': 1.936, 'learning_rate': 0.000994007490636704, 'epoch': 1.8}\n","{'loss': 1.9104, 'learning_rate': 0.0009936329588014982, 'epoch': 1.91}\n","  1% 177/26700 [09:25<13:09:48,  1.79s/it][INFO|trainer.py:3115] 2023-09-03 14:02:14,624 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3117] 2023-09-03 14:02:14,624 >>   Num examples = 22619\n","[INFO|trainer.py:3120] 2023-09-03 14:02:14,624 >>   Batch size = 512\n","\n","  0% 0/45 [00:00<?, ?it/s]\u001b[A\n","  4% 2/45 [00:02<00:55,  1.29s/it]\u001b[A\n","  7% 3/45 [00:05<01:20,  1.92s/it]\u001b[A\n","  9% 4/45 [00:07<01:27,  2.13s/it]\u001b[A\n"," 11% 5/45 [00:10<01:31,  2.30s/it]\u001b[A\n"," 13% 6/45 [00:13<01:39,  2.54s/it]\u001b[A\n"," 16% 7/45 [00:16<01:43,  2.74s/it]\u001b[A\n"," 18% 8/45 [00:19<01:45,  2.84s/it]\u001b[A\n"," 20% 9/45 [00:22<01:46,  2.96s/it]\u001b[A\n"," 22% 10/45 [00:26<01:47,  3.08s/it]\u001b[A\n"," 24% 11/45 [00:28<01:37,  2.88s/it]\u001b[A\n"," 27% 12/45 [00:31<01:33,  2.82s/it]\u001b[A\n"," 29% 13/45 [00:33<01:25,  2.67s/it]\u001b[A\n"," 31% 14/45 [00:36<01:23,  2.69s/it]\u001b[A\n"," 33% 15/45 [00:39<01:21,  2.70s/it]\u001b[A\n"," 36% 16/45 [00:41<01:17,  2.68s/it]\u001b[A\n"," 38% 17/45 [00:44<01:12,  2.59s/it]\u001b[A\n"," 40% 18/45 [00:46<01:05,  2.44s/it]\u001b[A\n"," 42% 19/45 [00:48<01:04,  2.47s/it]\u001b[A\n"," 44% 20/45 [00:51<01:04,  2.56s/it]\u001b[A\n"," 47% 21/45 [00:54<01:01,  2.57s/it]\u001b[A\n"," 49% 22/45 [00:56<00:57,  2.51s/it]\u001b[A\n"," 51% 23/45 [00:58<00:53,  2.43s/it]\u001b[A\n"," 53% 24/45 [01:01<00:54,  2.58s/it]\u001b[A\n"," 56% 25/45 [01:04<00:52,  2.64s/it]\u001b[A\n"," 58% 26/45 [01:06<00:46,  2.43s/it]\u001b[A\n"," 60% 27/45 [01:09<00:46,  2.61s/it]\u001b[A\n"," 62% 28/45 [01:12<00:46,  2.74s/it]\u001b[A\n"," 64% 29/45 [01:14<00:42,  2.65s/it]\u001b[A\n"," 67% 30/45 [01:17<00:39,  2.66s/it]\u001b[A\n"," 69% 31/45 [01:20<00:39,  2.82s/it]\u001b[A\n"," 71% 32/45 [01:23<00:37,  2.89s/it]\u001b[A\n"," 73% 33/45 [01:26<00:34,  2.85s/it]\u001b[A\n"," 76% 34/45 [01:29<00:31,  2.89s/it]\u001b[A\n"," 78% 35/45 [01:32<00:28,  2.88s/it]\u001b[A\n"," 80% 36/45 [01:35<00:25,  2.86s/it]\u001b[A\n"," 82% 37/45 [01:37<00:21,  2.65s/it]\u001b[A\n"," 84% 38/45 [01:39<00:17,  2.48s/it]\u001b[A\n"," 87% 39/45 [01:41<00:14,  2.44s/it]\u001b[A\n"," 89% 40/45 [01:44<00:13,  2.63s/it]\u001b[A\n"," 91% 41/45 [01:47<00:10,  2.54s/it]\u001b[A\n"," 93% 42/45 [01:49<00:07,  2.50s/it]\u001b[A\n"," 96% 43/45 [01:51<00:04,  2.40s/it]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 1.939971685409546, 'eval_accuracy': 0.49697157257173175, 'eval_runtime': 118.1339, 'eval_samples_per_second': 191.469, 'eval_steps_per_second': 0.381, 'epoch': 2.0}\n","  1% 178/26700 [11:24<13:09:46,  1.79s/it]\n","100% 45/45 [01:52<00:00,  1.86s/it]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2841] 2023-09-03 14:04:12,765 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-178\n","[INFO|configuration_utils.py:460] 2023-09-03 14:04:12,770 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-178/config.json\n","[INFO|modeling_utils.py:1992] 2023-09-03 14:04:12,884 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-178/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-03 14:04:12,888 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-178/preprocessor_config.json\n","{'loss': 1.8459, 'learning_rate': 0.0009932584269662923, 'epoch': 2.02}\n","{'loss': 1.7969, 'learning_rate': 0.0009928838951310862, 'epoch': 2.13}\n","{'loss': 1.8248, 'learning_rate': 0.00099250936329588, 'epoch': 2.25}\n","{'loss': 1.835, 'learning_rate': 0.0009921348314606742, 'epoch': 2.36}\n","{'loss': 1.7419, 'learning_rate': 0.0009917602996254683, 'epoch': 2.47}\n","{'loss': 1.7524, 'learning_rate': 0.0009913857677902622, 'epoch': 2.58}\n","{'loss': 1.7866, 'learning_rate': 0.0009910112359550563, 'epoch': 2.7}\n","{'loss': 1.788, 'learning_rate': 0.0009906367041198501, 'epoch': 2.81}\n","{'loss': 1.7805, 'learning_rate': 0.0009902621722846442, 'epoch': 2.92}\n","  1% 266/26700 [15:01<13:21:10,  1.82s/it][INFO|trainer.py:3115] 2023-09-03 14:07:50,447 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3117] 2023-09-03 14:07:50,447 >>   Num examples = 22619\n","[INFO|trainer.py:3120] 2023-09-03 14:07:50,447 >>   Batch size = 512\n","\n","  0% 0/45 [00:00<?, ?it/s]\u001b[A\n","  4% 2/45 [00:02<00:54,  1.26s/it]\u001b[A\n","  7% 3/45 [00:05<01:20,  1.91s/it]\u001b[A\n","  9% 4/45 [00:07<01:27,  2.13s/it]\u001b[A\n"," 11% 5/45 [00:10<01:31,  2.30s/it]\u001b[A\n"," 13% 6/45 [00:13<01:38,  2.53s/it]\u001b[A\n"," 16% 7/45 [00:16<01:42,  2.71s/it]\u001b[A\n"," 18% 8/45 [00:19<01:45,  2.84s/it]\u001b[A\n"," 20% 9/45 [00:22<01:46,  2.96s/it]\u001b[A\n"," 22% 10/45 [00:26<01:47,  3.07s/it]\u001b[A\n"," 24% 11/45 [00:28<01:37,  2.85s/it]\u001b[A\n"," 27% 12/45 [00:31<01:35,  2.89s/it]\u001b[A\n"," 29% 13/45 [00:33<01:27,  2.74s/it]\u001b[A\n"," 31% 14/45 [00:36<01:24,  2.74s/it]\u001b[A\n"," 33% 15/45 [00:39<01:19,  2.65s/it]\u001b[A\n"," 36% 16/45 [00:41<01:16,  2.65s/it]\u001b[A\n"," 38% 17/45 [00:44<01:11,  2.56s/it]\u001b[A\n"," 40% 18/45 [00:46<01:05,  2.41s/it]\u001b[A\n"," 42% 19/45 [00:48<01:03,  2.45s/it]\u001b[A\n"," 44% 20/45 [00:51<01:03,  2.54s/it]\u001b[A\n"," 47% 21/45 [00:54<01:01,  2.56s/it]\u001b[A\n"," 49% 22/45 [00:56<00:57,  2.51s/it]\u001b[A\n"," 51% 23/45 [00:58<00:53,  2.41s/it]\u001b[A\n"," 53% 24/45 [01:01<00:53,  2.57s/it]\u001b[A\n"," 56% 25/45 [01:04<00:52,  2.64s/it]\u001b[A\n"," 58% 26/45 [01:06<00:46,  2.43s/it]\u001b[A\n"," 60% 27/45 [01:09<00:47,  2.61s/it]\u001b[A\n"," 62% 28/45 [01:12<00:46,  2.74s/it]\u001b[A\n"," 64% 29/45 [01:14<00:42,  2.65s/it]\u001b[A\n"," 67% 30/45 [01:17<00:39,  2.66s/it]\u001b[A\n"," 69% 31/45 [01:20<00:39,  2.81s/it]\u001b[A\n"," 71% 32/45 [01:23<00:37,  2.89s/it]\u001b[A\n"," 73% 33/45 [01:26<00:33,  2.83s/it]\u001b[A\n"," 76% 34/45 [01:29<00:31,  2.86s/it]\u001b[A\n"," 78% 35/45 [01:32<00:28,  2.88s/it]\u001b[A\n"," 80% 36/45 [01:35<00:25,  2.85s/it]\u001b[A\n"," 82% 37/45 [01:37<00:21,  2.65s/it]\u001b[A\n"," 84% 38/45 [01:39<00:17,  2.48s/it]\u001b[A\n"," 87% 39/45 [01:41<00:14,  2.41s/it]\u001b[A\n"," 89% 40/45 [01:44<00:12,  2.60s/it]\u001b[A\n"," 91% 41/45 [01:47<00:10,  2.54s/it]\u001b[A\n"," 93% 42/45 [01:49<00:07,  2.50s/it]\u001b[A\n"," 96% 43/45 [01:51<00:04,  2.40s/it]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 2.0475656986236572, 'eval_accuracy': 0.47119678146690835, 'eval_runtime': 117.9102, 'eval_samples_per_second': 191.832, 'eval_steps_per_second': 0.382, 'epoch': 3.0}\n","  1% 267/26700 [16:59<13:21:08,  1.82s/it]\n","100% 45/45 [01:52<00:00,  1.86s/it]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2841] 2023-09-03 14:09:48,364 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-267\n","[INFO|configuration_utils.py:460] 2023-09-03 14:09:48,370 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-267/config.json\n","[INFO|modeling_utils.py:1992] 2023-09-03 14:09:48,486 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-267/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-03 14:09:48,490 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-267/preprocessor_config.json\n","{'loss': 1.7023, 'learning_rate': 0.0009898876404494383, 'epoch': 3.03}\n","{'loss': 1.6653, 'learning_rate': 0.0009895131086142322, 'epoch': 3.15}\n","{'loss': 1.6219, 'learning_rate': 0.000989138576779026, 'epoch': 3.26}\n","{'loss': 1.6426, 'learning_rate': 0.0009887640449438202, 'epoch': 3.37}\n","{'loss': 1.6782, 'learning_rate': 0.0009883895131086143, 'epoch': 3.48}\n","{'loss': 1.6355, 'learning_rate': 0.0009880149812734082, 'epoch': 3.6}\n","{'loss': 1.6349, 'learning_rate': 0.0009876404494382023, 'epoch': 3.71}\n","{'loss': 1.6323, 'learning_rate': 0.0009872659176029962, 'epoch': 3.82}\n","{'loss': 1.6755, 'learning_rate': 0.0009868913857677903, 'epoch': 3.93}\n","  1% 355/26700 [20:38<12:58:46,  1.77s/it][INFO|trainer.py:3115] 2023-09-03 14:13:27,434 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3117] 2023-09-03 14:13:27,434 >>   Num examples = 22619\n","[INFO|trainer.py:3120] 2023-09-03 14:13:27,434 >>   Batch size = 512\n","\n","  0% 0/45 [00:00<?, ?it/s]\u001b[A\n","  4% 2/45 [00:02<00:57,  1.33s/it]\u001b[A\n","  7% 3/45 [00:05<01:22,  1.96s/it]\u001b[A\n","  9% 4/45 [00:07<01:28,  2.16s/it]\u001b[A\n"," 11% 5/45 [00:10<01:32,  2.31s/it]\u001b[A\n"," 13% 6/45 [00:13<01:39,  2.54s/it]\u001b[A\n"," 16% 7/45 [00:16<01:42,  2.71s/it]\u001b[A\n"," 18% 8/45 [00:19<01:46,  2.88s/it]\u001b[A\n"," 20% 9/45 [00:23<01:47,  2.98s/it]\u001b[A\n"," 22% 10/45 [00:26<01:48,  3.09s/it]\u001b[A\n"," 24% 11/45 [00:28<01:37,  2.87s/it]\u001b[A\n"," 27% 12/45 [00:31<01:34,  2.88s/it]\u001b[A\n"," 29% 13/45 [00:34<01:27,  2.72s/it]\u001b[A\n"," 31% 14/45 [00:36<01:24,  2.73s/it]\u001b[A\n"," 33% 15/45 [00:39<01:19,  2.65s/it]\u001b[A\n"," 36% 16/45 [00:41<01:16,  2.65s/it]\u001b[A\n"," 38% 17/45 [00:44<01:11,  2.56s/it]\u001b[A\n"," 40% 18/45 [00:46<01:05,  2.42s/it]\u001b[A\n"," 42% 19/45 [00:48<01:04,  2.47s/it]\u001b[A\n"," 44% 20/45 [00:51<01:03,  2.56s/it]\u001b[A\n"," 47% 21/45 [00:54<01:01,  2.57s/it]\u001b[A\n"," 49% 22/45 [00:56<00:57,  2.51s/it]\u001b[A\n"," 51% 23/45 [00:58<00:53,  2.41s/it]\u001b[A\n"," 53% 24/45 [01:01<00:54,  2.57s/it]\u001b[A\n"," 56% 25/45 [01:04<00:52,  2.65s/it]\u001b[A\n"," 58% 26/45 [01:06<00:46,  2.43s/it]\u001b[A\n"," 60% 27/45 [01:09<00:46,  2.60s/it]\u001b[A\n"," 62% 28/45 [01:12<00:46,  2.74s/it]\u001b[A\n"," 64% 29/45 [01:15<00:42,  2.64s/it]\u001b[A\n"," 67% 30/45 [01:17<00:40,  2.70s/it]\u001b[A\n"," 69% 31/45 [01:21<00:39,  2.84s/it]\u001b[A\n"," 71% 32/45 [01:24<00:37,  2.90s/it]\u001b[A\n"," 73% 33/45 [01:26<00:34,  2.84s/it]\u001b[A\n"," 76% 34/45 [01:29<00:31,  2.86s/it]\u001b[A\n"," 78% 35/45 [01:32<00:28,  2.88s/it]\u001b[A\n"," 80% 36/45 [01:35<00:25,  2.86s/it]\u001b[A\n"," 82% 37/45 [01:37<00:21,  2.65s/it]\u001b[A\n"," 84% 38/45 [01:39<00:17,  2.48s/it]\u001b[A\n"," 87% 39/45 [01:41<00:14,  2.41s/it]\u001b[A\n"," 89% 40/45 [01:44<00:13,  2.60s/it]\u001b[A\n"," 91% 41/45 [01:47<00:10,  2.55s/it]\u001b[A\n"," 93% 42/45 [01:50<00:07,  2.59s/it]\u001b[A\n"," 96% 43/45 [01:52<00:04,  2.47s/it]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 1.7541468143463135, 'eval_accuracy': 0.5386621866572351, 'eval_runtime': 118.5386, 'eval_samples_per_second': 190.815, 'eval_steps_per_second': 0.38, 'epoch': 4.0}\n","  1% 356/26700 [22:37<12:58:44,  1.77s/it]\n","100% 45/45 [01:53<00:00,  1.91s/it]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2841] 2023-09-03 14:15:25,979 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-356\n","[INFO|configuration_utils.py:460] 2023-09-03 14:15:25,984 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-356/config.json\n","[INFO|modeling_utils.py:1992] 2023-09-03 14:15:26,093 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-356/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-03 14:15:26,097 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-356/preprocessor_config.json\n","[INFO|trainer.py:2928] 2023-09-03 14:15:26,308 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-89] due to args.save_total_limit\n","{'loss': 1.6418, 'learning_rate': 0.0009865168539325844, 'epoch': 4.04}\n","{'loss': 1.5317, 'learning_rate': 0.0009861423220973782, 'epoch': 4.16}\n","{'loss': 1.5501, 'learning_rate': 0.0009857677902621723, 'epoch': 4.27}\n","{'loss': 1.6136, 'learning_rate': 0.0009853932584269664, 'epoch': 4.38}\n","{'loss': 1.5239, 'learning_rate': 0.0009850187265917603, 'epoch': 4.49}\n","{'loss': 1.5406, 'learning_rate': 0.0009846441947565542, 'epoch': 4.61}\n","{'loss': 1.5258, 'learning_rate': 0.0009842696629213483, 'epoch': 4.72}\n","{'loss': 1.5438, 'learning_rate': 0.0009838951310861424, 'epoch': 4.83}\n","{'loss': 1.5788, 'learning_rate': 0.0009835205992509363, 'epoch': 4.94}\n","  2% 444/26700 [26:15<13:33:16,  1.86s/it][INFO|trainer.py:3115] 2023-09-03 14:19:03,857 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3117] 2023-09-03 14:19:03,858 >>   Num examples = 22619\n","[INFO|trainer.py:3120] 2023-09-03 14:19:03,858 >>   Batch size = 512\n","\n","  0% 0/45 [00:00<?, ?it/s]\u001b[A\n","  4% 2/45 [00:02<00:56,  1.31s/it]\u001b[A\n","  7% 3/45 [00:05<01:21,  1.94s/it]\u001b[A\n","  9% 4/45 [00:07<01:27,  2.14s/it]\u001b[A\n"," 11% 5/45 [00:10<01:31,  2.30s/it]\u001b[A\n"," 13% 6/45 [00:13<01:39,  2.54s/it]\u001b[A\n"," 16% 7/45 [00:16<01:43,  2.71s/it]\u001b[A\n"," 18% 8/45 [00:20<01:48,  2.93s/it]\u001b[A\n"," 20% 9/45 [00:23<01:48,  3.02s/it]\u001b[A\n"," 22% 10/45 [00:26<01:48,  3.11s/it]\u001b[A\n"," 24% 11/45 [00:28<01:38,  2.89s/it]\u001b[A\n"," 27% 12/45 [00:31<01:33,  2.84s/it]\u001b[A\n"," 29% 13/45 [00:34<01:26,  2.70s/it]\u001b[A\n"," 31% 14/45 [00:36<01:24,  2.72s/it]\u001b[A\n"," 33% 15/45 [00:39<01:19,  2.64s/it]\u001b[A\n"," 36% 16/45 [00:41<01:16,  2.64s/it]\u001b[A\n"," 38% 17/45 [00:44<01:11,  2.55s/it]\u001b[A\n"," 40% 18/45 [00:46<01:05,  2.41s/it]\u001b[A\n"," 42% 19/45 [00:48<01:03,  2.46s/it]\u001b[A\n"," 44% 20/45 [00:51<01:03,  2.55s/it]\u001b[A\n"," 47% 21/45 [00:54<01:01,  2.56s/it]\u001b[A\n"," 49% 22/45 [00:56<00:57,  2.51s/it]\u001b[A\n"," 51% 23/45 [00:58<00:52,  2.41s/it]\u001b[A\n"," 53% 24/45 [01:01<00:53,  2.56s/it]\u001b[A\n"," 56% 25/45 [01:04<00:52,  2.63s/it]\u001b[A\n"," 58% 26/45 [01:06<00:45,  2.41s/it]\u001b[A\n"," 60% 27/45 [01:09<00:46,  2.60s/it]\u001b[A\n"," 62% 28/45 [01:12<00:46,  2.73s/it]\u001b[A\n"," 64% 29/45 [01:14<00:42,  2.64s/it]\u001b[A\n"," 67% 30/45 [01:17<00:40,  2.68s/it]\u001b[A\n"," 69% 31/45 [01:20<00:39,  2.83s/it]\u001b[A\n"," 71% 32/45 [01:23<00:37,  2.90s/it]\u001b[A\n"," 73% 33/45 [01:26<00:34,  2.85s/it]\u001b[A\n"," 76% 34/45 [01:29<00:31,  2.91s/it]\u001b[A\n"," 78% 35/45 [01:32<00:29,  2.95s/it]\u001b[A\n"," 80% 36/45 [01:35<00:26,  2.90s/it]\u001b[A\n"," 82% 37/45 [01:37<00:21,  2.67s/it]\u001b[A\n"," 84% 38/45 [01:39<00:17,  2.50s/it]\u001b[A\n"," 87% 39/45 [01:41<00:14,  2.42s/it]\u001b[A\n"," 89% 40/45 [01:44<00:12,  2.59s/it]\u001b[A\n"," 91% 41/45 [01:47<00:10,  2.54s/it]\u001b[A\n"," 93% 42/45 [01:49<00:07,  2.50s/it]\u001b[A\n"," 96% 43/45 [01:51<00:04,  2.40s/it]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 1.7751048803329468, 'eval_accuracy': 0.5490958928334586, 'eval_runtime': 118.1747, 'eval_samples_per_second': 191.403, 'eval_steps_per_second': 0.381, 'epoch': 5.0}\n","  2% 445/26700 [28:13<13:33:14,  1.86s/it]\n","100% 45/45 [01:52<00:00,  1.85s/it]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2841] 2023-09-03 14:21:02,038 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-445\n","[INFO|configuration_utils.py:460] 2023-09-03 14:21:02,044 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-445/config.json\n","[INFO|modeling_utils.py:1992] 2023-09-03 14:21:02,153 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-445/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-03 14:21:02,169 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-445/preprocessor_config.json\n","[INFO|trainer.py:2928] 2023-09-03 14:21:02,380 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-178] due to args.save_total_limit\n","{'loss': 1.5977, 'learning_rate': 0.0009831460674157304, 'epoch': 5.06}\n","{'loss': 1.4486, 'learning_rate': 0.0009827715355805243, 'epoch': 5.17}\n","{'loss': 1.4533, 'learning_rate': 0.0009823970037453184, 'epoch': 5.28}\n","{'loss': 1.4445, 'learning_rate': 0.0009820224719101125, 'epoch': 5.39}\n","{'loss': 1.4502, 'learning_rate': 0.0009816479400749064, 'epoch': 5.51}\n","{'loss': 1.4613, 'learning_rate': 0.0009812734082397002, 'epoch': 5.62}\n","{'loss': 1.4819, 'learning_rate': 0.0009808988764044943, 'epoch': 5.73}\n","{'loss': 1.4548, 'learning_rate': 0.0009805243445692884, 'epoch': 5.84}\n","{'loss': 1.4913, 'learning_rate': 0.0009801498127340823, 'epoch': 5.96}\n","  2% 533/26700 [31:50<13:08:13,  1.81s/it][INFO|trainer.py:3115] 2023-09-03 14:24:39,064 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3117] 2023-09-03 14:24:39,065 >>   Num examples = 22619\n","[INFO|trainer.py:3120] 2023-09-03 14:24:39,065 >>   Batch size = 512\n","\n","  0% 0/45 [00:00<?, ?it/s]\u001b[A\n","  4% 2/45 [00:02<00:54,  1.27s/it]\u001b[A\n","  7% 3/45 [00:05<01:21,  1.93s/it]\u001b[A\n","  9% 4/45 [00:07<01:27,  2.13s/it]\u001b[A\n"," 11% 5/45 [00:10<01:31,  2.29s/it]\u001b[A\n"," 13% 6/45 [00:13<01:38,  2.53s/it]\u001b[A\n"," 16% 7/45 [00:16<01:42,  2.70s/it]\u001b[A\n"," 18% 8/45 [00:19<01:45,  2.84s/it]\u001b[A\n"," 20% 9/45 [00:22<01:46,  2.96s/it]\u001b[A\n"," 22% 10/45 [00:26<01:47,  3.07s/it]\u001b[A\n"," 24% 11/45 [00:28<01:37,  2.85s/it]\u001b[A\n"," 27% 12/45 [00:31<01:32,  2.80s/it]\u001b[A\n"," 29% 13/45 [00:33<01:25,  2.68s/it]\u001b[A\n"," 31% 14/45 [00:36<01:23,  2.70s/it]\u001b[A\n"," 33% 15/45 [00:38<01:18,  2.63s/it]\u001b[A\n"," 36% 16/45 [00:41<01:16,  2.63s/it]\u001b[A\n"," 38% 17/45 [00:43<01:11,  2.54s/it]\u001b[A\n"," 40% 18/45 [00:45<01:04,  2.41s/it]\u001b[A\n"," 42% 19/45 [00:48<01:03,  2.46s/it]\u001b[A\n"," 44% 20/45 [00:51<01:03,  2.54s/it]\u001b[A\n"," 47% 21/45 [00:53<01:01,  2.56s/it]\u001b[A\n"," 49% 22/45 [00:56<00:57,  2.50s/it]\u001b[A\n"," 51% 23/45 [00:58<00:52,  2.40s/it]\u001b[A\n"," 53% 24/45 [01:01<00:53,  2.55s/it]\u001b[A\n"," 56% 25/45 [01:04<00:52,  2.64s/it]\u001b[A\n"," 58% 26/45 [01:06<00:46,  2.42s/it]\u001b[A\n"," 60% 27/45 [01:09<00:47,  2.62s/it]\u001b[A\n"," 62% 28/45 [01:12<00:46,  2.74s/it]\u001b[A\n"," 64% 29/45 [01:14<00:42,  2.64s/it]\u001b[A\n"," 67% 30/45 [01:17<00:40,  2.67s/it]\u001b[A\n"," 69% 31/45 [01:20<00:39,  2.83s/it]\u001b[A\n"," 71% 32/45 [01:23<00:37,  2.89s/it]\u001b[A\n"," 73% 33/45 [01:26<00:34,  2.84s/it]\u001b[A\n"," 76% 34/45 [01:29<00:31,  2.85s/it]\u001b[A\n"," 78% 35/45 [01:32<00:28,  2.89s/it]\u001b[A\n"," 80% 36/45 [01:34<00:25,  2.85s/it]\u001b[A\n"," 82% 37/45 [01:37<00:21,  2.64s/it]\u001b[A\n"," 84% 38/45 [01:39<00:17,  2.47s/it]\u001b[A\n"," 87% 39/45 [01:41<00:14,  2.39s/it]\u001b[A\n"," 89% 40/45 [01:44<00:12,  2.58s/it]\u001b[A\n"," 91% 41/45 [01:46<00:10,  2.53s/it]\u001b[A\n"," 93% 42/45 [01:49<00:07,  2.50s/it]\u001b[A\n"," 96% 43/45 [01:51<00:04,  2.41s/it]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 1.6473239660263062, 'eval_accuracy': 0.5683717228878377, 'eval_runtime': 117.7927, 'eval_samples_per_second': 192.024, 'eval_steps_per_second': 0.382, 'epoch': 6.0}\n","  2% 534/26700 [33:48<13:08:12,  1.81s/it]\n","100% 45/45 [01:52<00:00,  1.86s/it]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2841] 2023-09-03 14:26:36,864 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-534\n","[INFO|configuration_utils.py:460] 2023-09-03 14:26:36,870 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-534/config.json\n","[INFO|modeling_utils.py:1992] 2023-09-03 14:26:36,985 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-534/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-03 14:26:36,988 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-534/preprocessor_config.json\n","[INFO|trainer.py:2928] 2023-09-03 14:26:37,197 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-267] due to args.save_total_limit\n","{'loss': 1.4423, 'learning_rate': 0.0009797752808988764, 'epoch': 6.07}\n","{'loss': 1.3604, 'learning_rate': 0.0009794007490636703, 'epoch': 6.18}\n","{'loss': 1.3618, 'learning_rate': 0.0009790262172284644, 'epoch': 6.29}\n","{'loss': 1.3442, 'learning_rate': 0.0009786516853932585, 'epoch': 6.4}\n","{'loss': 1.3985, 'learning_rate': 0.0009782771535580524, 'epoch': 6.52}\n","{'loss': 1.3971, 'learning_rate': 0.0009779026217228465, 'epoch': 6.63}\n","{'loss': 1.421, 'learning_rate': 0.0009775280898876404, 'epoch': 6.74}\n","{'loss': 1.381, 'learning_rate': 0.0009771535580524345, 'epoch': 6.85}\n","{'loss': 1.4039, 'learning_rate': 0.0009767790262172286, 'epoch': 6.97}\n","  2% 622/26700 [37:26<13:26:04,  1.85s/it][INFO|trainer.py:3115] 2023-09-03 14:30:14,878 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3117] 2023-09-03 14:30:14,878 >>   Num examples = 22619\n","[INFO|trainer.py:3120] 2023-09-03 14:30:14,878 >>   Batch size = 512\n","\n","  0% 0/45 [00:00<?, ?it/s]\u001b[A\n","  4% 2/45 [00:02<00:54,  1.27s/it]\u001b[A\n","  7% 3/45 [00:05<01:21,  1.94s/it]\u001b[A\n","  9% 4/45 [00:07<01:28,  2.15s/it]\u001b[A\n"," 11% 5/45 [00:10<01:35,  2.39s/it]\u001b[A\n"," 13% 6/45 [00:13<01:41,  2.61s/it]\u001b[A\n"," 16% 7/45 [00:16<01:44,  2.76s/it]\u001b[A\n"," 18% 8/45 [00:20<01:46,  2.88s/it]\u001b[A\n"," 20% 9/45 [00:23<01:47,  2.99s/it]\u001b[A\n"," 22% 10/45 [00:26<01:48,  3.09s/it]\u001b[A\n"," 24% 11/45 [00:28<01:37,  2.87s/it]\u001b[A\n"," 27% 12/45 [00:31<01:33,  2.82s/it]\u001b[A\n"," 29% 13/45 [00:34<01:26,  2.69s/it]\u001b[A\n"," 31% 14/45 [00:36<01:24,  2.72s/it]\u001b[A\n"," 33% 15/45 [00:39<01:19,  2.65s/it]\u001b[A\n"," 36% 16/45 [00:41<01:16,  2.65s/it]\u001b[A\n"," 38% 17/45 [00:44<01:11,  2.56s/it]\u001b[A\n"," 40% 18/45 [00:46<01:05,  2.43s/it]\u001b[A\n"," 42% 19/45 [00:49<01:04,  2.47s/it]\u001b[A\n"," 44% 20/45 [00:51<01:04,  2.56s/it]\u001b[A\n"," 47% 21/45 [00:54<01:02,  2.58s/it]\u001b[A\n"," 49% 22/45 [00:56<00:58,  2.53s/it]\u001b[A\n"," 51% 23/45 [00:59<00:53,  2.42s/it]\u001b[A\n"," 53% 24/45 [01:01<00:54,  2.57s/it]\u001b[A\n"," 56% 25/45 [01:04<00:53,  2.66s/it]\u001b[A\n"," 58% 26/45 [01:06<00:46,  2.44s/it]\u001b[A\n"," 60% 27/45 [01:09<00:47,  2.63s/it]\u001b[A\n"," 62% 28/45 [01:12<00:46,  2.75s/it]\u001b[A\n"," 64% 29/45 [01:15<00:42,  2.68s/it]\u001b[A\n"," 67% 30/45 [01:18<00:40,  2.71s/it]\u001b[A\n"," 69% 31/45 [01:21<00:39,  2.86s/it]\u001b[A\n"," 71% 32/45 [01:24<00:38,  2.93s/it]\u001b[A\n"," 73% 33/45 [01:27<00:34,  2.87s/it]\u001b[A\n"," 76% 34/45 [01:30<00:31,  2.88s/it]\u001b[A\n"," 78% 35/45 [01:33<00:29,  2.92s/it]\u001b[A\n"," 80% 36/45 [01:35<00:26,  2.89s/it]\u001b[A\n"," 82% 37/45 [01:38<00:21,  2.68s/it]\u001b[A\n"," 84% 38/45 [01:40<00:17,  2.51s/it]\u001b[A\n"," 87% 39/45 [01:42<00:14,  2.43s/it]\u001b[A\n"," 89% 40/45 [01:45<00:13,  2.61s/it]\u001b[A\n"," 91% 41/45 [01:47<00:10,  2.55s/it]\u001b[A\n"," 93% 42/45 [01:50<00:07,  2.52s/it]\u001b[A\n"," 96% 43/45 [01:52<00:04,  2.42s/it]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 1.6629223823547363, 'eval_accuracy': 0.5674432998806314, 'eval_runtime': 118.7631, 'eval_samples_per_second': 190.455, 'eval_steps_per_second': 0.379, 'epoch': 7.0}\n","  2% 623/26700 [39:24<13:26:02,  1.85s/it]\n","100% 45/45 [01:53<00:00,  1.87s/it]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2841] 2023-09-03 14:32:13,647 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-623\n","[INFO|configuration_utils.py:460] 2023-09-03 14:32:13,653 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-623/config.json\n","[INFO|modeling_utils.py:1992] 2023-09-03 14:32:13,765 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-623/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-03 14:32:13,768 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-623/preprocessor_config.json\n","[INFO|trainer.py:2928] 2023-09-03 14:32:13,981 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-356] due to args.save_total_limit\n","{'loss': 1.286, 'learning_rate': 0.0009764044943820225, 'epoch': 7.08}\n","{'loss': 1.3279, 'learning_rate': 0.0009760299625468166, 'epoch': 7.19}\n","{'loss': 1.2966, 'learning_rate': 0.0009756554307116106, 'epoch': 7.3}\n","{'loss': 1.32, 'learning_rate': 0.0009752808988764044, 'epoch': 7.42}\n","{'loss': 1.3121, 'learning_rate': 0.0009749063670411985, 'epoch': 7.53}\n","{'loss': 1.2935, 'learning_rate': 0.0009745318352059925, 'epoch': 7.64}\n","{'loss': 1.3549, 'learning_rate': 0.0009741573033707865, 'epoch': 7.75}\n","{'loss': 1.3703, 'learning_rate': 0.0009737827715355806, 'epoch': 7.87}\n","{'loss': 1.3173, 'learning_rate': 0.0009734082397003745, 'epoch': 7.98}\n","  3% 711/26700 [43:02<12:38:24,  1.75s/it][INFO|trainer.py:3115] 2023-09-03 14:35:51,452 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3117] 2023-09-03 14:35:51,452 >>   Num examples = 22619\n","[INFO|trainer.py:3120] 2023-09-03 14:35:51,452 >>   Batch size = 512\n","\n","  0% 0/45 [00:00<?, ?it/s]\u001b[A\n","  4% 2/45 [00:02<00:54,  1.26s/it]\u001b[A\n","  7% 3/45 [00:05<01:24,  2.01s/it]\u001b[A\n","  9% 4/45 [00:08<01:30,  2.20s/it]\u001b[A\n"," 11% 5/45 [00:10<01:33,  2.34s/it]\u001b[A\n"," 13% 6/45 [00:13<01:39,  2.56s/it]\u001b[A\n"," 16% 7/45 [00:16<01:43,  2.72s/it]\u001b[A\n"," 18% 8/45 [00:19<01:45,  2.85s/it]\u001b[A\n"," 20% 9/45 [00:23<01:46,  2.96s/it]\u001b[A\n"," 22% 10/45 [00:26<01:47,  3.07s/it]\u001b[A\n"," 24% 11/45 [00:28<01:37,  2.86s/it]\u001b[A\n"," 27% 12/45 [00:31<01:32,  2.81s/it]\u001b[A\n"," 29% 13/45 [00:34<01:27,  2.74s/it]\u001b[A\n"," 31% 14/45 [00:36<01:25,  2.74s/it]\u001b[A\n"," 33% 15/45 [00:39<01:19,  2.66s/it]\u001b[A\n"," 36% 16/45 [00:42<01:19,  2.73s/it]\u001b[A\n"," 38% 17/45 [00:44<01:13,  2.61s/it]\u001b[A\n"," 40% 18/45 [00:46<01:05,  2.44s/it]\u001b[A\n"," 42% 19/45 [00:49<01:04,  2.47s/it]\u001b[A\n"," 44% 20/45 [00:51<01:04,  2.57s/it]\u001b[A\n"," 47% 21/45 [00:54<01:01,  2.58s/it]\u001b[A\n"," 49% 22/45 [00:56<00:57,  2.52s/it]\u001b[A\n"," 51% 23/45 [00:59<00:52,  2.40s/it]\u001b[A\n"," 53% 24/45 [01:01<00:53,  2.55s/it]\u001b[A\n"," 56% 25/45 [01:04<00:52,  2.64s/it]\u001b[A\n"," 58% 26/45 [01:06<00:46,  2.43s/it]\u001b[A\n"," 60% 27/45 [01:09<00:47,  2.61s/it]\u001b[A\n"," 62% 28/45 [01:12<00:46,  2.73s/it]\u001b[A\n"," 64% 29/45 [01:15<00:42,  2.64s/it]\u001b[A\n"," 67% 30/45 [01:17<00:39,  2.66s/it]\u001b[A\n"," 69% 31/45 [01:21<00:39,  2.82s/it]\u001b[A\n"," 71% 32/45 [01:24<00:37,  2.89s/it]\u001b[A\n"," 73% 33/45 [01:26<00:34,  2.84s/it]\u001b[A\n"," 76% 34/45 [01:29<00:31,  2.85s/it]\u001b[A\n"," 78% 35/45 [01:32<00:28,  2.87s/it]\u001b[A\n"," 80% 36/45 [01:35<00:25,  2.86s/it]\u001b[A\n"," 82% 37/45 [01:37<00:21,  2.65s/it]\u001b[A\n"," 84% 38/45 [01:39<00:17,  2.49s/it]\u001b[A\n"," 87% 39/45 [01:41<00:14,  2.42s/it]\u001b[A\n"," 89% 40/45 [01:44<00:12,  2.59s/it]\u001b[A\n"," 91% 41/45 [01:47<00:10,  2.53s/it]\u001b[A\n"," 93% 42/45 [01:49<00:07,  2.53s/it]\u001b[A\n"," 96% 43/45 [01:52<00:04,  2.42s/it]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 1.5633020401000977, 'eval_accuracy': 0.5830938591449666, 'eval_runtime': 118.2887, 'eval_samples_per_second': 191.219, 'eval_steps_per_second': 0.38, 'epoch': 8.0}\n","  3% 712/26700 [45:00<12:38:22,  1.75s/it]\n","100% 45/45 [01:52<00:00,  1.87s/it]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2841] 2023-09-03 14:37:49,746 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-712\n","[INFO|configuration_utils.py:460] 2023-09-03 14:37:49,752 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-712/config.json\n","[INFO|modeling_utils.py:1992] 2023-09-03 14:37:49,867 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-712/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-03 14:37:49,871 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-712/preprocessor_config.json\n","[INFO|trainer.py:2928] 2023-09-03 14:37:50,100 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-445] due to args.save_total_limit\n","{'loss': 1.2301, 'learning_rate': 0.0009730337078651685, 'epoch': 8.09}\n","{'loss': 1.2182, 'learning_rate': 0.0009726591760299626, 'epoch': 8.2}\n","{'loss': 1.2391, 'learning_rate': 0.0009722846441947566, 'epoch': 8.31}\n","{'loss': 1.2608, 'learning_rate': 0.0009719101123595506, 'epoch': 8.43}\n","{'loss': 1.235, 'learning_rate': 0.0009715355805243446, 'epoch': 8.54}\n","{'loss': 1.2564, 'learning_rate': 0.0009711610486891386, 'epoch': 8.65}\n","{'loss': 1.2608, 'learning_rate': 0.0009707865168539325, 'epoch': 8.76}\n","{'loss': 1.2679, 'learning_rate': 0.0009704119850187266, 'epoch': 8.88}\n","{'loss': 1.2975, 'learning_rate': 0.0009700374531835206, 'epoch': 8.99}\n","  3% 800/26700 [48:39<13:51:57,  1.93s/it][INFO|trainer.py:3115] 2023-09-03 14:41:28,410 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3117] 2023-09-03 14:41:28,410 >>   Num examples = 22619\n","[INFO|trainer.py:3120] 2023-09-03 14:41:28,410 >>   Batch size = 512\n","\n","  0% 0/45 [00:00<?, ?it/s]\u001b[A\n","  4% 2/45 [00:02<00:54,  1.27s/it]\u001b[A\n","  7% 3/45 [00:05<01:25,  2.03s/it]\u001b[A\n","  9% 4/45 [00:08<01:30,  2.21s/it]\u001b[A\n"," 11% 5/45 [00:10<01:33,  2.34s/it]\u001b[A\n"," 13% 6/45 [00:13<01:40,  2.57s/it]\u001b[A\n"," 16% 7/45 [00:16<01:43,  2.72s/it]\u001b[A\n"," 18% 8/45 [00:19<01:45,  2.86s/it]\u001b[A\n"," 20% 9/45 [00:23<01:47,  2.98s/it]\u001b[A\n"," 22% 10/45 [00:26<01:47,  3.08s/it]\u001b[A\n"," 24% 11/45 [00:28<01:37,  2.86s/it]\u001b[A\n"," 27% 12/45 [00:31<01:32,  2.80s/it]\u001b[A\n"," 29% 13/45 [00:33<01:25,  2.66s/it]\u001b[A\n"," 31% 14/45 [00:36<01:23,  2.71s/it]\u001b[A\n"," 33% 15/45 [00:39<01:19,  2.64s/it]\u001b[A\n"," 36% 16/45 [00:41<01:16,  2.64s/it]\u001b[A\n"," 38% 17/45 [00:44<01:11,  2.55s/it]\u001b[A\n"," 40% 18/45 [00:46<01:04,  2.40s/it]\u001b[A\n"," 42% 19/45 [00:48<01:03,  2.45s/it]\u001b[A\n"," 44% 20/45 [00:51<01:03,  2.56s/it]\u001b[A\n"," 47% 21/45 [00:54<01:01,  2.56s/it]\u001b[A\n"," 49% 22/45 [00:56<00:57,  2.50s/it]\u001b[A\n"," 51% 23/45 [00:58<00:52,  2.40s/it]\u001b[A\n"," 53% 24/45 [01:01<00:53,  2.55s/it]\u001b[A\n"," 56% 25/45 [01:04<00:52,  2.64s/it]\u001b[A\n"," 58% 26/45 [01:06<00:46,  2.43s/it]\u001b[A\n"," 60% 27/45 [01:09<00:47,  2.62s/it]\u001b[A\n"," 62% 28/45 [01:12<00:46,  2.74s/it]\u001b[A\n"," 64% 29/45 [01:14<00:42,  2.64s/it]\u001b[A\n"," 67% 30/45 [01:17<00:40,  2.67s/it]\u001b[A\n"," 69% 31/45 [01:20<00:39,  2.85s/it]\u001b[A\n"," 71% 32/45 [01:23<00:37,  2.91s/it]\u001b[A\n"," 73% 33/45 [01:26<00:34,  2.86s/it]\u001b[A\n"," 76% 34/45 [01:29<00:31,  2.86s/it]\u001b[A\n"," 78% 35/45 [01:32<00:28,  2.89s/it]\u001b[A\n"," 80% 36/45 [01:35<00:26,  2.90s/it]\u001b[A\n"," 82% 37/45 [01:37<00:21,  2.68s/it]\u001b[A\n"," 84% 38/45 [01:39<00:17,  2.51s/it]\u001b[A\n"," 87% 39/45 [01:41<00:14,  2.43s/it]\u001b[A\n"," 89% 40/45 [01:44<00:13,  2.60s/it]\u001b[A\n"," 91% 41/45 [01:47<00:10,  2.57s/it]\u001b[A\n"," 93% 42/45 [01:49<00:07,  2.54s/it]\u001b[A\n"," 96% 43/45 [01:52<00:04,  2.44s/it]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 1.5916951894760132, 'eval_accuracy': 0.5961802024846368, 'eval_runtime': 118.3651, 'eval_samples_per_second': 191.095, 'eval_steps_per_second': 0.38, 'epoch': 9.0}\n","  3% 801/26700 [50:38<13:51:55,  1.93s/it]\n","100% 45/45 [01:52<00:00,  1.89s/it]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2841] 2023-09-03 14:43:26,781 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-801\n","[INFO|configuration_utils.py:460] 2023-09-03 14:43:26,787 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-801/config.json\n","[INFO|modeling_utils.py:1992] 2023-09-03 14:43:26,900 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-801/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-03 14:43:26,904 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-801/preprocessor_config.json\n","[INFO|trainer.py:2928] 2023-09-03 14:43:27,123 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-534] due to args.save_total_limit\n","{'loss': 1.1691, 'learning_rate': 0.0009696629213483145, 'epoch': 9.1}\n","{'loss': 1.1843, 'learning_rate': 0.0009692883895131086, 'epoch': 9.21}\n","{'loss': 1.2243, 'learning_rate': 0.0009689138576779026, 'epoch': 9.33}\n","{'loss': 1.1994, 'learning_rate': 0.0009685393258426967, 'epoch': 9.44}\n","{'loss': 1.1763, 'learning_rate': 0.0009681647940074907, 'epoch': 9.55}\n","{'loss': 1.2234, 'learning_rate': 0.0009677902621722847, 'epoch': 9.66}\n","{'loss': 1.1808, 'learning_rate': 0.0009674157303370787, 'epoch': 9.78}\n","{'loss': 1.2021, 'learning_rate': 0.0009670411985018727, 'epoch': 9.89}\n","{'loss': 1.2621, 'learning_rate': 0.0009666666666666667, 'epoch': 10.0}\n","  3% 890/26700 [54:16<13:27:26,  1.88s/it][INFO|trainer.py:3115] 2023-09-03 14:47:05,278 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3117] 2023-09-03 14:47:05,278 >>   Num examples = 22619\n","[INFO|trainer.py:3120] 2023-09-03 14:47:05,278 >>   Batch size = 512\n","\n","  0% 0/45 [00:00<?, ?it/s]\u001b[A\n","  4% 2/45 [00:02<00:53,  1.25s/it]\u001b[A\n","  7% 3/45 [00:05<01:20,  1.92s/it]\u001b[A\n","  9% 4/45 [00:07<01:28,  2.15s/it]\u001b[A\n"," 11% 5/45 [00:10<01:32,  2.31s/it]\u001b[A\n"," 13% 6/45 [00:13<01:39,  2.55s/it]\u001b[A\n"," 16% 7/45 [00:16<01:42,  2.70s/it]\u001b[A\n"," 18% 8/45 [00:19<01:47,  2.89s/it]\u001b[A\n"," 20% 9/45 [00:23<01:48,  3.01s/it]\u001b[A\n"," 22% 10/45 [00:26<01:48,  3.10s/it]\u001b[A\n"," 24% 11/45 [00:28<01:38,  2.89s/it]\u001b[A\n"," 27% 12/45 [00:31<01:32,  2.81s/it]\u001b[A\n"," 29% 13/45 [00:33<01:25,  2.68s/it]\u001b[A\n"," 31% 14/45 [00:36<01:24,  2.71s/it]\u001b[A\n"," 33% 15/45 [00:39<01:19,  2.64s/it]\u001b[A\n"," 36% 16/45 [00:41<01:16,  2.64s/it]\u001b[A\n"," 38% 17/45 [00:44<01:11,  2.54s/it]\u001b[A\n"," 40% 18/45 [00:46<01:04,  2.39s/it]\u001b[A\n"," 42% 19/45 [00:48<01:03,  2.44s/it]\u001b[A\n"," 44% 20/45 [00:51<01:04,  2.58s/it]\u001b[A\n"," 47% 21/45 [00:54<01:02,  2.59s/it]\u001b[A\n"," 49% 22/45 [00:56<00:58,  2.53s/it]\u001b[A\n"," 51% 23/45 [00:58<00:53,  2.41s/it]\u001b[A\n"," 53% 24/45 [01:01<00:53,  2.55s/it]\u001b[A\n"," 56% 25/45 [01:04<00:52,  2.63s/it]\u001b[A\n"," 58% 26/45 [01:06<00:46,  2.45s/it]\u001b[A\n"," 60% 27/45 [01:09<00:47,  2.62s/it]\u001b[A\n"," 62% 28/45 [01:12<00:46,  2.73s/it]\u001b[A\n"," 64% 29/45 [01:14<00:42,  2.63s/it]\u001b[A\n"," 67% 30/45 [01:17<00:39,  2.65s/it]\u001b[A\n"," 69% 31/45 [01:20<00:39,  2.82s/it]\u001b[A\n"," 71% 32/45 [01:23<00:37,  2.89s/it]\u001b[A\n"," 73% 33/45 [01:26<00:34,  2.84s/it]\u001b[A\n"," 76% 34/45 [01:29<00:31,  2.84s/it]\u001b[A\n"," 78% 35/45 [01:32<00:28,  2.86s/it]\u001b[A\n"," 80% 36/45 [01:35<00:25,  2.86s/it]\u001b[A\n"," 82% 37/45 [01:37<00:21,  2.65s/it]\u001b[A\n"," 84% 38/45 [01:39<00:17,  2.48s/it]\u001b[A\n"," 87% 39/45 [01:41<00:14,  2.41s/it]\u001b[A\n"," 89% 40/45 [01:44<00:12,  2.58s/it]\u001b[A\n"," 91% 41/45 [01:46<00:10,  2.52s/it]\u001b[A\n"," 93% 42/45 [01:49<00:07,  2.52s/it]\u001b[A\n"," 96% 43/45 [01:51<00:04,  2.42s/it]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 1.5851306915283203, 'eval_accuracy': 0.5930412485078916, 'eval_runtime': 117.8725, 'eval_samples_per_second': 191.894, 'eval_steps_per_second': 0.382, 'epoch': 10.0}\n","  3% 890/26700 [56:14<13:27:26,  1.88s/it]\n","100% 45/45 [01:52<00:00,  1.87s/it]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2841] 2023-09-03 14:49:03,157 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-890\n","[INFO|configuration_utils.py:460] 2023-09-03 14:49:03,162 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-890/config.json\n","[INFO|modeling_utils.py:1992] 2023-09-03 14:49:03,269 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-890/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-03 14:49:03,273 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-890/preprocessor_config.json\n","[INFO|trainer.py:2928] 2023-09-03 14:49:03,490 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-623] due to args.save_total_limit\n","{'loss': 1.1147, 'learning_rate': 0.0009662921348314608, 'epoch': 10.11}\n","{'loss': 1.154, 'learning_rate': 0.0009659176029962548, 'epoch': 10.22}\n","{'loss': 1.132, 'learning_rate': 0.0009655430711610486, 'epoch': 10.34}\n","{'loss': 1.1706, 'learning_rate': 0.0009651685393258427, 'epoch': 10.45}\n","{'loss': 1.1705, 'learning_rate': 0.0009647940074906367, 'epoch': 10.56}\n","{'loss': 1.1901, 'learning_rate': 0.0009644194756554307, 'epoch': 10.67}\n","{'loss': 1.162, 'learning_rate': 0.0009640449438202248, 'epoch': 10.79}\n","{'loss': 1.1742, 'learning_rate': 0.0009636704119850187, 'epoch': 10.9}\n","  4% 978/26700 [59:51<13:32:03,  1.89s/it][INFO|trainer.py:3115] 2023-09-03 14:52:40,611 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3117] 2023-09-03 14:52:40,612 >>   Num examples = 22619\n","[INFO|trainer.py:3120] 2023-09-03 14:52:40,612 >>   Batch size = 512\n","\n","  0% 0/45 [00:00<?, ?it/s]\u001b[A\n","  4% 2/45 [00:02<00:53,  1.24s/it]\u001b[A\n","  7% 3/45 [00:05<01:23,  1.98s/it]\u001b[A\n","  9% 4/45 [00:08<01:30,  2.21s/it]\u001b[A\n"," 11% 5/45 [00:10<01:33,  2.34s/it]\u001b[A\n"," 13% 6/45 [00:13<01:39,  2.56s/it]\u001b[A\n"," 16% 7/45 [00:16<01:42,  2.70s/it]\u001b[A\n"," 18% 8/45 [00:19<01:46,  2.88s/it]\u001b[A\n"," 20% 9/45 [00:23<01:48,  3.01s/it]\u001b[A\n"," 22% 10/45 [00:26<01:48,  3.10s/it]\u001b[A\n"," 24% 11/45 [00:28<01:37,  2.88s/it]\u001b[A\n"," 27% 12/45 [00:31<01:32,  2.81s/it]\u001b[A\n"," 29% 13/45 [00:33<01:26,  2.69s/it]\u001b[A\n"," 31% 14/45 [00:36<01:24,  2.74s/it]\u001b[A\n"," 33% 15/45 [00:39<01:19,  2.66s/it]\u001b[A\n"," 36% 16/45 [00:42<01:17,  2.67s/it]\u001b[A\n"," 38% 17/45 [00:44<01:12,  2.58s/it]\u001b[A\n"," 40% 18/45 [00:46<01:05,  2.42s/it]\u001b[A\n"," 42% 19/45 [00:49<01:04,  2.49s/it]\u001b[A\n"," 44% 20/45 [00:52<01:05,  2.62s/it]\u001b[A\n"," 47% 21/45 [00:54<01:02,  2.61s/it]\u001b[A\n"," 49% 22/45 [00:57<00:58,  2.55s/it]\u001b[A\n"," 51% 23/45 [00:59<00:53,  2.43s/it]\u001b[A\n"," 53% 24/45 [01:02<00:53,  2.56s/it]\u001b[A\n"," 56% 25/45 [01:04<00:52,  2.65s/it]\u001b[A\n"," 58% 26/45 [01:06<00:46,  2.47s/it]\u001b[A\n"," 60% 27/45 [01:09<00:47,  2.64s/it]\u001b[A\n"," 62% 28/45 [01:12<00:46,  2.75s/it]\u001b[A\n"," 64% 29/45 [01:15<00:42,  2.64s/it]\u001b[A\n"," 67% 30/45 [01:18<00:39,  2.65s/it]\u001b[A\n"," 69% 31/45 [01:21<00:39,  2.84s/it]\u001b[A\n"," 71% 32/45 [01:24<00:37,  2.91s/it]\u001b[A\n"," 73% 33/45 [01:27<00:34,  2.86s/it]\u001b[A\n"," 76% 34/45 [01:30<00:31,  2.86s/it]\u001b[A\n"," 78% 35/45 [01:32<00:28,  2.86s/it]\u001b[A\n"," 80% 36/45 [01:35<00:25,  2.87s/it]\u001b[A\n"," 82% 37/45 [01:37<00:21,  2.66s/it]\u001b[A\n"," 84% 38/45 [01:40<00:17,  2.49s/it]\u001b[A\n"," 87% 39/45 [01:42<00:14,  2.41s/it]\u001b[A\n"," 89% 40/45 [01:45<00:12,  2.58s/it]\u001b[A\n"," 91% 41/45 [01:47<00:10,  2.53s/it]\u001b[A\n"," 93% 42/45 [01:50<00:07,  2.52s/it]\u001b[A\n"," 96% 43/45 [01:52<00:04,  2.43s/it]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 1.5716054439544678, 'eval_accuracy': 0.6049781157434015, 'eval_runtime': 118.5855, 'eval_samples_per_second': 190.74, 'eval_steps_per_second': 0.379, 'epoch': 11.0}\n","  4% 979/26700 [1:01:50<13:32:01,  1.89s/it]\n","100% 45/45 [01:53<00:00,  1.88s/it]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2841] 2023-09-03 14:54:39,202 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-979\n","[INFO|configuration_utils.py:460] 2023-09-03 14:54:39,208 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-979/config.json\n","[INFO|modeling_utils.py:1992] 2023-09-03 14:54:39,318 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-979/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-03 14:54:39,322 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-979/preprocessor_config.json\n","[INFO|trainer.py:2928] 2023-09-03 14:54:39,550 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-801] due to args.save_total_limit\n","{'loss': 1.1832, 'learning_rate': 0.0009632958801498127, 'epoch': 11.01}\n","{'loss': 1.0782, 'learning_rate': 0.0009629213483146068, 'epoch': 11.12}\n","{'loss': 1.0324, 'learning_rate': 0.0009625468164794008, 'epoch': 11.24}\n","{'loss': 1.1039, 'learning_rate': 0.0009621722846441948, 'epoch': 11.35}\n","{'loss': 1.1254, 'learning_rate': 0.0009617977528089888, 'epoch': 11.46}\n","{'loss': 1.1196, 'learning_rate': 0.0009614232209737828, 'epoch': 11.57}\n","{'loss': 1.1091, 'learning_rate': 0.0009610486891385768, 'epoch': 11.69}\n","{'loss': 1.1093, 'learning_rate': 0.0009606741573033709, 'epoch': 11.8}\n","{'loss': 1.0909, 'learning_rate': 0.0009602996254681649, 'epoch': 11.91}\n","  4% 1067/26700 [1:05:27<13:05:54,  1.84s/it][INFO|trainer.py:3115] 2023-09-03 14:58:16,300 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3117] 2023-09-03 14:58:16,300 >>   Num examples = 22619\n","[INFO|trainer.py:3120] 2023-09-03 14:58:16,300 >>   Batch size = 512\n","\n","  0% 0/45 [00:00<?, ?it/s]\u001b[A\n","  4% 2/45 [00:02<00:53,  1.24s/it]\u001b[A\n","  7% 3/45 [00:05<01:19,  1.88s/it]\u001b[A\n","  9% 4/45 [00:07<01:27,  2.13s/it]\u001b[A\n"," 11% 5/45 [00:10<01:33,  2.34s/it]\u001b[A\n"," 13% 6/45 [00:13<01:39,  2.56s/it]\u001b[A\n"," 16% 7/45 [00:16<01:43,  2.71s/it]\u001b[A\n"," 18% 8/45 [00:19<01:47,  2.90s/it]\u001b[A\n"," 20% 9/45 [00:23<01:48,  3.03s/it]\u001b[A\n"," 22% 10/45 [00:26<01:48,  3.11s/it]\u001b[A\n"," 24% 11/45 [00:28<01:38,  2.89s/it]\u001b[A\n"," 27% 12/45 [00:31<01:32,  2.80s/it]\u001b[A\n"," 29% 13/45 [00:33<01:24,  2.66s/it]\u001b[A\n"," 31% 14/45 [00:36<01:23,  2.68s/it]\u001b[A\n"," 33% 15/45 [00:39<01:18,  2.63s/it]\u001b[A\n"," 36% 16/45 [00:41<01:16,  2.64s/it]\u001b[A\n"," 38% 17/45 [00:44<01:11,  2.54s/it]\u001b[A\n"," 40% 18/45 [00:46<01:04,  2.38s/it]\u001b[A\n"," 42% 19/45 [00:48<01:02,  2.42s/it]\u001b[A\n"," 44% 20/45 [00:51<01:03,  2.53s/it]\u001b[A\n"," 47% 21/45 [00:54<01:02,  2.59s/it]\u001b[A\n"," 49% 22/45 [00:56<00:58,  2.52s/it]\u001b[A\n"," 51% 23/45 [00:58<00:53,  2.42s/it]\u001b[A\n"," 53% 24/45 [01:01<00:53,  2.53s/it]\u001b[A\n"," 56% 25/45 [01:04<00:51,  2.60s/it]\u001b[A\n"," 58% 26/45 [01:06<00:45,  2.41s/it]\u001b[A\n"," 60% 27/45 [01:09<00:47,  2.62s/it]\u001b[A\n"," 62% 28/45 [01:12<00:46,  2.74s/it]\u001b[A\n"," 64% 29/45 [01:14<00:42,  2.63s/it]\u001b[A\n"," 67% 30/45 [01:17<00:39,  2.63s/it]\u001b[A\n"," 69% 31/45 [01:20<00:39,  2.80s/it]\u001b[A\n"," 71% 32/45 [01:23<00:37,  2.89s/it]\u001b[A\n"," 73% 33/45 [01:26<00:34,  2.84s/it]\u001b[A\n"," 76% 34/45 [01:29<00:31,  2.85s/it]\u001b[A\n"," 78% 35/45 [01:32<00:28,  2.85s/it]\u001b[A\n"," 80% 36/45 [01:34<00:25,  2.84s/it]\u001b[A\n"," 82% 37/45 [01:37<00:21,  2.68s/it]\u001b[A\n"," 84% 38/45 [01:39<00:17,  2.50s/it]\u001b[A\n"," 87% 39/45 [01:41<00:14,  2.42s/it]\u001b[A\n"," 89% 40/45 [01:44<00:12,  2.59s/it]\u001b[A\n"," 91% 41/45 [01:46<00:10,  2.52s/it]\u001b[A\n"," 93% 42/45 [01:49<00:07,  2.54s/it]\u001b[A\n"," 96% 43/45 [01:51<00:04,  2.45s/it]\u001b[A\n","                                             \n","\u001b[A{'eval_loss': 1.577445387840271, 'eval_accuracy': 0.5994959989389451, 'eval_runtime': 117.8609, 'eval_samples_per_second': 191.913, 'eval_steps_per_second': 0.382, 'epoch': 12.0}\n","  4% 1068/26700 [1:07:25<13:05:52,  1.84s/it]\n","100% 45/45 [01:52<00:00,  1.90s/it]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2841] 2023-09-03 15:00:14,167 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-1068\n","[INFO|configuration_utils.py:460] 2023-09-03 15:00:14,173 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-1068/config.json\n","[INFO|modeling_utils.py:1992] 2023-09-03 15:00:14,287 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-1068/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-03 15:00:14,291 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-1068/preprocessor_config.json\n","[INFO|trainer.py:2928] 2023-09-03 15:00:14,511 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-890] due to args.save_total_limit\n","{'loss': 1.1056, 'learning_rate': 0.0009599250936329587, 'epoch': 12.02}\n","{'loss': 1.0073, 'learning_rate': 0.0009595505617977528, 'epoch': 12.13}\n","{'loss': 1.0438, 'learning_rate': 0.0009591760299625468, 'epoch': 12.25}\n","{'loss': 1.085, 'learning_rate': 0.0009588014981273408, 'epoch': 12.36}\n","{'loss': 1.0481, 'learning_rate': 0.0009584269662921349, 'epoch': 12.47}\n","{'loss': 1.1081, 'learning_rate': 0.0009580524344569289, 'epoch': 12.58}\n","{'loss': 1.0813, 'learning_rate': 0.0009576779026217228, 'epoch': 12.7}\n","{'loss': 1.1045, 'learning_rate': 0.0009573033707865169, 'epoch': 12.81}\n","{'loss': 1.0971, 'learning_rate': 0.0009569288389513109, 'epoch': 12.92}\n","  4% 1156/26700 [1:11:03<13:28:34,  1.90s/it][INFO|trainer.py:3115] 2023-09-03 15:03:52,380 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3117] 2023-09-03 15:03:52,380 >>   Num examples = 22619\n","[INFO|trainer.py:3120] 2023-09-03 15:03:52,380 >>   Batch size = 512\n","\n","  0% 0/45 [00:00<?, ?it/s]\u001b[A\n","  4% 2/45 [00:02<00:53,  1.25s/it]\u001b[A\n","  7% 3/45 [00:05<01:19,  1.89s/it]\u001b[A\n","  9% 4/45 [00:07<01:27,  2.12s/it]\u001b[A\n"," 11% 5/45 [00:10<01:33,  2.33s/it]\u001b[A\n"," 13% 6/45 [00:13<01:40,  2.57s/it]\u001b[A\n"," 16% 7/45 [00:16<01:43,  2.72s/it]\u001b[A\n"," 18% 8/45 [00:19<01:44,  2.83s/it]\u001b[A\n"," 20% 9/45 [00:22<01:47,  2.98s/it]\u001b[A\n"," 22% 10/45 [00:26<01:48,  3.10s/it]\u001b[A\n"," 24% 11/45 [00:28<01:37,  2.88s/it]\u001b[A\n"," 27% 12/45 [00:31<01:32,  2.80s/it]\u001b[A\n"," 29% 13/45 [00:33<01:24,  2.65s/it]\u001b[A\n"," 31% 14/45 [00:36<01:23,  2.70s/it]\u001b[A\n"," 33% 15/45 [00:39<01:19,  2.65s/it]\u001b[A\n"," 36% 16/45 [00:41<01:16,  2.65s/it]\u001b[A\n"," 38% 17/45 [00:43<01:11,  2.55s/it]\u001b[A\n"," 40% 18/45 [00:46<01:04,  2.39s/it]\u001b[A\n"," 42% 19/45 [00:48<01:03,  2.43s/it]\u001b[A\n"," 44% 20/45 [00:51<01:03,  2.54s/it]\u001b[A\n"," 47% 21/45 [00:53<01:01,  2.57s/it]\u001b[A\n"," 49% 22/45 [00:56<00:57,  2.52s/it]\u001b[A\n"," 51% 23/45 [00:58<00:53,  2.41s/it]\u001b[A\n"," 53% 24/45 [01:01<00:53,  2.54s/it]\u001b[A\n"," 56% 25/45 [01:04<00:52,  2.60s/it]\u001b[A\n"," 58% 26/45 [01:06<00:46,  2.45s/it]\u001b[A\n"," 60% 27/45 [01:09<00:47,  2.65s/it]\u001b[A\n"," 62% 28/45 [01:12<00:46,  2.76s/it]\u001b[A\n"," 64% 29/45 [01:14<00:42,  2.65s/it]\u001b[A\n"," 67% 30/45 [01:17<00:39,  2.64s/it]\u001b[A\n"," 69% 31/45 [01:20<00:40,  2.88s/it]\u001b[A\n"," 71% 32/45 [01:23<00:38,  2.96s/it]\u001b[A\n"," 73% 33/45 [01:26<00:34,  2.89s/it]\u001b[A\n"," 76% 34/45 [01:29<00:31,  2.89s/it]\u001b[A\n"," 78% 35/45 [01:32<00:28,  2.88s/it]\u001b[A\n"," 80% 36/45 [01:35<00:25,  2.87s/it]\u001b[A\n"," 82% 37/45 [01:37<00:21,  2.68s/it]\u001b[A\n"," 84% 38/45 [01:39<00:17,  2.52s/it]\u001b[A\n"," 87% 39/45 [01:41<00:14,  2.42s/it]\u001b[A\n"," 89% 40/45 [01:44<00:12,  2.59s/it]\u001b[A\n"," 91% 41/45 [01:47<00:10,  2.52s/it]\u001b[A\n"," 93% 42/45 [01:49<00:07,  2.49s/it]\u001b[A\n"," 96% 43/45 [01:51<00:04,  2.43s/it]\u001b[A\n","                                             \n","\u001b[A{'eval_loss': 1.5697352886199951, 'eval_accuracy': 0.6120960254653167, 'eval_runtime': 118.2252, 'eval_samples_per_second': 191.321, 'eval_steps_per_second': 0.381, 'epoch': 13.0}\n","  4% 1157/26700 [1:13:01<13:28:32,  1.90s/it]\n","100% 45/45 [01:52<00:00,  1.89s/it]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2841] 2023-09-03 15:05:50,611 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-1157\n","[INFO|configuration_utils.py:460] 2023-09-03 15:05:50,617 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-1157/config.json\n","[INFO|modeling_utils.py:1992] 2023-09-03 15:05:50,730 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-1157/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-03 15:05:50,734 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-1157/preprocessor_config.json\n","[INFO|trainer.py:2928] 2023-09-03 15:05:50,971 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-979] due to args.save_total_limit\n","{'loss': 1.1249, 'learning_rate': 0.0009565543071161049, 'epoch': 13.03}\n","{'loss': 0.9836, 'learning_rate': 0.000956179775280899, 'epoch': 13.15}\n","{'loss': 0.9837, 'learning_rate': 0.0009558052434456929, 'epoch': 13.26}\n","{'loss': 1.009, 'learning_rate': 0.0009554307116104869, 'epoch': 13.37}\n","{'loss': 1.0163, 'learning_rate': 0.000955056179775281, 'epoch': 13.48}\n","{'loss': 1.0621, 'learning_rate': 0.0009546816479400749, 'epoch': 13.6}\n","{'loss': 1.0492, 'learning_rate': 0.0009543071161048689, 'epoch': 13.71}\n","{'loss': 1.0059, 'learning_rate': 0.0009539325842696629, 'epoch': 13.82}\n","{'loss': 1.0554, 'learning_rate': 0.0009535580524344569, 'epoch': 13.93}\n","  5% 1245/26700 [1:16:40<13:09:30,  1.86s/it][INFO|trainer.py:3115] 2023-09-03 15:09:29,451 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3117] 2023-09-03 15:09:29,451 >>   Num examples = 22619\n","[INFO|trainer.py:3120] 2023-09-03 15:09:29,451 >>   Batch size = 512\n","\n","  0% 0/45 [00:00<?, ?it/s]\u001b[A\n","  4% 2/45 [00:02<00:53,  1.25s/it]\u001b[A\n","  7% 3/45 [00:05<01:19,  1.89s/it]\u001b[A\n","  9% 4/45 [00:07<01:28,  2.15s/it]\u001b[A\n"," 11% 5/45 [00:10<01:33,  2.33s/it]\u001b[A\n"," 13% 6/45 [00:13<01:40,  2.57s/it]\u001b[A\n"," 16% 7/45 [00:16<01:43,  2.72s/it]\u001b[A\n"," 18% 8/45 [00:19<01:44,  2.83s/it]\u001b[A\n"," 20% 9/45 [00:22<01:47,  2.97s/it]\u001b[A\n"," 22% 10/45 [00:26<01:49,  3.12s/it]\u001b[A\n"," 24% 11/45 [00:28<01:38,  2.89s/it]\u001b[A\n"," 27% 12/45 [00:31<01:32,  2.81s/it]\u001b[A\n"," 29% 13/45 [00:33<01:25,  2.67s/it]\u001b[A\n"," 31% 14/45 [00:36<01:23,  2.71s/it]\u001b[A\n"," 33% 15/45 [00:39<01:19,  2.66s/it]\u001b[A\n"," 36% 16/45 [00:41<01:17,  2.67s/it]\u001b[A\n"," 38% 17/45 [00:44<01:12,  2.57s/it]\u001b[A\n"," 40% 18/45 [00:46<01:05,  2.41s/it]\u001b[A\n"," 42% 19/45 [00:48<01:03,  2.44s/it]\u001b[A\n"," 44% 20/45 [00:51<01:04,  2.56s/it]\u001b[A\n"," 47% 21/45 [00:54<01:02,  2.59s/it]\u001b[A\n"," 49% 22/45 [00:56<00:58,  2.52s/it]\u001b[A\n"," 51% 23/45 [00:58<00:53,  2.41s/it]\u001b[A\n"," 53% 24/45 [01:01<00:53,  2.54s/it]\u001b[A\n"," 56% 25/45 [01:04<00:52,  2.61s/it]\u001b[A\n"," 58% 26/45 [01:06<00:46,  2.42s/it]\u001b[A\n"," 60% 27/45 [01:09<00:47,  2.63s/it]\u001b[A\n"," 62% 28/45 [01:12<00:46,  2.76s/it]\u001b[A\n"," 64% 29/45 [01:14<00:42,  2.65s/it]\u001b[A\n"," 67% 30/45 [01:17<00:39,  2.65s/it]\u001b[A\n"," 69% 31/45 [01:20<00:39,  2.82s/it]\u001b[A\n"," 71% 32/45 [01:23<00:37,  2.92s/it]\u001b[A\n"," 73% 33/45 [01:26<00:34,  2.86s/it]\u001b[A\n"," 76% 34/45 [01:29<00:31,  2.87s/it]\u001b[A\n"," 78% 35/45 [01:32<00:28,  2.87s/it]\u001b[A\n"," 80% 36/45 [01:35<00:25,  2.86s/it]\u001b[A\n"," 82% 37/45 [01:37<00:21,  2.68s/it]\u001b[A\n"," 84% 38/45 [01:39<00:17,  2.53s/it]\u001b[A\n"," 87% 39/45 [01:41<00:14,  2.44s/it]\u001b[A\n"," 89% 40/45 [01:44<00:13,  2.61s/it]\u001b[A\n"," 91% 41/45 [01:47<00:10,  2.53s/it]\u001b[A\n"," 93% 42/45 [01:49<00:07,  2.51s/it]\u001b[A\n"," 96% 43/45 [01:52<00:04,  2.46s/it]\u001b[A\n","                                             \n","\u001b[A{'eval_loss': 1.5750385522842407, 'eval_accuracy': 0.6103276006896856, 'eval_runtime': 118.4599, 'eval_samples_per_second': 190.942, 'eval_steps_per_second': 0.38, 'epoch': 14.0}\n","  5% 1246/26700 [1:18:39<13:09:28,  1.86s/it]\n","100% 45/45 [01:52<00:00,  1.91s/it]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2841] 2023-09-03 15:11:27,918 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-1246\n","[INFO|configuration_utils.py:460] 2023-09-03 15:11:27,925 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-1246/config.json\n","[INFO|modeling_utils.py:1992] 2023-09-03 15:11:28,043 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-1246/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-03 15:11:28,047 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-1246/preprocessor_config.json\n","[INFO|trainer.py:2928] 2023-09-03 15:11:28,288 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-1068] due to args.save_total_limit\n","{'loss': 1.0159, 'learning_rate': 0.0009531835205992509, 'epoch': 14.04}\n","{'loss': 0.9298, 'learning_rate': 0.000952808988764045, 'epoch': 14.16}\n","{'loss': 1.0042, 'learning_rate': 0.000952434456928839, 'epoch': 14.27}\n","{'loss': 0.9468, 'learning_rate': 0.0009520599250936329, 'epoch': 14.38}\n","{'loss': 0.9749, 'learning_rate': 0.000951685393258427, 'epoch': 14.49}\n","{'loss': 0.9679, 'learning_rate': 0.000951310861423221, 'epoch': 14.61}\n","{'loss': 1.0194, 'learning_rate': 0.000950936329588015, 'epoch': 14.72}\n","{'loss': 1.0296, 'learning_rate': 0.0009505617977528091, 'epoch': 14.83}\n","{'loss': 1.0548, 'learning_rate': 0.000950187265917603, 'epoch': 14.94}\n","  5% 1334/26700 [1:22:17<12:51:44,  1.83s/it][INFO|trainer.py:3115] 2023-09-03 15:15:05,982 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3117] 2023-09-03 15:15:05,982 >>   Num examples = 22619\n","[INFO|trainer.py:3120] 2023-09-03 15:15:05,982 >>   Batch size = 512\n","\n","  0% 0/45 [00:00<?, ?it/s]\u001b[A\n","  4% 2/45 [00:02<00:53,  1.24s/it]\u001b[A\n","  7% 3/45 [00:05<01:19,  1.88s/it]\u001b[A\n","  9% 4/45 [00:07<01:27,  2.14s/it]\u001b[A\n"," 11% 5/45 [00:10<01:33,  2.34s/it]\u001b[A\n"," 13% 6/45 [00:13<01:40,  2.57s/it]\u001b[A\n"," 16% 7/45 [00:16<01:42,  2.71s/it]\u001b[A\n"," 18% 8/45 [00:19<01:44,  2.82s/it]\u001b[A\n"," 20% 9/45 [00:22<01:46,  2.97s/it]\u001b[A\n"," 22% 10/45 [00:26<01:48,  3.10s/it]\u001b[A\n"," 24% 11/45 [00:28<01:37,  2.88s/it]\u001b[A\n"," 27% 12/45 [00:31<01:32,  2.81s/it]\u001b[A\n"," 29% 13/45 [00:33<01:25,  2.66s/it]\u001b[A\n"," 31% 14/45 [00:36<01:23,  2.70s/it]\u001b[A\n"," 33% 15/45 [00:38<01:19,  2.64s/it]\u001b[A\n"," 36% 16/45 [00:41<01:16,  2.64s/it]\u001b[A\n"," 38% 17/45 [00:43<01:11,  2.55s/it]\u001b[A\n"," 40% 18/45 [00:45<01:04,  2.40s/it]\u001b[A\n"," 42% 19/45 [00:48<01:03,  2.43s/it]\u001b[A\n"," 44% 20/45 [00:51<01:04,  2.58s/it]\u001b[A\n"," 47% 21/45 [00:54<01:03,  2.64s/it]\u001b[A\n"," 49% 22/45 [00:56<00:58,  2.56s/it]\u001b[A\n"," 51% 23/45 [00:58<00:53,  2.44s/it]\u001b[A\n"," 53% 24/45 [01:01<00:53,  2.56s/it]\u001b[A\n"," 56% 25/45 [01:04<00:52,  2.63s/it]\u001b[A\n"," 58% 26/45 [01:06<00:46,  2.44s/it]\u001b[A\n"," 60% 27/45 [01:09<00:47,  2.66s/it]\u001b[A\n"," 62% 28/45 [01:12<00:47,  2.77s/it]\u001b[A\n"," 64% 29/45 [01:15<00:42,  2.66s/it]\u001b[A\n"," 67% 30/45 [01:17<00:40,  2.67s/it]\u001b[A\n"," 69% 31/45 [01:20<00:39,  2.82s/it]\u001b[A\n"," 71% 32/45 [01:24<00:37,  2.92s/it]\u001b[A\n"," 73% 33/45 [01:26<00:34,  2.86s/it]\u001b[A\n"," 76% 34/45 [01:29<00:31,  2.87s/it]\u001b[A\n"," 78% 35/45 [01:32<00:28,  2.87s/it]\u001b[A\n"," 80% 36/45 [01:35<00:25,  2.86s/it]\u001b[A\n"," 82% 37/45 [01:37<00:21,  2.68s/it]\u001b[A\n"," 84% 38/45 [01:39<00:17,  2.53s/it]\u001b[A\n"," 87% 39/45 [01:42<00:14,  2.44s/it]\u001b[A\n"," 89% 40/45 [01:44<00:13,  2.60s/it]\u001b[A\n"," 91% 41/45 [01:47<00:10,  2.54s/it]\u001b[A\n"," 93% 42/45 [01:49<00:07,  2.53s/it]\u001b[A\n"," 96% 43/45 [01:52<00:04,  2.48s/it]\u001b[A\n","                                             \n","\u001b[A{'eval_loss': 1.5219348669052124, 'eval_accuracy': 0.6297802732216279, 'eval_runtime': 118.5865, 'eval_samples_per_second': 190.738, 'eval_steps_per_second': 0.379, 'epoch': 15.0}\n","  5% 1335/26700 [1:24:15<12:51:42,  1.83s/it]\n","100% 45/45 [01:53<00:00,  1.91s/it]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2841] 2023-09-03 15:17:04,573 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-1335\n","[INFO|configuration_utils.py:460] 2023-09-03 15:17:04,579 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-1335/config.json\n","[INFO|modeling_utils.py:1992] 2023-09-03 15:17:04,698 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-1335/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-03 15:17:04,702 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-1335/preprocessor_config.json\n","[INFO|trainer.py:2928] 2023-09-03 15:17:04,925 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-712] due to args.save_total_limit\n","{'loss': 0.9807, 'learning_rate': 0.0009498127340823969, 'epoch': 15.06}\n","{'loss': 0.9181, 'learning_rate': 0.000949438202247191, 'epoch': 15.17}\n","{'loss': 0.9275, 'learning_rate': 0.000949063670411985, 'epoch': 15.28}\n","{'loss': 0.9352, 'learning_rate': 0.000948689138576779, 'epoch': 15.39}\n","{'loss': 0.9734, 'learning_rate': 0.0009483146067415731, 'epoch': 15.51}\n","{'loss': 0.9511, 'learning_rate': 0.000947940074906367, 'epoch': 15.62}\n","{'loss': 0.9667, 'learning_rate': 0.0009475655430711611, 'epoch': 15.73}\n","{'loss': 0.9552, 'learning_rate': 0.0009471910112359551, 'epoch': 15.84}\n","{'loss': 0.9868, 'learning_rate': 0.0009468164794007491, 'epoch': 15.96}\n","  5% 1423/26700 [1:27:54<13:13:47,  1.88s/it][INFO|trainer.py:3115] 2023-09-03 15:20:42,940 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3117] 2023-09-03 15:20:42,940 >>   Num examples = 22619\n","[INFO|trainer.py:3120] 2023-09-03 15:20:42,940 >>   Batch size = 512\n","\n","  0% 0/45 [00:00<?, ?it/s]\u001b[A\n","  4% 2/45 [00:02<00:53,  1.25s/it]\u001b[A\n","  7% 3/45 [00:05<01:19,  1.89s/it]\u001b[A\n","  9% 4/45 [00:07<01:27,  2.14s/it]\u001b[A\n"," 11% 5/45 [00:10<01:33,  2.35s/it]\u001b[A\n"," 13% 6/45 [00:13<01:40,  2.59s/it]\u001b[A\n"," 16% 7/45 [00:16<01:43,  2.73s/it]\u001b[A\n"," 18% 8/45 [00:19<01:44,  2.83s/it]\u001b[A\n"," 20% 9/45 [00:22<01:46,  2.96s/it]\u001b[A\n"," 22% 10/45 [00:26<01:47,  3.08s/it]\u001b[A\n"," 24% 11/45 [00:28<01:37,  2.86s/it]\u001b[A\n"," 27% 12/45 [00:31<01:31,  2.79s/it]\u001b[A\n"," 29% 13/45 [00:33<01:24,  2.64s/it]\u001b[A\n"," 31% 14/45 [00:36<01:22,  2.68s/it]\u001b[A\n"," 33% 15/45 [00:38<01:19,  2.64s/it]\u001b[A\n"," 36% 16/45 [00:41<01:16,  2.65s/it]\u001b[A\n"," 38% 17/45 [00:43<01:11,  2.55s/it]\u001b[A\n"," 40% 18/45 [00:45<01:04,  2.39s/it]\u001b[A\n"," 42% 19/45 [00:48<01:03,  2.42s/it]\u001b[A\n"," 44% 20/45 [00:51<01:04,  2.57s/it]\u001b[A\n"," 47% 21/45 [00:54<01:03,  2.63s/it]\u001b[A\n"," 49% 22/45 [00:56<00:58,  2.56s/it]\u001b[A\n"," 51% 23/45 [00:58<00:53,  2.44s/it]\u001b[A\n"," 53% 24/45 [01:01<00:53,  2.57s/it]\u001b[A\n"," 56% 25/45 [01:04<00:52,  2.62s/it]\u001b[A\n"," 58% 26/45 [01:06<00:46,  2.44s/it]\u001b[A\n"," 60% 27/45 [01:09<00:47,  2.66s/it]\u001b[A\n"," 62% 28/45 [01:12<00:46,  2.76s/it]\u001b[A\n"," 64% 29/45 [01:14<00:42,  2.65s/it]\u001b[A\n"," 67% 30/45 [01:17<00:39,  2.65s/it]\u001b[A\n"," 69% 31/45 [01:20<00:39,  2.81s/it]\u001b[A\n"," 71% 32/45 [01:24<00:38,  3.00s/it]\u001b[A\n"," 73% 33/45 [01:26<00:34,  2.92s/it]\u001b[A\n"," 76% 34/45 [01:29<00:31,  2.90s/it]\u001b[A\n"," 78% 35/45 [01:32<00:28,  2.88s/it]\u001b[A\n"," 80% 36/45 [01:35<00:25,  2.87s/it]\u001b[A\n"," 82% 37/45 [01:37<00:21,  2.68s/it]\u001b[A\n"," 84% 38/45 [01:39<00:17,  2.51s/it]\u001b[A\n"," 87% 39/45 [01:42<00:14,  2.42s/it]\u001b[A\n"," 89% 40/45 [01:45<00:13,  2.60s/it]\u001b[A\n"," 91% 41/45 [01:47<00:10,  2.53s/it]\u001b[A\n"," 93% 42/45 [01:49<00:07,  2.51s/it]\u001b[A\n"," 96% 43/45 [01:52<00:04,  2.42s/it]\u001b[A\n","                                             \n","\u001b[A{'eval_loss': 1.5801711082458496, 'eval_accuracy': 0.6225739422609311, 'eval_runtime': 118.3755, 'eval_samples_per_second': 191.078, 'eval_steps_per_second': 0.38, 'epoch': 16.0}\n","  5% 1424/26700 [1:29:52<13:13:46,  1.88s/it]\n","100% 45/45 [01:52<00:00,  1.88s/it]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2841] 2023-09-03 15:22:41,320 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-1424\n","[INFO|configuration_utils.py:460] 2023-09-03 15:22:41,326 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-1424/config.json\n","[INFO|modeling_utils.py:1992] 2023-09-03 15:22:41,439 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-1424/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-03 15:22:41,443 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-1424/preprocessor_config.json\n","[INFO|trainer.py:2928] 2023-09-03 15:22:41,667 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-1157] due to args.save_total_limit\n","{'loss': 0.9444, 'learning_rate': 0.0009464419475655432, 'epoch': 16.07}\n","{'loss': 0.881, 'learning_rate': 0.0009460674157303371, 'epoch': 16.18}\n","{'loss': 0.9098, 'learning_rate': 0.0009456928838951311, 'epoch': 16.29}\n","{'loss': 0.9329, 'learning_rate': 0.0009453183520599252, 'epoch': 16.4}\n","{'loss': 0.8861, 'learning_rate': 0.0009449438202247192, 'epoch': 16.52}\n","{'loss': 0.9459, 'learning_rate': 0.0009445692883895131, 'epoch': 16.63}\n","{'loss': 0.965, 'learning_rate': 0.0009441947565543071, 'epoch': 16.74}\n","{'loss': 0.9301, 'learning_rate': 0.0009438202247191011, 'epoch': 16.85}\n","{'loss': 0.9636, 'learning_rate': 0.0009434456928838951, 'epoch': 16.97}\n","  6% 1512/26700 [1:33:29<13:13:09,  1.89s/it][INFO|trainer.py:3115] 2023-09-03 15:26:18,737 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3117] 2023-09-03 15:26:18,738 >>   Num examples = 22619\n","[INFO|trainer.py:3120] 2023-09-03 15:26:18,738 >>   Batch size = 512\n","\n","  0% 0/45 [00:00<?, ?it/s]\u001b[A\n","  4% 2/45 [00:02<00:53,  1.25s/it]\u001b[A\n","  7% 3/45 [00:05<01:19,  1.89s/it]\u001b[A\n","  9% 4/45 [00:07<01:27,  2.13s/it]\u001b[A\n"," 11% 5/45 [00:10<01:32,  2.32s/it]\u001b[A\n"," 13% 6/45 [00:13<01:39,  2.56s/it]\u001b[A\n"," 16% 7/45 [00:16<01:43,  2.72s/it]\u001b[A\n"," 18% 8/45 [00:19<01:44,  2.83s/it]\u001b[A\n"," 20% 9/45 [00:22<01:46,  2.96s/it]\u001b[A\n"," 22% 10/45 [00:26<01:48,  3.10s/it]\u001b[A\n"," 24% 11/45 [00:28<01:37,  2.88s/it]\u001b[A\n"," 27% 12/45 [00:31<01:34,  2.87s/it]\u001b[A\n"," 29% 13/45 [00:33<01:26,  2.71s/it]\u001b[A\n"," 31% 14/45 [00:36<01:24,  2.73s/it]\u001b[A\n"," 33% 15/45 [00:39<01:20,  2.67s/it]\u001b[A\n"," 36% 16/45 [00:42<01:18,  2.71s/it]\u001b[A\n"," 38% 17/45 [00:44<01:12,  2.59s/it]\u001b[A\n"," 40% 18/45 [00:46<01:05,  2.42s/it]\u001b[A\n"," 42% 19/45 [00:48<01:03,  2.45s/it]\u001b[A\n"," 44% 20/45 [00:51<01:04,  2.57s/it]\u001b[A\n"," 47% 21/45 [00:54<01:03,  2.66s/it]\u001b[A\n"," 49% 22/45 [00:56<00:59,  2.58s/it]\u001b[A\n"," 51% 23/45 [00:59<00:53,  2.45s/it]\u001b[A\n"," 53% 24/45 [01:01<00:54,  2.57s/it]\u001b[A\n"," 56% 25/45 [01:04<00:52,  2.63s/it]\u001b[A\n"," 58% 26/45 [01:06<00:46,  2.43s/it]\u001b[A\n"," 60% 27/45 [01:09<00:47,  2.63s/it]\u001b[A\n"," 62% 28/45 [01:12<00:46,  2.75s/it]\u001b[A\n"," 64% 29/45 [01:15<00:42,  2.65s/it]\u001b[A\n"," 67% 30/45 [01:17<00:39,  2.65s/it]\u001b[A\n"," 69% 31/45 [01:21<00:39,  2.80s/it]\u001b[A\n"," 71% 32/45 [01:24<00:37,  2.90s/it]\u001b[A\n"," 73% 33/45 [01:26<00:34,  2.85s/it]\u001b[A\n"," 76% 34/45 [01:29<00:31,  2.85s/it]\u001b[A\n"," 78% 35/45 [01:32<00:28,  2.85s/it]\u001b[A\n"," 80% 36/45 [01:35<00:25,  2.86s/it]\u001b[A\n"," 82% 37/45 [01:37<00:21,  2.66s/it]\u001b[A\n"," 84% 38/45 [01:39<00:17,  2.52s/it]\u001b[A\n"," 87% 39/45 [01:42<00:14,  2.43s/it]\u001b[A\n"," 89% 40/45 [01:45<00:12,  2.59s/it]\u001b[A\n"," 91% 41/45 [01:47<00:10,  2.52s/it]\u001b[A\n"," 93% 42/45 [01:49<00:07,  2.49s/it]\u001b[A\n"," 96% 43/45 [01:52<00:04,  2.42s/it]\u001b[A\n","                                             \n","\u001b[A{'eval_loss': 1.523610234260559, 'eval_accuracy': 0.630929749325788, 'eval_runtime': 118.4463, 'eval_samples_per_second': 190.964, 'eval_steps_per_second': 0.38, 'epoch': 17.0}\n","  6% 1513/26700 [1:35:28<13:13:07,  1.89s/it]\n","100% 45/45 [01:52<00:00,  1.87s/it]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2841] 2023-09-03 15:28:17,190 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-1513\n","[INFO|configuration_utils.py:460] 2023-09-03 15:28:17,196 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-1513/config.json\n","[INFO|modeling_utils.py:1992] 2023-09-03 15:28:17,312 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-1513/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-03 15:28:17,316 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-1513/preprocessor_config.json\n","[INFO|trainer.py:2928] 2023-09-03 15:28:17,566 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-1246] due to args.save_total_limit\n","{'loss': 0.8507, 'learning_rate': 0.0009430711610486892, 'epoch': 17.08}\n","{'loss': 0.8373, 'learning_rate': 0.0009426966292134832, 'epoch': 17.19}\n","{'loss': 0.8771, 'learning_rate': 0.0009423220973782771, 'epoch': 17.3}\n","{'loss': 0.8742, 'learning_rate': 0.0009419475655430712, 'epoch': 17.42}\n","{'loss': 0.8711, 'learning_rate': 0.0009415730337078652, 'epoch': 17.53}\n","{'loss': 0.8951, 'learning_rate': 0.0009411985018726592, 'epoch': 17.64}\n","{'loss': 0.935, 'learning_rate': 0.0009408239700374533, 'epoch': 17.75}\n","{'loss': 0.9097, 'learning_rate': 0.0009404494382022473, 'epoch': 17.87}\n","{'loss': 0.9314, 'learning_rate': 0.0009400749063670412, 'epoch': 17.98}\n","  6% 1601/26700 [1:39:05<12:53:27,  1.85s/it][INFO|trainer.py:3115] 2023-09-03 15:31:54,660 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3117] 2023-09-03 15:31:54,660 >>   Num examples = 22619\n","[INFO|trainer.py:3120] 2023-09-03 15:31:54,661 >>   Batch size = 512\n","\n","  0% 0/45 [00:00<?, ?it/s]\u001b[A\n","  4% 2/45 [00:02<00:53,  1.24s/it]\u001b[A\n","  7% 3/45 [00:05<01:19,  1.90s/it]\u001b[A\n","  9% 4/45 [00:07<01:26,  2.12s/it]\u001b[A\n"," 11% 5/45 [00:10<01:32,  2.30s/it]\u001b[A\n"," 13% 6/45 [00:13<01:40,  2.57s/it]\u001b[A\n"," 16% 7/45 [00:16<01:43,  2.71s/it]\u001b[A\n"," 18% 8/45 [00:19<01:44,  2.82s/it]\u001b[A\n"," 20% 9/45 [00:22<01:45,  2.94s/it]\u001b[A\n"," 22% 10/45 [00:26<01:47,  3.07s/it]\u001b[A\n"," 24% 11/45 [00:28<01:37,  2.87s/it]\u001b[A\n"," 27% 12/45 [00:31<01:32,  2.80s/it]\u001b[A\n"," 29% 13/45 [00:33<01:24,  2.65s/it]\u001b[A\n"," 31% 14/45 [00:36<01:23,  2.68s/it]\u001b[A\n"," 33% 15/45 [00:39<01:20,  2.70s/it]\u001b[A\n"," 36% 16/45 [00:41<01:18,  2.70s/it]\u001b[A\n"," 38% 17/45 [00:44<01:12,  2.59s/it]\u001b[A\n"," 40% 18/45 [00:46<01:05,  2.42s/it]\u001b[A\n"," 42% 19/45 [00:48<01:03,  2.44s/it]\u001b[A\n"," 44% 20/45 [00:51<01:03,  2.54s/it]\u001b[A\n"," 47% 21/45 [00:53<01:01,  2.57s/it]\u001b[A\n"," 49% 22/45 [00:56<00:58,  2.52s/it]\u001b[A\n"," 51% 23/45 [00:58<00:53,  2.41s/it]\u001b[A\n"," 53% 24/45 [01:01<00:53,  2.54s/it]\u001b[A\n"," 56% 25/45 [01:04<00:52,  2.61s/it]\u001b[A\n"," 58% 26/45 [01:06<00:45,  2.40s/it]\u001b[A\n"," 60% 27/45 [01:09<00:46,  2.60s/it]\u001b[A\n"," 62% 28/45 [01:12<00:46,  2.73s/it]\u001b[A\n"," 64% 29/45 [01:14<00:42,  2.63s/it]\u001b[A\n"," 67% 30/45 [01:17<00:39,  2.64s/it]\u001b[A\n"," 69% 31/45 [01:20<00:39,  2.80s/it]\u001b[A\n"," 71% 32/45 [01:23<00:37,  2.92s/it]\u001b[A\n"," 73% 33/45 [01:26<00:34,  2.91s/it]\u001b[A\n"," 76% 34/45 [01:29<00:31,  2.90s/it]\u001b[A\n"," 78% 35/45 [01:32<00:28,  2.89s/it]\u001b[A\n"," 80% 36/45 [01:34<00:25,  2.85s/it]\u001b[A\n"," 82% 37/45 [01:37<00:21,  2.65s/it]\u001b[A\n"," 84% 38/45 [01:39<00:17,  2.51s/it]\u001b[A\n"," 87% 39/45 [01:41<00:14,  2.44s/it]\u001b[A\n"," 89% 40/45 [01:44<00:13,  2.62s/it]\u001b[A\n"," 91% 41/45 [01:47<00:10,  2.54s/it]\u001b[A\n"," 93% 42/45 [01:49<00:07,  2.50s/it]\u001b[A\n"," 96% 43/45 [01:51<00:04,  2.42s/it]\u001b[A\n","                                             \n","\u001b[A{'eval_loss': 1.581723690032959, 'eval_accuracy': 0.6295150095052832, 'eval_runtime': 117.9828, 'eval_samples_per_second': 191.714, 'eval_steps_per_second': 0.381, 'epoch': 18.0}\n","  6% 1602/26700 [1:41:03<12:53:25,  1.85s/it]\n","100% 45/45 [01:52<00:00,  1.87s/it]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2841] 2023-09-03 15:33:52,650 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-1602\n","[INFO|configuration_utils.py:460] 2023-09-03 15:33:52,657 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-1602/config.json\n","[INFO|modeling_utils.py:1992] 2023-09-03 15:33:52,765 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-1602/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-03 15:33:52,769 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-1602/preprocessor_config.json\n","[INFO|trainer.py:2928] 2023-09-03 15:33:52,995 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-1424] due to args.save_total_limit\n","{'loss': 0.818, 'learning_rate': 0.0009397003745318353, 'epoch': 18.09}\n","{'loss': 0.8123, 'learning_rate': 0.0009393258426966292, 'epoch': 18.2}\n","{'loss': 0.8519, 'learning_rate': 0.0009389513108614232, 'epoch': 18.31}\n","{'loss': 0.8292, 'learning_rate': 0.0009385767790262173, 'epoch': 18.43}\n","{'loss': 0.8832, 'learning_rate': 0.0009382022471910112, 'epoch': 18.54}\n","{'loss': 0.8842, 'learning_rate': 0.0009378277153558052, 'epoch': 18.65}\n","{'loss': 0.8884, 'learning_rate': 0.0009374531835205993, 'epoch': 18.76}\n","{'loss': 0.9082, 'learning_rate': 0.0009370786516853933, 'epoch': 18.88}\n","{'loss': 0.9189, 'learning_rate': 0.0009367041198501873, 'epoch': 18.99}\n","  6% 1690/26700 [1:44:42<12:33:49,  1.81s/it][INFO|trainer.py:3115] 2023-09-03 15:37:30,816 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3117] 2023-09-03 15:37:30,817 >>   Num examples = 22619\n","[INFO|trainer.py:3120] 2023-09-03 15:37:30,817 >>   Batch size = 512\n","\n","  0% 0/45 [00:00<?, ?it/s]\u001b[A\n","  4% 2/45 [00:02<00:53,  1.24s/it]\u001b[A\n","  7% 3/45 [00:05<01:18,  1.88s/it]\u001b[A\n","  9% 4/45 [00:07<01:26,  2.10s/it]\u001b[A\n"," 11% 5/45 [00:10<01:31,  2.28s/it]\u001b[A\n"," 13% 6/45 [00:13<01:40,  2.58s/it]\u001b[A\n"," 16% 7/45 [00:16<01:43,  2.72s/it]\u001b[A\n"," 18% 8/45 [00:19<01:44,  2.83s/it]\u001b[A\n"," 20% 9/45 [00:22<01:46,  2.95s/it]\u001b[A\n"," 22% 10/45 [00:26<01:48,  3.09s/it]\u001b[A\n"," 24% 11/45 [00:28<01:38,  2.90s/it]\u001b[A\n"," 27% 12/45 [00:31<01:32,  2.81s/it]\u001b[A\n"," 29% 13/45 [00:33<01:25,  2.66s/it]\u001b[A\n"," 31% 14/45 [00:36<01:23,  2.68s/it]\u001b[A\n"," 33% 15/45 [00:39<01:20,  2.69s/it]\u001b[A\n"," 36% 16/45 [00:41<01:18,  2.72s/it]\u001b[A\n"," 38% 17/45 [00:44<01:12,  2.60s/it]\u001b[A\n"," 40% 18/45 [00:46<01:05,  2.43s/it]\u001b[A\n"," 42% 19/45 [00:48<01:03,  2.45s/it]\u001b[A\n"," 44% 20/45 [00:51<01:03,  2.54s/it]\u001b[A\n"," 47% 21/45 [00:54<01:02,  2.61s/it]\u001b[A\n"," 49% 22/45 [00:56<01:01,  2.66s/it]\u001b[A\n"," 51% 23/45 [00:59<00:55,  2.51s/it]\u001b[A\n"," 53% 24/45 [01:01<00:54,  2.60s/it]\u001b[A\n"," 56% 25/45 [01:04<00:53,  2.66s/it]\u001b[A\n"," 58% 26/45 [01:06<00:46,  2.43s/it]\u001b[A\n"," 60% 27/45 [01:09<00:47,  2.65s/it]\u001b[A\n"," 62% 28/45 [01:12<00:47,  2.79s/it]\u001b[A\n"," 64% 29/45 [01:15<00:42,  2.67s/it]\u001b[A\n"," 67% 30/45 [01:17<00:39,  2.66s/it]\u001b[A\n"," 69% 31/45 [01:21<00:39,  2.81s/it]\u001b[A\n"," 71% 32/45 [01:24<00:37,  2.89s/it]\u001b[A\n"," 73% 33/45 [01:26<00:34,  2.86s/it]\u001b[A\n"," 76% 34/45 [01:29<00:31,  2.86s/it]\u001b[A\n"," 78% 35/45 [01:32<00:28,  2.86s/it]\u001b[A\n"," 80% 36/45 [01:35<00:25,  2.83s/it]\u001b[A\n"," 82% 37/45 [01:37<00:21,  2.66s/it]\u001b[A\n"," 84% 38/45 [01:39<00:17,  2.52s/it]\u001b[A\n"," 87% 39/45 [01:42<00:14,  2.44s/it]\u001b[A\n"," 89% 40/45 [01:45<00:12,  2.60s/it]\u001b[A\n"," 91% 41/45 [01:47<00:10,  2.53s/it]\u001b[A\n"," 93% 42/45 [01:49<00:07,  2.49s/it]\u001b[A\n"," 96% 43/45 [01:52<00:04,  2.46s/it]\u001b[A\n","                                             \n","\u001b[A{'eval_loss': 1.5806957483291626, 'eval_accuracy': 0.6282771121623414, 'eval_runtime': 118.665, 'eval_samples_per_second': 190.612, 'eval_steps_per_second': 0.379, 'epoch': 19.0}\n","  6% 1691/26700 [1:46:40<12:33:47,  1.81s/it]\n","100% 45/45 [01:53<00:00,  1.90s/it]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2841] 2023-09-03 15:39:29,501 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-1691\n","[INFO|configuration_utils.py:460] 2023-09-03 15:39:29,509 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-1691/config.json\n","[INFO|modeling_utils.py:1992] 2023-09-03 15:39:29,620 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-1691/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-03 15:39:29,624 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-1691/preprocessor_config.json\n","[INFO|trainer.py:2928] 2023-09-03 15:39:29,844 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-1513] due to args.save_total_limit\n","{'loss': 0.8496, 'learning_rate': 0.0009363295880149813, 'epoch': 19.1}\n","{'loss': 0.8055, 'learning_rate': 0.0009359550561797753, 'epoch': 19.21}\n","{'loss': 0.7925, 'learning_rate': 0.0009355805243445693, 'epoch': 19.33}\n","{'loss': 0.8394, 'learning_rate': 0.0009352059925093634, 'epoch': 19.44}\n","{'loss': 0.8682, 'learning_rate': 0.0009348314606741574, 'epoch': 19.55}\n","{'loss': 0.8299, 'learning_rate': 0.0009344569288389512, 'epoch': 19.66}\n","{'loss': 0.8783, 'learning_rate': 0.0009340823970037453, 'epoch': 19.78}\n","{'loss': 0.8544, 'learning_rate': 0.0009337078651685393, 'epoch': 19.89}\n","{'loss': 0.8989, 'learning_rate': 0.0009333333333333333, 'epoch': 20.0}\n","  7% 1780/26700 [1:50:18<13:03:39,  1.89s/it][INFO|trainer.py:3115] 2023-09-03 15:43:07,588 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3117] 2023-09-03 15:43:07,588 >>   Num examples = 22619\n","[INFO|trainer.py:3120] 2023-09-03 15:43:07,588 >>   Batch size = 512\n","\n","  0% 0/45 [00:00<?, ?it/s]\u001b[A\n","  4% 2/45 [00:02<00:54,  1.26s/it]\u001b[A\n","  7% 3/45 [00:05<01:23,  1.99s/it]\u001b[A\n","  9% 4/45 [00:08<01:29,  2.18s/it]\u001b[A\n"," 11% 5/45 [00:10<01:33,  2.34s/it]\u001b[A\n"," 13% 6/45 [00:13<01:40,  2.57s/it]\u001b[A\n"," 16% 7/45 [00:16<01:43,  2.73s/it]\u001b[A\n"," 18% 8/45 [00:19<01:45,  2.86s/it]\u001b[A\n"," 20% 9/45 [00:23<01:47,  2.98s/it]\u001b[A\n"," 22% 10/45 [00:26<01:48,  3.09s/it]\u001b[A\n"," 24% 11/45 [00:28<01:37,  2.88s/it]\u001b[A\n"," 27% 12/45 [00:31<01:33,  2.83s/it]\u001b[A\n"," 29% 13/45 [00:34<01:26,  2.71s/it]\u001b[A\n"," 31% 14/45 [00:36<01:24,  2.73s/it]\u001b[A\n"," 33% 15/45 [00:39<01:19,  2.64s/it]\u001b[A\n"," 36% 16/45 [00:41<01:16,  2.64s/it]\u001b[A\n"," 38% 17/45 [00:44<01:11,  2.54s/it]\u001b[A\n"," 40% 18/45 [00:46<01:04,  2.40s/it]\u001b[A\n"," 42% 19/45 [00:48<01:03,  2.45s/it]\u001b[A\n"," 44% 20/45 [00:51<01:03,  2.54s/it]\u001b[A\n"," 47% 21/45 [00:54<01:01,  2.56s/it]\u001b[A\n"," 49% 22/45 [00:56<00:57,  2.50s/it]\u001b[A\n"," 51% 23/45 [00:58<00:53,  2.41s/it]\u001b[A\n"," 53% 24/45 [01:01<00:54,  2.59s/it]\u001b[A\n"," 56% 25/45 [01:04<00:52,  2.64s/it]\u001b[A\n"," 58% 26/45 [01:06<00:46,  2.43s/it]\u001b[A\n"," 60% 27/45 [01:09<00:46,  2.61s/it]\u001b[A\n"," 62% 28/45 [01:12<00:46,  2.73s/it]\u001b[A\n"," 64% 29/45 [01:14<00:42,  2.65s/it]\u001b[A\n"," 67% 30/45 [01:17<00:39,  2.66s/it]\u001b[A\n"," 69% 31/45 [01:20<00:39,  2.81s/it]\u001b[A\n"," 71% 32/45 [01:23<00:37,  2.89s/it]\u001b[A\n"," 73% 33/45 [01:26<00:34,  2.84s/it]\u001b[A\n"," 76% 34/45 [01:29<00:31,  2.87s/it]\u001b[A\n"," 78% 35/45 [01:32<00:28,  2.88s/it]\u001b[A\n"," 80% 36/45 [01:35<00:25,  2.85s/it]\u001b[A\n"," 82% 37/45 [01:37<00:21,  2.64s/it]\u001b[A\n"," 84% 38/45 [01:39<00:17,  2.48s/it]\u001b[A\n"," 87% 39/45 [01:41<00:14,  2.44s/it]\u001b[A\n"," 89% 40/45 [01:45<00:13,  2.73s/it]\u001b[A\n"," 91% 41/45 [01:47<00:10,  2.62s/it]\u001b[A\n"," 93% 42/45 [01:50<00:07,  2.56s/it]\u001b[A\n"," 96% 43/45 [01:52<00:04,  2.45s/it]\u001b[A\n","                                             \n","\u001b[A{'eval_loss': 1.5458524227142334, 'eval_accuracy': 0.6403908218754145, 'eval_runtime': 118.448, 'eval_samples_per_second': 190.961, 'eval_steps_per_second': 0.38, 'epoch': 20.0}\n","  7% 1780/26700 [1:52:17<13:03:39,  1.89s/it]\n","100% 45/45 [01:52<00:00,  1.89s/it]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2841] 2023-09-03 15:45:06,041 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-1780\n","[INFO|configuration_utils.py:460] 2023-09-03 15:45:06,046 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-1780/config.json\n","[INFO|modeling_utils.py:1992] 2023-09-03 15:45:06,156 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-1780/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-03 15:45:06,160 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-1780/preprocessor_config.json\n","[INFO|trainer.py:2928] 2023-09-03 15:45:06,393 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-1602] due to args.save_total_limit\n","{'loss': 0.772, 'learning_rate': 0.0009329588014981274, 'epoch': 20.11}\n","{'loss': 0.755, 'learning_rate': 0.0009325842696629213, 'epoch': 20.22}\n","{'loss': 0.7703, 'learning_rate': 0.0009322097378277153, 'epoch': 20.34}\n","{'loss': 0.7915, 'learning_rate': 0.0009318352059925094, 'epoch': 20.45}\n","{'loss': 0.8087, 'learning_rate': 0.0009314606741573034, 'epoch': 20.56}\n","{'loss': 0.872, 'learning_rate': 0.0009310861423220974, 'epoch': 20.67}\n","{'loss': 0.8628, 'learning_rate': 0.0009307116104868915, 'epoch': 20.79}\n","{'loss': 0.8882, 'learning_rate': 0.0009303370786516854, 'epoch': 20.9}\n","  7% 1868/26700 [1:55:54<12:34:19,  1.82s/it][INFO|trainer.py:3115] 2023-09-03 15:48:42,970 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3117] 2023-09-03 15:48:42,971 >>   Num examples = 22619\n","[INFO|trainer.py:3120] 2023-09-03 15:48:42,971 >>   Batch size = 512\n","\n","  0% 0/45 [00:00<?, ?it/s]\u001b[A\n","  4% 2/45 [00:02<00:53,  1.24s/it]\u001b[A\n","  7% 3/45 [00:05<01:19,  1.88s/it]\u001b[A\n","  9% 4/45 [00:07<01:27,  2.14s/it]\u001b[A\n"," 11% 5/45 [00:10<01:32,  2.31s/it]\u001b[A\n"," 13% 6/45 [00:13<01:39,  2.54s/it]\u001b[A\n"," 16% 7/45 [00:16<01:42,  2.69s/it]\u001b[A\n"," 18% 8/45 [00:19<01:44,  2.82s/it]\u001b[A\n"," 20% 9/45 [00:22<01:47,  2.98s/it]\u001b[A\n"," 22% 10/45 [00:26<01:47,  3.08s/it]\u001b[A\n"," 24% 11/45 [00:28<01:37,  2.87s/it]\u001b[A\n"," 27% 12/45 [00:31<01:32,  2.79s/it]\u001b[A\n"," 29% 13/45 [00:33<01:24,  2.64s/it]\u001b[A\n"," 31% 14/45 [00:36<01:23,  2.69s/it]\u001b[A\n"," 33% 15/45 [00:38<01:20,  2.69s/it]\u001b[A\n"," 36% 16/45 [00:41<01:17,  2.67s/it]\u001b[A\n"," 38% 17/45 [00:43<01:11,  2.57s/it]\u001b[A\n"," 40% 18/45 [00:45<01:04,  2.40s/it]\u001b[A\n"," 42% 19/45 [00:48<01:03,  2.44s/it]\u001b[A\n"," 44% 20/45 [00:51<01:03,  2.55s/it]\u001b[A\n"," 47% 21/45 [00:53<01:01,  2.56s/it]\u001b[A\n"," 49% 22/45 [00:56<00:57,  2.50s/it]\u001b[A\n"," 51% 23/45 [00:58<00:52,  2.40s/it]\u001b[A\n"," 53% 24/45 [01:01<00:53,  2.53s/it]\u001b[A\n"," 56% 25/45 [01:04<00:52,  2.61s/it]\u001b[A\n"," 58% 26/45 [01:06<00:46,  2.44s/it]\u001b[A\n"," 60% 27/45 [01:09<00:47,  2.62s/it]\u001b[A\n"," 62% 28/45 [01:12<00:46,  2.73s/it]\u001b[A\n"," 64% 29/45 [01:14<00:42,  2.63s/it]\u001b[A\n"," 67% 30/45 [01:17<00:39,  2.65s/it]\u001b[A\n"," 69% 31/45 [01:20<00:39,  2.84s/it]\u001b[A\n"," 71% 32/45 [01:23<00:37,  2.90s/it]\u001b[A\n"," 73% 33/45 [01:26<00:34,  2.84s/it]\u001b[A\n"," 76% 34/45 [01:29<00:31,  2.84s/it]\u001b[A\n"," 78% 35/45 [01:32<00:28,  2.87s/it]\u001b[A\n"," 80% 36/45 [01:34<00:25,  2.87s/it]\u001b[A\n"," 82% 37/45 [01:37<00:21,  2.65s/it]\u001b[A\n"," 84% 38/45 [01:39<00:17,  2.48s/it]\u001b[A\n"," 87% 39/45 [01:41<00:14,  2.40s/it]\u001b[A\n"," 89% 40/45 [01:44<00:12,  2.58s/it]\u001b[A\n"," 91% 41/45 [01:46<00:10,  2.53s/it]\u001b[A\n"," 93% 42/45 [01:49<00:07,  2.51s/it]\u001b[A\n"," 96% 43/45 [01:51<00:04,  2.41s/it]\u001b[A\n","                                             \n","\u001b[A{'eval_loss': 1.5463865995407104, 'eval_accuracy': 0.6347760732127857, 'eval_runtime': 117.5552, 'eval_samples_per_second': 192.412, 'eval_steps_per_second': 0.383, 'epoch': 21.0}\n","  7% 1869/26700 [1:57:51<12:34:18,  1.82s/it]\n","100% 45/45 [01:52<00:00,  1.86s/it]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2841] 2023-09-03 15:50:40,532 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-1869\n","[INFO|configuration_utils.py:460] 2023-09-03 15:50:40,538 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-1869/config.json\n","[INFO|modeling_utils.py:1992] 2023-09-03 15:50:40,652 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-1869/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-03 15:50:40,657 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-1869/preprocessor_config.json\n","[INFO|trainer.py:2928] 2023-09-03 15:50:40,873 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-1691] due to args.save_total_limit\n","{'loss': 0.8194, 'learning_rate': 0.0009299625468164794, 'epoch': 21.01}\n","{'loss': 0.7544, 'learning_rate': 0.0009295880149812735, 'epoch': 21.12}\n","{'loss': 0.753, 'learning_rate': 0.0009292134831460674, 'epoch': 21.24}\n","{'loss': 0.7466, 'learning_rate': 0.0009288389513108614, 'epoch': 21.35}\n","{'loss': 0.8175, 'learning_rate': 0.0009284644194756554, 'epoch': 21.46}\n","{'loss': 0.8146, 'learning_rate': 0.0009280898876404494, 'epoch': 21.57}\n","{'loss': 0.7953, 'learning_rate': 0.0009277153558052434, 'epoch': 21.69}\n","{'loss': 0.8272, 'learning_rate': 0.0009273408239700375, 'epoch': 21.8}\n","{'loss': 0.8084, 'learning_rate': 0.0009269662921348315, 'epoch': 21.91}\n","  7% 1957/26700 [2:01:29<12:14:23,  1.78s/it][INFO|trainer.py:3115] 2023-09-03 15:54:18,162 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3117] 2023-09-03 15:54:18,163 >>   Num examples = 22619\n","[INFO|trainer.py:3120] 2023-09-03 15:54:18,163 >>   Batch size = 512\n","\n","  0% 0/45 [00:00<?, ?it/s]\u001b[A\n","  4% 2/45 [00:02<00:53,  1.25s/it]\u001b[A\n","  7% 3/45 [00:05<01:19,  1.90s/it]\u001b[A\n","  9% 4/45 [00:07<01:26,  2.12s/it]\u001b[A\n"," 11% 5/45 [00:10<01:31,  2.29s/it]\u001b[A\n"," 13% 6/45 [00:13<01:39,  2.56s/it]\u001b[A\n"," 16% 7/45 [00:16<01:42,  2.70s/it]\u001b[A\n"," 18% 8/45 [00:19<01:44,  2.82s/it]\u001b[A\n"," 20% 9/45 [00:22<01:46,  2.95s/it]\u001b[A\n"," 22% 10/45 [00:26<01:47,  3.08s/it]\u001b[A\n"," 24% 11/45 [00:28<01:38,  2.89s/it]\u001b[A\n"," 27% 12/45 [00:31<01:32,  2.81s/it]\u001b[A\n"," 29% 13/45 [00:33<01:25,  2.66s/it]\u001b[A\n"," 31% 14/45 [00:36<01:23,  2.68s/it]\u001b[A\n"," 33% 15/45 [00:38<01:18,  2.62s/it]\u001b[A\n"," 36% 16/45 [00:41<01:16,  2.65s/it]\u001b[A\n"," 38% 17/45 [00:43<01:11,  2.56s/it]\u001b[A\n"," 40% 18/45 [00:45<01:04,  2.39s/it]\u001b[A\n"," 42% 19/45 [00:48<01:02,  2.42s/it]\u001b[A\n"," 44% 20/45 [00:51<01:03,  2.53s/it]\u001b[A\n"," 47% 21/45 [00:53<01:01,  2.55s/it]\u001b[A\n"," 49% 22/45 [00:56<00:57,  2.52s/it]\u001b[A\n"," 51% 23/45 [00:58<00:53,  2.41s/it]\u001b[A\n"," 53% 24/45 [01:01<00:53,  2.54s/it]\u001b[A\n"," 56% 25/45 [01:03<00:51,  2.60s/it]\u001b[A\n"," 58% 26/45 [01:05<00:45,  2.39s/it]\u001b[A\n"," 60% 27/45 [01:09<00:47,  2.64s/it]\u001b[A\n"," 62% 28/45 [01:12<00:46,  2.75s/it]\u001b[A\n"," 64% 29/45 [01:14<00:42,  2.64s/it]\u001b[A\n"," 67% 30/45 [01:17<00:39,  2.64s/it]\u001b[A\n"," 69% 31/45 [01:20<00:38,  2.78s/it]\u001b[A\n"," 71% 32/45 [01:23<00:37,  2.89s/it]\u001b[A\n"," 73% 33/45 [01:26<00:34,  2.83s/it]\u001b[A\n"," 76% 34/45 [01:28<00:31,  2.83s/it]\u001b[A\n"," 78% 35/45 [01:31<00:28,  2.84s/it]\u001b[A\n"," 80% 36/45 [01:34<00:25,  2.83s/it]\u001b[A\n"," 82% 37/45 [01:36<00:21,  2.70s/it]\u001b[A\n"," 84% 38/45 [01:39<00:17,  2.54s/it]\u001b[A\n"," 87% 39/45 [01:41<00:14,  2.44s/it]\u001b[A\n"," 89% 40/45 [01:44<00:13,  2.60s/it]\u001b[A\n"," 91% 41/45 [01:46<00:10,  2.53s/it]\u001b[A\n"," 93% 42/45 [01:49<00:07,  2.51s/it]\u001b[A\n"," 96% 43/45 [01:51<00:05,  2.50s/it]\u001b[A\n","                                             \n","\u001b[A{'eval_loss': 1.6527200937271118, 'eval_accuracy': 0.6244749988947346, 'eval_runtime': 117.8698, 'eval_samples_per_second': 191.898, 'eval_steps_per_second': 0.382, 'epoch': 22.0}\n","  7% 1958/26700 [2:03:27<12:14:21,  1.78s/it]\n","100% 45/45 [01:52<00:00,  1.93s/it]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2841] 2023-09-03 15:56:16,039 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-1958\n","[INFO|configuration_utils.py:460] 2023-09-03 15:56:16,044 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-1958/config.json\n","[INFO|modeling_utils.py:1992] 2023-09-03 15:56:16,163 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-1958/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-03 15:56:16,167 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-1958/preprocessor_config.json\n","[INFO|trainer.py:2928] 2023-09-03 15:56:16,385 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-1780] due to args.save_total_limit\n","{'loss': 0.8153, 'learning_rate': 0.0009265917602996254, 'epoch': 22.02}\n","{'loss': 0.7212, 'learning_rate': 0.0009262172284644195, 'epoch': 22.13}\n","{'loss': 0.7792, 'learning_rate': 0.0009258426966292135, 'epoch': 22.25}\n","{'loss': 0.772, 'learning_rate': 0.0009254681647940076, 'epoch': 22.36}\n","{'loss': 0.7596, 'learning_rate': 0.0009250936329588016, 'epoch': 22.47}\n","{'loss': 0.7815, 'learning_rate': 0.0009247191011235955, 'epoch': 22.58}\n","{'loss': 0.7821, 'learning_rate': 0.0009243445692883896, 'epoch': 22.7}\n","{'loss': 0.7747, 'learning_rate': 0.0009239700374531835, 'epoch': 22.81}\n","{'loss': 0.823, 'learning_rate': 0.0009235955056179775, 'epoch': 22.92}\n","  8% 2046/26700 [2:07:04<12:23:03,  1.81s/it][INFO|trainer.py:3115] 2023-09-03 15:59:52,945 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3117] 2023-09-03 15:59:52,946 >>   Num examples = 22619\n","[INFO|trainer.py:3120] 2023-09-03 15:59:52,946 >>   Batch size = 512\n","\n","  0% 0/45 [00:00<?, ?it/s]\u001b[A\n","  4% 2/45 [00:02<00:55,  1.28s/it]\u001b[A\n","  7% 3/45 [00:05<01:20,  1.92s/it]\u001b[A\n","  9% 4/45 [00:07<01:27,  2.13s/it]\u001b[A\n"," 11% 5/45 [00:10<01:31,  2.29s/it]\u001b[A\n"," 13% 6/45 [00:13<01:38,  2.53s/it]\u001b[A\n"," 16% 7/45 [00:16<01:42,  2.71s/it]\u001b[A\n"," 18% 8/45 [00:19<01:44,  2.82s/it]\u001b[A\n"," 20% 9/45 [00:22<01:45,  2.94s/it]\u001b[A\n"," 22% 10/45 [00:26<01:49,  3.12s/it]\u001b[A\n"," 24% 11/45 [00:28<01:39,  2.91s/it]\u001b[A\n"," 27% 12/45 [00:31<01:33,  2.85s/it]\u001b[A\n"," 29% 13/45 [00:33<01:26,  2.69s/it]\u001b[A\n"," 31% 14/45 [00:36<01:23,  2.70s/it]\u001b[A\n"," 33% 15/45 [00:38<01:18,  2.62s/it]\u001b[A\n"," 36% 16/45 [00:41<01:16,  2.63s/it]\u001b[A\n"," 38% 17/45 [00:43<01:11,  2.56s/it]\u001b[A\n"," 40% 18/45 [00:46<01:04,  2.41s/it]\u001b[A\n"," 42% 19/45 [00:48<01:03,  2.43s/it]\u001b[A\n"," 44% 20/45 [00:51<01:03,  2.53s/it]\u001b[A\n"," 47% 21/45 [00:53<01:01,  2.54s/it]\u001b[A\n"," 49% 22/45 [00:56<00:57,  2.50s/it]\u001b[A\n"," 51% 23/45 [00:58<00:53,  2.41s/it]\u001b[A\n"," 53% 24/45 [01:01<00:53,  2.54s/it]\u001b[A\n"," 56% 25/45 [01:04<00:52,  2.60s/it]\u001b[A\n"," 58% 26/45 [01:05<00:45,  2.40s/it]\u001b[A\n"," 60% 27/45 [01:09<00:46,  2.58s/it]\u001b[A\n"," 62% 28/45 [01:12<00:47,  2.79s/it]\u001b[A\n"," 64% 29/45 [01:14<00:42,  2.69s/it]\u001b[A\n"," 67% 30/45 [01:17<00:40,  2.67s/it]\u001b[A\n"," 69% 31/45 [01:20<00:39,  2.82s/it]\u001b[A\n"," 71% 32/45 [01:23<00:37,  2.88s/it]\u001b[A\n"," 73% 33/45 [01:26<00:34,  2.84s/it]\u001b[A\n"," 76% 34/45 [01:29<00:31,  2.86s/it]\u001b[A\n"," 78% 35/45 [01:32<00:28,  2.86s/it]\u001b[A\n"," 80% 36/45 [01:34<00:25,  2.83s/it]\u001b[A\n"," 82% 37/45 [01:36<00:21,  2.63s/it]\u001b[A\n"," 84% 38/45 [01:39<00:17,  2.49s/it]\u001b[A\n"," 87% 39/45 [01:41<00:14,  2.42s/it]\u001b[A\n"," 89% 40/45 [01:44<00:12,  2.59s/it]\u001b[A\n"," 91% 41/45 [01:46<00:10,  2.52s/it]\u001b[A\n"," 93% 42/45 [01:49<00:07,  2.48s/it]\u001b[A\n"," 96% 43/45 [01:51<00:04,  2.38s/it]\u001b[A\n","                                             \n","\u001b[A{'eval_loss': 1.6103267669677734, 'eval_accuracy': 0.6402581900172422, 'eval_runtime': 117.5087, 'eval_samples_per_second': 192.488, 'eval_steps_per_second': 0.383, 'epoch': 23.0}\n","  8% 2047/26700 [2:09:01<12:23:01,  1.81s/it]\n","100% 45/45 [01:52<00:00,  1.84s/it]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2841] 2023-09-03 16:01:50,461 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-2047\n","[INFO|configuration_utils.py:460] 2023-09-03 16:01:50,467 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-2047/config.json\n","[INFO|modeling_utils.py:1992] 2023-09-03 16:01:50,578 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-2047/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-03 16:01:50,582 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-2047/preprocessor_config.json\n","[INFO|trainer.py:2928] 2023-09-03 16:01:50,813 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-1869] due to args.save_total_limit\n","{'loss': 0.7374, 'learning_rate': 0.0009232209737827716, 'epoch': 23.03}\n","{'loss': 0.7033, 'learning_rate': 0.0009228464419475655, 'epoch': 23.15}\n","{'loss': 0.7407, 'learning_rate': 0.0009224719101123595, 'epoch': 23.26}\n","{'loss': 0.7522, 'learning_rate': 0.0009220973782771536, 'epoch': 23.37}\n","{'loss': 0.7417, 'learning_rate': 0.0009217228464419476, 'epoch': 23.48}\n","{'loss': 0.7526, 'learning_rate': 0.0009213483146067416, 'epoch': 23.6}\n","{'loss': 0.7775, 'learning_rate': 0.0009209737827715357, 'epoch': 23.71}\n","{'loss': 0.793, 'learning_rate': 0.0009205992509363296, 'epoch': 23.82}\n","{'loss': 0.774, 'learning_rate': 0.0009202247191011236, 'epoch': 23.93}\n","  8% 2135/26700 [2:12:39<12:48:09,  1.88s/it][INFO|trainer.py:3115] 2023-09-03 16:05:28,287 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3117] 2023-09-03 16:05:28,288 >>   Num examples = 22619\n","[INFO|trainer.py:3120] 2023-09-03 16:05:28,288 >>   Batch size = 512\n","\n","  0% 0/45 [00:00<?, ?it/s]\u001b[A\n","  4% 2/45 [00:02<00:53,  1.25s/it]\u001b[A\n","  7% 3/45 [00:05<01:25,  2.04s/it]\u001b[A\n","  9% 4/45 [00:08<01:30,  2.21s/it]\u001b[A\n"," 11% 5/45 [00:10<01:33,  2.34s/it]\u001b[A\n"," 13% 6/45 [00:13<01:40,  2.58s/it]\u001b[A\n"," 16% 7/45 [00:16<01:43,  2.72s/it]\u001b[A\n"," 18% 8/45 [00:19<01:45,  2.85s/it]\u001b[A\n"," 20% 9/45 [00:23<01:46,  2.97s/it]\u001b[A\n"," 22% 10/45 [00:26<01:47,  3.07s/it]\u001b[A\n"," 24% 11/45 [00:28<01:37,  2.85s/it]\u001b[A\n"," 27% 12/45 [00:31<01:32,  2.79s/it]\u001b[A\n"," 29% 13/45 [00:33<01:26,  2.70s/it]\u001b[A\n"," 31% 14/45 [00:36<01:24,  2.71s/it]\u001b[A\n"," 33% 15/45 [00:39<01:19,  2.63s/it]\u001b[A\n"," 36% 16/45 [00:41<01:16,  2.64s/it]\u001b[A\n"," 38% 17/45 [00:44<01:11,  2.55s/it]\u001b[A\n"," 40% 18/45 [00:46<01:04,  2.40s/it]\u001b[A\n"," 42% 19/45 [00:48<01:04,  2.46s/it]\u001b[A\n"," 44% 20/45 [00:51<01:03,  2.56s/it]\u001b[A\n"," 47% 21/45 [00:54<01:01,  2.58s/it]\u001b[A\n"," 49% 22/45 [00:56<00:57,  2.52s/it]\u001b[A\n"," 51% 23/45 [00:58<00:53,  2.41s/it]\u001b[A\n"," 53% 24/45 [01:01<00:53,  2.56s/it]\u001b[A\n"," 56% 25/45 [01:04<00:53,  2.66s/it]\u001b[A\n"," 58% 26/45 [01:06<00:46,  2.43s/it]\u001b[A\n"," 60% 27/45 [01:09<00:46,  2.61s/it]\u001b[A\n"," 62% 28/45 [01:12<00:46,  2.73s/it]\u001b[A\n"," 64% 29/45 [01:14<00:42,  2.63s/it]\u001b[A\n"," 67% 30/45 [01:17<00:39,  2.67s/it]\u001b[A\n"," 69% 31/45 [01:20<00:39,  2.81s/it]\u001b[A\n"," 71% 32/45 [01:23<00:37,  2.87s/it]\u001b[A\n"," 73% 33/45 [01:26<00:33,  2.83s/it]\u001b[A\n"," 76% 34/45 [01:29<00:32,  2.93s/it]\u001b[A\n"," 78% 35/45 [01:32<00:29,  2.97s/it]\u001b[A\n"," 80% 36/45 [01:35<00:26,  2.91s/it]\u001b[A\n"," 82% 37/45 [01:37<00:21,  2.69s/it]\u001b[A\n"," 84% 38/45 [01:39<00:17,  2.51s/it]\u001b[A\n"," 87% 39/45 [01:42<00:14,  2.43s/it]\u001b[A\n"," 89% 40/45 [01:45<00:13,  2.63s/it]\u001b[A\n"," 91% 41/45 [01:47<00:10,  2.55s/it]\u001b[A\n"," 93% 42/45 [01:49<00:07,  2.51s/it]\u001b[A\n"," 96% 43/45 [01:52<00:04,  2.42s/it]\u001b[A\n","                                             \n","\u001b[A{'eval_loss': 1.6488823890686035, 'eval_accuracy': 0.6360139705557275, 'eval_runtime': 118.2869, 'eval_samples_per_second': 191.222, 'eval_steps_per_second': 0.38, 'epoch': 24.0}\n","  8% 2136/26700 [2:14:37<12:48:07,  1.88s/it]\n","100% 45/45 [01:52<00:00,  1.87s/it]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2841] 2023-09-03 16:07:26,581 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-2136\n","[INFO|configuration_utils.py:460] 2023-09-03 16:07:26,586 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-2136/config.json\n","[INFO|modeling_utils.py:1992] 2023-09-03 16:07:26,696 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-2136/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-03 16:07:26,700 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-2136/preprocessor_config.json\n","[INFO|trainer.py:2928] 2023-09-03 16:07:26,914 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-1958] due to args.save_total_limit\n","{'loss': 0.8058, 'learning_rate': 0.0009198501872659177, 'epoch': 24.04}\n","{'loss': 0.6948, 'learning_rate': 0.0009194756554307117, 'epoch': 24.16}\n","{'loss': 0.7312, 'learning_rate': 0.0009191011235955057, 'epoch': 24.27}\n","{'loss': 0.7208, 'learning_rate': 0.0009187265917602996, 'epoch': 24.38}\n","{'loss': 0.7486, 'learning_rate': 0.0009183520599250936, 'epoch': 24.49}\n","{'loss': 0.7691, 'learning_rate': 0.0009179775280898876, 'epoch': 24.61}\n","{'loss': 0.7257, 'learning_rate': 0.0009176029962546817, 'epoch': 24.72}\n","{'loss': 0.7424, 'learning_rate': 0.0009172284644194757, 'epoch': 24.83}\n","{'loss': 0.7561, 'learning_rate': 0.0009168539325842696, 'epoch': 24.94}\n","  8% 2224/26700 [2:18:14<12:16:16,  1.80s/it][INFO|trainer.py:3115] 2023-09-03 16:11:03,726 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3117] 2023-09-03 16:11:03,726 >>   Num examples = 22619\n","[INFO|trainer.py:3120] 2023-09-03 16:11:03,727 >>   Batch size = 512\n","\n","  0% 0/45 [00:00<?, ?it/s]\u001b[A\n","  4% 2/45 [00:02<00:53,  1.24s/it]\u001b[A\n","  7% 3/45 [00:05<01:19,  1.89s/it]\u001b[A\n","  9% 4/45 [00:07<01:26,  2.12s/it]\u001b[A\n"," 11% 5/45 [00:10<01:32,  2.31s/it]\u001b[A\n"," 13% 6/45 [00:13<01:39,  2.55s/it]\u001b[A\n"," 16% 7/45 [00:16<01:42,  2.69s/it]\u001b[A\n"," 18% 8/45 [00:19<01:43,  2.80s/it]\u001b[A\n"," 20% 9/45 [00:22<01:46,  2.97s/it]\u001b[A\n"," 22% 10/45 [00:26<01:49,  3.13s/it]\u001b[A\n"," 24% 11/45 [00:28<01:38,  2.90s/it]\u001b[A\n"," 27% 12/45 [00:31<01:32,  2.81s/it]\u001b[A\n"," 29% 13/45 [00:33<01:25,  2.66s/it]\u001b[A\n"," 31% 14/45 [00:36<01:23,  2.69s/it]\u001b[A\n"," 33% 15/45 [00:38<01:19,  2.63s/it]\u001b[A\n"," 36% 16/45 [00:41<01:16,  2.64s/it]\u001b[A\n"," 38% 17/45 [00:43<01:11,  2.54s/it]\u001b[A\n"," 40% 18/45 [00:45<01:04,  2.39s/it]\u001b[A\n"," 42% 19/45 [00:48<01:03,  2.43s/it]\u001b[A\n"," 44% 20/45 [00:51<01:03,  2.53s/it]\u001b[A\n"," 47% 21/45 [00:53<01:02,  2.59s/it]\u001b[A\n"," 49% 22/45 [00:56<00:58,  2.53s/it]\u001b[A\n"," 51% 23/45 [00:58<00:53,  2.42s/it]\u001b[A\n"," 53% 24/45 [01:01<00:53,  2.54s/it]\u001b[A\n"," 56% 25/45 [01:04<00:52,  2.60s/it]\u001b[A\n"," 58% 26/45 [01:06<00:46,  2.44s/it]\u001b[A\n"," 60% 27/45 [01:09<00:47,  2.62s/it]\u001b[A\n"," 62% 28/45 [01:12<00:46,  2.74s/it]\u001b[A\n"," 64% 29/45 [01:14<00:42,  2.64s/it]\u001b[A\n"," 67% 30/45 [01:17<00:39,  2.65s/it]\u001b[A\n"," 69% 31/45 [01:20<00:39,  2.82s/it]\u001b[A\n"," 71% 32/45 [01:23<00:37,  2.89s/it]\u001b[A\n"," 73% 33/45 [01:26<00:34,  2.84s/it]\u001b[A\n"," 76% 34/45 [01:29<00:31,  2.85s/it]\u001b[A\n"," 78% 35/45 [01:31<00:28,  2.85s/it]\u001b[A\n"," 80% 36/45 [01:34<00:25,  2.84s/it]\u001b[A\n"," 82% 37/45 [01:36<00:21,  2.64s/it]\u001b[A\n"," 84% 38/45 [01:39<00:17,  2.47s/it]\u001b[A\n"," 87% 39/45 [01:41<00:14,  2.40s/it]\u001b[A\n"," 89% 40/45 [01:44<00:12,  2.57s/it]\u001b[A\n"," 91% 41/45 [01:46<00:10,  2.51s/it]\u001b[A\n"," 93% 42/45 [01:49<00:07,  2.59s/it]\u001b[A\n"," 96% 43/45 [01:51<00:04,  2.47s/it]\u001b[A\n","                                             \n","\u001b[A{'eval_loss': 1.5452593564987183, 'eval_accuracy': 0.6513108448649365, 'eval_runtime': 117.825, 'eval_samples_per_second': 191.971, 'eval_steps_per_second': 0.382, 'epoch': 25.0}\n","  8% 2225/26700 [2:20:12<12:16:15,  1.80s/it]\n","100% 45/45 [01:52<00:00,  1.90s/it]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2841] 2023-09-03 16:13:01,558 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-2225\n","[INFO|configuration_utils.py:460] 2023-09-03 16:13:01,564 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-2225/config.json\n","[INFO|modeling_utils.py:1992] 2023-09-03 16:13:01,679 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-2225/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-03 16:13:01,683 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-2225/preprocessor_config.json\n","[INFO|trainer.py:2928] 2023-09-03 16:13:01,908 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-2047] due to args.save_total_limit\n","[INFO|trainer.py:1960] 2023-09-03 16:13:01,929 >> \n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","[INFO|trainer.py:2122] 2023-09-03 16:13:01,929 >> Loading best model from drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/checkpoint-1335 (score: 1.5219348669052124).\n","{'train_runtime': 8413.2497, 'train_samples_per_second': 1607.999, 'train_steps_per_second': 3.174, 'train_loss': 1.1956403768732307, 'epoch': 25.0}\n","  8% 2225/26700 [2:20:13<25:42:25,  3.78s/it]\n","[INFO|trainer.py:2841] 2023-09-03 16:13:02,002 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/\n","[INFO|configuration_utils.py:460] 2023-09-03 16:13:02,007 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/config.json\n","[INFO|modeling_utils.py:1992] 2023-09-03 16:13:02,117 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-03 16:13:02,121 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_8/preprocessor_config.json\n","***** train metrics *****\n","  epoch                    =       25.0\n","  train_loss               =     1.1956\n","  train_runtime            = 2:20:13.24\n","  train_samples_per_second =   1607.999\n","  train_steps_per_second   =      3.174\n","[INFO|trainer.py:3115] 2023-09-03 16:13:02,139 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3117] 2023-09-03 16:13:02,140 >>   Num examples = 22619\n","[INFO|trainer.py:3120] 2023-09-03 16:13:02,140 >>   Batch size = 512\n","100% 45/45 [01:52<00:00,  2.50s/it]\n","***** eval metrics *****\n","  epoch                   =       25.0\n","  eval_accuracy           =     0.6298\n","  eval_loss               =     1.5219\n","  eval_runtime            = 0:01:57.92\n","  eval_samples_per_second =    191.801\n","  eval_steps_per_second   =      0.382\n","\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n","\u001b[34m\u001b[1mwandb\u001b[0m:                  eval/accuracy ▁▄▄▅▆▆▆▆▇▇▇▇▇▇▇▇█▇▇██▇███▇\n","\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/loss █▄▄▂▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/runtime ▇▄▃▇▅▃█▅▆▃▇▃▅▆▇▆▆▄▇▆▁▃▁▅▃▃\n","\u001b[34m\u001b[1mwandb\u001b[0m:        eval/samples_per_second ▂▄▆▂▄▆▁▄▃▆▂▆▄▃▂▃▃▅▂▃█▆█▄▆▆\n","\u001b[34m\u001b[1mwandb\u001b[0m:          eval/steps_per_second ▃▅▆▃▅▆▁▃▃▆▁▆▅▃▁▃▃▅▁▃█▆█▃▆▆\n","\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\n","\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\n","\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate ███▇▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss █▆▅▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n","\u001b[34m\u001b[1mwandb\u001b[0m:                  eval/accuracy 0.62978\n","\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/loss 1.52193\n","\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/runtime 117.9294\n","\u001b[34m\u001b[1mwandb\u001b[0m:        eval/samples_per_second 191.801\n","\u001b[34m\u001b[1mwandb\u001b[0m:          eval/steps_per_second 0.382\n","\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch 25.0\n","\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step 2225\n","\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate 0.00092\n","\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss 0.7561\n","\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos 1.1433304180634112e+19\n","\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss 1.19564\n","\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime 8413.2497\n","\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second 1607.999\n","\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second 3.174\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mdark-disco-18\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/u15048366/colabCnnIp102Run1/runs/ljj5bzs6\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n","\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230903_135200-ljj5bzs6/logs\u001b[0m\n"]}],"source":["!python drive/MyDrive/hons-research/script/cnn-run6.py \\\n","    --model_type efficientnet \\\n","    --dataset_name mnist \\\n","    --output_dir drive/MyDrive/hons-research/output/mnist_outputs_6/ \\\n","    --remove_unused_columns False \\\n","    --do_train \\\n","    --do_eval \\\n","    --push_to_hub False \\\n","    --learning_rate 0.001 \\\n","    --num_train_epochs 50 \\\n","    --per_device_train_batch_size 64 \\\n","    --per_device_eval_batch_size 64 \\\n","    --logging_strategy steps \\\n","    --logging_steps 10 \\\n","    --evaluation_strategy epoch \\\n","    --save_strategy epoch \\\n","    --load_best_model_at_end True \\\n","    --save_total_limit 3 \\\n","    --save_steps 500 \\\n","    --data_seed 6 \\\n","    --seed 6\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1693166189326,"user":{"displayName":"Andreas Louw","userId":"11183032721846533402"},"user_tz":-120},"id":"-nDNgY-PFYRZ","outputId":"cbc5f09b-632c-4ed6-c486-a7fd88872f6b"},"outputs":[{"name":"stdout","output_type":"stream","text":["2023-09-03 16:15:15.693283: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mu15048366\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.9\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20230903_161520-2x5u6872\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33meager-darkness-19\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/u15048366/colabCnnIp102Run1\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/u15048366/colabCnnIp102Run1/runs/2x5u6872\u001b[0m\n","09/03/2023 16:15:21 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n","09/03/2023 16:15:21 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n","_n_gpu=1,\n","adafactor=False,\n","adam_beta1=0.9,\n","adam_beta2=0.999,\n","adam_epsilon=1e-08,\n","auto_find_batch_size=False,\n","bf16=False,\n","bf16_full_eval=False,\n","data_seed=9,\n","dataloader_drop_last=False,\n","dataloader_num_workers=0,\n","dataloader_pin_memory=True,\n","ddp_backend=None,\n","ddp_broadcast_buffers=None,\n","ddp_bucket_cap_mb=None,\n","ddp_find_unused_parameters=None,\n","ddp_timeout=1800,\n","debug=[],\n","deepspeed=None,\n","disable_tqdm=False,\n","dispatch_batches=None,\n","do_eval=True,\n","do_predict=False,\n","do_train=True,\n","eval_accumulation_steps=None,\n","eval_delay=0,\n","eval_steps=None,\n","evaluation_strategy=epoch,\n","fp16=False,\n","fp16_backend=auto,\n","fp16_full_eval=False,\n","fp16_opt_level=O1,\n","fsdp=[],\n","fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n","fsdp_min_num_params=0,\n","fsdp_transformer_layer_cls_to_wrap=None,\n","full_determinism=False,\n","gradient_accumulation_steps=1,\n","gradient_checkpointing=False,\n","greater_is_better=False,\n","group_by_length=False,\n","half_precision_backend=auto,\n","hub_always_push=False,\n","hub_model_id=None,\n","hub_private_repo=False,\n","hub_strategy=every_save,\n","hub_token=<HUB_TOKEN>,\n","ignore_data_skip=False,\n","include_inputs_for_metrics=False,\n","jit_mode_eval=False,\n","label_names=None,\n","label_smoothing_factor=0.0,\n","learning_rate=0.001,\n","length_column_name=length,\n","load_best_model_at_end=True,\n","local_rank=0,\n","log_level=passive,\n","log_level_replica=warning,\n","log_on_each_node=True,\n","logging_dir=drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/runs/Sep03_16-15-20_ad494e439e78,\n","logging_first_step=False,\n","logging_nan_inf_filter=True,\n","logging_steps=10,\n","logging_strategy=steps,\n","lr_scheduler_type=linear,\n","max_grad_norm=1.0,\n","max_steps=-1,\n","metric_for_best_model=loss,\n","mp_parameters=,\n","no_cuda=False,\n","num_train_epochs=300.0,\n","optim=adamw_torch,\n","optim_args=None,\n","output_dir=drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/,\n","overwrite_output_dir=False,\n","past_index=-1,\n","per_device_eval_batch_size=512,\n","per_device_train_batch_size=512,\n","prediction_loss_only=False,\n","push_to_hub=False,\n","push_to_hub_model_id=None,\n","push_to_hub_organization=None,\n","push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n","ray_scope=last,\n","remove_unused_columns=False,\n","report_to=['wandb'],\n","resume_from_checkpoint=None,\n","run_name=drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/,\n","save_on_each_node=False,\n","save_safetensors=False,\n","save_steps=500.0,\n","save_strategy=epoch,\n","save_total_limit=3,\n","seed=9,\n","sharded_ddp=[],\n","skip_memory_metrics=True,\n","tf32=None,\n","torch_compile=False,\n","torch_compile_backend=None,\n","torch_compile_mode=None,\n","torchdynamo=None,\n","tpu_metrics_debug=False,\n","tpu_num_cores=None,\n","use_cpu=False,\n","use_ipex=False,\n","use_legacy_prediction_loop=False,\n","use_mps_device=False,\n","warmup_ratio=0.0,\n","warmup_steps=0,\n","weight_decay=0.0,\n",")\n","/usr/local/lib/python3.10/dist-packages/datasets/load.py:2086: FutureWarning: 'task' was deprecated in version 2.13.0 and will be removed in 3.0.0.\n","\n","  warnings.warn(\n","Resolving data files: 100% 45095/45095 [00:00<00:00, 390968.06it/s]\n","Resolving data files: 100% 22619/22619 [00:00<00:00, 174665.50it/s]\n","\n","\n","\n","None\n","\n","\n","\n","[INFO|configuration_utils.py:715] 2023-09-03 16:15:43,298 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--resnet-18/snapshots/f45a6faa12e0381f5620c5c8d7e916bca90f2c44/config.json\n","[INFO|configuration_utils.py:775] 2023-09-03 16:15:43,300 >> Model config ResNetConfig {\n","  \"_name_or_path\": \"microsoft/resnet-18\",\n","  \"architectures\": [\n","    \"ResNetForImageClassification\"\n","  ],\n","  \"depths\": [\n","    2,\n","    2,\n","    2,\n","    2\n","  ],\n","  \"downsample_in_first_stage\": false,\n","  \"embedding_size\": 64,\n","  \"finetuning_task\": \"image-classification\",\n","  \"hidden_act\": \"relu\",\n","  \"hidden_sizes\": [\n","    64,\n","    128,\n","    256,\n","    512\n","  ],\n","  \"id2label\": {\n","    \"0\": \"0\",\n","    \"1\": \"1\",\n","    \"10\": \"16\",\n","    \"100\": \"98\",\n","    \"101\": \"99\",\n","    \"11\": \"17\",\n","    \"12\": \"18\",\n","    \"13\": \"19\",\n","    \"14\": \"2\",\n","    \"15\": \"20\",\n","    \"16\": \"21\",\n","    \"17\": \"22\",\n","    \"18\": \"23\",\n","    \"19\": \"24\",\n","    \"2\": \"10\",\n","    \"20\": \"25\",\n","    \"21\": \"26\",\n","    \"22\": \"27\",\n","    \"23\": \"28\",\n","    \"24\": \"29\",\n","    \"25\": \"3\",\n","    \"26\": \"30\",\n","    \"27\": \"31\",\n","    \"28\": \"32\",\n","    \"29\": \"33\",\n","    \"3\": \"100\",\n","    \"30\": \"34\",\n","    \"31\": \"35\",\n","    \"32\": \"36\",\n","    \"33\": \"37\",\n","    \"34\": \"38\",\n","    \"35\": \"39\",\n","    \"36\": \"4\",\n","    \"37\": \"40\",\n","    \"38\": \"41\",\n","    \"39\": \"42\",\n","    \"4\": \"101\",\n","    \"40\": \"43\",\n","    \"41\": \"44\",\n","    \"42\": \"45\",\n","    \"43\": \"46\",\n","    \"44\": \"47\",\n","    \"45\": \"48\",\n","    \"46\": \"49\",\n","    \"47\": \"5\",\n","    \"48\": \"50\",\n","    \"49\": \"51\",\n","    \"5\": \"11\",\n","    \"50\": \"52\",\n","    \"51\": \"53\",\n","    \"52\": \"54\",\n","    \"53\": \"55\",\n","    \"54\": \"56\",\n","    \"55\": \"57\",\n","    \"56\": \"58\",\n","    \"57\": \"59\",\n","    \"58\": \"6\",\n","    \"59\": \"60\",\n","    \"6\": \"12\",\n","    \"60\": \"61\",\n","    \"61\": \"62\",\n","    \"62\": \"63\",\n","    \"63\": \"64\",\n","    \"64\": \"65\",\n","    \"65\": \"66\",\n","    \"66\": \"67\",\n","    \"67\": \"68\",\n","    \"68\": \"69\",\n","    \"69\": \"7\",\n","    \"7\": \"13\",\n","    \"70\": \"70\",\n","    \"71\": \"71\",\n","    \"72\": \"72\",\n","    \"73\": \"73\",\n","    \"74\": \"74\",\n","    \"75\": \"75\",\n","    \"76\": \"76\",\n","    \"77\": \"77\",\n","    \"78\": \"78\",\n","    \"79\": \"79\",\n","    \"8\": \"14\",\n","    \"80\": \"8\",\n","    \"81\": \"80\",\n","    \"82\": \"81\",\n","    \"83\": \"82\",\n","    \"84\": \"83\",\n","    \"85\": \"84\",\n","    \"86\": \"85\",\n","    \"87\": \"86\",\n","    \"88\": \"87\",\n","    \"89\": \"88\",\n","    \"9\": \"15\",\n","    \"90\": \"89\",\n","    \"91\": \"9\",\n","    \"92\": \"90\",\n","    \"93\": \"91\",\n","    \"94\": \"92\",\n","    \"95\": \"93\",\n","    \"96\": \"94\",\n","    \"97\": \"95\",\n","    \"98\": \"96\",\n","    \"99\": \"97\"\n","  },\n","  \"label2id\": {\n","    \"0\": \"0\",\n","    \"1\": \"1\",\n","    \"10\": \"2\",\n","    \"100\": \"3\",\n","    \"101\": \"4\",\n","    \"11\": \"5\",\n","    \"12\": \"6\",\n","    \"13\": \"7\",\n","    \"14\": \"8\",\n","    \"15\": \"9\",\n","    \"16\": \"10\",\n","    \"17\": \"11\",\n","    \"18\": \"12\",\n","    \"19\": \"13\",\n","    \"2\": \"14\",\n","    \"20\": \"15\",\n","    \"21\": \"16\",\n","    \"22\": \"17\",\n","    \"23\": \"18\",\n","    \"24\": \"19\",\n","    \"25\": \"20\",\n","    \"26\": \"21\",\n","    \"27\": \"22\",\n","    \"28\": \"23\",\n","    \"29\": \"24\",\n","    \"3\": \"25\",\n","    \"30\": \"26\",\n","    \"31\": \"27\",\n","    \"32\": \"28\",\n","    \"33\": \"29\",\n","    \"34\": \"30\",\n","    \"35\": \"31\",\n","    \"36\": \"32\",\n","    \"37\": \"33\",\n","    \"38\": \"34\",\n","    \"39\": \"35\",\n","    \"4\": \"36\",\n","    \"40\": \"37\",\n","    \"41\": \"38\",\n","    \"42\": \"39\",\n","    \"43\": \"40\",\n","    \"44\": \"41\",\n","    \"45\": \"42\",\n","    \"46\": \"43\",\n","    \"47\": \"44\",\n","    \"48\": \"45\",\n","    \"49\": \"46\",\n","    \"5\": \"47\",\n","    \"50\": \"48\",\n","    \"51\": \"49\",\n","    \"52\": \"50\",\n","    \"53\": \"51\",\n","    \"54\": \"52\",\n","    \"55\": \"53\",\n","    \"56\": \"54\",\n","    \"57\": \"55\",\n","    \"58\": \"56\",\n","    \"59\": \"57\",\n","    \"6\": \"58\",\n","    \"60\": \"59\",\n","    \"61\": \"60\",\n","    \"62\": \"61\",\n","    \"63\": \"62\",\n","    \"64\": \"63\",\n","    \"65\": \"64\",\n","    \"66\": \"65\",\n","    \"67\": \"66\",\n","    \"68\": \"67\",\n","    \"69\": \"68\",\n","    \"7\": \"69\",\n","    \"70\": \"70\",\n","    \"71\": \"71\",\n","    \"72\": \"72\",\n","    \"73\": \"73\",\n","    \"74\": \"74\",\n","    \"75\": \"75\",\n","    \"76\": \"76\",\n","    \"77\": \"77\",\n","    \"78\": \"78\",\n","    \"79\": \"79\",\n","    \"8\": \"80\",\n","    \"80\": \"81\",\n","    \"81\": \"82\",\n","    \"82\": \"83\",\n","    \"83\": \"84\",\n","    \"84\": \"85\",\n","    \"85\": \"86\",\n","    \"86\": \"87\",\n","    \"87\": \"88\",\n","    \"88\": \"89\",\n","    \"89\": \"90\",\n","    \"9\": \"91\",\n","    \"90\": \"92\",\n","    \"91\": \"93\",\n","    \"92\": \"94\",\n","    \"93\": \"95\",\n","    \"94\": \"96\",\n","    \"95\": \"97\",\n","    \"96\": \"98\",\n","    \"97\": \"99\",\n","    \"98\": \"100\",\n","    \"99\": \"101\"\n","  },\n","  \"layer_type\": \"basic\",\n","  \"model_type\": \"resnet\",\n","  \"num_channels\": 3,\n","  \"out_features\": [\n","    \"stage4\"\n","  ],\n","  \"out_indices\": [\n","    4\n","  ],\n","  \"stage_names\": [\n","    \"stem\",\n","    \"stage1\",\n","    \"stage2\",\n","    \"stage3\",\n","    \"stage4\"\n","  ],\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.33.0.dev0\"\n","}\n","\n","[INFO|modeling_utils.py:2857] 2023-09-03 16:15:43,303 >> loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--microsoft--resnet-18/snapshots/f45a6faa12e0381f5620c5c8d7e916bca90f2c44/model.safetensors\n","[INFO|modeling_utils.py:3643] 2023-09-03 16:15:43,416 >> All model checkpoint weights were used when initializing ResNetForImageClassification.\n","\n","[WARNING|modeling_utils.py:3664] 2023-09-03 16:15:43,416 >> Some weights of ResNetForImageClassification were not initialized from the model checkpoint at microsoft/resnet-18 and are newly initialized because the shapes did not match:\n","- classifier.1.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([102]) in the model instantiated\n","- classifier.1.weight: found shape torch.Size([1000, 512]) in the checkpoint and torch.Size([102, 512]) in the model instantiated\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","[INFO|image_processing_utils.py:369] 2023-09-03 16:15:43,844 >> loading configuration file preprocessor_config.json from cache at /root/.cache/huggingface/hub/models--microsoft--resnet-18/snapshots/f45a6faa12e0381f5620c5c8d7e916bca90f2c44/preprocessor_config.json\n","[WARNING|image_processing_auto.py:355] 2023-09-03 16:15:43,844 >> Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n","[INFO|image_processing_utils.py:732] 2023-09-03 16:15:43,846 >> size should be a dictionary on of the following set of keys: ({'width', 'height'}, {'shortest_edge'}, {'shortest_edge', 'longest_edge'}, {'longest_edge'}), got 224. Converted to {'shortest_edge': 224}.\n","[INFO|image_processing_utils.py:419] 2023-09-03 16:15:43,846 >> Image processor ConvNextImageProcessor {\n","  \"crop_pct\": 0.875,\n","  \"do_normalize\": true,\n","  \"do_rescale\": true,\n","  \"do_resize\": true,\n","  \"image_mean\": [\n","    0.485,\n","    0.456,\n","    0.406\n","  ],\n","  \"image_processor_type\": \"ConvNextImageProcessor\",\n","  \"image_std\": [\n","    0.229,\n","    0.224,\n","    0.225\n","  ],\n","  \"resample\": 3,\n","  \"rescale_factor\": 0.00392156862745098,\n","  \"size\": {\n","    \"shortest_edge\": 224\n","  }\n","}\n","\n","[INFO|trainer.py:1712] 2023-09-03 16:15:45,703 >> ***** Running training *****\n","[INFO|trainer.py:1713] 2023-09-03 16:15:45,703 >>   Num examples = 45,095\n","[INFO|trainer.py:1714] 2023-09-03 16:15:45,703 >>   Num Epochs = 300\n","[INFO|trainer.py:1715] 2023-09-03 16:15:45,704 >>   Instantaneous batch size per device = 512\n","[INFO|trainer.py:1718] 2023-09-03 16:15:45,704 >>   Total train batch size (w. parallel, distributed & accumulation) = 512\n","[INFO|trainer.py:1719] 2023-09-03 16:15:45,704 >>   Gradient Accumulation steps = 1\n","[INFO|trainer.py:1720] 2023-09-03 16:15:45,704 >>   Total optimization steps = 26,700\n","[INFO|trainer.py:1721] 2023-09-03 16:15:45,704 >>   Number of trainable parameters = 11,228,838\n","[INFO|integration_utils.py:716] 2023-09-03 16:15:45,705 >> Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n","{'loss': 3.657, 'learning_rate': 0.0009996254681647941, 'epoch': 0.11}\n","{'loss': 2.9449, 'learning_rate': 0.000999250936329588, 'epoch': 0.22}\n","{'loss': 2.7003, 'learning_rate': 0.000998876404494382, 'epoch': 0.34}\n","{'loss': 2.5321, 'learning_rate': 0.000998501872659176, 'epoch': 0.45}\n","{'loss': 2.4536, 'learning_rate': 0.00099812734082397, 'epoch': 0.56}\n","{'loss': 2.3636, 'learning_rate': 0.0009977528089887642, 'epoch': 0.67}\n","{'loss': 2.3048, 'learning_rate': 0.000997378277153558, 'epoch': 0.79}\n","{'loss': 2.2189, 'learning_rate': 0.000997003745318352, 'epoch': 0.9}\n","  0% 89/26700 [03:41<9:43:14,  1.32s/it] [INFO|trainer.py:3115] 2023-09-03 16:19:27,393 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3117] 2023-09-03 16:19:27,393 >>   Num examples = 22619\n","[INFO|trainer.py:3120] 2023-09-03 16:19:27,393 >>   Batch size = 512\n","\n","  0% 0/45 [00:00<?, ?it/s]\u001b[A\n","  4% 2/45 [00:02<00:59,  1.38s/it]\u001b[A\n","  7% 3/45 [00:05<01:22,  1.97s/it]\u001b[A\n","  9% 4/45 [00:08<01:28,  2.16s/it]\u001b[A\n"," 11% 5/45 [00:10<01:32,  2.30s/it]\u001b[A\n"," 13% 6/45 [00:13<01:40,  2.57s/it]\u001b[A\n"," 16% 7/45 [00:16<01:43,  2.74s/it]\u001b[A\n"," 18% 8/45 [00:19<01:44,  2.84s/it]\u001b[A\n"," 20% 9/45 [00:23<01:46,  2.95s/it]\u001b[A\n"," 22% 10/45 [00:26<01:46,  3.05s/it]\u001b[A\n"," 24% 11/45 [00:28<01:38,  2.88s/it]\u001b[A\n"," 27% 12/45 [00:31<01:32,  2.81s/it]\u001b[A\n"," 29% 13/45 [00:33<01:25,  2.66s/it]\u001b[A\n"," 31% 14/45 [00:36<01:23,  2.68s/it]\u001b[A\n"," 33% 15/45 [00:38<01:18,  2.61s/it]\u001b[A\n"," 36% 16/45 [00:41<01:16,  2.64s/it]\u001b[A\n"," 38% 17/45 [00:44<01:12,  2.58s/it]\u001b[A\n"," 40% 18/45 [00:46<01:05,  2.41s/it]\u001b[A\n"," 42% 19/45 [00:48<01:03,  2.43s/it]\u001b[A\n"," 44% 20/45 [00:51<01:03,  2.53s/it]\u001b[A\n"," 47% 21/45 [00:53<01:01,  2.54s/it]\u001b[A\n"," 49% 22/45 [00:56<00:57,  2.51s/it]\u001b[A\n"," 51% 23/45 [00:58<00:53,  2.44s/it]\u001b[A\n"," 53% 24/45 [01:01<00:53,  2.56s/it]\u001b[A\n"," 56% 25/45 [01:04<00:52,  2.62s/it]\u001b[A\n"," 58% 26/45 [01:06<00:45,  2.41s/it]\u001b[A\n"," 60% 27/45 [01:09<00:46,  2.60s/it]\u001b[A\n"," 62% 28/45 [01:12<00:46,  2.75s/it]\u001b[A\n"," 64% 29/45 [01:14<00:42,  2.64s/it]\u001b[A\n"," 67% 30/45 [01:17<00:39,  2.64s/it]\u001b[A\n"," 69% 31/45 [01:20<00:39,  2.80s/it]\u001b[A\n"," 71% 32/45 [01:23<00:37,  2.88s/it]\u001b[A\n"," 73% 33/45 [01:26<00:34,  2.87s/it]\u001b[A\n"," 76% 34/45 [01:29<00:31,  2.86s/it]\u001b[A\n"," 78% 35/45 [01:32<00:28,  2.86s/it]\u001b[A\n"," 80% 36/45 [01:34<00:25,  2.84s/it]\u001b[A\n"," 82% 37/45 [01:37<00:21,  2.66s/it]\u001b[A\n"," 84% 38/45 [01:39<00:17,  2.50s/it]\u001b[A\n"," 87% 39/45 [01:41<00:14,  2.44s/it]\u001b[A\n"," 89% 40/45 [01:44<00:13,  2.60s/it]\u001b[A\n"," 91% 41/45 [01:46<00:10,  2.53s/it]\u001b[A\n"," 93% 42/45 [01:49<00:07,  2.49s/it]\u001b[A\n"," 96% 43/45 [01:51<00:04,  2.41s/it]\u001b[A\n","                                        \n","\u001b[A{'eval_loss': 2.5028560161590576, 'eval_accuracy': 0.38335028073743316, 'eval_runtime': 117.8132, 'eval_samples_per_second': 191.99, 'eval_steps_per_second': 0.382, 'epoch': 1.0}\n","  0% 89/26700 [05:39<9:43:14,  1.32s/it]\n","100% 45/45 [01:52<00:00,  1.86s/it]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2841] 2023-09-03 16:21:25,213 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-89\n","[INFO|configuration_utils.py:460] 2023-09-03 16:21:25,218 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-89/config.json\n","[INFO|modeling_utils.py:1992] 2023-09-03 16:21:25,337 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-89/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-03 16:21:25,341 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-89/preprocessor_config.json\n","{'loss': 2.2293, 'learning_rate': 0.000996629213483146, 'epoch': 1.01}\n","{'loss': 2.0771, 'learning_rate': 0.0009962546816479402, 'epoch': 1.12}\n","{'loss': 2.0568, 'learning_rate': 0.000995880149812734, 'epoch': 1.24}\n","{'loss': 2.05, 'learning_rate': 0.0009955056179775281, 'epoch': 1.35}\n","{'loss': 2.009, 'learning_rate': 0.0009951310861423222, 'epoch': 1.46}\n","{'loss': 2.0236, 'learning_rate': 0.0009947565543071161, 'epoch': 1.57}\n","{'loss': 1.9917, 'learning_rate': 0.0009943820224719102, 'epoch': 1.69}\n","{'loss': 1.9507, 'learning_rate': 0.000994007490636704, 'epoch': 1.8}\n","{'loss': 1.9461, 'learning_rate': 0.0009936329588014982, 'epoch': 1.91}\n","  1% 177/26700 [09:16<13:20:48,  1.81s/it][INFO|trainer.py:3115] 2023-09-03 16:25:02,625 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3117] 2023-09-03 16:25:02,626 >>   Num examples = 22619\n","[INFO|trainer.py:3120] 2023-09-03 16:25:02,626 >>   Batch size = 512\n","\n","  0% 0/45 [00:00<?, ?it/s]\u001b[A\n","  4% 2/45 [00:02<00:58,  1.36s/it]\u001b[A\n","  7% 3/45 [00:05<01:22,  1.96s/it]\u001b[A\n","  9% 4/45 [00:08<01:28,  2.16s/it]\u001b[A\n"," 11% 5/45 [00:10<01:32,  2.30s/it]\u001b[A\n"," 13% 6/45 [00:13<01:39,  2.55s/it]\u001b[A\n"," 16% 7/45 [00:16<01:43,  2.72s/it]\u001b[A\n"," 18% 8/45 [00:19<01:45,  2.86s/it]\u001b[A\n"," 20% 9/45 [00:23<01:46,  2.97s/it]\u001b[A\n"," 22% 10/45 [00:26<01:47,  3.07s/it]\u001b[A\n"," 24% 11/45 [00:28<01:37,  2.85s/it]\u001b[A\n"," 27% 12/45 [00:31<01:32,  2.80s/it]\u001b[A\n"," 29% 13/45 [00:33<01:25,  2.67s/it]\u001b[A\n"," 31% 14/45 [00:36<01:23,  2.69s/it]\u001b[A\n"," 33% 15/45 [00:38<01:18,  2.62s/it]\u001b[A\n"," 36% 16/45 [00:41<01:16,  2.63s/it]\u001b[A\n"," 38% 17/45 [00:43<01:11,  2.54s/it]\u001b[A\n"," 40% 18/45 [00:46<01:04,  2.40s/it]\u001b[A\n"," 42% 19/45 [00:48<01:03,  2.45s/it]\u001b[A\n"," 44% 20/45 [00:51<01:03,  2.54s/it]\u001b[A\n"," 47% 21/45 [00:53<01:01,  2.56s/it]\u001b[A\n"," 49% 22/45 [00:56<00:57,  2.51s/it]\u001b[A\n"," 51% 23/45 [00:58<00:53,  2.43s/it]\u001b[A\n"," 53% 24/45 [01:01<00:54,  2.60s/it]\u001b[A\n"," 56% 25/45 [01:04<00:52,  2.65s/it]\u001b[A\n"," 58% 26/45 [01:06<00:46,  2.42s/it]\u001b[A\n"," 60% 27/45 [01:09<00:46,  2.60s/it]\u001b[A\n"," 62% 28/45 [01:12<00:47,  2.81s/it]\u001b[A\n"," 64% 29/45 [01:15<00:43,  2.72s/it]\u001b[A\n"," 67% 30/45 [01:17<00:40,  2.70s/it]\u001b[A\n"," 69% 31/45 [01:20<00:39,  2.85s/it]\u001b[A\n"," 71% 32/45 [01:23<00:37,  2.91s/it]\u001b[A\n"," 73% 33/45 [01:26<00:34,  2.87s/it]\u001b[A\n"," 76% 34/45 [01:29<00:32,  2.93s/it]\u001b[A\n"," 78% 35/45 [01:32<00:29,  2.90s/it]\u001b[A\n"," 80% 36/45 [01:35<00:25,  2.86s/it]\u001b[A\n"," 82% 37/45 [01:37<00:21,  2.65s/it]\u001b[A\n"," 84% 38/45 [01:39<00:17,  2.49s/it]\u001b[A\n"," 87% 39/45 [01:42<00:14,  2.48s/it]\u001b[A\n"," 89% 40/45 [01:45<00:13,  2.67s/it]\u001b[A\n"," 91% 41/45 [01:47<00:10,  2.57s/it]\u001b[A\n"," 93% 42/45 [01:49<00:07,  2.52s/it]\u001b[A\n"," 96% 43/45 [01:52<00:04,  2.41s/it]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 2.085638999938965, 'eval_accuracy': 0.4693399354524957, 'eval_runtime': 118.3374, 'eval_samples_per_second': 191.14, 'eval_steps_per_second': 0.38, 'epoch': 2.0}\n","  1% 178/26700 [11:15<13:20:46,  1.81s/it]\n","100% 45/45 [01:52<00:00,  1.86s/it]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2841] 2023-09-03 16:27:00,969 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-178\n","[INFO|configuration_utils.py:460] 2023-09-03 16:27:00,976 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-178/config.json\n","[INFO|modeling_utils.py:1992] 2023-09-03 16:27:01,091 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-178/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-03 16:27:01,108 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-178/preprocessor_config.json\n","{'loss': 1.9531, 'learning_rate': 0.0009932584269662923, 'epoch': 2.02}\n","{'loss': 1.8153, 'learning_rate': 0.0009928838951310862, 'epoch': 2.13}\n","{'loss': 1.8412, 'learning_rate': 0.00099250936329588, 'epoch': 2.25}\n","{'loss': 1.806, 'learning_rate': 0.0009921348314606742, 'epoch': 2.36}\n","{'loss': 1.773, 'learning_rate': 0.0009917602996254683, 'epoch': 2.47}\n","{'loss': 1.8053, 'learning_rate': 0.0009913857677902622, 'epoch': 2.58}\n","{'loss': 1.8018, 'learning_rate': 0.0009910112359550563, 'epoch': 2.7}\n","{'loss': 1.7693, 'learning_rate': 0.0009906367041198501, 'epoch': 2.81}\n","{'loss': 1.7921, 'learning_rate': 0.0009902621722846442, 'epoch': 2.92}\n","  1% 266/26700 [14:52<13:26:21,  1.83s/it][INFO|trainer.py:3115] 2023-09-03 16:30:38,034 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3117] 2023-09-03 16:30:38,034 >>   Num examples = 22619\n","[INFO|trainer.py:3120] 2023-09-03 16:30:38,034 >>   Batch size = 512\n","\n","  0% 0/45 [00:00<?, ?it/s]\u001b[A\n","  4% 2/45 [00:02<00:53,  1.24s/it]\u001b[A\n","  7% 3/45 [00:05<01:19,  1.88s/it]\u001b[A\n","  9% 4/45 [00:07<01:27,  2.13s/it]\u001b[A\n"," 11% 5/45 [00:10<01:31,  2.29s/it]\u001b[A\n"," 13% 6/45 [00:13<01:38,  2.53s/it]\u001b[A\n"," 16% 7/45 [00:16<01:41,  2.68s/it]\u001b[A\n"," 18% 8/45 [00:19<01:43,  2.80s/it]\u001b[A\n"," 20% 9/45 [00:22<01:46,  2.95s/it]\u001b[A\n"," 22% 10/45 [00:26<01:46,  3.06s/it]\u001b[A\n"," 24% 11/45 [00:28<01:36,  2.84s/it]\u001b[A\n"," 27% 12/45 [00:31<01:31,  2.78s/it]\u001b[A\n"," 29% 13/45 [00:33<01:24,  2.63s/it]\u001b[A\n"," 31% 14/45 [00:36<01:23,  2.68s/it]\u001b[A\n"," 33% 15/45 [00:38<01:18,  2.62s/it]\u001b[A\n"," 36% 16/45 [00:41<01:16,  2.63s/it]\u001b[A\n"," 38% 17/45 [00:43<01:11,  2.55s/it]\u001b[A\n"," 40% 18/45 [00:45<01:04,  2.39s/it]\u001b[A\n"," 42% 19/45 [00:48<01:03,  2.44s/it]\u001b[A\n"," 44% 20/45 [00:51<01:03,  2.55s/it]\u001b[A\n"," 47% 21/45 [00:53<01:01,  2.57s/it]\u001b[A\n"," 49% 22/45 [00:55<00:57,  2.51s/it]\u001b[A\n"," 51% 23/45 [00:58<00:52,  2.41s/it]\u001b[A\n"," 53% 24/45 [01:01<00:53,  2.54s/it]\u001b[A\n"," 56% 25/45 [01:03<00:52,  2.62s/it]\u001b[A\n"," 58% 26/45 [01:06<00:47,  2.50s/it]\u001b[A\n"," 60% 27/45 [01:09<00:47,  2.66s/it]\u001b[A\n"," 62% 28/45 [01:12<00:46,  2.76s/it]\u001b[A\n"," 64% 29/45 [01:14<00:42,  2.65s/it]\u001b[A\n"," 67% 30/45 [01:17<00:39,  2.66s/it]\u001b[A\n"," 69% 31/45 [01:20<00:39,  2.81s/it]\u001b[A\n"," 71% 32/45 [01:23<00:37,  2.88s/it]\u001b[A\n"," 73% 33/45 [01:26<00:33,  2.83s/it]\u001b[A\n"," 76% 34/45 [01:28<00:31,  2.84s/it]\u001b[A\n"," 78% 35/45 [01:31<00:28,  2.86s/it]\u001b[A\n"," 80% 36/45 [01:34<00:25,  2.87s/it]\u001b[A\n"," 82% 37/45 [01:36<00:21,  2.66s/it]\u001b[A\n"," 84% 38/45 [01:38<00:17,  2.49s/it]\u001b[A\n"," 87% 39/45 [01:41<00:14,  2.41s/it]\u001b[A\n"," 89% 40/45 [01:44<00:12,  2.58s/it]\u001b[A\n"," 91% 41/45 [01:46<00:10,  2.54s/it]\u001b[A\n"," 93% 42/45 [01:49<00:07,  2.52s/it]\u001b[A\n"," 96% 43/45 [01:51<00:04,  2.41s/it]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 2.0289387702941895, 'eval_accuracy': 0.4848578628586587, 'eval_runtime': 117.4756, 'eval_samples_per_second': 192.542, 'eval_steps_per_second': 0.383, 'epoch': 3.0}\n","  1% 267/26700 [16:49<13:26:20,  1.83s/it]\n","100% 45/45 [01:52<00:00,  1.87s/it]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2841] 2023-09-03 16:32:35,515 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-267\n","[INFO|configuration_utils.py:460] 2023-09-03 16:32:35,520 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-267/config.json\n","[INFO|modeling_utils.py:1992] 2023-09-03 16:32:35,631 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-267/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-03 16:32:35,635 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-267/preprocessor_config.json\n","{'loss': 1.6592, 'learning_rate': 0.0009898876404494383, 'epoch': 3.03}\n","{'loss': 1.6363, 'learning_rate': 0.0009895131086142322, 'epoch': 3.15}\n","{'loss': 1.6069, 'learning_rate': 0.000989138576779026, 'epoch': 3.26}\n","{'loss': 1.6663, 'learning_rate': 0.0009887640449438202, 'epoch': 3.37}\n","{'loss': 1.6565, 'learning_rate': 0.0009883895131086143, 'epoch': 3.48}\n","{'loss': 1.6659, 'learning_rate': 0.0009880149812734082, 'epoch': 3.6}\n","{'loss': 1.6582, 'learning_rate': 0.0009876404494382023, 'epoch': 3.71}\n","{'loss': 1.7144, 'learning_rate': 0.0009872659176029962, 'epoch': 3.82}\n","{'loss': 1.6554, 'learning_rate': 0.0009868913857677903, 'epoch': 3.93}\n","  1% 355/26700 [20:27<14:20:49,  1.96s/it][INFO|trainer.py:3115] 2023-09-03 16:36:13,309 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3117] 2023-09-03 16:36:13,310 >>   Num examples = 22619\n","[INFO|trainer.py:3120] 2023-09-03 16:36:13,310 >>   Batch size = 512\n","\n","  0% 0/45 [00:00<?, ?it/s]\u001b[A\n","  4% 2/45 [00:02<00:53,  1.25s/it]\u001b[A\n","  7% 3/45 [00:05<01:19,  1.89s/it]\u001b[A\n","  9% 4/45 [00:08<01:30,  2.21s/it]\u001b[A\n"," 11% 5/45 [00:10<01:34,  2.36s/it]\u001b[A\n"," 13% 6/45 [00:13<01:41,  2.60s/it]\u001b[A\n"," 16% 7/45 [00:16<01:43,  2.74s/it]\u001b[A\n"," 18% 8/45 [00:19<01:45,  2.84s/it]\u001b[A\n"," 20% 9/45 [00:23<01:47,  2.97s/it]\u001b[A\n"," 22% 10/45 [00:26<01:49,  3.12s/it]\u001b[A\n"," 24% 11/45 [00:28<01:38,  2.90s/it]\u001b[A\n"," 27% 12/45 [00:31<01:33,  2.82s/it]\u001b[A\n"," 29% 13/45 [00:33<01:25,  2.67s/it]\u001b[A\n"," 31% 14/45 [00:36<01:23,  2.70s/it]\u001b[A\n"," 33% 15/45 [00:39<01:20,  2.67s/it]\u001b[A\n"," 36% 16/45 [00:42<01:17,  2.68s/it]\u001b[A\n"," 38% 17/45 [00:44<01:12,  2.58s/it]\u001b[A\n"," 40% 18/45 [00:46<01:05,  2.42s/it]\u001b[A\n"," 42% 19/45 [00:48<01:03,  2.44s/it]\u001b[A\n"," 44% 20/45 [00:51<01:03,  2.55s/it]\u001b[A\n"," 47% 21/45 [00:54<01:01,  2.58s/it]\u001b[A\n"," 49% 22/45 [00:56<00:57,  2.52s/it]\u001b[A\n"," 51% 23/45 [00:58<00:53,  2.42s/it]\u001b[A\n"," 53% 24/45 [01:01<00:53,  2.55s/it]\u001b[A\n"," 56% 25/45 [01:04<00:52,  2.62s/it]\u001b[A\n"," 58% 26/45 [01:06<00:47,  2.48s/it]\u001b[A\n"," 60% 27/45 [01:09<00:47,  2.66s/it]\u001b[A\n"," 62% 28/45 [01:12<00:46,  2.76s/it]\u001b[A\n"," 64% 29/45 [01:15<00:42,  2.65s/it]\u001b[A\n"," 67% 30/45 [01:17<00:39,  2.65s/it]\u001b[A\n"," 69% 31/45 [01:21<00:39,  2.82s/it]\u001b[A\n"," 71% 32/45 [01:24<00:37,  2.92s/it]\u001b[A\n"," 73% 33/45 [01:26<00:34,  2.86s/it]\u001b[A\n"," 76% 34/45 [01:29<00:31,  2.86s/it]\u001b[A\n"," 78% 35/45 [01:32<00:28,  2.86s/it]\u001b[A\n"," 80% 36/45 [01:35<00:25,  2.85s/it]\u001b[A\n"," 82% 37/45 [01:37<00:21,  2.65s/it]\u001b[A\n"," 84% 38/45 [01:39<00:17,  2.48s/it]\u001b[A\n"," 87% 39/45 [01:41<00:14,  2.40s/it]\u001b[A\n"," 89% 40/45 [01:44<00:12,  2.58s/it]\u001b[A\n"," 91% 41/45 [01:47<00:10,  2.51s/it]\u001b[A\n"," 93% 42/45 [01:49<00:07,  2.51s/it]\u001b[A\n"," 96% 43/45 [01:51<00:04,  2.41s/it]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 1.769232988357544, 'eval_accuracy': 0.5299084840178611, 'eval_runtime': 118.3341, 'eval_samples_per_second': 191.145, 'eval_steps_per_second': 0.38, 'epoch': 4.0}\n","  1% 356/26700 [22:25<14:20:47,  1.96s/it]\n","100% 45/45 [01:52<00:00,  1.87s/it]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2841] 2023-09-03 16:38:11,648 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-356\n","[INFO|configuration_utils.py:460] 2023-09-03 16:38:11,654 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-356/config.json\n","[INFO|modeling_utils.py:1992] 2023-09-03 16:38:11,764 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-356/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-03 16:38:11,781 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-356/preprocessor_config.json\n","[INFO|trainer.py:2928] 2023-09-03 16:38:11,995 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-89] due to args.save_total_limit\n","{'loss': 1.6279, 'learning_rate': 0.0009865168539325844, 'epoch': 4.04}\n","{'loss': 1.5563, 'learning_rate': 0.0009861423220973782, 'epoch': 4.16}\n","{'loss': 1.5225, 'learning_rate': 0.0009857677902621723, 'epoch': 4.27}\n","{'loss': 1.5146, 'learning_rate': 0.0009853932584269664, 'epoch': 4.38}\n","{'loss': 1.5683, 'learning_rate': 0.0009850187265917603, 'epoch': 4.49}\n","{'loss': 1.5306, 'learning_rate': 0.0009846441947565542, 'epoch': 4.61}\n","{'loss': 1.5667, 'learning_rate': 0.0009842696629213483, 'epoch': 4.72}\n","{'loss': 1.5527, 'learning_rate': 0.0009838951310861424, 'epoch': 4.83}\n","{'loss': 1.5199, 'learning_rate': 0.0009835205992509363, 'epoch': 4.94}\n","  2% 444/26700 [26:04<13:40:33,  1.88s/it][INFO|trainer.py:3115] 2023-09-03 16:41:50,127 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3117] 2023-09-03 16:41:50,127 >>   Num examples = 22619\n","[INFO|trainer.py:3120] 2023-09-03 16:41:50,127 >>   Batch size = 512\n","\n","  0% 0/45 [00:00<?, ?it/s]\u001b[A\n","  4% 2/45 [00:02<00:54,  1.26s/it]\u001b[A\n","  7% 3/45 [00:05<01:19,  1.90s/it]\u001b[A\n","  9% 4/45 [00:07<01:27,  2.12s/it]\u001b[A\n"," 11% 5/45 [00:10<01:31,  2.29s/it]\u001b[A\n"," 13% 6/45 [00:13<01:39,  2.55s/it]\u001b[A\n"," 16% 7/45 [00:16<01:43,  2.71s/it]\u001b[A\n"," 18% 8/45 [00:19<01:44,  2.83s/it]\u001b[A\n"," 20% 9/45 [00:22<01:46,  2.96s/it]\u001b[A\n"," 22% 10/45 [00:26<01:47,  3.08s/it]\u001b[A\n"," 24% 11/45 [00:28<01:38,  2.90s/it]\u001b[A\n"," 27% 12/45 [00:31<01:33,  2.82s/it]\u001b[A\n"," 29% 13/45 [00:33<01:25,  2.67s/it]\u001b[A\n"," 31% 14/45 [00:36<01:23,  2.70s/it]\u001b[A\n"," 33% 15/45 [00:38<01:18,  2.63s/it]\u001b[A\n"," 36% 16/45 [00:41<01:20,  2.76s/it]\u001b[A\n"," 38% 17/45 [00:44<01:14,  2.65s/it]\u001b[A\n"," 40% 18/45 [00:46<01:06,  2.46s/it]\u001b[A\n"," 42% 19/45 [00:48<01:04,  2.49s/it]\u001b[A\n"," 44% 20/45 [00:51<01:04,  2.57s/it]\u001b[A\n"," 47% 21/45 [00:54<01:02,  2.60s/it]\u001b[A\n"," 49% 22/45 [00:56<00:58,  2.56s/it]\u001b[A\n"," 51% 23/45 [00:59<00:53,  2.45s/it]\u001b[A\n"," 53% 24/45 [01:01<00:54,  2.58s/it]\u001b[A\n"," 56% 25/45 [01:04<00:52,  2.64s/it]\u001b[A\n"," 58% 26/45 [01:06<00:46,  2.43s/it]\u001b[A\n"," 60% 27/45 [01:09<00:47,  2.65s/it]\u001b[A\n"," 62% 28/45 [01:12<00:47,  2.78s/it]\u001b[A\n"," 64% 29/45 [01:15<00:42,  2.67s/it]\u001b[A\n"," 67% 30/45 [01:17<00:40,  2.67s/it]\u001b[A\n"," 69% 31/45 [01:21<00:39,  2.83s/it]\u001b[A\n"," 71% 32/45 [01:24<00:38,  2.93s/it]\u001b[A\n"," 73% 33/45 [01:27<00:34,  2.88s/it]\u001b[A\n"," 76% 34/45 [01:29<00:31,  2.88s/it]\u001b[A\n"," 78% 35/45 [01:32<00:28,  2.89s/it]\u001b[A\n"," 80% 36/45 [01:35<00:25,  2.88s/it]\u001b[A\n"," 82% 37/45 [01:38<00:21,  2.70s/it]\u001b[A\n"," 84% 38/45 [01:40<00:17,  2.53s/it]\u001b[A\n"," 87% 39/45 [01:42<00:14,  2.45s/it]\u001b[A\n"," 89% 40/45 [01:45<00:13,  2.61s/it]\u001b[A\n"," 91% 41/45 [01:47<00:10,  2.54s/it]\u001b[A\n"," 93% 42/45 [01:50<00:07,  2.51s/it]\u001b[A\n"," 96% 43/45 [01:52<00:04,  2.43s/it]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 1.6728441715240479, 'eval_accuracy': 0.5583801229055219, 'eval_runtime': 118.8339, 'eval_samples_per_second': 190.341, 'eval_steps_per_second': 0.379, 'epoch': 5.0}\n","  2% 445/26700 [28:03<13:40:31,  1.88s/it]\n","100% 45/45 [01:53<00:00,  1.89s/it]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2841] 2023-09-03 16:43:48,966 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-445\n","[INFO|configuration_utils.py:460] 2023-09-03 16:43:48,972 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-445/config.json\n","[INFO|modeling_utils.py:1992] 2023-09-03 16:43:49,083 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-445/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-03 16:43:49,087 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-445/preprocessor_config.json\n","[INFO|trainer.py:2928] 2023-09-03 16:43:49,307 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-178] due to args.save_total_limit\n","{'loss': 1.521, 'learning_rate': 0.0009831460674157304, 'epoch': 5.06}\n","{'loss': 1.4487, 'learning_rate': 0.0009827715355805243, 'epoch': 5.17}\n","{'loss': 1.4513, 'learning_rate': 0.0009823970037453184, 'epoch': 5.28}\n","{'loss': 1.4511, 'learning_rate': 0.0009820224719101125, 'epoch': 5.39}\n","{'loss': 1.4445, 'learning_rate': 0.0009816479400749064, 'epoch': 5.51}\n","{'loss': 1.4826, 'learning_rate': 0.0009812734082397002, 'epoch': 5.62}\n","{'loss': 1.4508, 'learning_rate': 0.0009808988764044943, 'epoch': 5.73}\n","{'loss': 1.47, 'learning_rate': 0.0009805243445692884, 'epoch': 5.84}\n","{'loss': 1.4409, 'learning_rate': 0.0009801498127340823, 'epoch': 5.96}\n","  2% 533/26700 [31:41<13:14:21,  1.82s/it][INFO|trainer.py:3115] 2023-09-03 16:47:27,236 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3117] 2023-09-03 16:47:27,237 >>   Num examples = 22619\n","[INFO|trainer.py:3120] 2023-09-03 16:47:27,237 >>   Batch size = 512\n","\n","  0% 0/45 [00:00<?, ?it/s]\u001b[A\n","  4% 2/45 [00:02<00:56,  1.31s/it]\u001b[A\n","  7% 3/45 [00:05<01:20,  1.92s/it]\u001b[A\n","  9% 4/45 [00:07<01:27,  2.13s/it]\u001b[A\n"," 11% 5/45 [00:10<01:31,  2.29s/it]\u001b[A\n"," 13% 6/45 [00:13<01:39,  2.55s/it]\u001b[A\n"," 16% 7/45 [00:16<01:44,  2.75s/it]\u001b[A\n"," 18% 8/45 [00:20<01:48,  2.93s/it]\u001b[A\n"," 20% 9/45 [00:23<01:48,  3.02s/it]\u001b[A\n"," 22% 10/45 [00:26<01:48,  3.11s/it]\u001b[A\n"," 24% 11/45 [00:29<01:40,  2.96s/it]\u001b[A\n"," 27% 12/45 [00:31<01:35,  2.89s/it]\u001b[A\n"," 29% 13/45 [00:34<01:26,  2.71s/it]\u001b[A\n"," 31% 14/45 [00:36<01:24,  2.73s/it]\u001b[A\n"," 33% 15/45 [00:39<01:19,  2.65s/it]\u001b[A\n"," 36% 16/45 [00:42<01:17,  2.67s/it]\u001b[A\n"," 38% 17/45 [00:44<01:12,  2.60s/it]\u001b[A\n"," 40% 18/45 [00:46<01:05,  2.43s/it]\u001b[A\n"," 42% 19/45 [00:49<01:03,  2.45s/it]\u001b[A\n"," 44% 20/45 [00:51<01:03,  2.54s/it]\u001b[A\n"," 47% 21/45 [00:54<01:01,  2.56s/it]\u001b[A\n"," 49% 22/45 [00:56<00:58,  2.53s/it]\u001b[A\n"," 51% 23/45 [00:59<00:53,  2.44s/it]\u001b[A\n"," 53% 24/45 [01:02<00:53,  2.56s/it]\u001b[A\n"," 56% 25/45 [01:04<00:52,  2.62s/it]\u001b[A\n"," 58% 26/45 [01:06<00:45,  2.41s/it]\u001b[A\n"," 60% 27/45 [01:09<00:46,  2.61s/it]\u001b[A\n"," 62% 28/45 [01:12<00:46,  2.76s/it]\u001b[A\n"," 64% 29/45 [01:15<00:42,  2.65s/it]\u001b[A\n"," 67% 30/45 [01:17<00:39,  2.65s/it]\u001b[A\n"," 69% 31/45 [01:21<00:39,  2.80s/it]\u001b[A\n"," 71% 32/45 [01:24<00:37,  2.89s/it]\u001b[A\n"," 73% 33/45 [01:27<00:34,  2.89s/it]\u001b[A\n"," 76% 34/45 [01:29<00:31,  2.88s/it]\u001b[A\n"," 78% 35/45 [01:32<00:28,  2.87s/it]\u001b[A\n"," 80% 36/45 [01:35<00:25,  2.84s/it]\u001b[A\n"," 82% 37/45 [01:37<00:21,  2.64s/it]\u001b[A\n"," 84% 38/45 [01:39<00:17,  2.48s/it]\u001b[A\n"," 87% 39/45 [01:42<00:14,  2.44s/it]\u001b[A\n"," 89% 40/45 [01:45<00:13,  2.60s/it]\u001b[A\n"," 91% 41/45 [01:47<00:10,  2.53s/it]\u001b[A\n"," 93% 42/45 [01:49<00:07,  2.49s/it]\u001b[A\n"," 96% 43/45 [01:52<00:04,  2.39s/it]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 1.7843307256698608, 'eval_accuracy': 0.5405190326716477, 'eval_runtime': 118.4183, 'eval_samples_per_second': 191.009, 'eval_steps_per_second': 0.38, 'epoch': 6.0}\n","  2% 534/26700 [33:39<13:14:20,  1.82s/it]\n","100% 45/45 [01:52<00:00,  1.86s/it]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2841] 2023-09-03 16:49:25,661 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-534\n","[INFO|configuration_utils.py:460] 2023-09-03 16:49:25,667 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-534/config.json\n","[INFO|modeling_utils.py:1992] 2023-09-03 16:49:25,789 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-534/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-03 16:49:25,794 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-534/preprocessor_config.json\n","[INFO|trainer.py:2928] 2023-09-03 16:49:26,008 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-267] due to args.save_total_limit\n","{'loss': 1.3918, 'learning_rate': 0.0009797752808988764, 'epoch': 6.07}\n","{'loss': 1.3534, 'learning_rate': 0.0009794007490636703, 'epoch': 6.18}\n","{'loss': 1.3761, 'learning_rate': 0.0009790262172284644, 'epoch': 6.29}\n","{'loss': 1.3478, 'learning_rate': 0.0009786516853932585, 'epoch': 6.4}\n","{'loss': 1.397, 'learning_rate': 0.0009782771535580524, 'epoch': 6.52}\n","{'loss': 1.4054, 'learning_rate': 0.0009779026217228465, 'epoch': 6.63}\n","{'loss': 1.4167, 'learning_rate': 0.0009775280898876404, 'epoch': 6.74}\n","{'loss': 1.3932, 'learning_rate': 0.0009771535580524345, 'epoch': 6.85}\n","{'loss': 1.4229, 'learning_rate': 0.0009767790262172286, 'epoch': 6.97}\n","  2% 622/26700 [37:17<13:20:24,  1.84s/it][INFO|trainer.py:3115] 2023-09-03 16:53:03,349 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3117] 2023-09-03 16:53:03,349 >>   Num examples = 22619\n","[INFO|trainer.py:3120] 2023-09-03 16:53:03,349 >>   Batch size = 512\n","\n","  0% 0/45 [00:00<?, ?it/s]\u001b[A\n","  4% 2/45 [00:02<00:53,  1.25s/it]\u001b[A\n","  7% 3/45 [00:05<01:21,  1.93s/it]\u001b[A\n","  9% 4/45 [00:07<01:28,  2.16s/it]\u001b[A\n"," 11% 5/45 [00:10<01:32,  2.31s/it]\u001b[A\n"," 13% 6/45 [00:13<01:39,  2.55s/it]\u001b[A\n"," 16% 7/45 [00:16<01:43,  2.73s/it]\u001b[A\n"," 18% 8/45 [00:19<01:46,  2.89s/it]\u001b[A\n"," 20% 9/45 [00:23<01:47,  2.99s/it]\u001b[A\n"," 22% 10/45 [00:26<01:47,  3.08s/it]\u001b[A\n"," 24% 11/45 [00:28<01:37,  2.87s/it]\u001b[A\n"," 27% 12/45 [00:31<01:32,  2.80s/it]\u001b[A\n"," 29% 13/45 [00:33<01:26,  2.69s/it]\u001b[A\n"," 31% 14/45 [00:36<01:24,  2.72s/it]\u001b[A\n"," 33% 15/45 [00:39<01:19,  2.64s/it]\u001b[A\n"," 36% 16/45 [00:41<01:16,  2.64s/it]\u001b[A\n"," 38% 17/45 [00:44<01:11,  2.55s/it]\u001b[A\n"," 40% 18/45 [00:46<01:05,  2.42s/it]\u001b[A\n"," 42% 19/45 [00:48<01:04,  2.49s/it]\u001b[A\n"," 44% 20/45 [00:51<01:04,  2.57s/it]\u001b[A\n"," 47% 21/45 [00:54<01:01,  2.58s/it]\u001b[A\n"," 49% 22/45 [00:56<00:57,  2.52s/it]\u001b[A\n"," 51% 23/45 [00:58<00:53,  2.42s/it]\u001b[A\n"," 53% 24/45 [01:01<00:55,  2.65s/it]\u001b[A\n"," 56% 25/45 [01:04<00:53,  2.68s/it]\u001b[A\n"," 58% 26/45 [01:06<00:46,  2.45s/it]\u001b[A\n"," 60% 27/45 [01:09<00:47,  2.63s/it]\u001b[A\n"," 62% 28/45 [01:12<00:46,  2.76s/it]\u001b[A\n"," 64% 29/45 [01:15<00:43,  2.70s/it]\u001b[A\n"," 67% 30/45 [01:17<00:40,  2.69s/it]\u001b[A\n"," 69% 31/45 [01:21<00:39,  2.84s/it]\u001b[A\n"," 71% 32/45 [01:24<00:37,  2.90s/it]\u001b[A\n"," 73% 33/45 [01:26<00:34,  2.86s/it]\u001b[A\n"," 76% 34/45 [01:29<00:31,  2.88s/it]\u001b[A\n"," 78% 35/45 [01:32<00:28,  2.88s/it]\u001b[A\n"," 80% 36/45 [01:35<00:25,  2.85s/it]\u001b[A\n"," 82% 37/45 [01:37<00:21,  2.64s/it]\u001b[A\n"," 84% 38/45 [01:39<00:17,  2.48s/it]\u001b[A\n"," 87% 39/45 [01:42<00:14,  2.42s/it]\u001b[A\n"," 89% 40/45 [01:45<00:13,  2.62s/it]\u001b[A\n"," 91% 41/45 [01:47<00:10,  2.53s/it]\u001b[A\n"," 93% 42/45 [01:49<00:07,  2.50s/it]\u001b[A\n"," 96% 43/45 [01:52<00:04,  2.40s/it]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 1.7233028411865234, 'eval_accuracy': 0.5463990450506212, 'eval_runtime': 118.3094, 'eval_samples_per_second': 191.185, 'eval_steps_per_second': 0.38, 'epoch': 7.0}\n","  2% 623/26700 [39:15<13:20:22,  1.84s/it]\n","100% 45/45 [01:52<00:00,  1.85s/it]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2841] 2023-09-03 16:55:01,665 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-623\n","[INFO|configuration_utils.py:460] 2023-09-03 16:55:01,671 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-623/config.json\n","[INFO|modeling_utils.py:1992] 2023-09-03 16:55:01,783 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-623/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-03 16:55:01,799 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-623/preprocessor_config.json\n","[INFO|trainer.py:2928] 2023-09-03 16:55:02,017 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-356] due to args.save_total_limit\n","{'loss': 1.3779, 'learning_rate': 0.0009764044943820225, 'epoch': 7.08}\n","{'loss': 1.3032, 'learning_rate': 0.0009760299625468166, 'epoch': 7.19}\n","{'loss': 1.3107, 'learning_rate': 0.0009756554307116106, 'epoch': 7.3}\n","{'loss': 1.3167, 'learning_rate': 0.0009752808988764044, 'epoch': 7.42}\n","{'loss': 1.3199, 'learning_rate': 0.0009749063670411985, 'epoch': 7.53}\n","{'loss': 1.3343, 'learning_rate': 0.0009745318352059925, 'epoch': 7.64}\n","{'loss': 1.3308, 'learning_rate': 0.0009741573033707865, 'epoch': 7.75}\n","{'loss': 1.3544, 'learning_rate': 0.0009737827715355806, 'epoch': 7.87}\n","{'loss': 1.3424, 'learning_rate': 0.0009734082397003745, 'epoch': 7.98}\n","  3% 711/26700 [42:53<12:50:40,  1.78s/it][INFO|trainer.py:3115] 2023-09-03 16:58:39,505 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3117] 2023-09-03 16:58:39,506 >>   Num examples = 22619\n","[INFO|trainer.py:3120] 2023-09-03 16:58:39,506 >>   Batch size = 512\n","\n","  0% 0/45 [00:00<?, ?it/s]\u001b[A\n","  4% 2/45 [00:02<00:53,  1.24s/it]\u001b[A\n","  7% 3/45 [00:05<01:18,  1.88s/it]\u001b[A\n","  9% 4/45 [00:07<01:27,  2.13s/it]\u001b[A\n"," 11% 5/45 [00:10<01:32,  2.31s/it]\u001b[A\n"," 13% 6/45 [00:13<01:39,  2.54s/it]\u001b[A\n"," 16% 7/45 [00:16<01:42,  2.69s/it]\u001b[A\n"," 18% 8/45 [00:19<01:43,  2.81s/it]\u001b[A\n"," 20% 9/45 [00:22<01:46,  2.95s/it]\u001b[A\n"," 22% 10/45 [00:26<01:46,  3.05s/it]\u001b[A\n"," 24% 11/45 [00:28<01:36,  2.84s/it]\u001b[A\n"," 27% 12/45 [00:31<01:31,  2.78s/it]\u001b[A\n"," 29% 13/45 [00:33<01:24,  2.64s/it]\u001b[A\n"," 31% 14/45 [00:36<01:23,  2.70s/it]\u001b[A\n"," 33% 15/45 [00:38<01:18,  2.63s/it]\u001b[A\n"," 36% 16/45 [00:41<01:16,  2.63s/it]\u001b[A\n"," 38% 17/45 [00:43<01:11,  2.54s/it]\u001b[A\n"," 40% 18/45 [00:45<01:04,  2.38s/it]\u001b[A\n"," 42% 19/45 [00:48<01:02,  2.42s/it]\u001b[A\n"," 44% 20/45 [00:51<01:05,  2.61s/it]\u001b[A\n"," 47% 21/45 [00:53<01:02,  2.60s/it]\u001b[A\n"," 49% 22/45 [00:56<00:58,  2.54s/it]\u001b[A\n"," 51% 23/45 [00:58<00:53,  2.43s/it]\u001b[A\n"," 53% 24/45 [01:01<00:53,  2.56s/it]\u001b[A\n"," 56% 25/45 [01:04<00:52,  2.63s/it]\u001b[A\n"," 58% 26/45 [01:06<00:46,  2.44s/it]\u001b[A\n"," 60% 27/45 [01:09<00:47,  2.62s/it]\u001b[A\n"," 62% 28/45 [01:12<00:46,  2.74s/it]\u001b[A\n"," 64% 29/45 [01:14<00:42,  2.63s/it]\u001b[A\n"," 67% 30/45 [01:17<00:39,  2.65s/it]\u001b[A\n"," 69% 31/45 [01:20<00:39,  2.82s/it]\u001b[A\n"," 71% 32/45 [01:23<00:37,  2.90s/it]\u001b[A\n"," 73% 33/45 [01:26<00:34,  2.84s/it]\u001b[A\n"," 76% 34/45 [01:29<00:31,  2.85s/it]\u001b[A\n"," 78% 35/45 [01:31<00:28,  2.86s/it]\u001b[A\n"," 80% 36/45 [01:34<00:25,  2.85s/it]\u001b[A\n"," 82% 37/45 [01:36<00:21,  2.64s/it]\u001b[A\n"," 84% 38/45 [01:39<00:17,  2.47s/it]\u001b[A\n"," 87% 39/45 [01:41<00:14,  2.39s/it]\u001b[A\n"," 89% 40/45 [01:44<00:12,  2.57s/it]\u001b[A\n"," 91% 41/45 [01:46<00:10,  2.52s/it]\u001b[A\n"," 93% 42/45 [01:49<00:07,  2.51s/it]\u001b[A\n"," 96% 43/45 [01:51<00:04,  2.41s/it]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 1.7564830780029297, 'eval_accuracy': 0.5643043459038861, 'eval_runtime': 117.4791, 'eval_samples_per_second': 192.536, 'eval_steps_per_second': 0.383, 'epoch': 8.0}\n","  3% 712/26700 [44:51<12:50:38,  1.78s/it]\n","100% 45/45 [01:52<00:00,  1.86s/it]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2841] 2023-09-03 17:00:36,990 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-712\n","[INFO|configuration_utils.py:460] 2023-09-03 17:00:36,995 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-712/config.json\n","[INFO|modeling_utils.py:1992] 2023-09-03 17:00:37,104 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-712/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-03 17:00:37,108 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-712/preprocessor_config.json\n","[INFO|trainer.py:2928] 2023-09-03 17:00:37,317 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-534] due to args.save_total_limit\n","{'loss': 1.2817, 'learning_rate': 0.0009730337078651685, 'epoch': 8.09}\n","{'loss': 1.2298, 'learning_rate': 0.0009726591760299626, 'epoch': 8.2}\n","{'loss': 1.2362, 'learning_rate': 0.0009722846441947566, 'epoch': 8.31}\n","{'loss': 1.2407, 'learning_rate': 0.0009719101123595506, 'epoch': 8.43}\n","{'loss': 1.2582, 'learning_rate': 0.0009715355805243446, 'epoch': 8.54}\n","{'loss': 1.2753, 'learning_rate': 0.0009711610486891386, 'epoch': 8.65}\n","{'loss': 1.2806, 'learning_rate': 0.0009707865168539325, 'epoch': 8.76}\n","{'loss': 1.289, 'learning_rate': 0.0009704119850187266, 'epoch': 8.88}\n","{'loss': 1.2734, 'learning_rate': 0.0009700374531835206, 'epoch': 8.99}\n","  3% 800/26700 [48:28<13:42:19,  1.90s/it][INFO|trainer.py:3115] 2023-09-03 17:04:14,682 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3117] 2023-09-03 17:04:14,682 >>   Num examples = 22619\n","[INFO|trainer.py:3120] 2023-09-03 17:04:14,683 >>   Batch size = 512\n","\n","  0% 0/45 [00:00<?, ?it/s]\u001b[A\n","  4% 2/45 [00:02<00:53,  1.25s/it]\u001b[A\n","  7% 3/45 [00:05<01:19,  1.89s/it]\u001b[A\n","  9% 4/45 [00:07<01:26,  2.12s/it]\u001b[A\n"," 11% 5/45 [00:10<01:32,  2.30s/it]\u001b[A\n"," 13% 6/45 [00:13<01:39,  2.56s/it]\u001b[A\n"," 16% 7/45 [00:16<01:43,  2.71s/it]\u001b[A\n"," 18% 8/45 [00:19<01:44,  2.83s/it]\u001b[A\n"," 20% 9/45 [00:22<01:46,  2.95s/it]\u001b[A\n"," 22% 10/45 [00:26<01:48,  3.09s/it]\u001b[A\n"," 24% 11/45 [00:28<01:38,  2.88s/it]\u001b[A\n"," 27% 12/45 [00:31<01:32,  2.81s/it]\u001b[A\n"," 29% 13/45 [00:33<01:25,  2.66s/it]\u001b[A\n"," 31% 14/45 [00:36<01:23,  2.69s/it]\u001b[A\n"," 33% 15/45 [00:38<01:19,  2.64s/it]\u001b[A\n"," 36% 16/45 [00:41<01:17,  2.67s/it]\u001b[A\n"," 38% 17/45 [00:43<01:11,  2.57s/it]\u001b[A\n"," 40% 18/45 [00:46<01:05,  2.41s/it]\u001b[A\n"," 42% 19/45 [00:48<01:03,  2.44s/it]\u001b[A\n"," 44% 20/45 [00:51<01:03,  2.55s/it]\u001b[A\n"," 47% 21/45 [00:54<01:02,  2.59s/it]\u001b[A\n"," 49% 22/45 [00:56<00:58,  2.54s/it]\u001b[A\n"," 51% 23/45 [00:58<00:53,  2.43s/it]\u001b[A\n"," 53% 24/45 [01:01<00:53,  2.56s/it]\u001b[A\n"," 56% 25/45 [01:04<00:52,  2.62s/it]\u001b[A\n"," 58% 26/45 [01:06<00:46,  2.42s/it]\u001b[A\n"," 60% 27/45 [01:09<00:47,  2.62s/it]\u001b[A\n"," 62% 28/45 [01:12<00:46,  2.74s/it]\u001b[A\n"," 64% 29/45 [01:14<00:42,  2.64s/it]\u001b[A\n"," 67% 30/45 [01:17<00:39,  2.65s/it]\u001b[A\n"," 69% 31/45 [01:20<00:39,  2.82s/it]\u001b[A\n"," 71% 32/45 [01:23<00:37,  2.90s/it]\u001b[A\n"," 73% 33/45 [01:26<00:34,  2.85s/it]\u001b[A\n"," 76% 34/45 [01:29<00:31,  2.85s/it]\u001b[A\n"," 78% 35/45 [01:32<00:28,  2.85s/it]\u001b[A\n"," 80% 36/45 [01:34<00:25,  2.85s/it]\u001b[A\n"," 82% 37/45 [01:37<00:21,  2.65s/it]\u001b[A\n"," 84% 38/45 [01:39<00:17,  2.49s/it]\u001b[A\n"," 87% 39/45 [01:41<00:14,  2.41s/it]\u001b[A\n"," 89% 40/45 [01:44<00:12,  2.59s/it]\u001b[A\n"," 91% 41/45 [01:46<00:10,  2.52s/it]\u001b[A\n"," 93% 42/45 [01:49<00:07,  2.50s/it]\u001b[A\n"," 96% 43/45 [01:51<00:04,  2.41s/it]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 1.563530683517456, 'eval_accuracy': 0.5969759936336708, 'eval_runtime': 117.9169, 'eval_samples_per_second': 191.821, 'eval_steps_per_second': 0.382, 'epoch': 9.0}\n","  3% 801/26700 [50:26<13:42:17,  1.90s/it]\n","100% 45/45 [01:52<00:00,  1.87s/it]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2841] 2023-09-03 17:06:12,604 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-801\n","[INFO|configuration_utils.py:460] 2023-09-03 17:06:12,610 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-801/config.json\n","[INFO|modeling_utils.py:1992] 2023-09-03 17:06:12,723 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-801/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-03 17:06:12,728 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-801/preprocessor_config.json\n","[INFO|trainer.py:2928] 2023-09-03 17:06:12,941 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-445] due to args.save_total_limit\n","{'loss': 1.1695, 'learning_rate': 0.0009696629213483145, 'epoch': 9.1}\n","{'loss': 1.1498, 'learning_rate': 0.0009692883895131086, 'epoch': 9.21}\n","{'loss': 1.1494, 'learning_rate': 0.0009689138576779026, 'epoch': 9.33}\n","{'loss': 1.2049, 'learning_rate': 0.0009685393258426967, 'epoch': 9.44}\n","{'loss': 1.1888, 'learning_rate': 0.0009681647940074907, 'epoch': 9.55}\n","{'loss': 1.228, 'learning_rate': 0.0009677902621722847, 'epoch': 9.66}\n","{'loss': 1.2303, 'learning_rate': 0.0009674157303370787, 'epoch': 9.78}\n","{'loss': 1.2232, 'learning_rate': 0.0009670411985018727, 'epoch': 9.89}\n","{'loss': 1.2754, 'learning_rate': 0.0009666666666666667, 'epoch': 10.0}\n","  3% 890/26700 [54:04<12:44:58,  1.78s/it][INFO|trainer.py:3115] 2023-09-03 17:09:49,828 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3117] 2023-09-03 17:09:49,829 >>   Num examples = 22619\n","[INFO|trainer.py:3120] 2023-09-03 17:09:49,829 >>   Batch size = 512\n","\n","  0% 0/45 [00:00<?, ?it/s]\u001b[A\n","  4% 2/45 [00:02<00:55,  1.30s/it]\u001b[A\n","  7% 3/45 [00:05<01:20,  1.92s/it]\u001b[A\n","  9% 4/45 [00:07<01:27,  2.13s/it]\u001b[A\n"," 11% 5/45 [00:10<01:31,  2.29s/it]\u001b[A\n"," 13% 6/45 [00:13<01:39,  2.54s/it]\u001b[A\n"," 16% 7/45 [00:16<01:42,  2.71s/it]\u001b[A\n"," 18% 8/45 [00:19<01:44,  2.82s/it]\u001b[A\n"," 20% 9/45 [00:22<01:46,  2.95s/it]\u001b[A\n"," 22% 10/45 [00:26<01:46,  3.05s/it]\u001b[A\n"," 24% 11/45 [00:28<01:37,  2.85s/it]\u001b[A\n"," 27% 12/45 [00:31<01:32,  2.81s/it]\u001b[A\n"," 29% 13/45 [00:33<01:25,  2.66s/it]\u001b[A\n"," 31% 14/45 [00:36<01:23,  2.69s/it]\u001b[A\n"," 33% 15/45 [00:38<01:18,  2.62s/it]\u001b[A\n"," 36% 16/45 [00:41<01:16,  2.64s/it]\u001b[A\n"," 38% 17/45 [00:43<01:12,  2.57s/it]\u001b[A\n"," 40% 18/45 [00:45<01:05,  2.41s/it]\u001b[A\n"," 42% 19/45 [00:48<01:03,  2.45s/it]\u001b[A\n"," 44% 20/45 [00:51<01:03,  2.53s/it]\u001b[A\n"," 47% 21/45 [00:53<01:01,  2.55s/it]\u001b[A\n"," 49% 22/45 [00:56<00:57,  2.51s/it]\u001b[A\n"," 51% 23/45 [00:58<00:53,  2.43s/it]\u001b[A\n"," 53% 24/45 [01:01<00:53,  2.56s/it]\u001b[A\n"," 56% 25/45 [01:04<00:52,  2.62s/it]\u001b[A\n"," 58% 26/45 [01:05<00:45,  2.41s/it]\u001b[A\n"," 60% 27/45 [01:08<00:46,  2.60s/it]\u001b[A\n"," 62% 28/45 [01:12<00:46,  2.76s/it]\u001b[A\n"," 64% 29/45 [01:14<00:42,  2.65s/it]\u001b[A\n"," 67% 30/45 [01:17<00:39,  2.65s/it]\u001b[A\n"," 69% 31/45 [01:20<00:39,  2.80s/it]\u001b[A\n"," 71% 32/45 [01:23<00:37,  2.88s/it]\u001b[A\n"," 73% 33/45 [01:26<00:34,  2.87s/it]\u001b[A\n"," 76% 34/45 [01:29<00:31,  2.87s/it]\u001b[A\n"," 78% 35/45 [01:31<00:28,  2.86s/it]\u001b[A\n"," 80% 36/45 [01:34<00:25,  2.84s/it]\u001b[A\n"," 82% 37/45 [01:36<00:21,  2.63s/it]\u001b[A\n"," 84% 38/45 [01:39<00:17,  2.53s/it]\u001b[A\n"," 87% 39/45 [01:41<00:14,  2.48s/it]\u001b[A\n"," 89% 40/45 [01:44<00:13,  2.63s/it]\u001b[A\n"," 91% 41/45 [01:47<00:10,  2.61s/it]\u001b[A\n"," 93% 42/45 [01:49<00:07,  2.54s/it]\u001b[A\n"," 96% 43/45 [01:51<00:04,  2.44s/it]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 1.6231355667114258, 'eval_accuracy': 0.5908749281577435, 'eval_runtime': 117.9566, 'eval_samples_per_second': 191.757, 'eval_steps_per_second': 0.381, 'epoch': 10.0}\n","  3% 890/26700 [56:02<12:44:58,  1.78s/it]\n","100% 45/45 [01:52<00:00,  1.89s/it]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2841] 2023-09-03 17:11:47,790 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-890\n","[INFO|configuration_utils.py:460] 2023-09-03 17:11:47,797 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-890/config.json\n","[INFO|modeling_utils.py:1992] 2023-09-03 17:11:47,919 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-890/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-03 17:11:47,923 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-890/preprocessor_config.json\n","[INFO|trainer.py:2928] 2023-09-03 17:11:48,156 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-623] due to args.save_total_limit\n","{'loss': 1.1272, 'learning_rate': 0.0009662921348314608, 'epoch': 10.11}\n","{'loss': 1.1129, 'learning_rate': 0.0009659176029962548, 'epoch': 10.22}\n","{'loss': 1.1504, 'learning_rate': 0.0009655430711610486, 'epoch': 10.34}\n","{'loss': 1.1457, 'learning_rate': 0.0009651685393258427, 'epoch': 10.45}\n","{'loss': 1.1742, 'learning_rate': 0.0009647940074906367, 'epoch': 10.56}\n","{'loss': 1.2244, 'learning_rate': 0.0009644194756554307, 'epoch': 10.67}\n","{'loss': 1.195, 'learning_rate': 0.0009640449438202248, 'epoch': 10.79}\n","{'loss': 1.207, 'learning_rate': 0.0009636704119850187, 'epoch': 10.9}\n","  4% 978/26700 [59:39<13:37:10,  1.91s/it][INFO|trainer.py:3115] 2023-09-03 17:15:25,209 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3117] 2023-09-03 17:15:25,210 >>   Num examples = 22619\n","[INFO|trainer.py:3120] 2023-09-03 17:15:25,210 >>   Batch size = 512\n","\n","  0% 0/45 [00:00<?, ?it/s]\u001b[A\n","  4% 2/45 [00:02<00:54,  1.27s/it]\u001b[A\n","  7% 3/45 [00:05<01:21,  1.94s/it]\u001b[A\n","  9% 4/45 [00:07<01:28,  2.15s/it]\u001b[A\n"," 11% 5/45 [00:10<01:31,  2.30s/it]\u001b[A\n"," 13% 6/45 [00:13<01:39,  2.54s/it]\u001b[A\n"," 16% 7/45 [00:16<01:42,  2.70s/it]\u001b[A\n"," 18% 8/45 [00:19<01:45,  2.86s/it]\u001b[A\n"," 20% 9/45 [00:22<01:46,  2.97s/it]\u001b[A\n"," 22% 10/45 [00:26<01:47,  3.07s/it]\u001b[A\n"," 24% 11/45 [00:28<01:37,  2.86s/it]\u001b[A\n"," 27% 12/45 [00:31<01:33,  2.83s/it]\u001b[A\n"," 29% 13/45 [00:33<01:26,  2.71s/it]\u001b[A\n"," 31% 14/45 [00:36<01:24,  2.73s/it]\u001b[A\n"," 33% 15/45 [00:39<01:19,  2.64s/it]\u001b[A\n"," 36% 16/45 [00:41<01:16,  2.65s/it]\u001b[A\n"," 38% 17/45 [00:44<01:11,  2.56s/it]\u001b[A\n"," 40% 18/45 [00:46<01:05,  2.44s/it]\u001b[A\n"," 42% 19/45 [00:48<01:04,  2.50s/it]\u001b[A\n"," 44% 20/45 [00:51<01:04,  2.57s/it]\u001b[A\n"," 47% 21/45 [00:54<01:01,  2.58s/it]\u001b[A\n"," 49% 22/45 [00:56<00:57,  2.51s/it]\u001b[A\n"," 51% 23/45 [00:58<00:53,  2.41s/it]\u001b[A\n"," 53% 24/45 [01:01<00:53,  2.56s/it]\u001b[A\n"," 56% 25/45 [01:04<00:52,  2.62s/it]\u001b[A\n"," 58% 26/45 [01:06<00:45,  2.41s/it]\u001b[A\n"," 60% 27/45 [01:09<00:46,  2.60s/it]\u001b[A\n"," 62% 28/45 [01:12<00:46,  2.72s/it]\u001b[A\n"," 64% 29/45 [01:14<00:42,  2.64s/it]\u001b[A\n"," 67% 30/45 [01:17<00:39,  2.65s/it]\u001b[A\n"," 69% 31/45 [01:20<00:39,  2.79s/it]\u001b[A\n"," 71% 32/45 [01:23<00:37,  2.87s/it]\u001b[A\n"," 73% 33/45 [01:26<00:33,  2.82s/it]\u001b[A\n"," 76% 34/45 [01:29<00:31,  2.86s/it]\u001b[A\n"," 78% 35/45 [01:32<00:28,  2.86s/it]\u001b[A\n"," 80% 36/45 [01:34<00:25,  2.84s/it]\u001b[A\n"," 82% 37/45 [01:37<00:21,  2.63s/it]\u001b[A\n"," 84% 38/45 [01:39<00:17,  2.47s/it]\u001b[A\n"," 87% 39/45 [01:41<00:14,  2.40s/it]\u001b[A\n"," 89% 40/45 [01:44<00:13,  2.61s/it]\u001b[A\n"," 91% 41/45 [01:46<00:10,  2.54s/it]\u001b[A\n"," 93% 42/45 [01:49<00:07,  2.50s/it]\u001b[A\n"," 96% 43/45 [01:51<00:04,  2.40s/it]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 1.4751743078231812, 'eval_accuracy': 0.6202749900526107, 'eval_runtime': 117.7359, 'eval_samples_per_second': 192.116, 'eval_steps_per_second': 0.382, 'epoch': 11.0}\n","  4% 979/26700 [1:01:37<13:37:08,  1.91s/it]\n","100% 45/45 [01:52<00:00,  1.86s/it]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2841] 2023-09-03 17:17:22,950 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-979\n","[INFO|configuration_utils.py:460] 2023-09-03 17:17:22,956 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-979/config.json\n","[INFO|modeling_utils.py:1992] 2023-09-03 17:17:23,062 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-979/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-03 17:17:23,066 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-979/preprocessor_config.json\n","[INFO|trainer.py:2928] 2023-09-03 17:17:23,279 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-712] due to args.save_total_limit\n","{'loss': 1.2386, 'learning_rate': 0.0009632958801498127, 'epoch': 11.01}\n","{'loss': 1.0255, 'learning_rate': 0.0009629213483146068, 'epoch': 11.12}\n","{'loss': 1.084, 'learning_rate': 0.0009625468164794008, 'epoch': 11.24}\n","{'loss': 1.1203, 'learning_rate': 0.0009621722846441948, 'epoch': 11.35}\n","{'loss': 1.1042, 'learning_rate': 0.0009617977528089888, 'epoch': 11.46}\n","{'loss': 1.1245, 'learning_rate': 0.0009614232209737828, 'epoch': 11.57}\n","{'loss': 1.1158, 'learning_rate': 0.0009610486891385768, 'epoch': 11.69}\n","{'loss': 1.1404, 'learning_rate': 0.0009606741573033709, 'epoch': 11.8}\n","{'loss': 1.1333, 'learning_rate': 0.0009602996254681649, 'epoch': 11.91}\n","  4% 1067/26700 [1:05:15<13:21:14,  1.88s/it][INFO|trainer.py:3115] 2023-09-03 17:21:01,272 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3117] 2023-09-03 17:21:01,272 >>   Num examples = 22619\n","[INFO|trainer.py:3120] 2023-09-03 17:21:01,272 >>   Batch size = 512\n","\n","  0% 0/45 [00:00<?, ?it/s]\u001b[A\n","  4% 2/45 [00:02<00:53,  1.25s/it]\u001b[A\n","  7% 3/45 [00:05<01:19,  1.90s/it]\u001b[A\n","  9% 4/45 [00:07<01:28,  2.16s/it]\u001b[A\n"," 11% 5/45 [00:10<01:32,  2.31s/it]\u001b[A\n"," 13% 6/45 [00:13<01:39,  2.55s/it]\u001b[A\n"," 16% 7/45 [00:16<01:43,  2.71s/it]\u001b[A\n"," 18% 8/45 [00:19<01:45,  2.84s/it]\u001b[A\n"," 20% 9/45 [00:23<01:47,  2.98s/it]\u001b[A\n"," 22% 10/45 [00:26<01:48,  3.09s/it]\u001b[A\n"," 24% 11/45 [00:28<01:37,  2.88s/it]\u001b[A\n"," 27% 12/45 [00:31<01:32,  2.81s/it]\u001b[A\n"," 29% 13/45 [00:33<01:25,  2.68s/it]\u001b[A\n"," 31% 14/45 [00:36<01:24,  2.72s/it]\u001b[A\n"," 33% 15/45 [00:39<01:19,  2.65s/it]\u001b[A\n"," 36% 16/45 [00:41<01:17,  2.66s/it]\u001b[A\n"," 38% 17/45 [00:44<01:11,  2.57s/it]\u001b[A\n"," 40% 18/45 [00:46<01:05,  2.41s/it]\u001b[A\n"," 42% 19/45 [00:48<01:03,  2.45s/it]\u001b[A\n"," 44% 20/45 [00:51<01:03,  2.54s/it]\u001b[A\n"," 47% 21/45 [00:54<01:01,  2.56s/it]\u001b[A\n"," 49% 22/45 [00:56<00:57,  2.51s/it]\u001b[A\n"," 51% 23/45 [00:58<00:52,  2.41s/it]\u001b[A\n"," 53% 24/45 [01:01<00:53,  2.54s/it]\u001b[A\n"," 56% 25/45 [01:04<00:52,  2.63s/it]\u001b[A\n"," 58% 26/45 [01:06<00:46,  2.43s/it]\u001b[A\n"," 60% 27/45 [01:09<00:47,  2.62s/it]\u001b[A\n"," 62% 28/45 [01:12<00:46,  2.74s/it]\u001b[A\n"," 64% 29/45 [01:14<00:42,  2.64s/it]\u001b[A\n"," 67% 30/45 [01:17<00:39,  2.66s/it]\u001b[A\n"," 69% 31/45 [01:20<00:39,  2.82s/it]\u001b[A\n"," 71% 32/45 [01:23<00:37,  2.90s/it]\u001b[A\n"," 73% 33/45 [01:26<00:34,  2.86s/it]\u001b[A\n"," 76% 34/45 [01:29<00:31,  2.87s/it]\u001b[A\n"," 78% 35/45 [01:32<00:28,  2.89s/it]\u001b[A\n"," 80% 36/45 [01:35<00:25,  2.86s/it]\u001b[A\n"," 82% 37/45 [01:37<00:21,  2.64s/it]\u001b[A\n"," 84% 38/45 [01:39<00:17,  2.47s/it]\u001b[A\n"," 87% 39/45 [01:41<00:14,  2.39s/it]\u001b[A\n"," 89% 40/45 [01:44<00:12,  2.58s/it]\u001b[A\n"," 91% 41/45 [01:46<00:10,  2.53s/it]\u001b[A\n"," 93% 42/45 [01:49<00:07,  2.50s/it]\u001b[A\n"," 96% 43/45 [01:51<00:04,  2.40s/it]\u001b[A\n","                                             \n","\u001b[A{'eval_loss': 1.5046602487564087, 'eval_accuracy': 0.6207170962465184, 'eval_runtime': 117.7673, 'eval_samples_per_second': 192.065, 'eval_steps_per_second': 0.382, 'epoch': 12.0}\n","  4% 1068/26700 [1:07:13<13:21:12,  1.88s/it]\n","100% 45/45 [01:52<00:00,  1.86s/it]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2841] 2023-09-03 17:22:59,046 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-1068\n","[INFO|configuration_utils.py:460] 2023-09-03 17:22:59,052 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-1068/config.json\n","[INFO|modeling_utils.py:1992] 2023-09-03 17:22:59,162 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-1068/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-03 17:22:59,166 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-1068/preprocessor_config.json\n","[INFO|trainer.py:2928] 2023-09-03 17:22:59,378 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-801] due to args.save_total_limit\n","{'loss': 1.2009, 'learning_rate': 0.0009599250936329587, 'epoch': 12.02}\n","{'loss': 1.028, 'learning_rate': 0.0009595505617977528, 'epoch': 12.13}\n","{'loss': 1.0196, 'learning_rate': 0.0009591760299625468, 'epoch': 12.25}\n","{'loss': 1.074, 'learning_rate': 0.0009588014981273408, 'epoch': 12.36}\n","{'loss': 1.0442, 'learning_rate': 0.0009584269662921349, 'epoch': 12.47}\n","{'loss': 1.0433, 'learning_rate': 0.0009580524344569289, 'epoch': 12.58}\n","{'loss': 1.0942, 'learning_rate': 0.0009576779026217228, 'epoch': 12.7}\n","{'loss': 1.113, 'learning_rate': 0.0009573033707865169, 'epoch': 12.81}\n","{'loss': 1.0907, 'learning_rate': 0.0009569288389513109, 'epoch': 12.92}\n","  4% 1156/26700 [1:10:51<12:41:07,  1.79s/it][INFO|trainer.py:3115] 2023-09-03 17:26:37,347 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3117] 2023-09-03 17:26:37,347 >>   Num examples = 22619\n","[INFO|trainer.py:3120] 2023-09-03 17:26:37,348 >>   Batch size = 512\n","\n","  0% 0/45 [00:00<?, ?it/s]\u001b[A\n","  4% 2/45 [00:02<00:53,  1.24s/it]\u001b[A\n","  7% 3/45 [00:05<01:18,  1.88s/it]\u001b[A\n","  9% 4/45 [00:07<01:27,  2.13s/it]\u001b[A\n"," 11% 5/45 [00:10<01:32,  2.32s/it]\u001b[A\n"," 13% 6/45 [00:13<01:39,  2.56s/it]\u001b[A\n"," 16% 7/45 [00:16<01:42,  2.71s/it]\u001b[A\n"," 18% 8/45 [00:19<01:44,  2.82s/it]\u001b[A\n"," 20% 9/45 [00:22<01:47,  2.98s/it]\u001b[A\n"," 22% 10/45 [00:26<01:47,  3.08s/it]\u001b[A\n"," 24% 11/45 [00:28<01:37,  2.86s/it]\u001b[A\n"," 27% 12/45 [00:31<01:31,  2.79s/it]\u001b[A\n"," 29% 13/45 [00:33<01:24,  2.64s/it]\u001b[A\n"," 31% 14/45 [00:36<01:23,  2.68s/it]\u001b[A\n"," 33% 15/45 [00:38<01:19,  2.65s/it]\u001b[A\n"," 36% 16/45 [00:41<01:16,  2.65s/it]\u001b[A\n"," 38% 17/45 [00:43<01:11,  2.55s/it]\u001b[A\n"," 40% 18/45 [00:45<01:04,  2.39s/it]\u001b[A\n"," 42% 19/45 [00:48<01:03,  2.43s/it]\u001b[A\n"," 44% 20/45 [00:51<01:03,  2.54s/it]\u001b[A\n"," 47% 21/45 [00:53<01:01,  2.57s/it]\u001b[A\n"," 49% 22/45 [00:56<00:57,  2.50s/it]\u001b[A\n"," 51% 23/45 [00:58<00:52,  2.40s/it]\u001b[A\n"," 53% 24/45 [01:01<00:53,  2.54s/it]\u001b[A\n"," 56% 25/45 [01:04<00:52,  2.62s/it]\u001b[A\n"," 58% 26/45 [01:05<00:46,  2.42s/it]\u001b[A\n"," 60% 27/45 [01:09<00:46,  2.61s/it]\u001b[A\n"," 62% 28/45 [01:12<00:46,  2.74s/it]\u001b[A\n"," 64% 29/45 [01:14<00:42,  2.64s/it]\u001b[A\n"," 67% 30/45 [01:17<00:39,  2.64s/it]\u001b[A\n"," 69% 31/45 [01:20<00:39,  2.82s/it]\u001b[A\n"," 71% 32/45 [01:23<00:38,  2.97s/it]\u001b[A\n"," 73% 33/45 [01:26<00:34,  2.89s/it]\u001b[A\n"," 76% 34/45 [01:29<00:31,  2.88s/it]\u001b[A\n"," 78% 35/45 [01:32<00:28,  2.88s/it]\u001b[A\n"," 80% 36/45 [01:34<00:25,  2.86s/it]\u001b[A\n"," 82% 37/45 [01:37<00:21,  2.65s/it]\u001b[A\n"," 84% 38/45 [01:39<00:17,  2.48s/it]\u001b[A\n"," 87% 39/45 [01:41<00:14,  2.41s/it]\u001b[A\n"," 89% 40/45 [01:44<00:12,  2.58s/it]\u001b[A\n"," 91% 41/45 [01:46<00:10,  2.54s/it]\u001b[A\n"," 93% 42/45 [01:49<00:07,  2.51s/it]\u001b[A\n"," 96% 43/45 [01:51<00:04,  2.41s/it]\u001b[A\n","                                             \n","\u001b[A{'eval_loss': 1.5140482187271118, 'eval_accuracy': 0.617622352889164, 'eval_runtime': 117.7723, 'eval_samples_per_second': 192.057, 'eval_steps_per_second': 0.382, 'epoch': 13.0}\n","  4% 1157/26700 [1:12:49<12:41:05,  1.79s/it]\n","100% 45/45 [01:52<00:00,  1.87s/it]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2841] 2023-09-03 17:28:35,125 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-1157\n","[INFO|configuration_utils.py:460] 2023-09-03 17:28:35,130 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-1157/config.json\n","[INFO|modeling_utils.py:1992] 2023-09-03 17:28:35,242 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-1157/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-03 17:28:35,246 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-1157/preprocessor_config.json\n","[INFO|trainer.py:2928] 2023-09-03 17:28:35,471 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-890] due to args.save_total_limit\n","{'loss': 1.0108, 'learning_rate': 0.0009565543071161049, 'epoch': 13.03}\n","{'loss': 0.9757, 'learning_rate': 0.000956179775280899, 'epoch': 13.15}\n","{'loss': 1.0096, 'learning_rate': 0.0009558052434456929, 'epoch': 13.26}\n","{'loss': 0.9987, 'learning_rate': 0.0009554307116104869, 'epoch': 13.37}\n","{'loss': 1.0161, 'learning_rate': 0.000955056179775281, 'epoch': 13.48}\n","{'loss': 1.0355, 'learning_rate': 0.0009546816479400749, 'epoch': 13.6}\n","{'loss': 1.0477, 'learning_rate': 0.0009543071161048689, 'epoch': 13.71}\n","{'loss': 1.0438, 'learning_rate': 0.0009539325842696629, 'epoch': 13.82}\n","{'loss': 1.0578, 'learning_rate': 0.0009535580524344569, 'epoch': 13.93}\n","  5% 1245/26700 [1:16:27<12:47:59,  1.81s/it][INFO|trainer.py:3115] 2023-09-03 17:32:12,869 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3117] 2023-09-03 17:32:12,870 >>   Num examples = 22619\n","[INFO|trainer.py:3120] 2023-09-03 17:32:12,870 >>   Batch size = 512\n","\n","  0% 0/45 [00:00<?, ?it/s]\u001b[A\n","  4% 2/45 [00:02<00:53,  1.25s/it]\u001b[A\n","  7% 3/45 [00:05<01:19,  1.90s/it]\u001b[A\n","  9% 4/45 [00:07<01:27,  2.12s/it]\u001b[A\n"," 11% 5/45 [00:10<01:31,  2.30s/it]\u001b[A\n"," 13% 6/45 [00:13<01:39,  2.56s/it]\u001b[A\n"," 16% 7/45 [00:16<01:42,  2.71s/it]\u001b[A\n"," 18% 8/45 [00:19<01:44,  2.82s/it]\u001b[A\n"," 20% 9/45 [00:22<01:46,  2.95s/it]\u001b[A\n"," 22% 10/45 [00:26<01:47,  3.08s/it]\u001b[A\n"," 24% 11/45 [00:28<01:38,  2.89s/it]\u001b[A\n"," 27% 12/45 [00:31<01:33,  2.82s/it]\u001b[A\n"," 29% 13/45 [00:33<01:25,  2.67s/it]\u001b[A\n"," 31% 14/45 [00:36<01:23,  2.70s/it]\u001b[A\n"," 33% 15/45 [00:38<01:18,  2.63s/it]\u001b[A\n"," 36% 16/45 [00:41<01:18,  2.69s/it]\u001b[A\n"," 38% 17/45 [00:44<01:12,  2.59s/it]\u001b[A\n"," 40% 18/45 [00:46<01:05,  2.42s/it]\u001b[A\n"," 42% 19/45 [00:48<01:03,  2.44s/it]\u001b[A\n"," 44% 20/45 [00:51<01:03,  2.54s/it]\u001b[A\n"," 47% 21/45 [00:53<01:01,  2.57s/it]\u001b[A\n"," 49% 22/45 [00:56<00:58,  2.53s/it]\u001b[A\n"," 51% 23/45 [00:58<00:53,  2.42s/it]\u001b[A\n"," 53% 24/45 [01:01<00:53,  2.55s/it]\u001b[A\n"," 56% 25/45 [01:04<00:52,  2.61s/it]\u001b[A\n"," 58% 26/45 [01:06<00:45,  2.41s/it]\u001b[A\n"," 60% 27/45 [01:09<00:47,  2.62s/it]\u001b[A\n"," 62% 28/45 [01:12<00:46,  2.74s/it]\u001b[A\n"," 64% 29/45 [01:14<00:42,  2.64s/it]\u001b[A\n"," 67% 30/45 [01:17<00:39,  2.64s/it]\u001b[A\n"," 69% 31/45 [01:20<00:39,  2.80s/it]\u001b[A\n"," 71% 32/45 [01:23<00:38,  2.93s/it]\u001b[A\n"," 73% 33/45 [01:26<00:34,  2.87s/it]\u001b[A\n"," 76% 34/45 [01:29<00:31,  2.87s/it]\u001b[A\n"," 78% 35/45 [01:32<00:28,  2.87s/it]\u001b[A\n"," 80% 36/45 [01:35<00:25,  2.86s/it]\u001b[A\n"," 82% 37/45 [01:37<00:21,  2.69s/it]\u001b[A\n"," 84% 38/45 [01:39<00:17,  2.51s/it]\u001b[A\n"," 87% 39/45 [01:41<00:14,  2.43s/it]\u001b[A\n"," 89% 40/45 [01:44<00:13,  2.66s/it]\u001b[A\n"," 91% 41/45 [01:47<00:10,  2.57s/it]\u001b[A\n"," 93% 42/45 [01:49<00:07,  2.53s/it]\u001b[A\n"," 96% 43/45 [01:51<00:04,  2.45s/it]\u001b[A\n","                                             \n","\u001b[A{'eval_loss': 1.477753758430481, 'eval_accuracy': 0.6314602767584774, 'eval_runtime': 118.4237, 'eval_samples_per_second': 191.001, 'eval_steps_per_second': 0.38, 'epoch': 14.0}\n","  5% 1246/26700 [1:18:25<12:47:57,  1.81s/it]\n","100% 45/45 [01:52<00:00,  1.90s/it]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2841] 2023-09-03 17:34:11,298 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-1246\n","[INFO|configuration_utils.py:460] 2023-09-03 17:34:11,304 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-1246/config.json\n","[INFO|modeling_utils.py:1992] 2023-09-03 17:34:11,416 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-1246/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-03 17:34:11,420 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-1246/preprocessor_config.json\n","[INFO|trainer.py:2928] 2023-09-03 17:34:11,640 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-1068] due to args.save_total_limit\n","{'loss': 1.0248, 'learning_rate': 0.0009531835205992509, 'epoch': 14.04}\n","{'loss': 0.9673, 'learning_rate': 0.000952808988764045, 'epoch': 14.16}\n","{'loss': 0.9716, 'learning_rate': 0.000952434456928839, 'epoch': 14.27}\n","{'loss': 0.9334, 'learning_rate': 0.0009520599250936329, 'epoch': 14.38}\n","{'loss': 0.9811, 'learning_rate': 0.000951685393258427, 'epoch': 14.49}\n","{'loss': 0.9966, 'learning_rate': 0.000951310861423221, 'epoch': 14.61}\n","{'loss': 1.001, 'learning_rate': 0.000950936329588015, 'epoch': 14.72}\n","{'loss': 1.0138, 'learning_rate': 0.0009505617977528091, 'epoch': 14.83}\n","{'loss': 1.0005, 'learning_rate': 0.000950187265917603, 'epoch': 14.94}\n","  5% 1334/26700 [1:22:03<12:56:40,  1.84s/it][INFO|trainer.py:3115] 2023-09-03 17:37:49,446 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3117] 2023-09-03 17:37:49,447 >>   Num examples = 22619\n","[INFO|trainer.py:3120] 2023-09-03 17:37:49,447 >>   Batch size = 512\n","\n","  0% 0/45 [00:00<?, ?it/s]\u001b[A\n","  4% 2/45 [00:02<00:54,  1.27s/it]\u001b[A\n","  7% 3/45 [00:05<01:20,  1.91s/it]\u001b[A\n","  9% 4/45 [00:07<01:27,  2.14s/it]\u001b[A\n"," 11% 5/45 [00:10<01:31,  2.30s/it]\u001b[A\n"," 13% 6/45 [00:13<01:40,  2.56s/it]\u001b[A\n"," 16% 7/45 [00:16<01:44,  2.74s/it]\u001b[A\n"," 18% 8/45 [00:19<01:45,  2.85s/it]\u001b[A\n"," 20% 9/45 [00:22<01:46,  2.96s/it]\u001b[A\n"," 22% 10/45 [00:26<01:47,  3.06s/it]\u001b[A\n"," 24% 11/45 [00:28<01:37,  2.88s/it]\u001b[A\n"," 27% 12/45 [00:31<01:33,  2.82s/it]\u001b[A\n"," 29% 13/45 [00:33<01:25,  2.67s/it]\u001b[A\n"," 31% 14/45 [00:36<01:23,  2.69s/it]\u001b[A\n"," 33% 15/45 [00:38<01:18,  2.62s/it]\u001b[A\n"," 36% 16/45 [00:41<01:16,  2.65s/it]\u001b[A\n"," 38% 17/45 [00:44<01:12,  2.59s/it]\u001b[A\n"," 40% 18/45 [00:46<01:05,  2.43s/it]\u001b[A\n"," 42% 19/45 [00:48<01:03,  2.46s/it]\u001b[A\n"," 44% 20/45 [00:51<01:03,  2.55s/it]\u001b[A\n"," 47% 21/45 [00:54<01:01,  2.57s/it]\u001b[A\n"," 49% 22/45 [00:56<00:58,  2.55s/it]\u001b[A\n"," 51% 23/45 [00:58<00:54,  2.47s/it]\u001b[A\n"," 53% 24/45 [01:01<00:54,  2.58s/it]\u001b[A\n"," 56% 25/45 [01:04<00:52,  2.63s/it]\u001b[A\n"," 58% 26/45 [01:06<00:45,  2.42s/it]\u001b[A\n"," 60% 27/45 [01:09<00:46,  2.61s/it]\u001b[A\n"," 62% 28/45 [01:12<00:46,  2.76s/it]\u001b[A\n"," 64% 29/45 [01:14<00:42,  2.65s/it]\u001b[A\n"," 67% 30/45 [01:17<00:39,  2.65s/it]\u001b[A\n"," 69% 31/45 [01:20<00:39,  2.80s/it]\u001b[A\n"," 71% 32/45 [01:23<00:37,  2.89s/it]\u001b[A\n"," 73% 33/45 [01:26<00:34,  2.90s/it]\u001b[A\n"," 76% 34/45 [01:29<00:31,  2.88s/it]\u001b[A\n"," 78% 35/45 [01:32<00:28,  2.87s/it]\u001b[A\n"," 80% 36/45 [01:35<00:25,  2.84s/it]\u001b[A\n"," 82% 37/45 [01:37<00:21,  2.64s/it]\u001b[A\n"," 84% 38/45 [01:39<00:17,  2.48s/it]\u001b[A\n"," 87% 39/45 [01:41<00:14,  2.43s/it]\u001b[A\n"," 89% 40/45 [01:44<00:12,  2.60s/it]\u001b[A\n"," 91% 41/45 [01:47<00:10,  2.52s/it]\u001b[A\n"," 93% 42/45 [01:49<00:07,  2.48s/it]\u001b[A\n"," 96% 43/45 [01:51<00:04,  2.40s/it]\u001b[A\n","                                             \n","\u001b[A{'eval_loss': 1.5050203800201416, 'eval_accuracy': 0.6248728944692515, 'eval_runtime': 118.035, 'eval_samples_per_second': 191.63, 'eval_steps_per_second': 0.381, 'epoch': 15.0}\n","  5% 1335/26700 [1:24:01<12:56:38,  1.84s/it]\n","100% 45/45 [01:52<00:00,  1.86s/it]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2841] 2023-09-03 17:39:47,488 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-1335\n","[INFO|configuration_utils.py:460] 2023-09-03 17:39:47,494 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-1335/config.json\n","[INFO|modeling_utils.py:1992] 2023-09-03 17:39:47,614 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-1335/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-03 17:39:47,618 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-1335/preprocessor_config.json\n","[INFO|trainer.py:2928] 2023-09-03 17:39:47,840 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-1157] due to args.save_total_limit\n","{'loss': 0.943, 'learning_rate': 0.0009498127340823969, 'epoch': 15.06}\n","{'loss': 0.9672, 'learning_rate': 0.000949438202247191, 'epoch': 15.17}\n","{'loss': 0.9061, 'learning_rate': 0.000949063670411985, 'epoch': 15.28}\n","{'loss': 0.9149, 'learning_rate': 0.000948689138576779, 'epoch': 15.39}\n","{'loss': 0.9444, 'learning_rate': 0.0009483146067415731, 'epoch': 15.51}\n","{'loss': 0.9431, 'learning_rate': 0.000947940074906367, 'epoch': 15.62}\n","{'loss': 0.9609, 'learning_rate': 0.0009475655430711611, 'epoch': 15.73}\n","{'loss': 0.994, 'learning_rate': 0.0009471910112359551, 'epoch': 15.84}\n","{'loss': 0.9909, 'learning_rate': 0.0009468164794007491, 'epoch': 15.96}\n","  5% 1423/26700 [1:27:38<13:37:26,  1.94s/it][INFO|trainer.py:3115] 2023-09-03 17:43:24,697 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3117] 2023-09-03 17:43:24,697 >>   Num examples = 22619\n","[INFO|trainer.py:3120] 2023-09-03 17:43:24,697 >>   Batch size = 512\n","\n","  0% 0/45 [00:00<?, ?it/s]\u001b[A\n","  4% 2/45 [00:02<00:54,  1.26s/it]\u001b[A\n","  7% 3/45 [00:05<01:20,  1.92s/it]\u001b[A\n","  9% 4/45 [00:07<01:27,  2.14s/it]\u001b[A\n"," 11% 5/45 [00:10<01:31,  2.29s/it]\u001b[A\n"," 13% 6/45 [00:13<01:38,  2.53s/it]\u001b[A\n"," 16% 7/45 [00:16<01:42,  2.70s/it]\u001b[A\n"," 18% 8/45 [00:19<01:45,  2.85s/it]\u001b[A\n"," 20% 9/45 [00:22<01:46,  2.97s/it]\u001b[A\n"," 22% 10/45 [00:26<01:47,  3.07s/it]\u001b[A\n"," 24% 11/45 [00:28<01:36,  2.85s/it]\u001b[A\n"," 27% 12/45 [00:31<01:32,  2.80s/it]\u001b[A\n"," 29% 13/45 [00:33<01:26,  2.69s/it]\u001b[A\n"," 31% 14/45 [00:36<01:23,  2.71s/it]\u001b[A\n"," 33% 15/45 [00:38<01:18,  2.63s/it]\u001b[A\n"," 36% 16/45 [00:41<01:16,  2.64s/it]\u001b[A\n"," 38% 17/45 [00:43<01:11,  2.55s/it]\u001b[A\n"," 40% 18/45 [00:46<01:05,  2.42s/it]\u001b[A\n"," 42% 19/45 [00:48<01:03,  2.46s/it]\u001b[A\n"," 44% 20/45 [00:51<01:03,  2.55s/it]\u001b[A\n"," 47% 21/45 [00:53<01:01,  2.56s/it]\u001b[A\n"," 49% 22/45 [00:56<00:57,  2.50s/it]\u001b[A\n"," 51% 23/45 [00:58<00:53,  2.41s/it]\u001b[A\n"," 53% 24/45 [01:01<00:54,  2.58s/it]\u001b[A\n"," 56% 25/45 [01:04<00:52,  2.64s/it]\u001b[A\n"," 58% 26/45 [01:06<00:46,  2.43s/it]\u001b[A\n"," 60% 27/45 [01:09<00:47,  2.61s/it]\u001b[A\n"," 62% 28/45 [01:12<00:46,  2.74s/it]\u001b[A\n"," 64% 29/45 [01:14<00:42,  2.68s/it]\u001b[A\n"," 67% 30/45 [01:17<00:40,  2.68s/it]\u001b[A\n"," 69% 31/45 [01:20<00:39,  2.82s/it]\u001b[A\n"," 71% 32/45 [01:23<00:37,  2.88s/it]\u001b[A\n"," 73% 33/45 [01:26<00:34,  2.83s/it]\u001b[A\n"," 76% 34/45 [01:29<00:31,  2.86s/it]\u001b[A\n"," 78% 35/45 [01:32<00:28,  2.87s/it]\u001b[A\n"," 80% 36/45 [01:34<00:25,  2.85s/it]\u001b[A\n"," 82% 37/45 [01:37<00:21,  2.64s/it]\u001b[A\n"," 84% 38/45 [01:39<00:17,  2.47s/it]\u001b[A\n"," 87% 39/45 [01:41<00:14,  2.43s/it]\u001b[A\n"," 89% 40/45 [01:44<00:13,  2.63s/it]\u001b[A\n"," 91% 41/45 [01:46<00:10,  2.55s/it]\u001b[A\n"," 93% 42/45 [01:49<00:07,  2.50s/it]\u001b[A\n"," 96% 43/45 [01:51<00:04,  2.40s/it]\u001b[A\n","                                             \n","\u001b[A{'eval_loss': 1.5190531015396118, 'eval_accuracy': 0.6268181617224458, 'eval_runtime': 117.7567, 'eval_samples_per_second': 192.082, 'eval_steps_per_second': 0.382, 'epoch': 16.0}\n","  5% 1424/26700 [1:29:36<13:37:24,  1.94s/it]\n","100% 45/45 [01:52<00:00,  1.86s/it]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2841] 2023-09-03 17:45:22,459 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-1424\n","[INFO|configuration_utils.py:460] 2023-09-03 17:45:22,465 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-1424/config.json\n","[INFO|modeling_utils.py:1992] 2023-09-03 17:45:22,575 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-1424/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-03 17:45:22,579 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-1424/preprocessor_config.json\n","[INFO|trainer.py:2928] 2023-09-03 17:45:22,807 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-1246] due to args.save_total_limit\n","{'loss': 0.9134, 'learning_rate': 0.0009464419475655432, 'epoch': 16.07}\n","{'loss': 0.8566, 'learning_rate': 0.0009460674157303371, 'epoch': 16.18}\n","{'loss': 0.8618, 'learning_rate': 0.0009456928838951311, 'epoch': 16.29}\n","{'loss': 0.9042, 'learning_rate': 0.0009453183520599252, 'epoch': 16.4}\n","{'loss': 0.9202, 'learning_rate': 0.0009449438202247192, 'epoch': 16.52}\n","{'loss': 0.9443, 'learning_rate': 0.0009445692883895131, 'epoch': 16.63}\n","{'loss': 0.9384, 'learning_rate': 0.0009441947565543071, 'epoch': 16.74}\n","{'loss': 0.9417, 'learning_rate': 0.0009438202247191011, 'epoch': 16.85}\n","{'loss': 0.9694, 'learning_rate': 0.0009434456928838951, 'epoch': 16.97}\n","  6% 1512/26700 [1:33:15<13:42:57,  1.96s/it][INFO|trainer.py:3115] 2023-09-03 17:49:00,843 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3117] 2023-09-03 17:49:00,844 >>   Num examples = 22619\n","[INFO|trainer.py:3120] 2023-09-03 17:49:00,844 >>   Batch size = 512\n","\n","  0% 0/45 [00:00<?, ?it/s]\u001b[A\n","  4% 2/45 [00:02<00:54,  1.26s/it]\u001b[A\n","  7% 3/45 [00:05<01:20,  1.91s/it]\u001b[A\n","  9% 4/45 [00:07<01:29,  2.19s/it]\u001b[A\n"," 11% 5/45 [00:10<01:33,  2.33s/it]\u001b[A\n"," 13% 6/45 [00:13<01:40,  2.57s/it]\u001b[A\n"," 16% 7/45 [00:16<01:43,  2.72s/it]\u001b[A\n"," 18% 8/45 [00:19<01:45,  2.85s/it]\u001b[A\n"," 20% 9/45 [00:23<01:47,  2.98s/it]\u001b[A\n"," 22% 10/45 [00:26<01:47,  3.08s/it]\u001b[A\n"," 24% 11/45 [00:28<01:37,  2.87s/it]\u001b[A\n"," 27% 12/45 [00:31<01:32,  2.80s/it]\u001b[A\n"," 29% 13/45 [00:33<01:25,  2.66s/it]\u001b[A\n"," 31% 14/45 [00:36<01:23,  2.71s/it]\u001b[A\n"," 33% 15/45 [00:39<01:19,  2.64s/it]\u001b[A\n"," 36% 16/45 [00:41<01:16,  2.64s/it]\u001b[A\n"," 38% 17/45 [00:44<01:11,  2.55s/it]\u001b[A\n"," 40% 18/45 [00:46<01:04,  2.40s/it]\u001b[A\n"," 42% 19/45 [00:48<01:03,  2.44s/it]\u001b[A\n"," 44% 20/45 [00:51<01:04,  2.56s/it]\u001b[A\n"," 47% 21/45 [00:54<01:01,  2.58s/it]\u001b[A\n"," 49% 22/45 [00:56<00:57,  2.52s/it]\u001b[A\n"," 51% 23/45 [00:58<00:53,  2.42s/it]\u001b[A\n"," 53% 24/45 [01:01<00:53,  2.57s/it]\u001b[A\n"," 56% 25/45 [01:04<00:53,  2.67s/it]\u001b[A\n"," 58% 26/45 [01:06<00:46,  2.45s/it]\u001b[A\n"," 60% 27/45 [01:09<00:47,  2.63s/it]\u001b[A\n"," 62% 28/45 [01:12<00:46,  2.75s/it]\u001b[A\n"," 64% 29/45 [01:14<00:42,  2.65s/it]\u001b[A\n"," 67% 30/45 [01:17<00:40,  2.67s/it]\u001b[A\n"," 69% 31/45 [01:20<00:39,  2.81s/it]\u001b[A\n"," 71% 32/45 [01:23<00:37,  2.88s/it]\u001b[A\n"," 73% 33/45 [01:26<00:34,  2.84s/it]\u001b[A\n"," 76% 34/45 [01:29<00:31,  2.86s/it]\u001b[A\n"," 78% 35/45 [01:32<00:29,  2.91s/it]\u001b[A\n"," 80% 36/45 [01:35<00:25,  2.89s/it]\u001b[A\n"," 82% 37/45 [01:37<00:21,  2.67s/it]\u001b[A\n"," 84% 38/45 [01:39<00:17,  2.50s/it]\u001b[A\n"," 87% 39/45 [01:41<00:14,  2.42s/it]\u001b[A\n"," 89% 40/45 [01:44<00:13,  2.60s/it]\u001b[A\n"," 91% 41/45 [01:47<00:10,  2.56s/it]\u001b[A\n"," 93% 42/45 [01:49<00:07,  2.52s/it]\u001b[A\n"," 96% 43/45 [01:51<00:04,  2.42s/it]\u001b[A\n","                                             \n","\u001b[A{'eval_loss': 1.4998877048492432, 'eval_accuracy': 0.6305760643706618, 'eval_runtime': 118.1561, 'eval_samples_per_second': 191.433, 'eval_steps_per_second': 0.381, 'epoch': 17.0}\n","  6% 1513/26700 [1:35:13<13:42:55,  1.96s/it]\n","100% 45/45 [01:52<00:00,  1.87s/it]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2841] 2023-09-03 17:50:59,022 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-1513\n","[INFO|configuration_utils.py:460] 2023-09-03 17:50:59,028 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-1513/config.json\n","[INFO|modeling_utils.py:1992] 2023-09-03 17:50:59,144 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-1513/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-03 17:50:59,148 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-1513/preprocessor_config.json\n","[INFO|trainer.py:2928] 2023-09-03 17:50:59,367 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-1335] due to args.save_total_limit\n","{'loss': 0.8955, 'learning_rate': 0.0009430711610486892, 'epoch': 17.08}\n","{'loss': 0.8419, 'learning_rate': 0.0009426966292134832, 'epoch': 17.19}\n","{'loss': 0.8761, 'learning_rate': 0.0009423220973782771, 'epoch': 17.3}\n","{'loss': 0.8961, 'learning_rate': 0.0009419475655430712, 'epoch': 17.42}\n","{'loss': 0.8943, 'learning_rate': 0.0009415730337078652, 'epoch': 17.53}\n","{'loss': 0.914, 'learning_rate': 0.0009411985018726592, 'epoch': 17.64}\n","{'loss': 0.9106, 'learning_rate': 0.0009408239700374533, 'epoch': 17.75}\n","{'loss': 0.9433, 'learning_rate': 0.0009404494382022473, 'epoch': 17.87}\n","{'loss': 0.9548, 'learning_rate': 0.0009400749063670412, 'epoch': 17.98}\n","  6% 1601/26700 [1:38:51<13:09:05,  1.89s/it][INFO|trainer.py:3115] 2023-09-03 17:54:37,389 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3117] 2023-09-03 17:54:37,390 >>   Num examples = 22619\n","[INFO|trainer.py:3120] 2023-09-03 17:54:37,390 >>   Batch size = 512\n","\n","  0% 0/45 [00:00<?, ?it/s]\u001b[A\n","  4% 2/45 [00:02<00:53,  1.26s/it]\u001b[A\n","  7% 3/45 [00:05<01:19,  1.90s/it]\u001b[A\n","  9% 4/45 [00:07<01:27,  2.14s/it]\u001b[A\n"," 11% 5/45 [00:10<01:33,  2.33s/it]\u001b[A\n"," 13% 6/45 [00:13<01:40,  2.58s/it]\u001b[A\n"," 16% 7/45 [00:16<01:43,  2.72s/it]\u001b[A\n"," 18% 8/45 [00:19<01:45,  2.84s/it]\u001b[A\n"," 20% 9/45 [00:22<01:46,  2.97s/it]\u001b[A\n"," 22% 10/45 [00:26<01:48,  3.09s/it]\u001b[A\n"," 24% 11/45 [00:28<01:37,  2.87s/it]\u001b[A\n"," 27% 12/45 [00:31<01:32,  2.80s/it]\u001b[A\n"," 29% 13/45 [00:33<01:25,  2.66s/it]\u001b[A\n"," 31% 14/45 [00:36<01:24,  2.73s/it]\u001b[A\n"," 33% 15/45 [00:39<01:20,  2.68s/it]\u001b[A\n"," 36% 16/45 [00:41<01:17,  2.68s/it]\u001b[A\n"," 38% 17/45 [00:44<01:12,  2.59s/it]\u001b[A\n"," 40% 18/45 [00:46<01:05,  2.42s/it]\u001b[A\n"," 42% 19/45 [00:48<01:03,  2.45s/it]\u001b[A\n"," 44% 20/45 [00:51<01:04,  2.57s/it]\u001b[A\n"," 47% 21/45 [00:54<01:02,  2.60s/it]\u001b[A\n"," 49% 22/45 [00:56<00:58,  2.54s/it]\u001b[A\n"," 51% 23/45 [00:58<00:53,  2.43s/it]\u001b[A\n"," 53% 24/45 [01:01<00:53,  2.56s/it]\u001b[A\n"," 56% 25/45 [01:04<00:52,  2.63s/it]\u001b[A\n"," 58% 26/45 [01:06<00:46,  2.44s/it]\u001b[A\n"," 60% 27/45 [01:09<00:47,  2.63s/it]\u001b[A\n"," 62% 28/45 [01:12<00:46,  2.74s/it]\u001b[A\n"," 64% 29/45 [01:14<00:42,  2.64s/it]\u001b[A\n"," 67% 30/45 [01:17<00:39,  2.64s/it]\u001b[A\n"," 69% 31/45 [01:20<00:39,  2.81s/it]\u001b[A\n"," 71% 32/45 [01:23<00:37,  2.88s/it]\u001b[A\n"," 73% 33/45 [01:26<00:33,  2.83s/it]\u001b[A\n"," 76% 34/45 [01:29<00:31,  2.85s/it]\u001b[A\n"," 78% 35/45 [01:32<00:28,  2.86s/it]\u001b[A\n"," 80% 36/45 [01:35<00:25,  2.85s/it]\u001b[A\n"," 82% 37/45 [01:37<00:21,  2.65s/it]\u001b[A\n"," 84% 38/45 [01:39<00:17,  2.48s/it]\u001b[A\n"," 87% 39/45 [01:41<00:14,  2.41s/it]\u001b[A\n"," 89% 40/45 [01:44<00:12,  2.58s/it]\u001b[A\n"," 91% 41/45 [01:47<00:10,  2.53s/it]\u001b[A\n"," 93% 42/45 [01:49<00:07,  2.57s/it]\u001b[A\n"," 96% 43/45 [01:51<00:04,  2.46s/it]\u001b[A\n","                                             \n","\u001b[A{'eval_loss': 1.6449819803237915, 'eval_accuracy': 0.6135107652858216, 'eval_runtime': 118.2417, 'eval_samples_per_second': 191.295, 'eval_steps_per_second': 0.381, 'epoch': 18.0}\n","  6% 1602/26700 [1:40:49<13:09:03,  1.89s/it]\n","100% 45/45 [01:52<00:00,  1.90s/it]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2841] 2023-09-03 17:56:35,638 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-1602\n","[INFO|configuration_utils.py:460] 2023-09-03 17:56:35,644 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-1602/config.json\n","[INFO|modeling_utils.py:1992] 2023-09-03 17:56:35,756 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-1602/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-03 17:56:35,760 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-1602/preprocessor_config.json\n","[INFO|trainer.py:2928] 2023-09-03 17:56:35,990 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-1424] due to args.save_total_limit\n","{'loss': 0.8644, 'learning_rate': 0.0009397003745318353, 'epoch': 18.09}\n","{'loss': 0.8479, 'learning_rate': 0.0009393258426966292, 'epoch': 18.2}\n","{'loss': 0.8288, 'learning_rate': 0.0009389513108614232, 'epoch': 18.31}\n","{'loss': 0.8673, 'learning_rate': 0.0009385767790262173, 'epoch': 18.43}\n","{'loss': 0.9054, 'learning_rate': 0.0009382022471910112, 'epoch': 18.54}\n","{'loss': 0.8855, 'learning_rate': 0.0009378277153558052, 'epoch': 18.65}\n","{'loss': 0.8538, 'learning_rate': 0.0009374531835205993, 'epoch': 18.76}\n","{'loss': 0.8863, 'learning_rate': 0.0009370786516853933, 'epoch': 18.88}\n","{'loss': 0.8661, 'learning_rate': 0.0009367041198501873, 'epoch': 18.99}\n","  6% 1690/26700 [1:44:27<12:46:43,  1.84s/it][INFO|trainer.py:3115] 2023-09-03 18:00:13,610 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3117] 2023-09-03 18:00:13,610 >>   Num examples = 22619\n","[INFO|trainer.py:3120] 2023-09-03 18:00:13,610 >>   Batch size = 512\n","\n","  0% 0/45 [00:00<?, ?it/s]\u001b[A\n","  4% 2/45 [00:02<00:53,  1.25s/it]\u001b[A\n","  7% 3/45 [00:05<01:19,  1.90s/it]\u001b[A\n","  9% 4/45 [00:07<01:27,  2.13s/it]\u001b[A\n"," 11% 5/45 [00:10<01:32,  2.31s/it]\u001b[A\n"," 13% 6/45 [00:13<01:40,  2.57s/it]\u001b[A\n"," 16% 7/45 [00:16<01:43,  2.73s/it]\u001b[A\n"," 18% 8/45 [00:19<01:45,  2.84s/it]\u001b[A\n"," 20% 9/45 [00:22<01:46,  2.96s/it]\u001b[A\n"," 22% 10/45 [00:26<01:47,  3.08s/it]\u001b[A\n"," 24% 11/45 [00:28<01:38,  2.89s/it]\u001b[A\n"," 27% 12/45 [00:31<01:32,  2.81s/it]\u001b[A\n"," 29% 13/45 [00:33<01:25,  2.66s/it]\u001b[A\n"," 31% 14/45 [00:36<01:23,  2.69s/it]\u001b[A\n"," 33% 15/45 [00:38<01:18,  2.62s/it]\u001b[A\n"," 36% 16/45 [00:41<01:17,  2.66s/it]\u001b[A\n"," 38% 17/45 [00:44<01:11,  2.56s/it]\u001b[A\n"," 40% 18/45 [00:46<01:04,  2.40s/it]\u001b[A\n"," 42% 19/45 [00:48<01:03,  2.43s/it]\u001b[A\n"," 44% 20/45 [00:51<01:03,  2.52s/it]\u001b[A\n"," 47% 21/45 [00:53<01:01,  2.56s/it]\u001b[A\n"," 49% 22/45 [00:56<00:57,  2.52s/it]\u001b[A\n"," 51% 23/45 [00:58<00:53,  2.41s/it]\u001b[A\n"," 53% 24/45 [01:01<00:53,  2.55s/it]\u001b[A\n"," 56% 25/45 [01:04<00:52,  2.61s/it]\u001b[A\n"," 58% 26/45 [01:06<00:45,  2.40s/it]\u001b[A\n"," 60% 27/45 [01:09<00:46,  2.60s/it]\u001b[A\n"," 62% 28/45 [01:12<00:46,  2.75s/it]\u001b[A\n"," 64% 29/45 [01:14<00:42,  2.65s/it]\u001b[A\n"," 67% 30/45 [01:17<00:39,  2.65s/it]\u001b[A\n"," 69% 31/45 [01:20<00:39,  2.80s/it]\u001b[A\n"," 71% 32/45 [01:23<00:37,  2.89s/it]\u001b[A\n"," 73% 33/45 [01:26<00:35,  2.92s/it]\u001b[A\n"," 76% 34/45 [01:29<00:31,  2.90s/it]\u001b[A\n"," 78% 35/45 [01:32<00:28,  2.89s/it]\u001b[A\n"," 80% 36/45 [01:34<00:25,  2.85s/it]\u001b[A\n"," 82% 37/45 [01:37<00:21,  2.66s/it]\u001b[A\n"," 84% 38/45 [01:39<00:17,  2.51s/it]\u001b[A\n"," 87% 39/45 [01:41<00:14,  2.42s/it]\u001b[A\n"," 89% 40/45 [01:44<00:12,  2.59s/it]\u001b[A\n"," 91% 41/45 [01:46<00:10,  2.52s/it]\u001b[A\n"," 93% 42/45 [01:49<00:07,  2.49s/it]\u001b[A\n"," 96% 43/45 [01:51<00:04,  2.42s/it]\u001b[A\n","                                             \n","\u001b[A{'eval_loss': 1.52847421169281, 'eval_accuracy': 0.6429550378000796, 'eval_runtime': 117.9826, 'eval_samples_per_second': 191.715, 'eval_steps_per_second': 0.381, 'epoch': 19.0}\n","  6% 1691/26700 [1:46:25<12:46:41,  1.84s/it]\n","100% 45/45 [01:52<00:00,  1.89s/it]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2841] 2023-09-03 18:02:11,599 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-1691\n","[INFO|configuration_utils.py:460] 2023-09-03 18:02:11,604 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-1691/config.json\n","[INFO|modeling_utils.py:1992] 2023-09-03 18:02:11,718 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-1691/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-03 18:02:11,722 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-1691/preprocessor_config.json\n","[INFO|trainer.py:2928] 2023-09-03 18:02:11,949 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-1513] due to args.save_total_limit\n","{'loss': 0.8341, 'learning_rate': 0.0009363295880149813, 'epoch': 19.1}\n","{'loss': 0.7847, 'learning_rate': 0.0009359550561797753, 'epoch': 19.21}\n","{'loss': 0.8404, 'learning_rate': 0.0009355805243445693, 'epoch': 19.33}\n","{'loss': 0.8325, 'learning_rate': 0.0009352059925093634, 'epoch': 19.44}\n","{'loss': 0.8132, 'learning_rate': 0.0009348314606741574, 'epoch': 19.55}\n","{'loss': 0.8391, 'learning_rate': 0.0009344569288389512, 'epoch': 19.66}\n","{'loss': 0.8734, 'learning_rate': 0.0009340823970037453, 'epoch': 19.78}\n","{'loss': 0.8776, 'learning_rate': 0.0009337078651685393, 'epoch': 19.89}\n","{'loss': 0.8989, 'learning_rate': 0.0009333333333333333, 'epoch': 20.0}\n","  7% 1780/26700 [1:50:03<12:45:05,  1.84s/it][INFO|trainer.py:3115] 2023-09-03 18:05:49,597 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3117] 2023-09-03 18:05:49,597 >>   Num examples = 22619\n","[INFO|trainer.py:3120] 2023-09-03 18:05:49,597 >>   Batch size = 512\n","\n","  0% 0/45 [00:00<?, ?it/s]\u001b[A\n","  4% 2/45 [00:02<00:54,  1.26s/it]\u001b[A\n","  7% 3/45 [00:05<01:20,  1.91s/it]\u001b[A\n","  9% 4/45 [00:07<01:27,  2.13s/it]\u001b[A\n"," 11% 5/45 [00:10<01:31,  2.29s/it]\u001b[A\n"," 13% 6/45 [00:13<01:38,  2.53s/it]\u001b[A\n"," 16% 7/45 [00:16<01:42,  2.70s/it]\u001b[A\n"," 18% 8/45 [00:19<01:44,  2.82s/it]\u001b[A\n"," 20% 9/45 [00:22<01:45,  2.94s/it]\u001b[A\n"," 22% 10/45 [00:26<01:46,  3.05s/it]\u001b[A\n"," 24% 11/45 [00:28<01:37,  2.86s/it]\u001b[A\n"," 27% 12/45 [00:31<01:33,  2.83s/it]\u001b[A\n"," 29% 13/45 [00:33<01:25,  2.68s/it]\u001b[A\n"," 31% 14/45 [00:36<01:23,  2.70s/it]\u001b[A\n"," 33% 15/45 [00:38<01:18,  2.62s/it]\u001b[A\n"," 36% 16/45 [00:41<01:16,  2.63s/it]\u001b[A\n"," 38% 17/45 [00:44<01:13,  2.62s/it]\u001b[A\n"," 40% 18/45 [00:46<01:06,  2.46s/it]\u001b[A\n"," 42% 19/45 [00:48<01:04,  2.48s/it]\u001b[A\n"," 44% 20/45 [00:51<01:03,  2.56s/it]\u001b[A\n"," 47% 21/45 [00:53<01:01,  2.57s/it]\u001b[A\n"," 49% 22/45 [00:56<00:57,  2.52s/it]\u001b[A\n"," 51% 23/45 [00:58<00:53,  2.42s/it]\u001b[A\n"," 53% 24/45 [01:01<00:53,  2.56s/it]\u001b[A\n"," 56% 25/45 [01:04<00:52,  2.62s/it]\u001b[A\n"," 58% 26/45 [01:06<00:45,  2.41s/it]\u001b[A\n"," 60% 27/45 [01:09<00:46,  2.59s/it]\u001b[A\n"," 62% 28/45 [01:12<00:47,  2.77s/it]\u001b[A\n"," 64% 29/45 [01:14<00:43,  2.69s/it]\u001b[A\n"," 67% 30/45 [01:17<00:40,  2.68s/it]\u001b[A\n"," 69% 31/45 [01:20<00:39,  2.82s/it]\u001b[A\n"," 71% 32/45 [01:23<00:37,  2.89s/it]\u001b[A\n"," 73% 33/45 [01:26<00:35,  2.93s/it]\u001b[A\n"," 76% 34/45 [01:29<00:32,  2.93s/it]\u001b[A\n"," 78% 35/45 [01:32<00:29,  2.91s/it]\u001b[A\n"," 80% 36/45 [01:35<00:25,  2.88s/it]\u001b[A\n"," 82% 37/45 [01:37<00:21,  2.67s/it]\u001b[A\n"," 84% 38/45 [01:39<00:17,  2.51s/it]\u001b[A\n"," 87% 39/45 [01:41<00:14,  2.45s/it]\u001b[A\n"," 89% 40/45 [01:44<00:13,  2.62s/it]\u001b[A\n"," 91% 41/45 [01:47<00:10,  2.54s/it]\u001b[A\n"," 93% 42/45 [01:49<00:07,  2.51s/it]\u001b[A\n"," 96% 43/45 [01:51<00:04,  2.40s/it]\u001b[A\n","                                             \n","\u001b[A{'eval_loss': 1.5763956308364868, 'eval_accuracy': 0.6373844997568416, 'eval_runtime': 118.196, 'eval_samples_per_second': 191.369, 'eval_steps_per_second': 0.381, 'epoch': 20.0}\n","  7% 1780/26700 [1:52:02<12:45:05,  1.84s/it]\n","100% 45/45 [01:52<00:00,  1.86s/it]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2841] 2023-09-03 18:07:47,798 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-1780\n","[INFO|configuration_utils.py:460] 2023-09-03 18:07:47,804 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-1780/config.json\n","[INFO|modeling_utils.py:1992] 2023-09-03 18:07:47,924 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-1780/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-03 18:07:47,928 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-1780/preprocessor_config.json\n","[INFO|trainer.py:2928] 2023-09-03 18:07:48,144 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-1602] due to args.save_total_limit\n","{'loss': 0.7692, 'learning_rate': 0.0009329588014981274, 'epoch': 20.11}\n","{'loss': 0.8306, 'learning_rate': 0.0009325842696629213, 'epoch': 20.22}\n","{'loss': 0.772, 'learning_rate': 0.0009322097378277153, 'epoch': 20.34}\n","{'loss': 0.7899, 'learning_rate': 0.0009318352059925094, 'epoch': 20.45}\n","{'loss': 0.8254, 'learning_rate': 0.0009314606741573034, 'epoch': 20.56}\n","{'loss': 0.8172, 'learning_rate': 0.0009310861423220974, 'epoch': 20.67}\n","{'loss': 0.8229, 'learning_rate': 0.0009307116104868915, 'epoch': 20.79}\n","{'loss': 0.8653, 'learning_rate': 0.0009303370786516854, 'epoch': 20.9}\n","  7% 1868/26700 [1:55:40<13:03:11,  1.89s/it][INFO|trainer.py:3115] 2023-09-03 18:11:26,237 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3117] 2023-09-03 18:11:26,237 >>   Num examples = 22619\n","[INFO|trainer.py:3120] 2023-09-03 18:11:26,238 >>   Batch size = 512\n","\n","  0% 0/45 [00:00<?, ?it/s]\u001b[A\n","  4% 2/45 [00:02<00:53,  1.24s/it]\u001b[A\n","  7% 3/45 [00:05<01:21,  1.94s/it]\u001b[A\n","  9% 4/45 [00:07<01:28,  2.15s/it]\u001b[A\n"," 11% 5/45 [00:10<01:31,  2.30s/it]\u001b[A\n"," 13% 6/45 [00:13<01:39,  2.54s/it]\u001b[A\n"," 16% 7/45 [00:16<01:42,  2.69s/it]\u001b[A\n"," 18% 8/45 [00:19<01:44,  2.83s/it]\u001b[A\n"," 20% 9/45 [00:22<01:46,  2.95s/it]\u001b[A\n"," 22% 10/45 [00:26<01:47,  3.07s/it]\u001b[A\n"," 24% 11/45 [00:28<01:36,  2.85s/it]\u001b[A\n"," 27% 12/45 [00:31<01:32,  2.79s/it]\u001b[A\n"," 29% 13/45 [00:33<01:26,  2.70s/it]\u001b[A\n"," 31% 14/45 [00:36<01:26,  2.79s/it]\u001b[A\n"," 33% 15/45 [00:39<01:20,  2.69s/it]\u001b[A\n"," 36% 16/45 [00:41<01:17,  2.67s/it]\u001b[A\n"," 38% 17/45 [00:44<01:11,  2.56s/it]\u001b[A\n"," 40% 18/45 [00:46<01:06,  2.45s/it]\u001b[A\n"," 42% 19/45 [00:48<01:05,  2.51s/it]\u001b[A\n"," 44% 20/45 [00:51<01:04,  2.58s/it]\u001b[A\n"," 47% 21/45 [00:54<01:02,  2.58s/it]\u001b[A\n"," 49% 22/45 [00:56<00:57,  2.52s/it]\u001b[A\n"," 51% 23/45 [00:58<00:52,  2.41s/it]\u001b[A\n"," 53% 24/45 [01:01<00:53,  2.56s/it]\u001b[A\n"," 56% 25/45 [01:04<00:52,  2.62s/it]\u001b[A\n"," 58% 26/45 [01:06<00:45,  2.41s/it]\u001b[A\n"," 60% 27/45 [01:09<00:46,  2.59s/it]\u001b[A\n"," 62% 28/45 [01:12<00:46,  2.72s/it]\u001b[A\n"," 64% 29/45 [01:14<00:42,  2.65s/it]\u001b[A\n"," 67% 30/45 [01:17<00:39,  2.67s/it]\u001b[A\n"," 69% 31/45 [01:20<00:39,  2.82s/it]\u001b[A\n"," 71% 32/45 [01:23<00:37,  2.89s/it]\u001b[A\n"," 73% 33/45 [01:26<00:33,  2.83s/it]\u001b[A\n"," 76% 34/45 [01:29<00:31,  2.85s/it]\u001b[A\n"," 78% 35/45 [01:32<00:28,  2.87s/it]\u001b[A\n"," 80% 36/45 [01:35<00:25,  2.85s/it]\u001b[A\n"," 82% 37/45 [01:37<00:21,  2.65s/it]\u001b[A\n"," 84% 38/45 [01:39<00:17,  2.49s/it]\u001b[A\n"," 87% 39/45 [01:41<00:14,  2.42s/it]\u001b[A\n"," 89% 40/45 [01:44<00:13,  2.62s/it]\u001b[A\n"," 91% 41/45 [01:47<00:10,  2.54s/it]\u001b[A\n"," 93% 42/45 [01:49<00:07,  2.51s/it]\u001b[A\n"," 96% 43/45 [01:51<00:04,  2.41s/it]\u001b[A\n","                                             \n","\u001b[A{'eval_loss': 1.546256184577942, 'eval_accuracy': 0.6410097705468853, 'eval_runtime': 117.9584, 'eval_samples_per_second': 191.754, 'eval_steps_per_second': 0.381, 'epoch': 21.0}\n","  7% 1869/26700 [1:57:38<13:03:09,  1.89s/it]\n","100% 45/45 [01:52<00:00,  1.86s/it]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2841] 2023-09-03 18:13:24,202 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-1869\n","[INFO|configuration_utils.py:460] 2023-09-03 18:13:24,207 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-1869/config.json\n","[INFO|modeling_utils.py:1992] 2023-09-03 18:13:24,322 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-1869/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-03 18:13:24,326 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-1869/preprocessor_config.json\n","[INFO|trainer.py:2928] 2023-09-03 18:13:24,560 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-1691] due to args.save_total_limit\n","[INFO|trainer.py:1960] 2023-09-03 18:13:24,580 >> \n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","[INFO|trainer.py:2122] 2023-09-03 18:13:24,581 >> Loading best model from drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/checkpoint-979 (score: 1.4751743078231812).\n","{'train_runtime': 7058.9314, 'train_samples_per_second': 1916.508, 'train_steps_per_second': 3.782, 'train_loss': 1.2808075009851676, 'epoch': 21.0}\n","  7% 1869/26700 [1:57:38<26:03:02,  3.78s/it]\n","[INFO|trainer.py:2841] 2023-09-03 18:13:24,640 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/\n","[INFO|configuration_utils.py:460] 2023-09-03 18:13:24,645 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/config.json\n","[INFO|modeling_utils.py:1992] 2023-09-03 18:13:24,760 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-03 18:13:24,763 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_9/preprocessor_config.json\n","***** train metrics *****\n","  epoch                    =       21.0\n","  train_loss               =     1.2808\n","  train_runtime            = 1:57:38.93\n","  train_samples_per_second =   1916.508\n","  train_steps_per_second   =      3.782\n","[INFO|trainer.py:3115] 2023-09-03 18:13:24,780 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3117] 2023-09-03 18:13:24,780 >>   Num examples = 22619\n","[INFO|trainer.py:3120] 2023-09-03 18:13:24,781 >>   Batch size = 512\n","100% 45/45 [01:52<00:00,  2.51s/it]\n","***** eval metrics *****\n","  epoch                   =       21.0\n","  eval_accuracy           =     0.6203\n","  eval_loss               =     1.4752\n","  eval_runtime            = 0:01:58.35\n","  eval_samples_per_second =    191.107\n","  eval_steps_per_second   =       0.38\n","\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n","\u001b[34m\u001b[1mwandb\u001b[0m:                  eval/accuracy ▁▃▄▅▆▅▅▆▇▇▇▇▇████▇███▇\n","\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/loss █▅▅▃▂▃▃▃▂▂▁▁▁▁▁▁▁▂▁▂▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/runtime ▃▅▁▅█▆▅▁▃▃▂▃▃▆▄▂▅▅▄▅▃▆\n","\u001b[34m\u001b[1mwandb\u001b[0m:        eval/samples_per_second ▆▄█▄▁▃▄█▆▆▇▆▆▃▅▇▄▄▅▄▅▃\n","\u001b[34m\u001b[1mwandb\u001b[0m:          eval/steps_per_second ▆▃█▃▁▃▃█▆▅▆▆▆▃▅▆▅▅▅▅▅▃\n","\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███\n","\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███\n","\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate ███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss █▆▅▅▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▂▁▁▁▁▁▁▁▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n","\u001b[34m\u001b[1mwandb\u001b[0m:                  eval/accuracy 0.62027\n","\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/loss 1.47517\n","\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/runtime 118.3576\n","\u001b[34m\u001b[1mwandb\u001b[0m:        eval/samples_per_second 191.107\n","\u001b[34m\u001b[1mwandb\u001b[0m:          eval/steps_per_second 0.38\n","\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch 21.0\n","\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step 1869\n","\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate 0.00093\n","\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss 0.8653\n","\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos 9.603975511732654e+18\n","\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss 1.28081\n","\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime 7058.9314\n","\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second 1916.508\n","\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second 3.782\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33meager-darkness-19\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/u15048366/colabCnnIp102Run1/runs/2x5u6872\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n","\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230903_161520-2x5u6872/logs\u001b[0m\n"]}],"source":["!python drive/MyDrive/hons-research/script/cnn-run7.py \\\n","    --model_type efficientnet \\\n","    --dataset_name mnist \\\n","    --output_dir drive/MyDrive/hons-research/output/mnist_outputs_7/ \\\n","    --remove_unused_columns False \\\n","    --do_train \\\n","    --do_eval \\\n","    --push_to_hub False \\\n","    --learning_rate 0.001 \\\n","    --num_train_epochs 50 \\\n","    --per_device_train_batch_size 64 \\\n","    --per_device_eval_batch_size 64 \\\n","    --logging_strategy steps \\\n","    --logging_steps 10 \\\n","    --evaluation_strategy epoch \\\n","    --save_strategy epoch \\\n","    --load_best_model_at_end True \\\n","    --save_total_limit 3 \\\n","    --save_steps 500 \\\n","    --data_seed 7 \\\n","    --seed 7\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GJ6zuVm0Fa-J","outputId":"d5ce35ef-c608-475a-a066-dfae54e81601"},"outputs":[{"output_type":"stream","name":"stdout","text":["2023-09-03 18:15:37.055304: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mu15048366\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.9\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20230903_181541-q9iyy5f8\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mlikely-elevator-20\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/u15048366/colabCnnIp102Run1\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/u15048366/colabCnnIp102Run1/runs/q9iyy5f8\u001b[0m\n","09/03/2023 18:15:42 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n","09/03/2023 18:15:42 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n","_n_gpu=1,\n","adafactor=False,\n","adam_beta1=0.9,\n","adam_beta2=0.999,\n","adam_epsilon=1e-08,\n","auto_find_batch_size=False,\n","bf16=False,\n","bf16_full_eval=False,\n","data_seed=10,\n","dataloader_drop_last=False,\n","dataloader_num_workers=0,\n","dataloader_pin_memory=True,\n","ddp_backend=None,\n","ddp_broadcast_buffers=None,\n","ddp_bucket_cap_mb=None,\n","ddp_find_unused_parameters=None,\n","ddp_timeout=1800,\n","debug=[],\n","deepspeed=None,\n","disable_tqdm=False,\n","dispatch_batches=None,\n","do_eval=True,\n","do_predict=False,\n","do_train=True,\n","eval_accumulation_steps=None,\n","eval_delay=0,\n","eval_steps=None,\n","evaluation_strategy=epoch,\n","fp16=False,\n","fp16_backend=auto,\n","fp16_full_eval=False,\n","fp16_opt_level=O1,\n","fsdp=[],\n","fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n","fsdp_min_num_params=0,\n","fsdp_transformer_layer_cls_to_wrap=None,\n","full_determinism=False,\n","gradient_accumulation_steps=1,\n","gradient_checkpointing=False,\n","greater_is_better=False,\n","group_by_length=False,\n","half_precision_backend=auto,\n","hub_always_push=False,\n","hub_model_id=None,\n","hub_private_repo=False,\n","hub_strategy=every_save,\n","hub_token=<HUB_TOKEN>,\n","ignore_data_skip=False,\n","include_inputs_for_metrics=False,\n","jit_mode_eval=False,\n","label_names=None,\n","label_smoothing_factor=0.0,\n","learning_rate=0.001,\n","length_column_name=length,\n","load_best_model_at_end=True,\n","local_rank=0,\n","log_level=passive,\n","log_level_replica=warning,\n","log_on_each_node=True,\n","logging_dir=drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/runs/Sep03_18-15-42_ad494e439e78,\n","logging_first_step=False,\n","logging_nan_inf_filter=True,\n","logging_steps=10,\n","logging_strategy=steps,\n","lr_scheduler_type=linear,\n","max_grad_norm=1.0,\n","max_steps=-1,\n","metric_for_best_model=loss,\n","mp_parameters=,\n","no_cuda=False,\n","num_train_epochs=300.0,\n","optim=adamw_torch,\n","optim_args=None,\n","output_dir=drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/,\n","overwrite_output_dir=False,\n","past_index=-1,\n","per_device_eval_batch_size=512,\n","per_device_train_batch_size=512,\n","prediction_loss_only=False,\n","push_to_hub=False,\n","push_to_hub_model_id=None,\n","push_to_hub_organization=None,\n","push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n","ray_scope=last,\n","remove_unused_columns=False,\n","report_to=['wandb'],\n","resume_from_checkpoint=None,\n","run_name=drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/,\n","save_on_each_node=False,\n","save_safetensors=False,\n","save_steps=500.0,\n","save_strategy=epoch,\n","save_total_limit=3,\n","seed=10,\n","sharded_ddp=[],\n","skip_memory_metrics=True,\n","tf32=None,\n","torch_compile=False,\n","torch_compile_backend=None,\n","torch_compile_mode=None,\n","torchdynamo=None,\n","tpu_metrics_debug=False,\n","tpu_num_cores=None,\n","use_cpu=False,\n","use_ipex=False,\n","use_legacy_prediction_loop=False,\n","use_mps_device=False,\n","warmup_ratio=0.0,\n","warmup_steps=0,\n","weight_decay=0.0,\n",")\n","/usr/local/lib/python3.10/dist-packages/datasets/load.py:2086: FutureWarning: 'task' was deprecated in version 2.13.0 and will be removed in 3.0.0.\n","\n","  warnings.warn(\n","Resolving data files: 100% 45095/45095 [00:00<00:00, 380591.42it/s]\n","Resolving data files: 100% 22619/22619 [00:00<00:00, 365991.92it/s]\n","\n","\n","\n","None\n","\n","\n","\n","[INFO|configuration_utils.py:715] 2023-09-03 18:16:04,256 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--resnet-18/snapshots/f45a6faa12e0381f5620c5c8d7e916bca90f2c44/config.json\n","[INFO|configuration_utils.py:775] 2023-09-03 18:16:04,258 >> Model config ResNetConfig {\n","  \"_name_or_path\": \"microsoft/resnet-18\",\n","  \"architectures\": [\n","    \"ResNetForImageClassification\"\n","  ],\n","  \"depths\": [\n","    2,\n","    2,\n","    2,\n","    2\n","  ],\n","  \"downsample_in_first_stage\": false,\n","  \"embedding_size\": 64,\n","  \"finetuning_task\": \"image-classification\",\n","  \"hidden_act\": \"relu\",\n","  \"hidden_sizes\": [\n","    64,\n","    128,\n","    256,\n","    512\n","  ],\n","  \"id2label\": {\n","    \"0\": \"0\",\n","    \"1\": \"1\",\n","    \"10\": \"16\",\n","    \"100\": \"98\",\n","    \"101\": \"99\",\n","    \"11\": \"17\",\n","    \"12\": \"18\",\n","    \"13\": \"19\",\n","    \"14\": \"2\",\n","    \"15\": \"20\",\n","    \"16\": \"21\",\n","    \"17\": \"22\",\n","    \"18\": \"23\",\n","    \"19\": \"24\",\n","    \"2\": \"10\",\n","    \"20\": \"25\",\n","    \"21\": \"26\",\n","    \"22\": \"27\",\n","    \"23\": \"28\",\n","    \"24\": \"29\",\n","    \"25\": \"3\",\n","    \"26\": \"30\",\n","    \"27\": \"31\",\n","    \"28\": \"32\",\n","    \"29\": \"33\",\n","    \"3\": \"100\",\n","    \"30\": \"34\",\n","    \"31\": \"35\",\n","    \"32\": \"36\",\n","    \"33\": \"37\",\n","    \"34\": \"38\",\n","    \"35\": \"39\",\n","    \"36\": \"4\",\n","    \"37\": \"40\",\n","    \"38\": \"41\",\n","    \"39\": \"42\",\n","    \"4\": \"101\",\n","    \"40\": \"43\",\n","    \"41\": \"44\",\n","    \"42\": \"45\",\n","    \"43\": \"46\",\n","    \"44\": \"47\",\n","    \"45\": \"48\",\n","    \"46\": \"49\",\n","    \"47\": \"5\",\n","    \"48\": \"50\",\n","    \"49\": \"51\",\n","    \"5\": \"11\",\n","    \"50\": \"52\",\n","    \"51\": \"53\",\n","    \"52\": \"54\",\n","    \"53\": \"55\",\n","    \"54\": \"56\",\n","    \"55\": \"57\",\n","    \"56\": \"58\",\n","    \"57\": \"59\",\n","    \"58\": \"6\",\n","    \"59\": \"60\",\n","    \"6\": \"12\",\n","    \"60\": \"61\",\n","    \"61\": \"62\",\n","    \"62\": \"63\",\n","    \"63\": \"64\",\n","    \"64\": \"65\",\n","    \"65\": \"66\",\n","    \"66\": \"67\",\n","    \"67\": \"68\",\n","    \"68\": \"69\",\n","    \"69\": \"7\",\n","    \"7\": \"13\",\n","    \"70\": \"70\",\n","    \"71\": \"71\",\n","    \"72\": \"72\",\n","    \"73\": \"73\",\n","    \"74\": \"74\",\n","    \"75\": \"75\",\n","    \"76\": \"76\",\n","    \"77\": \"77\",\n","    \"78\": \"78\",\n","    \"79\": \"79\",\n","    \"8\": \"14\",\n","    \"80\": \"8\",\n","    \"81\": \"80\",\n","    \"82\": \"81\",\n","    \"83\": \"82\",\n","    \"84\": \"83\",\n","    \"85\": \"84\",\n","    \"86\": \"85\",\n","    \"87\": \"86\",\n","    \"88\": \"87\",\n","    \"89\": \"88\",\n","    \"9\": \"15\",\n","    \"90\": \"89\",\n","    \"91\": \"9\",\n","    \"92\": \"90\",\n","    \"93\": \"91\",\n","    \"94\": \"92\",\n","    \"95\": \"93\",\n","    \"96\": \"94\",\n","    \"97\": \"95\",\n","    \"98\": \"96\",\n","    \"99\": \"97\"\n","  },\n","  \"label2id\": {\n","    \"0\": \"0\",\n","    \"1\": \"1\",\n","    \"10\": \"2\",\n","    \"100\": \"3\",\n","    \"101\": \"4\",\n","    \"11\": \"5\",\n","    \"12\": \"6\",\n","    \"13\": \"7\",\n","    \"14\": \"8\",\n","    \"15\": \"9\",\n","    \"16\": \"10\",\n","    \"17\": \"11\",\n","    \"18\": \"12\",\n","    \"19\": \"13\",\n","    \"2\": \"14\",\n","    \"20\": \"15\",\n","    \"21\": \"16\",\n","    \"22\": \"17\",\n","    \"23\": \"18\",\n","    \"24\": \"19\",\n","    \"25\": \"20\",\n","    \"26\": \"21\",\n","    \"27\": \"22\",\n","    \"28\": \"23\",\n","    \"29\": \"24\",\n","    \"3\": \"25\",\n","    \"30\": \"26\",\n","    \"31\": \"27\",\n","    \"32\": \"28\",\n","    \"33\": \"29\",\n","    \"34\": \"30\",\n","    \"35\": \"31\",\n","    \"36\": \"32\",\n","    \"37\": \"33\",\n","    \"38\": \"34\",\n","    \"39\": \"35\",\n","    \"4\": \"36\",\n","    \"40\": \"37\",\n","    \"41\": \"38\",\n","    \"42\": \"39\",\n","    \"43\": \"40\",\n","    \"44\": \"41\",\n","    \"45\": \"42\",\n","    \"46\": \"43\",\n","    \"47\": \"44\",\n","    \"48\": \"45\",\n","    \"49\": \"46\",\n","    \"5\": \"47\",\n","    \"50\": \"48\",\n","    \"51\": \"49\",\n","    \"52\": \"50\",\n","    \"53\": \"51\",\n","    \"54\": \"52\",\n","    \"55\": \"53\",\n","    \"56\": \"54\",\n","    \"57\": \"55\",\n","    \"58\": \"56\",\n","    \"59\": \"57\",\n","    \"6\": \"58\",\n","    \"60\": \"59\",\n","    \"61\": \"60\",\n","    \"62\": \"61\",\n","    \"63\": \"62\",\n","    \"64\": \"63\",\n","    \"65\": \"64\",\n","    \"66\": \"65\",\n","    \"67\": \"66\",\n","    \"68\": \"67\",\n","    \"69\": \"68\",\n","    \"7\": \"69\",\n","    \"70\": \"70\",\n","    \"71\": \"71\",\n","    \"72\": \"72\",\n","    \"73\": \"73\",\n","    \"74\": \"74\",\n","    \"75\": \"75\",\n","    \"76\": \"76\",\n","    \"77\": \"77\",\n","    \"78\": \"78\",\n","    \"79\": \"79\",\n","    \"8\": \"80\",\n","    \"80\": \"81\",\n","    \"81\": \"82\",\n","    \"82\": \"83\",\n","    \"83\": \"84\",\n","    \"84\": \"85\",\n","    \"85\": \"86\",\n","    \"86\": \"87\",\n","    \"87\": \"88\",\n","    \"88\": \"89\",\n","    \"89\": \"90\",\n","    \"9\": \"91\",\n","    \"90\": \"92\",\n","    \"91\": \"93\",\n","    \"92\": \"94\",\n","    \"93\": \"95\",\n","    \"94\": \"96\",\n","    \"95\": \"97\",\n","    \"96\": \"98\",\n","    \"97\": \"99\",\n","    \"98\": \"100\",\n","    \"99\": \"101\"\n","  },\n","  \"layer_type\": \"basic\",\n","  \"model_type\": \"resnet\",\n","  \"num_channels\": 3,\n","  \"out_features\": [\n","    \"stage4\"\n","  ],\n","  \"out_indices\": [\n","    4\n","  ],\n","  \"stage_names\": [\n","    \"stem\",\n","    \"stage1\",\n","    \"stage2\",\n","    \"stage3\",\n","    \"stage4\"\n","  ],\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.33.0.dev0\"\n","}\n","\n","[INFO|modeling_utils.py:2857] 2023-09-03 18:16:04,260 >> loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--microsoft--resnet-18/snapshots/f45a6faa12e0381f5620c5c8d7e916bca90f2c44/model.safetensors\n","[INFO|modeling_utils.py:3643] 2023-09-03 18:16:04,375 >> All model checkpoint weights were used when initializing ResNetForImageClassification.\n","\n","[WARNING|modeling_utils.py:3664] 2023-09-03 18:16:04,376 >> Some weights of ResNetForImageClassification were not initialized from the model checkpoint at microsoft/resnet-18 and are newly initialized because the shapes did not match:\n","- classifier.1.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([102]) in the model instantiated\n","- classifier.1.weight: found shape torch.Size([1000, 512]) in the checkpoint and torch.Size([102, 512]) in the model instantiated\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","[INFO|image_processing_utils.py:369] 2023-09-03 18:16:04,639 >> loading configuration file preprocessor_config.json from cache at /root/.cache/huggingface/hub/models--microsoft--resnet-18/snapshots/f45a6faa12e0381f5620c5c8d7e916bca90f2c44/preprocessor_config.json\n","[WARNING|image_processing_auto.py:355] 2023-09-03 18:16:04,640 >> Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n","[INFO|image_processing_utils.py:732] 2023-09-03 18:16:04,641 >> size should be a dictionary on of the following set of keys: ({'width', 'height'}, {'shortest_edge'}, {'longest_edge', 'shortest_edge'}, {'longest_edge'}), got 224. Converted to {'shortest_edge': 224}.\n","[INFO|image_processing_utils.py:419] 2023-09-03 18:16:04,642 >> Image processor ConvNextImageProcessor {\n","  \"crop_pct\": 0.875,\n","  \"do_normalize\": true,\n","  \"do_rescale\": true,\n","  \"do_resize\": true,\n","  \"image_mean\": [\n","    0.485,\n","    0.456,\n","    0.406\n","  ],\n","  \"image_processor_type\": \"ConvNextImageProcessor\",\n","  \"image_std\": [\n","    0.229,\n","    0.224,\n","    0.225\n","  ],\n","  \"resample\": 3,\n","  \"rescale_factor\": 0.00392156862745098,\n","  \"size\": {\n","    \"shortest_edge\": 224\n","  }\n","}\n","\n","[INFO|trainer.py:1712] 2023-09-03 18:16:06,518 >> ***** Running training *****\n","[INFO|trainer.py:1713] 2023-09-03 18:16:06,519 >>   Num examples = 45,095\n","[INFO|trainer.py:1714] 2023-09-03 18:16:06,519 >>   Num Epochs = 300\n","[INFO|trainer.py:1715] 2023-09-03 18:16:06,519 >>   Instantaneous batch size per device = 512\n","[INFO|trainer.py:1718] 2023-09-03 18:16:06,519 >>   Total train batch size (w. parallel, distributed & accumulation) = 512\n","[INFO|trainer.py:1719] 2023-09-03 18:16:06,519 >>   Gradient Accumulation steps = 1\n","[INFO|trainer.py:1720] 2023-09-03 18:16:06,519 >>   Total optimization steps = 26,700\n","[INFO|trainer.py:1721] 2023-09-03 18:16:06,520 >>   Number of trainable parameters = 11,228,838\n","[INFO|integration_utils.py:716] 2023-09-03 18:16:06,521 >> Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n","{'loss': 3.5908, 'learning_rate': 0.0009996254681647941, 'epoch': 0.11}\n","{'loss': 2.9326, 'learning_rate': 0.000999250936329588, 'epoch': 0.22}\n","{'loss': 2.6769, 'learning_rate': 0.000998876404494382, 'epoch': 0.34}\n","{'loss': 2.5292, 'learning_rate': 0.000998501872659176, 'epoch': 0.45}\n","{'loss': 2.434, 'learning_rate': 0.00099812734082397, 'epoch': 0.56}\n","{'loss': 2.3752, 'learning_rate': 0.0009977528089887642, 'epoch': 0.67}\n","{'loss': 2.2756, 'learning_rate': 0.000997378277153558, 'epoch': 0.79}\n","{'loss': 2.2611, 'learning_rate': 0.000997003745318352, 'epoch': 0.9}\n","  0% 89/26700 [03:41<10:03:17,  1.36s/it][INFO|trainer.py:3115] 2023-09-03 18:19:47,648 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3117] 2023-09-03 18:19:47,648 >>   Num examples = 22619\n","[INFO|trainer.py:3120] 2023-09-03 18:19:47,648 >>   Batch size = 512\n","\n","  0% 0/45 [00:00<?, ?it/s]\u001b[A\n","  4% 2/45 [00:02<00:53,  1.25s/it]\u001b[A\n","  7% 3/45 [00:05<01:19,  1.90s/it]\u001b[A\n","  9% 4/45 [00:07<01:26,  2.11s/it]\u001b[A\n"," 11% 5/45 [00:10<01:31,  2.29s/it]\u001b[A\n"," 13% 6/45 [00:13<01:38,  2.54s/it]\u001b[A\n"," 16% 7/45 [00:16<01:45,  2.78s/it]\u001b[A\n"," 18% 8/45 [00:19<01:46,  2.87s/it]\u001b[A\n"," 20% 9/45 [00:23<01:47,  2.99s/it]\u001b[A\n"," 22% 10/45 [00:26<01:49,  3.13s/it]\u001b[A\n"," 24% 11/45 [00:28<01:38,  2.90s/it]\u001b[A\n"," 27% 12/45 [00:31<01:32,  2.82s/it]\u001b[A\n"," 29% 13/45 [00:33<01:25,  2.67s/it]\u001b[A\n"," 31% 14/45 [00:36<01:23,  2.69s/it]\u001b[A\n"," 33% 15/45 [00:39<01:19,  2.64s/it]\u001b[A\n"," 36% 16/45 [00:41<01:17,  2.67s/it]\u001b[A\n"," 38% 17/45 [00:44<01:11,  2.57s/it]\u001b[A\n"," 40% 18/45 [00:46<01:05,  2.41s/it]\u001b[A\n"," 42% 19/45 [00:48<01:03,  2.44s/it]\u001b[A\n"," 44% 20/45 [00:51<01:03,  2.54s/it]\u001b[A\n"," 47% 21/45 [00:54<01:02,  2.60s/it]\u001b[A\n"," 49% 22/45 [00:56<00:58,  2.53s/it]\u001b[A\n"," 51% 23/45 [00:58<00:53,  2.42s/it]\u001b[A\n"," 53% 24/45 [01:01<00:53,  2.55s/it]\u001b[A\n"," 56% 25/45 [01:04<00:52,  2.61s/it]\u001b[A\n"," 58% 26/45 [01:06<00:45,  2.42s/it]\u001b[A\n"," 60% 27/45 [01:09<00:46,  2.60s/it]\u001b[A\n"," 62% 28/45 [01:12<00:46,  2.73s/it]\u001b[A\n"," 64% 29/45 [01:14<00:42,  2.63s/it]\u001b[A\n"," 67% 30/45 [01:17<00:39,  2.64s/it]\u001b[A\n"," 69% 31/45 [01:20<00:39,  2.82s/it]\u001b[A\n"," 71% 32/45 [01:23<00:37,  2.91s/it]\u001b[A\n"," 73% 33/45 [01:26<00:34,  2.86s/it]\u001b[A\n"," 76% 34/45 [01:29<00:31,  2.85s/it]\u001b[A\n"," 78% 35/45 [01:32<00:28,  2.86s/it]\u001b[A\n"," 80% 36/45 [01:35<00:25,  2.84s/it]\u001b[A\n"," 82% 37/45 [01:37<00:21,  2.66s/it]\u001b[A\n"," 84% 38/45 [01:39<00:17,  2.50s/it]\u001b[A\n"," 87% 39/45 [01:41<00:14,  2.42s/it]\u001b[A\n"," 89% 40/45 [01:44<00:12,  2.60s/it]\u001b[A\n"," 91% 41/45 [01:47<00:10,  2.53s/it]\u001b[A\n"," 93% 42/45 [01:49<00:07,  2.57s/it]\u001b[A\n"," 96% 43/45 [01:51<00:04,  2.48s/it]\u001b[A\n","                                         \n","\u001b[A{'eval_loss': 2.3865621089935303, 'eval_accuracy': 0.4123082364383925, 'eval_runtime': 118.2973, 'eval_samples_per_second': 191.205, 'eval_steps_per_second': 0.38, 'epoch': 1.0}\n","  0% 89/26700 [05:39<10:03:17,  1.36s/it]\n","100% 45/45 [01:52<00:00,  1.91s/it]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2841] 2023-09-03 18:21:45,950 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/checkpoint-89\n","[INFO|configuration_utils.py:460] 2023-09-03 18:21:45,955 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/checkpoint-89/config.json\n","[INFO|modeling_utils.py:1992] 2023-09-03 18:21:46,065 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/checkpoint-89/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-03 18:21:46,069 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/checkpoint-89/preprocessor_config.json\n","{'loss': 2.1882, 'learning_rate': 0.000996629213483146, 'epoch': 1.01}\n","{'loss': 2.1331, 'learning_rate': 0.0009962546816479402, 'epoch': 1.12}\n","{'loss': 2.0133, 'learning_rate': 0.000995880149812734, 'epoch': 1.24}\n","{'loss': 2.0071, 'learning_rate': 0.0009955056179775281, 'epoch': 1.35}\n","{'loss': 1.9873, 'learning_rate': 0.0009951310861423222, 'epoch': 1.46}\n","{'loss': 1.9848, 'learning_rate': 0.0009947565543071161, 'epoch': 1.57}\n","{'loss': 1.996, 'learning_rate': 0.0009943820224719102, 'epoch': 1.69}\n","{'loss': 1.9678, 'learning_rate': 0.000994007490636704, 'epoch': 1.8}\n","{'loss': 1.878, 'learning_rate': 0.0009936329588014982, 'epoch': 1.91}\n","  1% 177/26700 [09:18<13:27:01,  1.83s/it][INFO|trainer.py:3115] 2023-09-03 18:25:25,216 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3117] 2023-09-03 18:25:25,216 >>   Num examples = 22619\n","[INFO|trainer.py:3120] 2023-09-03 18:25:25,216 >>   Batch size = 512\n","\n","  0% 0/45 [00:00<?, ?it/s]\u001b[A\n","  4% 2/45 [00:02<00:53,  1.25s/it]\u001b[A\n","  7% 3/45 [00:05<01:19,  1.89s/it]\u001b[A\n","  9% 4/45 [00:07<01:26,  2.11s/it]\u001b[A\n"," 11% 5/45 [00:10<01:31,  2.29s/it]\u001b[A\n"," 13% 6/45 [00:13<01:40,  2.56s/it]\u001b[A\n"," 16% 7/45 [00:16<01:43,  2.72s/it]\u001b[A\n"," 18% 8/45 [00:19<01:44,  2.84s/it]\u001b[A\n"," 20% 9/45 [00:22<01:46,  2.96s/it]\u001b[A\n"," 22% 10/45 [00:26<01:49,  3.12s/it]\u001b[A\n"," 24% 11/45 [00:28<01:38,  2.91s/it]\u001b[A\n"," 27% 12/45 [00:31<01:33,  2.83s/it]\u001b[A\n"," 29% 13/45 [00:33<01:25,  2.67s/it]\u001b[A\n"," 31% 14/45 [00:36<01:23,  2.69s/it]\u001b[A\n"," 33% 15/45 [00:39<01:19,  2.66s/it]\u001b[A\n"," 36% 16/45 [00:41<01:17,  2.69s/it]\u001b[A\n"," 38% 17/45 [00:44<01:12,  2.58s/it]\u001b[A\n"," 40% 18/45 [00:46<01:05,  2.42s/it]\u001b[A\n"," 42% 19/45 [00:48<01:03,  2.44s/it]\u001b[A\n"," 44% 20/45 [00:51<01:03,  2.53s/it]\u001b[A\n"," 47% 21/45 [00:54<01:02,  2.59s/it]\u001b[A\n"," 49% 22/45 [00:56<00:58,  2.55s/it]\u001b[A\n"," 51% 23/45 [00:58<00:53,  2.43s/it]\u001b[A\n"," 53% 24/45 [01:01<00:53,  2.56s/it]\u001b[A\n"," 56% 25/45 [01:04<00:52,  2.62s/it]\u001b[A\n"," 58% 26/45 [01:06<00:46,  2.43s/it]\u001b[A\n"," 60% 27/45 [01:09<00:47,  2.64s/it]\u001b[A\n"," 62% 28/45 [01:12<00:46,  2.75s/it]\u001b[A\n"," 64% 29/45 [01:14<00:42,  2.64s/it]\u001b[A\n"," 67% 30/45 [01:17<00:39,  2.65s/it]\u001b[A\n"," 69% 31/45 [01:20<00:39,  2.80s/it]\u001b[A\n"," 71% 32/45 [01:23<00:37,  2.91s/it]\u001b[A\n"," 73% 33/45 [01:26<00:34,  2.86s/it]\u001b[A\n"," 76% 34/45 [01:29<00:31,  2.87s/it]\u001b[A\n"," 78% 35/45 [01:32<00:28,  2.87s/it]\u001b[A\n"," 80% 36/45 [01:35<00:26,  2.89s/it]\u001b[A\n"," 82% 37/45 [01:37<00:21,  2.69s/it]\u001b[A\n"," 84% 38/45 [01:39<00:17,  2.52s/it]\u001b[A\n"," 87% 39/45 [01:41<00:14,  2.43s/it]\u001b[A\n"," 89% 40/45 [01:44<00:13,  2.60s/it]\u001b[A\n"," 91% 41/45 [01:47<00:10,  2.53s/it]\u001b[A\n"," 93% 42/45 [01:49<00:07,  2.51s/it]\u001b[A\n"," 96% 43/45 [01:52<00:04,  2.45s/it]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 2.234896183013916, 'eval_accuracy': 0.44652725584685443, 'eval_runtime': 118.4029, 'eval_samples_per_second': 191.034, 'eval_steps_per_second': 0.38, 'epoch': 2.0}\n","  1% 178/26700 [11:17<13:26:59,  1.83s/it]\n","100% 45/45 [01:52<00:00,  1.89s/it]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2841] 2023-09-03 18:27:23,625 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/checkpoint-178\n","[INFO|configuration_utils.py:460] 2023-09-03 18:27:23,631 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/checkpoint-178/config.json\n","[INFO|modeling_utils.py:1992] 2023-09-03 18:27:23,740 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/checkpoint-178/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-03 18:27:23,744 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/checkpoint-178/preprocessor_config.json\n","{'loss': 1.9342, 'learning_rate': 0.0009932584269662923, 'epoch': 2.02}\n","{'loss': 1.8325, 'learning_rate': 0.0009928838951310862, 'epoch': 2.13}\n","{'loss': 1.8438, 'learning_rate': 0.00099250936329588, 'epoch': 2.25}\n","{'loss': 1.7738, 'learning_rate': 0.0009921348314606742, 'epoch': 2.36}\n","{'loss': 1.7931, 'learning_rate': 0.0009917602996254683, 'epoch': 2.47}\n","{'loss': 1.7384, 'learning_rate': 0.0009913857677902622, 'epoch': 2.58}\n","{'loss': 1.7711, 'learning_rate': 0.0009910112359550563, 'epoch': 2.7}\n","{'loss': 1.8059, 'learning_rate': 0.0009906367041198501, 'epoch': 2.81}\n","{'loss': 1.784, 'learning_rate': 0.0009902621722846442, 'epoch': 2.92}\n","  1% 266/26700 [14:54<13:16:57,  1.81s/it][INFO|trainer.py:3115] 2023-09-03 18:31:00,701 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3117] 2023-09-03 18:31:00,701 >>   Num examples = 22619\n","[INFO|trainer.py:3120] 2023-09-03 18:31:00,701 >>   Batch size = 512\n","\n","  0% 0/45 [00:00<?, ?it/s]\u001b[A\n","  4% 2/45 [00:02<00:57,  1.35s/it]\u001b[A\n","  7% 3/45 [00:05<01:21,  1.94s/it]\u001b[A\n","  9% 4/45 [00:07<01:27,  2.14s/it]\u001b[A\n"," 11% 5/45 [00:10<01:31,  2.30s/it]\u001b[A\n"," 13% 6/45 [00:13<01:41,  2.60s/it]\u001b[A\n"," 16% 7/45 [00:16<01:46,  2.80s/it]\u001b[A\n"," 18% 8/45 [00:20<01:46,  2.88s/it]\u001b[A\n"," 20% 9/45 [00:23<01:47,  2.99s/it]\u001b[A\n"," 22% 10/45 [00:26<01:48,  3.10s/it]\u001b[A\n"," 24% 11/45 [00:29<01:38,  2.90s/it]\u001b[A\n"," 27% 12/45 [00:31<01:33,  2.84s/it]\u001b[A\n"," 29% 13/45 [00:34<01:25,  2.68s/it]\u001b[A\n"," 31% 14/45 [00:36<01:23,  2.70s/it]\u001b[A\n"," 33% 15/45 [00:39<01:18,  2.63s/it]\u001b[A\n"," 36% 16/45 [00:41<01:16,  2.65s/it]\u001b[A\n"," 38% 17/45 [00:44<01:12,  2.59s/it]\u001b[A\n"," 40% 18/45 [00:46<01:05,  2.42s/it]\u001b[A\n"," 42% 19/45 [00:48<01:03,  2.45s/it]\u001b[A\n"," 44% 20/45 [00:51<01:03,  2.54s/it]\u001b[A\n"," 47% 21/45 [00:54<01:01,  2.56s/it]\u001b[A\n"," 49% 22/45 [00:56<00:57,  2.52s/it]\u001b[A\n"," 51% 23/45 [00:58<00:53,  2.42s/it]\u001b[A\n"," 53% 24/45 [01:01<00:53,  2.55s/it]\u001b[A\n"," 56% 25/45 [01:04<00:52,  2.61s/it]\u001b[A\n"," 58% 26/45 [01:06<00:45,  2.40s/it]\u001b[A\n"," 60% 27/45 [01:09<00:46,  2.60s/it]\u001b[A\n"," 62% 28/45 [01:12<00:46,  2.75s/it]\u001b[A\n"," 64% 29/45 [01:14<00:42,  2.65s/it]\u001b[A\n"," 67% 30/45 [01:17<00:39,  2.65s/it]\u001b[A\n"," 69% 31/45 [01:20<00:39,  2.81s/it]\u001b[A\n"," 71% 32/45 [01:23<00:37,  2.88s/it]\u001b[A\n"," 73% 33/45 [01:26<00:34,  2.87s/it]\u001b[A\n"," 76% 34/45 [01:29<00:31,  2.87s/it]\u001b[A\n"," 78% 35/45 [01:32<00:28,  2.87s/it]\u001b[A\n"," 80% 36/45 [01:35<00:25,  2.84s/it]\u001b[A\n"," 82% 37/45 [01:37<00:21,  2.65s/it]\u001b[A\n"," 84% 38/45 [01:39<00:17,  2.50s/it]\u001b[A\n"," 87% 39/45 [01:41<00:14,  2.43s/it]\u001b[A\n"," 89% 40/45 [01:44<00:13,  2.60s/it]\u001b[A\n"," 91% 41/45 [01:47<00:10,  2.53s/it]\u001b[A\n"," 93% 42/45 [01:49<00:07,  2.49s/it]\u001b[A\n"," 96% 43/45 [01:51<00:04,  2.41s/it]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 1.8906512260437012, 'eval_accuracy': 0.5063000132631859, 'eval_runtime': 118.5003, 'eval_samples_per_second': 190.877, 'eval_steps_per_second': 0.38, 'epoch': 3.0}\n","  1% 267/26700 [16:52<13:16:55,  1.81s/it]\n","100% 45/45 [01:52<00:00,  1.86s/it]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2841] 2023-09-03 18:32:59,207 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/checkpoint-267\n","[INFO|configuration_utils.py:460] 2023-09-03 18:32:59,213 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/checkpoint-267/config.json\n","[INFO|modeling_utils.py:1992] 2023-09-03 18:32:59,321 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/checkpoint-267/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-03 18:32:59,324 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/checkpoint-267/preprocessor_config.json\n","{'loss': 1.7822, 'learning_rate': 0.0009898876404494383, 'epoch': 3.03}\n","{'loss': 1.6526, 'learning_rate': 0.0009895131086142322, 'epoch': 3.15}\n","{'loss': 1.6639, 'learning_rate': 0.000989138576779026, 'epoch': 3.26}\n","{'loss': 1.6721, 'learning_rate': 0.0009887640449438202, 'epoch': 3.37}\n","{'loss': 1.6426, 'learning_rate': 0.0009883895131086143, 'epoch': 3.48}\n","{'loss': 1.6617, 'learning_rate': 0.0009880149812734082, 'epoch': 3.6}\n","{'loss': 1.664, 'learning_rate': 0.0009876404494382023, 'epoch': 3.71}\n","{'loss': 1.6548, 'learning_rate': 0.0009872659176029962, 'epoch': 3.82}\n","{'loss': 1.6691, 'learning_rate': 0.0009868913857677903, 'epoch': 3.93}\n","  1% 355/26700 [20:30<14:02:57,  1.92s/it][INFO|trainer.py:3115] 2023-09-03 18:36:37,191 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3117] 2023-09-03 18:36:37,192 >>   Num examples = 22619\n","[INFO|trainer.py:3120] 2023-09-03 18:36:37,192 >>   Batch size = 512\n","\n","  0% 0/45 [00:00<?, ?it/s]\u001b[A\n","  4% 2/45 [00:02<00:54,  1.27s/it]\u001b[A\n","  7% 3/45 [00:05<01:22,  1.97s/it]\u001b[A\n","  9% 4/45 [00:08<01:29,  2.18s/it]\u001b[A\n"," 11% 5/45 [00:10<01:33,  2.33s/it]\u001b[A\n"," 13% 6/45 [00:13<01:39,  2.56s/it]\u001b[A\n"," 16% 7/45 [00:16<01:43,  2.72s/it]\u001b[A\n"," 18% 8/45 [00:19<01:45,  2.85s/it]\u001b[A\n"," 20% 9/45 [00:23<01:46,  2.96s/it]\u001b[A\n"," 22% 10/45 [00:26<01:47,  3.07s/it]\u001b[A\n"," 24% 11/45 [00:28<01:37,  2.86s/it]\u001b[A\n"," 27% 12/45 [00:31<01:32,  2.81s/it]\u001b[A\n"," 29% 13/45 [00:33<01:26,  2.70s/it]\u001b[A\n"," 31% 14/45 [00:36<01:24,  2.72s/it]\u001b[A\n"," 33% 15/45 [00:39<01:19,  2.65s/it]\u001b[A\n"," 36% 16/45 [00:41<01:17,  2.66s/it]\u001b[A\n"," 38% 17/45 [00:44<01:11,  2.57s/it]\u001b[A\n"," 40% 18/45 [00:46<01:05,  2.43s/it]\u001b[A\n"," 42% 19/45 [00:48<01:04,  2.47s/it]\u001b[A\n"," 44% 20/45 [00:51<01:03,  2.56s/it]\u001b[A\n"," 47% 21/45 [00:54<01:01,  2.56s/it]\u001b[A\n"," 49% 22/45 [00:56<00:57,  2.51s/it]\u001b[A\n"," 51% 23/45 [00:58<00:52,  2.40s/it]\u001b[A\n"," 53% 24/45 [01:01<00:54,  2.58s/it]\u001b[A\n"," 56% 25/45 [01:04<00:52,  2.64s/it]\u001b[A\n"," 58% 26/45 [01:06<00:46,  2.43s/it]\u001b[A\n"," 60% 27/45 [01:09<00:46,  2.61s/it]\u001b[A\n"," 62% 28/45 [01:12<00:46,  2.74s/it]\u001b[A\n"," 64% 29/45 [01:15<00:43,  2.71s/it]\u001b[A\n"," 67% 30/45 [01:17<00:40,  2.70s/it]\u001b[A\n"," 69% 31/45 [01:20<00:39,  2.83s/it]\u001b[A\n"," 71% 32/45 [01:23<00:37,  2.89s/it]\u001b[A\n"," 73% 33/45 [01:26<00:34,  2.85s/it]\u001b[A\n"," 76% 34/45 [01:29<00:31,  2.87s/it]\u001b[A\n"," 78% 35/45 [01:32<00:28,  2.87s/it]\u001b[A\n"," 80% 36/45 [01:35<00:25,  2.84s/it]\u001b[A\n"," 82% 37/45 [01:37<00:21,  2.63s/it]\u001b[A\n"," 84% 38/45 [01:39<00:17,  2.47s/it]\u001b[A\n"," 87% 39/45 [01:41<00:14,  2.40s/it]\u001b[A\n"," 89% 40/45 [01:44<00:12,  2.59s/it]\u001b[A\n"," 91% 41/45 [01:47<00:10,  2.51s/it]\u001b[A\n"," 93% 42/45 [01:49<00:07,  2.48s/it]\u001b[A\n"," 96% 43/45 [01:51<00:04,  2.39s/it]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 1.782896637916565, 'eval_accuracy': 0.5391042928511428, 'eval_runtime': 117.9152, 'eval_samples_per_second': 191.824, 'eval_steps_per_second': 0.382, 'epoch': 4.0}\n","  1% 356/26700 [22:28<14:02:55,  1.92s/it]\n","100% 45/45 [01:52<00:00,  1.85s/it]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2841] 2023-09-03 18:38:35,112 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/checkpoint-356\n","[INFO|configuration_utils.py:460] 2023-09-03 18:38:35,117 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/checkpoint-356/config.json\n","[INFO|modeling_utils.py:1992] 2023-09-03 18:38:35,236 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/checkpoint-356/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-03 18:38:35,240 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/checkpoint-356/preprocessor_config.json\n","[INFO|trainer.py:2928] 2023-09-03 18:38:35,447 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/checkpoint-89] due to args.save_total_limit\n","{'loss': 1.5646, 'learning_rate': 0.0009865168539325844, 'epoch': 4.04}\n","{'loss': 1.5461, 'learning_rate': 0.0009861423220973782, 'epoch': 4.16}\n","{'loss': 1.5049, 'learning_rate': 0.0009857677902621723, 'epoch': 4.27}\n","{'loss': 1.5536, 'learning_rate': 0.0009853932584269664, 'epoch': 4.38}\n","{'loss': 1.5435, 'learning_rate': 0.0009850187265917603, 'epoch': 4.49}\n","{'loss': 1.4963, 'learning_rate': 0.0009846441947565542, 'epoch': 4.61}\n","{'loss': 1.5583, 'learning_rate': 0.0009842696629213483, 'epoch': 4.72}\n","{'loss': 1.5857, 'learning_rate': 0.0009838951310861424, 'epoch': 4.83}\n","{'loss': 1.5475, 'learning_rate': 0.0009835205992509363, 'epoch': 4.94}\n","  2% 444/26700 [26:06<14:31:31,  1.99s/it][INFO|trainer.py:3115] 2023-09-03 18:42:13,529 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3117] 2023-09-03 18:42:13,529 >>   Num examples = 22619\n","[INFO|trainer.py:3120] 2023-09-03 18:42:13,529 >>   Batch size = 512\n","\n","  0% 0/45 [00:00<?, ?it/s]\u001b[A\n","  4% 2/45 [00:02<00:53,  1.25s/it]\u001b[A\n","  7% 3/45 [00:05<01:20,  1.91s/it]\u001b[A\n","  9% 4/45 [00:07<01:29,  2.17s/it]\u001b[A\n"," 11% 5/45 [00:10<01:32,  2.32s/it]\u001b[A\n"," 13% 6/45 [00:13<01:40,  2.56s/it]\u001b[A\n"," 16% 7/45 [00:16<01:43,  2.72s/it]\u001b[A\n"," 18% 8/45 [00:19<01:45,  2.86s/it]\u001b[A\n"," 20% 9/45 [00:23<01:47,  2.98s/it]\u001b[A\n"," 22% 10/45 [00:26<01:48,  3.09s/it]\u001b[A\n"," 24% 11/45 [00:28<01:37,  2.88s/it]\u001b[A\n"," 27% 12/45 [00:31<01:32,  2.81s/it]\u001b[A\n"," 29% 13/45 [00:33<01:25,  2.68s/it]\u001b[A\n"," 31% 14/45 [00:36<01:24,  2.73s/it]\u001b[A\n"," 33% 15/45 [00:39<01:19,  2.65s/it]\u001b[A\n"," 36% 16/45 [00:41<01:16,  2.65s/it]\u001b[A\n"," 38% 17/45 [00:44<01:11,  2.55s/it]\u001b[A\n"," 40% 18/45 [00:46<01:04,  2.39s/it]\u001b[A\n"," 42% 19/45 [00:48<01:03,  2.44s/it]\u001b[A\n"," 44% 20/45 [00:51<01:03,  2.56s/it]\u001b[A\n"," 47% 21/45 [00:54<01:01,  2.57s/it]\u001b[A\n"," 49% 22/45 [00:56<00:57,  2.51s/it]\u001b[A\n"," 51% 23/45 [00:58<00:52,  2.40s/it]\u001b[A\n"," 53% 24/45 [01:01<00:53,  2.55s/it]\u001b[A\n"," 56% 25/45 [01:04<00:52,  2.65s/it]\u001b[A\n"," 58% 26/45 [01:06<00:46,  2.43s/it]\u001b[A\n"," 60% 27/45 [01:09<00:46,  2.61s/it]\u001b[A\n"," 62% 28/45 [01:12<00:46,  2.74s/it]\u001b[A\n"," 64% 29/45 [01:14<00:42,  2.65s/it]\u001b[A\n"," 67% 30/45 [01:17<00:39,  2.66s/it]\u001b[A\n"," 69% 31/45 [01:20<00:39,  2.82s/it]\u001b[A\n"," 71% 32/45 [01:23<00:37,  2.89s/it]\u001b[A\n"," 73% 33/45 [01:26<00:34,  2.85s/it]\u001b[A\n"," 76% 34/45 [01:29<00:31,  2.88s/it]\u001b[A\n"," 78% 35/45 [01:32<00:29,  2.92s/it]\u001b[A\n"," 80% 36/45 [01:35<00:25,  2.88s/it]\u001b[A\n"," 82% 37/45 [01:37<00:21,  2.67s/it]\u001b[A\n"," 84% 38/45 [01:39<00:17,  2.50s/it]\u001b[A\n"," 87% 39/45 [01:41<00:14,  2.42s/it]\u001b[A\n"," 89% 40/45 [01:44<00:13,  2.65s/it]\u001b[A\n"," 91% 41/45 [01:47<00:10,  2.58s/it]\u001b[A\n"," 93% 42/45 [01:49<00:07,  2.53s/it]\u001b[A\n"," 96% 43/45 [01:52<00:04,  2.43s/it]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 1.6813322305679321, 'eval_accuracy': 0.5600159158229807, 'eval_runtime': 118.2546, 'eval_samples_per_second': 191.274, 'eval_steps_per_second': 0.381, 'epoch': 5.0}\n","  2% 445/26700 [28:05<14:31:29,  1.99s/it]\n","100% 45/45 [01:52<00:00,  1.88s/it]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2841] 2023-09-03 18:44:11,788 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/checkpoint-445\n","[INFO|configuration_utils.py:460] 2023-09-03 18:44:11,794 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/checkpoint-445/config.json\n","[INFO|modeling_utils.py:1992] 2023-09-03 18:44:11,903 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/checkpoint-445/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-03 18:44:11,906 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/checkpoint-445/preprocessor_config.json\n","[INFO|trainer.py:2928] 2023-09-03 18:44:12,138 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/checkpoint-178] due to args.save_total_limit\n","{'loss': 1.5564, 'learning_rate': 0.0009831460674157304, 'epoch': 5.06}\n","{'loss': 1.4392, 'learning_rate': 0.0009827715355805243, 'epoch': 5.17}\n","{'loss': 1.399, 'learning_rate': 0.0009823970037453184, 'epoch': 5.28}\n","{'loss': 1.4596, 'learning_rate': 0.0009820224719101125, 'epoch': 5.39}\n","{'loss': 1.4729, 'learning_rate': 0.0009816479400749064, 'epoch': 5.51}\n","{'loss': 1.4263, 'learning_rate': 0.0009812734082397002, 'epoch': 5.62}\n","{'loss': 1.4737, 'learning_rate': 0.0009808988764044943, 'epoch': 5.73}\n","{'loss': 1.5023, 'learning_rate': 0.0009805243445692884, 'epoch': 5.84}\n","{'loss': 1.4284, 'learning_rate': 0.0009801498127340823, 'epoch': 5.96}\n","  2% 533/26700 [31:43<13:29:58,  1.86s/it][INFO|trainer.py:3115] 2023-09-03 18:47:50,409 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3117] 2023-09-03 18:47:50,409 >>   Num examples = 22619\n","[INFO|trainer.py:3120] 2023-09-03 18:47:50,409 >>   Batch size = 512\n","\n","  0% 0/45 [00:00<?, ?it/s]\u001b[A\n","  4% 2/45 [00:02<00:53,  1.25s/it]\u001b[A\n","  7% 3/45 [00:05<01:19,  1.90s/it]\u001b[A\n","  9% 4/45 [00:07<01:27,  2.14s/it]\u001b[A\n"," 11% 5/45 [00:10<01:32,  2.32s/it]\u001b[A\n"," 13% 6/45 [00:13<01:39,  2.56s/it]\u001b[A\n"," 16% 7/45 [00:16<01:43,  2.71s/it]\u001b[A\n"," 18% 8/45 [00:19<01:44,  2.83s/it]\u001b[A\n"," 20% 9/45 [00:23<01:47,  3.00s/it]\u001b[A\n"," 22% 10/45 [00:26<01:48,  3.11s/it]\u001b[A\n"," 24% 11/45 [00:28<01:37,  2.88s/it]\u001b[A\n"," 27% 12/45 [00:31<01:32,  2.81s/it]\u001b[A\n"," 29% 13/45 [00:33<01:25,  2.66s/it]\u001b[A\n"," 31% 14/45 [00:36<01:24,  2.74s/it]\u001b[A\n"," 33% 15/45 [00:39<01:20,  2.68s/it]\u001b[A\n"," 36% 16/45 [00:41<01:17,  2.67s/it]\u001b[A\n"," 38% 17/45 [00:44<01:12,  2.57s/it]\u001b[A\n"," 40% 18/45 [00:46<01:05,  2.42s/it]\u001b[A\n"," 42% 19/45 [00:48<01:03,  2.45s/it]\u001b[A\n"," 44% 20/45 [00:51<01:04,  2.57s/it]\u001b[A\n"," 47% 21/45 [00:54<01:02,  2.59s/it]\u001b[A\n"," 49% 22/45 [00:56<00:58,  2.53s/it]\u001b[A\n"," 51% 23/45 [00:58<00:53,  2.42s/it]\u001b[A\n"," 53% 24/45 [01:01<00:53,  2.55s/it]\u001b[A\n"," 56% 25/45 [01:04<00:52,  2.64s/it]\u001b[A\n"," 58% 26/45 [01:06<00:46,  2.45s/it]\u001b[A\n"," 60% 27/45 [01:09<00:47,  2.63s/it]\u001b[A\n"," 62% 28/45 [01:12<00:46,  2.75s/it]\u001b[A\n"," 64% 29/45 [01:15<00:42,  2.65s/it]\u001b[A\n"," 67% 30/45 [01:17<00:40,  2.67s/it]\u001b[A\n"," 69% 31/45 [01:20<00:39,  2.83s/it]\u001b[A\n"," 71% 32/45 [01:23<00:37,  2.90s/it]\u001b[A\n"," 73% 33/45 [01:26<00:34,  2.85s/it]\u001b[A\n"," 76% 34/45 [01:29<00:31,  2.86s/it]\u001b[A\n"," 78% 35/45 [01:32<00:28,  2.88s/it]\u001b[A\n"," 80% 36/45 [01:35<00:25,  2.89s/it]\u001b[A\n"," 82% 37/45 [01:37<00:21,  2.67s/it]\u001b[A\n"," 84% 38/45 [01:39<00:17,  2.50s/it]\u001b[A\n"," 87% 39/45 [01:41<00:14,  2.42s/it]\u001b[A\n"," 89% 40/45 [01:45<00:13,  2.61s/it]\u001b[A\n"," 91% 41/45 [01:47<00:10,  2.55s/it]\u001b[A\n"," 93% 42/45 [01:49<00:07,  2.52s/it]\u001b[A\n"," 96% 43/45 [01:52<00:04,  2.42s/it]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 1.6042553186416626, 'eval_accuracy': 0.5792033246385782, 'eval_runtime': 118.4009, 'eval_samples_per_second': 191.037, 'eval_steps_per_second': 0.38, 'epoch': 6.0}\n","  2% 534/26700 [33:42<13:29:56,  1.86s/it]\n","100% 45/45 [01:52<00:00,  1.88s/it]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2841] 2023-09-03 18:49:48,816 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/checkpoint-534\n","[INFO|configuration_utils.py:460] 2023-09-03 18:49:48,822 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/checkpoint-534/config.json\n","[INFO|modeling_utils.py:1992] 2023-09-03 18:49:48,935 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/checkpoint-534/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-03 18:49:48,939 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/checkpoint-534/preprocessor_config.json\n","[INFO|trainer.py:2928] 2023-09-03 18:49:49,160 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/checkpoint-267] due to args.save_total_limit\n","{'loss': 1.4819, 'learning_rate': 0.0009797752808988764, 'epoch': 6.07}\n","{'loss': 1.3617, 'learning_rate': 0.0009794007490636703, 'epoch': 6.18}\n","{'loss': 1.3628, 'learning_rate': 0.0009790262172284644, 'epoch': 6.29}\n","{'loss': 1.3534, 'learning_rate': 0.0009786516853932585, 'epoch': 6.4}\n","{'loss': 1.3831, 'learning_rate': 0.0009782771535580524, 'epoch': 6.52}\n","{'loss': 1.439, 'learning_rate': 0.0009779026217228465, 'epoch': 6.63}\n","{'loss': 1.4265, 'learning_rate': 0.0009775280898876404, 'epoch': 6.74}\n","{'loss': 1.4145, 'learning_rate': 0.0009771535580524345, 'epoch': 6.85}\n","{'loss': 1.4111, 'learning_rate': 0.0009767790262172286, 'epoch': 6.97}\n","  2% 622/26700 [37:20<13:04:38,  1.81s/it][INFO|trainer.py:3115] 2023-09-03 18:53:26,959 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3117] 2023-09-03 18:53:26,959 >>   Num examples = 22619\n","[INFO|trainer.py:3120] 2023-09-03 18:53:26,959 >>   Batch size = 512\n","\n","  0% 0/45 [00:00<?, ?it/s]\u001b[A\n","  4% 2/45 [00:02<00:54,  1.26s/it]\u001b[A\n","  7% 3/45 [00:05<01:20,  1.91s/it]\u001b[A\n","  9% 4/45 [00:07<01:27,  2.13s/it]\u001b[A\n"," 11% 5/45 [00:10<01:32,  2.32s/it]\u001b[A\n"," 13% 6/45 [00:13<01:40,  2.57s/it]\u001b[A\n"," 16% 7/45 [00:16<01:42,  2.71s/it]\u001b[A\n"," 18% 8/45 [00:19<01:44,  2.83s/it]\u001b[A\n"," 20% 9/45 [00:22<01:46,  2.96s/it]\u001b[A\n"," 22% 10/45 [00:26<01:49,  3.13s/it]\u001b[A\n"," 24% 11/45 [00:28<01:38,  2.91s/it]\u001b[A\n"," 27% 12/45 [00:31<01:33,  2.83s/it]\u001b[A\n"," 29% 13/45 [00:33<01:25,  2.68s/it]\u001b[A\n"," 31% 14/45 [00:36<01:23,  2.70s/it]\u001b[A\n"," 33% 15/45 [00:39<01:20,  2.68s/it]\u001b[A\n"," 36% 16/45 [00:41<01:17,  2.69s/it]\u001b[A\n"," 38% 17/45 [00:44<01:12,  2.59s/it]\u001b[A\n"," 40% 18/45 [00:46<01:05,  2.42s/it]\u001b[A\n"," 42% 19/45 [00:48<01:03,  2.46s/it]\u001b[A\n"," 44% 20/45 [00:51<01:04,  2.56s/it]\u001b[A\n"," 47% 21/45 [00:54<01:02,  2.60s/it]\u001b[A\n"," 49% 22/45 [00:56<00:58,  2.54s/it]\u001b[A\n"," 51% 23/45 [00:58<00:53,  2.43s/it]\u001b[A\n"," 53% 24/45 [01:01<00:53,  2.57s/it]\u001b[A\n"," 56% 25/45 [01:04<00:52,  2.63s/it]\u001b[A\n"," 58% 26/45 [01:06<00:46,  2.44s/it]\u001b[A\n"," 60% 27/45 [01:09<00:47,  2.64s/it]\u001b[A\n"," 62% 28/45 [01:12<00:46,  2.76s/it]\u001b[A\n"," 64% 29/45 [01:15<00:42,  2.66s/it]\u001b[A\n"," 67% 30/45 [01:17<00:40,  2.67s/it]\u001b[A\n"," 69% 31/45 [01:21<00:39,  2.85s/it]\u001b[A\n"," 71% 32/45 [01:24<00:38,  2.93s/it]\u001b[A\n"," 73% 33/45 [01:26<00:34,  2.87s/it]\u001b[A\n"," 76% 34/45 [01:29<00:31,  2.87s/it]\u001b[A\n"," 78% 35/45 [01:32<00:28,  2.87s/it]\u001b[A\n"," 80% 36/45 [01:35<00:26,  2.89s/it]\u001b[A\n"," 82% 37/45 [01:37<00:21,  2.68s/it]\u001b[A\n"," 84% 38/45 [01:39<00:17,  2.51s/it]\u001b[A\n"," 87% 39/45 [01:42<00:14,  2.44s/it]\u001b[A\n"," 89% 40/45 [01:45<00:13,  2.61s/it]\u001b[A\n"," 91% 41/45 [01:47<00:10,  2.55s/it]\u001b[A\n"," 93% 42/45 [01:50<00:07,  2.56s/it]\u001b[A\n"," 96% 43/45 [01:52<00:04,  2.45s/it]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 1.602091670036316, 'eval_accuracy': 0.5789822715416243, 'eval_runtime': 118.7277, 'eval_samples_per_second': 190.512, 'eval_steps_per_second': 0.379, 'epoch': 7.0}\n","  2% 623/26700 [39:19<13:04:36,  1.81s/it]\n","100% 45/45 [01:53<00:00,  1.89s/it]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2841] 2023-09-03 18:55:25,691 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/checkpoint-623\n","[INFO|configuration_utils.py:460] 2023-09-03 18:55:25,696 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/checkpoint-623/config.json\n","[INFO|modeling_utils.py:1992] 2023-09-03 18:55:25,806 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/checkpoint-623/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-03 18:55:25,810 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/checkpoint-623/preprocessor_config.json\n","[INFO|trainer.py:2928] 2023-09-03 18:55:26,021 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/checkpoint-356] due to args.save_total_limit\n","{'loss': 1.3305, 'learning_rate': 0.0009764044943820225, 'epoch': 7.08}\n","{'loss': 1.3002, 'learning_rate': 0.0009760299625468166, 'epoch': 7.19}\n","{'loss': 1.2987, 'learning_rate': 0.0009756554307116106, 'epoch': 7.3}\n","{'loss': 1.3218, 'learning_rate': 0.0009752808988764044, 'epoch': 7.42}\n","{'loss': 1.3264, 'learning_rate': 0.0009749063670411985, 'epoch': 7.53}\n","{'loss': 1.339, 'learning_rate': 0.0009745318352059925, 'epoch': 7.64}\n","{'loss': 1.2852, 'learning_rate': 0.0009741573033707865, 'epoch': 7.75}\n","{'loss': 1.3736, 'learning_rate': 0.0009737827715355806, 'epoch': 7.87}\n","{'loss': 1.3411, 'learning_rate': 0.0009734082397003745, 'epoch': 7.98}\n","  3% 711/26700 [42:57<12:42:14,  1.76s/it][INFO|trainer.py:3115] 2023-09-03 18:59:04,039 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3117] 2023-09-03 18:59:04,039 >>   Num examples = 22619\n","[INFO|trainer.py:3120] 2023-09-03 18:59:04,039 >>   Batch size = 512\n","\n","  0% 0/45 [00:00<?, ?it/s]\u001b[A\n","  4% 2/45 [00:02<00:54,  1.27s/it]\u001b[A\n","  7% 3/45 [00:05<01:20,  1.92s/it]\u001b[A\n","  9% 4/45 [00:07<01:27,  2.15s/it]\u001b[A\n"," 11% 5/45 [00:10<01:32,  2.32s/it]\u001b[A\n"," 13% 6/45 [00:13<01:41,  2.60s/it]\u001b[A\n"," 16% 7/45 [00:16<01:44,  2.74s/it]\u001b[A\n"," 18% 8/45 [00:19<01:45,  2.85s/it]\u001b[A\n"," 20% 9/45 [00:23<01:47,  2.98s/it]\u001b[A\n"," 22% 10/45 [00:26<01:48,  3.11s/it]\u001b[A\n"," 24% 11/45 [00:28<01:38,  2.91s/it]\u001b[A\n"," 27% 12/45 [00:31<01:33,  2.83s/it]\u001b[A\n"," 29% 13/45 [00:33<01:26,  2.69s/it]\u001b[A\n"," 31% 14/45 [00:36<01:24,  2.72s/it]\u001b[A\n"," 33% 15/45 [00:39<01:19,  2.66s/it]\u001b[A\n"," 36% 16/45 [00:42<01:18,  2.70s/it]\u001b[A\n"," 38% 17/45 [00:44<01:12,  2.59s/it]\u001b[A\n"," 40% 18/45 [00:46<01:05,  2.42s/it]\u001b[A\n"," 42% 19/45 [00:48<01:03,  2.45s/it]\u001b[A\n"," 44% 20/45 [00:51<01:03,  2.54s/it]\u001b[A\n"," 47% 21/45 [00:54<01:02,  2.59s/it]\u001b[A\n"," 49% 22/45 [00:56<00:59,  2.57s/it]\u001b[A\n"," 51% 23/45 [00:59<00:53,  2.45s/it]\u001b[A\n"," 53% 24/45 [01:01<00:53,  2.57s/it]\u001b[A\n"," 56% 25/45 [01:04<00:52,  2.63s/it]\u001b[A\n"," 58% 26/45 [01:06<00:45,  2.42s/it]\u001b[A\n"," 60% 27/45 [01:09<00:47,  2.65s/it]\u001b[A\n"," 62% 28/45 [01:12<00:46,  2.75s/it]\u001b[A\n"," 64% 29/45 [01:15<00:42,  2.65s/it]\u001b[A\n"," 67% 30/45 [01:17<00:39,  2.65s/it]\u001b[A\n"," 69% 31/45 [01:21<00:39,  2.80s/it]\u001b[A\n"," 71% 32/45 [01:24<00:37,  2.89s/it]\u001b[A\n"," 73% 33/45 [01:26<00:34,  2.84s/it]\u001b[A\n"," 76% 34/45 [01:29<00:31,  2.85s/it]\u001b[A\n"," 78% 35/45 [01:32<00:28,  2.85s/it]\u001b[A\n"," 80% 36/45 [01:35<00:25,  2.84s/it]\u001b[A\n"," 82% 37/45 [01:37<00:21,  2.65s/it]\u001b[A\n"," 84% 38/45 [01:39<00:17,  2.49s/it]\u001b[A\n"," 87% 39/45 [01:41<00:14,  2.41s/it]\u001b[A\n"," 89% 40/45 [01:44<00:12,  2.58s/it]\u001b[A\n"," 91% 41/45 [01:47<00:10,  2.52s/it]\u001b[A\n"," 93% 42/45 [01:49<00:07,  2.50s/it]\u001b[A\n"," 96% 43/45 [01:52<00:04,  2.43s/it]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 1.5882887840270996, 'eval_accuracy': 0.58499491577877, 'eval_runtime': 118.3835, 'eval_samples_per_second': 191.066, 'eval_steps_per_second': 0.38, 'epoch': 8.0}\n","  3% 712/26700 [44:55<12:42:13,  1.76s/it]\n","100% 45/45 [01:52<00:00,  1.88s/it]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2841] 2023-09-03 19:01:02,427 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/checkpoint-712\n","[INFO|configuration_utils.py:460] 2023-09-03 19:01:02,432 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/checkpoint-712/config.json\n","[INFO|modeling_utils.py:1992] 2023-09-03 19:01:02,540 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/checkpoint-712/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-03 19:01:02,544 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/checkpoint-712/preprocessor_config.json\n","[INFO|trainer.py:2928] 2023-09-03 19:01:02,753 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/checkpoint-445] due to args.save_total_limit\n","{'loss': 1.2709, 'learning_rate': 0.0009730337078651685, 'epoch': 8.09}\n","{'loss': 1.2444, 'learning_rate': 0.0009726591760299626, 'epoch': 8.2}\n","{'loss': 1.2551, 'learning_rate': 0.0009722846441947566, 'epoch': 8.31}\n","{'loss': 1.2482, 'learning_rate': 0.0009719101123595506, 'epoch': 8.43}\n","{'loss': 1.23, 'learning_rate': 0.0009715355805243446, 'epoch': 8.54}\n","{'loss': 1.2362, 'learning_rate': 0.0009711610486891386, 'epoch': 8.65}\n","{'loss': 1.2692, 'learning_rate': 0.0009707865168539325, 'epoch': 8.76}\n","{'loss': 1.2692, 'learning_rate': 0.0009704119850187266, 'epoch': 8.88}\n","{'loss': 1.2769, 'learning_rate': 0.0009700374531835206, 'epoch': 8.99}\n","  3% 800/26700 [48:33<12:46:42,  1.78s/it][INFO|trainer.py:3115] 2023-09-03 19:04:40,361 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3117] 2023-09-03 19:04:40,361 >>   Num examples = 22619\n","[INFO|trainer.py:3120] 2023-09-03 19:04:40,361 >>   Batch size = 512\n","\n","  0% 0/45 [00:00<?, ?it/s]\u001b[A\n","  4% 2/45 [00:02<00:54,  1.26s/it]\u001b[A\n","  7% 3/45 [00:05<01:19,  1.90s/it]\u001b[A\n","  9% 4/45 [00:07<01:26,  2.11s/it]\u001b[A\n"," 11% 5/45 [00:10<01:31,  2.29s/it]\u001b[A\n"," 13% 6/45 [00:13<01:38,  2.53s/it]\u001b[A\n"," 16% 7/45 [00:16<01:43,  2.72s/it]\u001b[A\n"," 18% 8/45 [00:19<01:44,  2.83s/it]\u001b[A\n"," 20% 9/45 [00:22<01:46,  2.95s/it]\u001b[A\n"," 22% 10/45 [00:26<01:47,  3.06s/it]\u001b[A\n"," 24% 11/45 [00:28<01:37,  2.87s/it]\u001b[A\n"," 27% 12/45 [00:31<01:32,  2.82s/it]\u001b[A\n"," 29% 13/45 [00:33<01:25,  2.67s/it]\u001b[A\n"," 31% 14/45 [00:36<01:23,  2.70s/it]\u001b[A\n"," 33% 15/45 [00:38<01:18,  2.62s/it]\u001b[A\n"," 36% 16/45 [00:41<01:16,  2.64s/it]\u001b[A\n"," 38% 17/45 [00:43<01:12,  2.58s/it]\u001b[A\n"," 40% 18/45 [00:46<01:05,  2.43s/it]\u001b[A\n"," 42% 19/45 [00:48<01:03,  2.45s/it]\u001b[A\n"," 44% 20/45 [00:51<01:03,  2.55s/it]\u001b[A\n"," 47% 21/45 [00:53<01:01,  2.56s/it]\u001b[A\n"," 49% 22/45 [00:56<00:57,  2.52s/it]\u001b[A\n"," 51% 23/45 [00:58<00:53,  2.44s/it]\u001b[A\n"," 53% 24/45 [01:01<00:54,  2.57s/it]\u001b[A\n"," 56% 25/45 [01:04<00:52,  2.64s/it]\u001b[A\n"," 58% 26/45 [01:06<00:46,  2.42s/it]\u001b[A\n"," 60% 27/45 [01:09<00:47,  2.62s/it]\u001b[A\n"," 62% 28/45 [01:12<00:47,  2.78s/it]\u001b[A\n"," 64% 29/45 [01:14<00:42,  2.68s/it]\u001b[A\n"," 67% 30/45 [01:17<00:40,  2.68s/it]\u001b[A\n"," 69% 31/45 [01:20<00:39,  2.84s/it]\u001b[A\n"," 71% 32/45 [01:23<00:37,  2.92s/it]\u001b[A\n"," 73% 33/45 [01:26<00:34,  2.90s/it]\u001b[A\n"," 76% 34/45 [01:29<00:31,  2.89s/it]\u001b[A\n"," 78% 35/45 [01:32<00:28,  2.88s/it]\u001b[A\n"," 80% 36/45 [01:35<00:25,  2.85s/it]\u001b[A\n"," 82% 37/45 [01:37<00:21,  2.64s/it]\u001b[A\n"," 84% 38/45 [01:39<00:17,  2.49s/it]\u001b[A\n"," 87% 39/45 [01:41<00:14,  2.42s/it]\u001b[A\n"," 89% 40/45 [01:44<00:12,  2.59s/it]\u001b[A\n"," 91% 41/45 [01:47<00:10,  2.59s/it]\u001b[A\n"," 93% 42/45 [01:49<00:07,  2.55s/it]\u001b[A\n"," 96% 43/45 [01:52<00:04,  2.46s/it]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 1.5120697021484375, 'eval_accuracy': 0.610460232547858, 'eval_runtime': 118.2767, 'eval_samples_per_second': 191.238, 'eval_steps_per_second': 0.38, 'epoch': 9.0}\n","  3% 801/26700 [50:32<12:46:40,  1.78s/it]\n","100% 45/45 [01:52<00:00,  1.90s/it]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2841] 2023-09-03 19:06:38,644 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/checkpoint-801\n","[INFO|configuration_utils.py:460] 2023-09-03 19:06:38,649 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/checkpoint-801/config.json\n","[INFO|modeling_utils.py:1992] 2023-09-03 19:06:38,762 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/checkpoint-801/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-03 19:06:38,777 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/checkpoint-801/preprocessor_config.json\n","[INFO|trainer.py:2928] 2023-09-03 19:06:38,998 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/checkpoint-534] due to args.save_total_limit\n","{'loss': 1.1696, 'learning_rate': 0.0009696629213483145, 'epoch': 9.1}\n","{'loss': 1.1624, 'learning_rate': 0.0009692883895131086, 'epoch': 9.21}\n","{'loss': 1.1515, 'learning_rate': 0.0009689138576779026, 'epoch': 9.33}\n","{'loss': 1.2128, 'learning_rate': 0.0009685393258426967, 'epoch': 9.44}\n","{'loss': 1.2446, 'learning_rate': 0.0009681647940074907, 'epoch': 9.55}\n","{'loss': 1.2195, 'learning_rate': 0.0009677902621722847, 'epoch': 9.66}\n","{'loss': 1.2128, 'learning_rate': 0.0009674157303370787, 'epoch': 9.78}\n","{'loss': 1.2089, 'learning_rate': 0.0009670411985018727, 'epoch': 9.89}\n","{'loss': 1.2706, 'learning_rate': 0.0009666666666666667, 'epoch': 10.0}\n","  3% 890/26700 [54:10<13:42:50,  1.91s/it][INFO|trainer.py:3115] 2023-09-03 19:10:16,574 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3117] 2023-09-03 19:10:16,574 >>   Num examples = 22619\n","[INFO|trainer.py:3120] 2023-09-03 19:10:16,574 >>   Batch size = 512\n","\n","  0% 0/45 [00:00<?, ?it/s]\u001b[A\n","  4% 2/45 [00:02<00:54,  1.26s/it]\u001b[A\n","  7% 3/45 [00:05<01:21,  1.94s/it]\u001b[A\n","  9% 4/45 [00:07<01:27,  2.14s/it]\u001b[A\n"," 11% 5/45 [00:10<01:31,  2.29s/it]\u001b[A\n"," 13% 6/45 [00:13<01:38,  2.53s/it]\u001b[A\n"," 16% 7/45 [00:16<01:42,  2.71s/it]\u001b[A\n"," 18% 8/45 [00:19<01:45,  2.84s/it]\u001b[A\n"," 20% 9/45 [00:22<01:46,  2.95s/it]\u001b[A\n"," 22% 10/45 [00:26<01:47,  3.06s/it]\u001b[A\n"," 24% 11/45 [00:28<01:36,  2.85s/it]\u001b[A\n"," 27% 12/45 [00:31<01:32,  2.80s/it]\u001b[A\n"," 29% 13/45 [00:33<01:25,  2.67s/it]\u001b[A\n"," 31% 14/45 [00:36<01:23,  2.70s/it]\u001b[A\n"," 33% 15/45 [00:38<01:18,  2.63s/it]\u001b[A\n"," 36% 16/45 [00:41<01:16,  2.63s/it]\u001b[A\n"," 38% 17/45 [00:43<01:11,  2.54s/it]\u001b[A\n"," 40% 18/45 [00:45<01:05,  2.41s/it]\u001b[A\n"," 42% 19/45 [00:48<01:03,  2.46s/it]\u001b[A\n"," 44% 20/45 [00:51<01:03,  2.55s/it]\u001b[A\n"," 47% 21/45 [00:53<01:01,  2.56s/it]\u001b[A\n"," 49% 22/45 [00:56<00:57,  2.50s/it]\u001b[A\n"," 51% 23/45 [00:58<00:52,  2.40s/it]\u001b[A\n"," 53% 24/45 [01:01<00:53,  2.56s/it]\u001b[A\n"," 56% 25/45 [01:04<00:52,  2.63s/it]\u001b[A\n"," 58% 26/45 [01:06<00:45,  2.42s/it]\u001b[A\n"," 60% 27/45 [01:09<00:46,  2.60s/it]\u001b[A\n"," 62% 28/45 [01:12<00:46,  2.75s/it]\u001b[A\n"," 64% 29/45 [01:14<00:42,  2.67s/it]\u001b[A\n"," 67% 30/45 [01:17<00:39,  2.67s/it]\u001b[A\n"," 69% 31/45 [01:20<00:39,  2.81s/it]\u001b[A\n"," 71% 32/45 [01:23<00:37,  2.88s/it]\u001b[A\n"," 73% 33/45 [01:26<00:34,  2.86s/it]\u001b[A\n"," 76% 34/45 [01:29<00:32,  2.93s/it]\u001b[A\n"," 78% 35/45 [01:32<00:29,  2.92s/it]\u001b[A\n"," 80% 36/45 [01:35<00:25,  2.88s/it]\u001b[A\n"," 82% 37/45 [01:37<00:21,  2.66s/it]\u001b[A\n"," 84% 38/45 [01:39<00:17,  2.49s/it]\u001b[A\n"," 87% 39/45 [01:41<00:14,  2.42s/it]\u001b[A\n"," 89% 40/45 [01:44<00:13,  2.61s/it]\u001b[A\n"," 91% 41/45 [01:46<00:10,  2.53s/it]\u001b[A\n"," 93% 42/45 [01:49<00:07,  2.50s/it]\u001b[A\n"," 96% 43/45 [01:51<00:04,  2.40s/it]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 1.562817096710205, 'eval_accuracy': 0.6024581104381272, 'eval_runtime': 117.7571, 'eval_samples_per_second': 192.082, 'eval_steps_per_second': 0.382, 'epoch': 10.0}\n","  3% 890/26700 [56:07<13:42:50,  1.91s/it]\n","100% 45/45 [01:52<00:00,  1.86s/it]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2841] 2023-09-03 19:12:14,336 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/checkpoint-890\n","[INFO|configuration_utils.py:460] 2023-09-03 19:12:14,342 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/checkpoint-890/config.json\n","[INFO|modeling_utils.py:1992] 2023-09-03 19:12:14,451 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/checkpoint-890/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-03 19:12:14,455 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/checkpoint-890/preprocessor_config.json\n","[INFO|trainer.py:2928] 2023-09-03 19:12:14,674 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/checkpoint-623] due to args.save_total_limit\n","{'loss': 1.1344, 'learning_rate': 0.0009662921348314608, 'epoch': 10.11}\n","{'loss': 1.1268, 'learning_rate': 0.0009659176029962548, 'epoch': 10.22}\n","{'loss': 1.1336, 'learning_rate': 0.0009655430711610486, 'epoch': 10.34}\n","{'loss': 1.1257, 'learning_rate': 0.0009651685393258427, 'epoch': 10.45}\n","{'loss': 1.2014, 'learning_rate': 0.0009647940074906367, 'epoch': 10.56}\n","{'loss': 1.1448, 'learning_rate': 0.0009644194756554307, 'epoch': 10.67}\n","{'loss': 1.1657, 'learning_rate': 0.0009640449438202248, 'epoch': 10.79}\n","{'loss': 1.1935, 'learning_rate': 0.0009636704119850187, 'epoch': 10.9}\n","  4% 978/26700 [59:46<14:18:38,  2.00s/it][INFO|trainer.py:3115] 2023-09-03 19:15:53,020 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3117] 2023-09-03 19:15:53,020 >>   Num examples = 22619\n","[INFO|trainer.py:3120] 2023-09-03 19:15:53,020 >>   Batch size = 512\n","\n","  0% 0/45 [00:00<?, ?it/s]\u001b[A\n","  4% 2/45 [00:02<00:54,  1.27s/it]\u001b[A\n","  7% 3/45 [00:05<01:21,  1.94s/it]\u001b[A\n","  9% 4/45 [00:08<01:31,  2.23s/it]\u001b[A\n"," 11% 5/45 [00:10<01:34,  2.35s/it]\u001b[A\n"," 13% 6/45 [00:13<01:40,  2.58s/it]\u001b[A\n"," 16% 7/45 [00:16<01:43,  2.72s/it]\u001b[A\n"," 18% 8/45 [00:19<01:45,  2.85s/it]\u001b[A\n"," 20% 9/45 [00:23<01:47,  2.97s/it]\u001b[A\n"," 22% 10/45 [00:26<01:47,  3.08s/it]\u001b[A\n"," 24% 11/45 [00:28<01:37,  2.86s/it]\u001b[A\n"," 27% 12/45 [00:31<01:32,  2.79s/it]\u001b[A\n"," 29% 13/45 [00:33<01:24,  2.65s/it]\u001b[A\n"," 31% 14/45 [00:36<01:23,  2.70s/it]\u001b[A\n"," 33% 15/45 [00:39<01:18,  2.62s/it]\u001b[A\n"," 36% 16/45 [00:41<01:16,  2.63s/it]\u001b[A\n"," 38% 17/45 [00:44<01:11,  2.54s/it]\u001b[A\n"," 40% 18/45 [00:46<01:04,  2.39s/it]\u001b[A\n"," 42% 19/45 [00:48<01:04,  2.47s/it]\u001b[A\n"," 44% 20/45 [00:51<01:04,  2.58s/it]\u001b[A\n"," 47% 21/45 [00:54<01:02,  2.59s/it]\u001b[A\n"," 49% 22/45 [00:56<00:58,  2.52s/it]\u001b[A\n"," 51% 23/45 [00:58<00:53,  2.42s/it]\u001b[A\n"," 53% 24/45 [01:01<00:54,  2.61s/it]\u001b[A\n"," 56% 25/45 [01:04<00:53,  2.68s/it]\u001b[A\n"," 58% 26/45 [01:06<00:46,  2.46s/it]\u001b[A\n"," 60% 27/45 [01:09<00:47,  2.63s/it]\u001b[A\n"," 62% 28/45 [01:12<00:46,  2.76s/it]\u001b[A\n"," 64% 29/45 [01:15<00:42,  2.67s/it]\u001b[A\n"," 67% 30/45 [01:17<00:40,  2.69s/it]\u001b[A\n"," 69% 31/45 [01:21<00:39,  2.84s/it]\u001b[A\n"," 71% 32/45 [01:24<00:37,  2.90s/it]\u001b[A\n"," 73% 33/45 [01:26<00:34,  2.85s/it]\u001b[A\n"," 76% 34/45 [01:29<00:31,  2.87s/it]\u001b[A\n"," 78% 35/45 [01:32<00:28,  2.90s/it]\u001b[A\n"," 80% 36/45 [01:35<00:25,  2.87s/it]\u001b[A\n"," 82% 37/45 [01:37<00:21,  2.74s/it]\u001b[A\n"," 84% 38/45 [01:40<00:17,  2.55s/it]\u001b[A\n"," 87% 39/45 [01:42<00:14,  2.45s/it]\u001b[A\n"," 89% 40/45 [01:45<00:13,  2.65s/it]\u001b[A\n"," 91% 41/45 [01:47<00:10,  2.57s/it]\u001b[A\n"," 93% 42/45 [01:50<00:07,  2.52s/it]\u001b[A\n"," 96% 43/45 [01:52<00:04,  2.42s/it]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 1.5702033042907715, 'eval_accuracy': 0.6061718024669526, 'eval_runtime': 118.6359, 'eval_samples_per_second': 190.659, 'eval_steps_per_second': 0.379, 'epoch': 11.0}\n","  4% 979/26700 [1:01:45<14:18:36,  2.00s/it]\n","100% 45/45 [01:53<00:00,  1.88s/it]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2841] 2023-09-03 19:17:51,660 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/checkpoint-979\n","[INFO|configuration_utils.py:460] 2023-09-03 19:17:51,665 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/checkpoint-979/config.json\n","[INFO|modeling_utils.py:1992] 2023-09-03 19:17:51,775 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/checkpoint-979/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-03 19:17:51,779 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/checkpoint-979/preprocessor_config.json\n","[INFO|trainer.py:2928] 2023-09-03 19:17:51,997 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/checkpoint-712] due to args.save_total_limit\n","{'loss': 1.1505, 'learning_rate': 0.0009632958801498127, 'epoch': 11.01}\n","{'loss': 1.0686, 'learning_rate': 0.0009629213483146068, 'epoch': 11.12}\n","{'loss': 1.095, 'learning_rate': 0.0009625468164794008, 'epoch': 11.24}\n","{'loss': 1.0692, 'learning_rate': 0.0009621722846441948, 'epoch': 11.35}\n","{'loss': 1.0881, 'learning_rate': 0.0009617977528089888, 'epoch': 11.46}\n","{'loss': 1.1318, 'learning_rate': 0.0009614232209737828, 'epoch': 11.57}\n","{'loss': 1.1515, 'learning_rate': 0.0009610486891385768, 'epoch': 11.69}\n","{'loss': 1.1141, 'learning_rate': 0.0009606741573033709, 'epoch': 11.8}\n","{'loss': 1.1518, 'learning_rate': 0.0009602996254681649, 'epoch': 11.91}\n","  4% 1067/26700 [1:05:23<13:20:56,  1.87s/it][INFO|trainer.py:3115] 2023-09-03 19:21:30,016 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3117] 2023-09-03 19:21:30,016 >>   Num examples = 22619\n","[INFO|trainer.py:3120] 2023-09-03 19:21:30,016 >>   Batch size = 512\n","\n","  0% 0/45 [00:00<?, ?it/s]\u001b[A\n","  4% 2/45 [00:02<00:53,  1.24s/it]\u001b[A\n","  7% 3/45 [00:05<01:19,  1.89s/it]\u001b[A\n","  9% 4/45 [00:07<01:27,  2.14s/it]\u001b[A\n"," 11% 5/45 [00:10<01:33,  2.33s/it]\u001b[A\n"," 13% 6/45 [00:13<01:39,  2.56s/it]\u001b[A\n"," 16% 7/45 [00:16<01:42,  2.70s/it]\u001b[A\n"," 18% 8/45 [00:19<01:44,  2.82s/it]\u001b[A\n"," 20% 9/45 [00:22<01:46,  2.96s/it]\u001b[A\n"," 22% 10/45 [00:26<01:47,  3.08s/it]\u001b[A\n"," 24% 11/45 [00:28<01:37,  2.86s/it]\u001b[A\n"," 27% 12/45 [00:31<01:32,  2.79s/it]\u001b[A\n"," 29% 13/45 [00:33<01:24,  2.64s/it]\u001b[A\n"," 31% 14/45 [00:36<01:23,  2.69s/it]\u001b[A\n"," 33% 15/45 [00:38<01:20,  2.67s/it]\u001b[A\n"," 36% 16/45 [00:41<01:17,  2.67s/it]\u001b[A\n"," 38% 17/45 [00:43<01:11,  2.57s/it]\u001b[A\n"," 40% 18/45 [00:45<01:04,  2.40s/it]\u001b[A\n"," 42% 19/45 [00:48<01:03,  2.43s/it]\u001b[A\n"," 44% 20/45 [00:51<01:03,  2.54s/it]\u001b[A\n"," 47% 21/45 [00:53<01:01,  2.58s/it]\u001b[A\n"," 49% 22/45 [00:56<00:57,  2.52s/it]\u001b[A\n"," 51% 23/45 [00:58<00:53,  2.41s/it]\u001b[A\n"," 53% 24/45 [01:01<00:53,  2.54s/it]\u001b[A\n"," 56% 25/45 [01:04<00:52,  2.63s/it]\u001b[A\n"," 58% 26/45 [01:06<00:46,  2.45s/it]\u001b[A\n"," 60% 27/45 [01:09<00:47,  2.62s/it]\u001b[A\n"," 62% 28/45 [01:12<00:46,  2.74s/it]\u001b[A\n"," 64% 29/45 [01:14<00:42,  2.64s/it]\u001b[A\n"," 67% 30/45 [01:17<00:39,  2.65s/it]\u001b[A\n"," 69% 31/45 [01:20<00:39,  2.84s/it]\u001b[A\n"," 71% 32/45 [01:23<00:37,  2.90s/it]\u001b[A\n"," 73% 33/45 [01:26<00:34,  2.84s/it]\u001b[A\n"," 76% 34/45 [01:29<00:31,  2.84s/it]\u001b[A\n"," 78% 35/45 [01:32<00:29,  2.94s/it]\u001b[A\n"," 80% 36/45 [01:35<00:26,  2.93s/it]\u001b[A\n"," 82% 37/45 [01:37<00:21,  2.70s/it]\u001b[A\n"," 84% 38/45 [01:39<00:17,  2.51s/it]\u001b[A\n"," 87% 39/45 [01:41<00:14,  2.42s/it]\u001b[A\n"," 89% 40/45 [01:44<00:13,  2.67s/it]\u001b[A\n"," 91% 41/45 [01:47<00:10,  2.61s/it]\u001b[A\n"," 93% 42/45 [01:49<00:07,  2.58s/it]\u001b[A\n"," 96% 43/45 [01:52<00:04,  2.46s/it]\u001b[A\n","                                             \n","\u001b[A{'eval_loss': 1.5833120346069336, 'eval_accuracy': 0.6001149476104161, 'eval_runtime': 118.3476, 'eval_samples_per_second': 191.123, 'eval_steps_per_second': 0.38, 'epoch': 12.0}\n","  4% 1068/26700 [1:07:21<13:20:54,  1.87s/it]\n","100% 45/45 [01:52<00:00,  1.90s/it]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2841] 2023-09-03 19:23:28,368 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/checkpoint-1068\n","[INFO|configuration_utils.py:460] 2023-09-03 19:23:28,374 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/checkpoint-1068/config.json\n","[INFO|modeling_utils.py:1992] 2023-09-03 19:23:28,483 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/checkpoint-1068/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-03 19:23:28,487 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/checkpoint-1068/preprocessor_config.json\n","[INFO|trainer.py:2928] 2023-09-03 19:23:28,697 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/checkpoint-890] due to args.save_total_limit\n","{'loss': 1.1089, 'learning_rate': 0.0009599250936329587, 'epoch': 12.02}\n","{'loss': 1.0236, 'learning_rate': 0.0009595505617977528, 'epoch': 12.13}\n","{'loss': 1.0388, 'learning_rate': 0.0009591760299625468, 'epoch': 12.25}\n","{'loss': 1.0205, 'learning_rate': 0.0009588014981273408, 'epoch': 12.36}\n","{'loss': 1.0538, 'learning_rate': 0.0009584269662921349, 'epoch': 12.47}\n","{'loss': 1.0587, 'learning_rate': 0.0009580524344569289, 'epoch': 12.58}\n","{'loss': 1.1008, 'learning_rate': 0.0009576779026217228, 'epoch': 12.7}\n","{'loss': 1.0489, 'learning_rate': 0.0009573033707865169, 'epoch': 12.81}\n","{'loss': 1.1245, 'learning_rate': 0.0009569288389513109, 'epoch': 12.92}\n","  4% 1156/26700 [1:10:59<12:46:55,  1.80s/it][INFO|trainer.py:3115] 2023-09-03 19:27:06,088 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3117] 2023-09-03 19:27:06,088 >>   Num examples = 22619\n","[INFO|trainer.py:3120] 2023-09-03 19:27:06,088 >>   Batch size = 512\n","\n","  0% 0/45 [00:00<?, ?it/s]\u001b[A\n","  4% 2/45 [00:02<00:53,  1.24s/it]\u001b[A\n","  7% 3/45 [00:05<01:19,  1.89s/it]\u001b[A\n","  9% 4/45 [00:07<01:26,  2.11s/it]\u001b[A\n"," 11% 5/45 [00:10<01:31,  2.29s/it]\u001b[A\n"," 13% 6/45 [00:13<01:39,  2.55s/it]\u001b[A\n"," 16% 7/45 [00:16<01:42,  2.70s/it]\u001b[A\n"," 18% 8/45 [00:19<01:44,  2.82s/it]\u001b[A\n"," 20% 9/45 [00:22<01:46,  2.96s/it]\u001b[A\n"," 22% 10/45 [00:26<01:49,  3.12s/it]\u001b[A\n"," 24% 11/45 [00:28<01:38,  2.89s/it]\u001b[A\n"," 27% 12/45 [00:31<01:32,  2.81s/it]\u001b[A\n"," 29% 13/45 [00:33<01:25,  2.66s/it]\u001b[A\n"," 31% 14/45 [00:36<01:23,  2.68s/it]\u001b[A\n"," 33% 15/45 [00:38<01:18,  2.63s/it]\u001b[A\n"," 36% 16/45 [00:41<01:16,  2.65s/it]\u001b[A\n"," 38% 17/45 [00:43<01:11,  2.55s/it]\u001b[A\n"," 40% 18/45 [00:45<01:04,  2.39s/it]\u001b[A\n"," 42% 19/45 [00:48<01:03,  2.43s/it]\u001b[A\n"," 44% 20/45 [00:51<01:03,  2.53s/it]\u001b[A\n"," 47% 21/45 [00:53<01:01,  2.56s/it]\u001b[A\n"," 49% 22/45 [00:56<00:57,  2.50s/it]\u001b[A\n"," 51% 23/45 [00:58<00:52,  2.40s/it]\u001b[A\n"," 53% 24/45 [01:01<00:53,  2.53s/it]\u001b[A\n"," 56% 25/45 [01:03<00:51,  2.60s/it]\u001b[A\n"," 58% 26/45 [01:05<00:45,  2.40s/it]\u001b[A\n"," 60% 27/45 [01:08<00:46,  2.60s/it]\u001b[A\n"," 62% 28/45 [01:11<00:46,  2.72s/it]\u001b[A\n"," 64% 29/45 [01:14<00:42,  2.63s/it]\u001b[A\n"," 67% 30/45 [01:17<00:39,  2.63s/it]\u001b[A\n"," 69% 31/45 [01:20<00:39,  2.81s/it]\u001b[A\n"," 71% 32/45 [01:23<00:37,  2.90s/it]\u001b[A\n"," 73% 33/45 [01:26<00:34,  2.84s/it]\u001b[A\n"," 76% 34/45 [01:28<00:31,  2.84s/it]\u001b[A\n"," 78% 35/45 [01:31<00:28,  2.84s/it]\u001b[A\n"," 80% 36/45 [01:34<00:26,  2.93s/it]\u001b[A\n"," 82% 37/45 [01:37<00:21,  2.72s/it]\u001b[A\n"," 84% 38/45 [01:39<00:17,  2.53s/it]\u001b[A\n"," 87% 39/45 [01:41<00:14,  2.44s/it]\u001b[A\n"," 89% 40/45 [01:44<00:12,  2.60s/it]\u001b[A\n"," 91% 41/45 [01:46<00:10,  2.60s/it]\u001b[A\n"," 93% 42/45 [01:49<00:07,  2.55s/it]\u001b[A\n"," 96% 43/45 [01:51<00:04,  2.45s/it]\u001b[A\n","                                             \n","\u001b[A{'eval_loss': 1.5642809867858887, 'eval_accuracy': 0.6122286573234891, 'eval_runtime': 117.994, 'eval_samples_per_second': 191.696, 'eval_steps_per_second': 0.381, 'epoch': 13.0}\n","  4% 1157/26700 [1:12:57<12:46:53,  1.80s/it]\n","100% 45/45 [01:52<00:00,  1.89s/it]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2841] 2023-09-03 19:29:04,088 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/checkpoint-1157\n","[INFO|configuration_utils.py:460] 2023-09-03 19:29:04,093 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/checkpoint-1157/config.json\n","[INFO|modeling_utils.py:1992] 2023-09-03 19:29:04,200 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/checkpoint-1157/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-03 19:29:04,204 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/checkpoint-1157/preprocessor_config.json\n","[INFO|trainer.py:2928] 2023-09-03 19:29:04,411 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/checkpoint-979] due to args.save_total_limit\n","{'loss': 1.0647, 'learning_rate': 0.0009565543071161049, 'epoch': 13.03}\n","{'loss': 1.0265, 'learning_rate': 0.000956179775280899, 'epoch': 13.15}\n","{'loss': 0.9678, 'learning_rate': 0.0009558052434456929, 'epoch': 13.26}\n","{'loss': 1.0197, 'learning_rate': 0.0009554307116104869, 'epoch': 13.37}\n","{'loss': 1.0207, 'learning_rate': 0.000955056179775281, 'epoch': 13.48}\n","{'loss': 1.0325, 'learning_rate': 0.0009546816479400749, 'epoch': 13.6}\n","{'loss': 1.0624, 'learning_rate': 0.0009543071161048689, 'epoch': 13.71}\n","{'loss': 1.0863, 'learning_rate': 0.0009539325842696629, 'epoch': 13.82}\n","{'loss': 1.0256, 'learning_rate': 0.0009535580524344569, 'epoch': 13.93}\n","  5% 1245/26700 [1:16:35<13:23:26,  1.89s/it][INFO|trainer.py:3115] 2023-09-03 19:32:42,151 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3117] 2023-09-03 19:32:42,151 >>   Num examples = 22619\n","[INFO|trainer.py:3120] 2023-09-03 19:32:42,151 >>   Batch size = 512\n","\n","  0% 0/45 [00:00<?, ?it/s]\u001b[A\n","  4% 2/45 [00:02<00:54,  1.26s/it]\u001b[A\n","  7% 3/45 [00:05<01:19,  1.89s/it]\u001b[A\n","  9% 4/45 [00:07<01:26,  2.11s/it]\u001b[A\n"," 11% 5/45 [00:10<01:31,  2.28s/it]\u001b[A\n"," 13% 6/45 [00:13<01:38,  2.53s/it]\u001b[A\n"," 16% 7/45 [00:16<01:42,  2.71s/it]\u001b[A\n"," 18% 8/45 [00:19<01:44,  2.82s/it]\u001b[A\n"," 20% 9/45 [00:22<01:45,  2.94s/it]\u001b[A\n"," 22% 10/45 [00:26<01:47,  3.06s/it]\u001b[A\n"," 24% 11/45 [00:28<01:37,  2.86s/it]\u001b[A\n"," 27% 12/45 [00:31<01:32,  2.81s/it]\u001b[A\n"," 29% 13/45 [00:33<01:25,  2.66s/it]\u001b[A\n"," 31% 14/45 [00:36<01:23,  2.68s/it]\u001b[A\n"," 33% 15/45 [00:38<01:18,  2.61s/it]\u001b[A\n"," 36% 16/45 [00:41<01:16,  2.64s/it]\u001b[A\n"," 38% 17/45 [00:43<01:11,  2.57s/it]\u001b[A\n"," 40% 18/45 [00:45<01:04,  2.41s/it]\u001b[A\n"," 42% 19/45 [00:48<01:03,  2.44s/it]\u001b[A\n"," 44% 20/45 [00:51<01:03,  2.53s/it]\u001b[A\n"," 47% 21/45 [00:53<01:01,  2.55s/it]\u001b[A\n"," 49% 22/45 [00:56<00:58,  2.54s/it]\u001b[A\n"," 51% 23/45 [00:58<00:53,  2.44s/it]\u001b[A\n"," 53% 24/45 [01:01<00:53,  2.56s/it]\u001b[A\n"," 56% 25/45 [01:04<00:53,  2.69s/it]\u001b[A\n"," 58% 26/45 [01:06<00:46,  2.46s/it]\u001b[A\n"," 60% 27/45 [01:09<00:47,  2.64s/it]\u001b[A\n"," 62% 28/45 [01:12<00:47,  2.79s/it]\u001b[A\n"," 64% 29/45 [01:14<00:42,  2.67s/it]\u001b[A\n"," 67% 30/45 [01:17<00:39,  2.66s/it]\u001b[A\n"," 69% 31/45 [01:20<00:39,  2.81s/it]\u001b[A\n"," 71% 32/45 [01:23<00:37,  2.88s/it]\u001b[A\n"," 73% 33/45 [01:26<00:34,  2.86s/it]\u001b[A\n"," 76% 34/45 [01:29<00:31,  2.86s/it]\u001b[A\n"," 78% 35/45 [01:32<00:28,  2.86s/it]\u001b[A\n"," 80% 36/45 [01:34<00:25,  2.84s/it]\u001b[A\n"," 82% 37/45 [01:37<00:21,  2.64s/it]\u001b[A\n"," 84% 38/45 [01:39<00:17,  2.49s/it]\u001b[A\n"," 87% 39/45 [01:41<00:14,  2.41s/it]\u001b[A\n"," 89% 40/45 [01:44<00:12,  2.58s/it]\u001b[A\n"," 91% 41/45 [01:46<00:10,  2.51s/it]\u001b[A\n"," 93% 42/45 [01:49<00:07,  2.47s/it]\u001b[A\n"," 96% 43/45 [01:51<00:04,  2.40s/it]\u001b[A\n","                                             \n","\u001b[A{'eval_loss': 1.5342081785202026, 'eval_accuracy': 0.6203634112913922, 'eval_runtime': 117.6614, 'eval_samples_per_second': 192.238, 'eval_steps_per_second': 0.382, 'epoch': 14.0}\n","  5% 1246/26700 [1:18:33<13:23:24,  1.89s/it]\n","100% 45/45 [01:52<00:00,  1.86s/it]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2841] 2023-09-03 19:34:39,817 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/checkpoint-1246\n","[INFO|configuration_utils.py:460] 2023-09-03 19:34:39,823 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/checkpoint-1246/config.json\n","[INFO|modeling_utils.py:1992] 2023-09-03 19:34:39,933 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/checkpoint-1246/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-03 19:34:39,938 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/checkpoint-1246/preprocessor_config.json\n","[INFO|trainer.py:2928] 2023-09-03 19:34:40,178 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/checkpoint-1068] due to args.save_total_limit\n","{'loss': 1.0112, 'learning_rate': 0.0009531835205992509, 'epoch': 14.04}\n","{'loss': 0.9599, 'learning_rate': 0.000952808988764045, 'epoch': 14.16}\n","{'loss': 0.9743, 'learning_rate': 0.000952434456928839, 'epoch': 14.27}\n","{'loss': 0.9354, 'learning_rate': 0.0009520599250936329, 'epoch': 14.38}\n","{'loss': 0.9952, 'learning_rate': 0.000951685393258427, 'epoch': 14.49}\n","{'loss': 0.9812, 'learning_rate': 0.000951310861423221, 'epoch': 14.61}\n","{'loss': 1.0146, 'learning_rate': 0.000950936329588015, 'epoch': 14.72}\n","{'loss': 1.0128, 'learning_rate': 0.0009505617977528091, 'epoch': 14.83}\n","{'loss': 1.0337, 'learning_rate': 0.000950187265917603, 'epoch': 14.94}\n","  5% 1334/26700 [1:22:10<13:03:53,  1.85s/it][INFO|trainer.py:3115] 2023-09-03 19:38:17,195 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3117] 2023-09-03 19:38:17,195 >>   Num examples = 22619\n","[INFO|trainer.py:3120] 2023-09-03 19:38:17,195 >>   Batch size = 512\n","\n","  0% 0/45 [00:00<?, ?it/s]\u001b[A\n","  4% 2/45 [00:02<00:54,  1.26s/it]\u001b[A\n","  7% 3/45 [00:05<01:21,  1.94s/it]\u001b[A\n","  9% 4/45 [00:07<01:27,  2.14s/it]\u001b[A\n"," 11% 5/45 [00:10<01:31,  2.29s/it]\u001b[A\n"," 13% 6/45 [00:13<01:38,  2.54s/it]\u001b[A\n"," 16% 7/45 [00:16<01:42,  2.71s/it]\u001b[A\n"," 18% 8/45 [00:19<01:45,  2.84s/it]\u001b[A\n"," 20% 9/45 [00:22<01:46,  2.96s/it]\u001b[A\n"," 22% 10/45 [00:26<01:47,  3.06s/it]\u001b[A\n"," 24% 11/45 [00:28<01:37,  2.86s/it]\u001b[A\n"," 27% 12/45 [00:31<01:32,  2.81s/it]\u001b[A\n"," 29% 13/45 [00:33<01:25,  2.67s/it]\u001b[A\n"," 31% 14/45 [00:36<01:23,  2.70s/it]\u001b[A\n"," 33% 15/45 [00:38<01:18,  2.63s/it]\u001b[A\n"," 36% 16/45 [00:41<01:16,  2.63s/it]\u001b[A\n"," 38% 17/45 [00:43<01:11,  2.55s/it]\u001b[A\n"," 40% 18/45 [00:45<01:05,  2.41s/it]\u001b[A\n"," 42% 19/45 [00:48<01:03,  2.46s/it]\u001b[A\n"," 44% 20/45 [00:51<01:03,  2.54s/it]\u001b[A\n"," 47% 21/45 [00:53<01:01,  2.56s/it]\u001b[A\n"," 49% 22/45 [00:56<00:57,  2.50s/it]\u001b[A\n"," 51% 23/45 [00:58<00:55,  2.54s/it]\u001b[A\n"," 53% 24/45 [01:01<00:56,  2.69s/it]\u001b[A\n"," 56% 25/45 [01:04<00:54,  2.71s/it]\u001b[A\n"," 58% 26/45 [01:06<00:47,  2.48s/it]\u001b[A\n"," 60% 27/45 [01:09<00:47,  2.64s/it]\u001b[A\n"," 62% 28/45 [01:12<00:46,  2.76s/it]\u001b[A\n"," 64% 29/45 [01:15<00:42,  2.68s/it]\u001b[A\n"," 67% 30/45 [01:17<00:40,  2.67s/it]\u001b[A\n"," 69% 31/45 [01:20<00:39,  2.81s/it]\u001b[A\n"," 71% 32/45 [01:23<00:37,  2.87s/it]\u001b[A\n"," 73% 33/45 [01:26<00:34,  2.84s/it]\u001b[A\n"," 76% 34/45 [01:29<00:31,  2.88s/it]\u001b[A\n"," 78% 35/45 [01:32<00:28,  2.88s/it]\u001b[A\n"," 80% 36/45 [01:35<00:25,  2.85s/it]\u001b[A\n"," 82% 37/45 [01:37<00:21,  2.64s/it]\u001b[A\n"," 84% 38/45 [01:39<00:17,  2.47s/it]\u001b[A\n"," 87% 39/45 [01:41<00:14,  2.41s/it]\u001b[A\n"," 89% 40/45 [01:44<00:12,  2.60s/it]\u001b[A\n"," 91% 41/45 [01:47<00:10,  2.52s/it]\u001b[A\n"," 93% 42/45 [01:49<00:07,  2.48s/it]\u001b[A\n"," 96% 43/45 [01:51<00:04,  2.38s/it]\u001b[A\n","                                             \n","\u001b[A{'eval_loss': 1.5194101333618164, 'eval_accuracy': 0.6246960519916884, 'eval_runtime': 117.9605, 'eval_samples_per_second': 191.751, 'eval_steps_per_second': 0.381, 'epoch': 15.0}\n","  5% 1335/26700 [1:24:08<13:03:51,  1.85s/it]\n","100% 45/45 [01:52<00:00,  1.85s/it]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2841] 2023-09-03 19:40:15,161 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/checkpoint-1335\n","[INFO|configuration_utils.py:460] 2023-09-03 19:40:15,166 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/checkpoint-1335/config.json\n","[INFO|modeling_utils.py:1992] 2023-09-03 19:40:15,271 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/checkpoint-1335/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-03 19:40:15,276 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/checkpoint-1335/preprocessor_config.json\n","[INFO|trainer.py:2928] 2023-09-03 19:40:15,501 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/checkpoint-1157] due to args.save_total_limit\n","{'loss': 1.0086, 'learning_rate': 0.0009498127340823969, 'epoch': 15.06}\n","{'loss': 0.9071, 'learning_rate': 0.000949438202247191, 'epoch': 15.17}\n","{'loss': 0.9133, 'learning_rate': 0.000949063670411985, 'epoch': 15.28}\n","{'loss': 0.9357, 'learning_rate': 0.000948689138576779, 'epoch': 15.39}\n","{'loss': 0.9583, 'learning_rate': 0.0009483146067415731, 'epoch': 15.51}\n","{'loss': 0.9703, 'learning_rate': 0.000947940074906367, 'epoch': 15.62}\n","{'loss': 0.962, 'learning_rate': 0.0009475655430711611, 'epoch': 15.73}\n","{'loss': 0.9796, 'learning_rate': 0.0009471910112359551, 'epoch': 15.84}\n","{'loss': 0.9684, 'learning_rate': 0.0009468164794007491, 'epoch': 15.96}\n","  5% 1423/26700 [1:27:45<12:41:03,  1.81s/it][INFO|trainer.py:3115] 2023-09-03 19:43:52,214 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3117] 2023-09-03 19:43:52,214 >>   Num examples = 22619\n","[INFO|trainer.py:3120] 2023-09-03 19:43:52,214 >>   Batch size = 512\n","\n","  0% 0/45 [00:00<?, ?it/s]\u001b[A\n","  4% 2/45 [00:02<00:53,  1.24s/it]\u001b[A\n","  7% 3/45 [00:05<01:19,  1.90s/it]\u001b[A\n","  9% 4/45 [00:07<01:28,  2.16s/it]\u001b[A\n"," 11% 5/45 [00:10<01:33,  2.33s/it]\u001b[A\n"," 13% 6/45 [00:13<01:40,  2.57s/it]\u001b[A\n"," 16% 7/45 [00:16<01:43,  2.72s/it]\u001b[A\n"," 18% 8/45 [00:19<01:45,  2.86s/it]\u001b[A\n"," 20% 9/45 [00:23<01:48,  3.00s/it]\u001b[A\n"," 22% 10/45 [00:26<01:48,  3.09s/it]\u001b[A\n"," 24% 11/45 [00:28<01:37,  2.87s/it]\u001b[A\n"," 27% 12/45 [00:31<01:32,  2.80s/it]\u001b[A\n"," 29% 13/45 [00:34<01:27,  2.74s/it]\u001b[A\n"," 31% 14/45 [00:36<01:26,  2.78s/it]\u001b[A\n"," 33% 15/45 [00:39<01:20,  2.69s/it]\u001b[A\n"," 36% 16/45 [00:42<01:17,  2.68s/it]\u001b[A\n"," 38% 17/45 [00:44<01:12,  2.57s/it]\u001b[A\n"," 40% 18/45 [00:46<01:05,  2.41s/it]\u001b[A\n"," 42% 19/45 [00:48<01:03,  2.45s/it]\u001b[A\n"," 44% 20/45 [00:51<01:03,  2.56s/it]\u001b[A\n"," 47% 21/45 [00:54<01:01,  2.57s/it]\u001b[A\n"," 49% 22/45 [00:56<00:57,  2.51s/it]\u001b[A\n"," 51% 23/45 [00:58<00:52,  2.41s/it]\u001b[A\n"," 53% 24/45 [01:01<00:53,  2.55s/it]\u001b[A\n"," 56% 25/45 [01:04<00:52,  2.64s/it]\u001b[A\n"," 58% 26/45 [01:06<00:46,  2.43s/it]\u001b[A\n"," 60% 27/45 [01:09<00:46,  2.61s/it]\u001b[A\n"," 62% 28/45 [01:12<00:46,  2.73s/it]\u001b[A\n"," 64% 29/45 [01:14<00:42,  2.63s/it]\u001b[A\n"," 67% 30/45 [01:17<00:39,  2.65s/it]\u001b[A\n"," 69% 31/45 [01:20<00:39,  2.82s/it]\u001b[A\n"," 71% 32/45 [01:23<00:37,  2.88s/it]\u001b[A\n"," 73% 33/45 [01:26<00:34,  2.84s/it]\u001b[A\n"," 76% 34/45 [01:29<00:31,  2.85s/it]\u001b[A\n"," 78% 35/45 [01:32<00:28,  2.87s/it]\u001b[A\n"," 80% 36/45 [01:35<00:25,  2.84s/it]\u001b[A\n"," 82% 37/45 [01:37<00:21,  2.64s/it]\u001b[A\n"," 84% 38/45 [01:39<00:17,  2.47s/it]\u001b[A\n"," 87% 39/45 [01:41<00:14,  2.40s/it]\u001b[A\n"," 89% 40/45 [01:44<00:12,  2.58s/it]\u001b[A\n"," 91% 41/45 [01:47<00:10,  2.54s/it]\u001b[A\n"," 93% 42/45 [01:49<00:07,  2.51s/it]\u001b[A\n"," 96% 43/45 [01:51<00:04,  2.41s/it]\u001b[A\n","                                             \n","\u001b[A{'eval_loss': 1.513673186302185, 'eval_accuracy': 0.6294265882665017, 'eval_runtime': 117.9386, 'eval_samples_per_second': 191.786, 'eval_steps_per_second': 0.382, 'epoch': 16.0}\n","  5% 1424/26700 [1:29:43<12:41:01,  1.81s/it]\n","100% 45/45 [01:52<00:00,  1.86s/it]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2841] 2023-09-03 19:45:50,159 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/checkpoint-1424\n","[INFO|configuration_utils.py:460] 2023-09-03 19:45:50,165 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/checkpoint-1424/config.json\n","[INFO|modeling_utils.py:1992] 2023-09-03 19:45:50,273 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/checkpoint-1424/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-03 19:45:50,277 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/checkpoint-1424/preprocessor_config.json\n","[INFO|trainer.py:2928] 2023-09-03 19:45:50,490 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/checkpoint-1246] due to args.save_total_limit\n","{'loss': 0.9746, 'learning_rate': 0.0009464419475655432, 'epoch': 16.07}\n","{'loss': 0.8621, 'learning_rate': 0.0009460674157303371, 'epoch': 16.18}\n","{'loss': 0.8969, 'learning_rate': 0.0009456928838951311, 'epoch': 16.29}\n","{'loss': 0.9375, 'learning_rate': 0.0009453183520599252, 'epoch': 16.4}\n","{'loss': 0.9398, 'learning_rate': 0.0009449438202247192, 'epoch': 16.52}\n","{'loss': 0.952, 'learning_rate': 0.0009445692883895131, 'epoch': 16.63}\n","{'loss': 0.9139, 'learning_rate': 0.0009441947565543071, 'epoch': 16.74}\n","{'loss': 0.985, 'learning_rate': 0.0009438202247191011, 'epoch': 16.85}\n","{'loss': 0.9522, 'learning_rate': 0.0009434456928838951, 'epoch': 16.97}\n","  6% 1512/26700 [1:33:20<12:33:10,  1.79s/it][INFO|trainer.py:3115] 2023-09-03 19:49:27,432 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3117] 2023-09-03 19:49:27,432 >>   Num examples = 22619\n","[INFO|trainer.py:3120] 2023-09-03 19:49:27,432 >>   Batch size = 512\n","\n","  0% 0/45 [00:00<?, ?it/s]\u001b[A\n","  4% 2/45 [00:02<00:53,  1.24s/it]\u001b[A\n","  7% 3/45 [00:05<01:19,  1.89s/it]\u001b[A\n","  9% 4/45 [00:07<01:26,  2.12s/it]\u001b[A\n"," 11% 5/45 [00:10<01:33,  2.33s/it]\u001b[A\n"," 13% 6/45 [00:13<01:40,  2.58s/it]\u001b[A\n"," 16% 7/45 [00:16<01:43,  2.72s/it]\u001b[A\n"," 18% 8/45 [00:19<01:44,  2.83s/it]\u001b[A\n"," 20% 9/45 [00:22<01:46,  2.97s/it]\u001b[A\n"," 22% 10/45 [00:26<01:48,  3.10s/it]\u001b[A\n"," 24% 11/45 [00:28<01:40,  2.96s/it]\u001b[A\n"," 27% 12/45 [00:31<01:34,  2.86s/it]\u001b[A\n"," 29% 13/45 [00:33<01:26,  2.70s/it]\u001b[A\n"," 31% 14/45 [00:36<01:24,  2.74s/it]\u001b[A\n"," 33% 15/45 [00:39<01:20,  2.68s/it]\u001b[A\n"," 36% 16/45 [00:42<01:17,  2.68s/it]\u001b[A\n"," 38% 17/45 [00:44<01:12,  2.58s/it]\u001b[A\n"," 40% 18/45 [00:46<01:05,  2.41s/it]\u001b[A\n"," 42% 19/45 [00:48<01:03,  2.44s/it]\u001b[A\n"," 44% 20/45 [00:51<01:03,  2.55s/it]\u001b[A\n"," 47% 21/45 [00:54<01:02,  2.60s/it]\u001b[A\n"," 49% 22/45 [00:56<00:58,  2.54s/it]\u001b[A\n"," 51% 23/45 [00:58<00:53,  2.43s/it]\u001b[A\n"," 53% 24/45 [01:01<00:53,  2.56s/it]\u001b[A\n"," 56% 25/45 [01:04<00:52,  2.63s/it]\u001b[A\n"," 58% 26/45 [01:06<00:46,  2.44s/it]\u001b[A\n"," 60% 27/45 [01:09<00:47,  2.63s/it]\u001b[A\n"," 62% 28/45 [01:12<00:46,  2.74s/it]\u001b[A\n"," 64% 29/45 [01:15<00:42,  2.64s/it]\u001b[A\n"," 67% 30/45 [01:17<00:39,  2.65s/it]\u001b[A\n"," 69% 31/45 [01:21<00:39,  2.86s/it]\u001b[A\n"," 71% 32/45 [01:24<00:38,  2.93s/it]\u001b[A\n"," 73% 33/45 [01:26<00:34,  2.88s/it]\u001b[A\n"," 76% 34/45 [01:29<00:31,  2.88s/it]\u001b[A\n"," 78% 35/45 [01:32<00:28,  2.88s/it]\u001b[A\n"," 80% 36/45 [01:35<00:25,  2.88s/it]\u001b[A\n"," 82% 37/45 [01:37<00:21,  2.67s/it]\u001b[A\n"," 84% 38/45 [01:39<00:17,  2.50s/it]\u001b[A\n"," 87% 39/45 [01:42<00:14,  2.42s/it]\u001b[A\n"," 89% 40/45 [01:45<00:12,  2.59s/it]\u001b[A\n"," 91% 41/45 [01:47<00:10,  2.53s/it]\u001b[A\n"," 93% 42/45 [01:49<00:07,  2.52s/it]\u001b[A\n"," 96% 43/45 [01:52<00:04,  2.43s/it]\u001b[A\n","                                             \n","\u001b[A{'eval_loss': 1.568617343902588, 'eval_accuracy': 0.6244749988947346, 'eval_runtime': 118.6275, 'eval_samples_per_second': 190.672, 'eval_steps_per_second': 0.379, 'epoch': 17.0}\n","  6% 1513/26700 [1:35:19<12:33:08,  1.79s/it]\n","100% 45/45 [01:52<00:00,  1.88s/it]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2841] 2023-09-03 19:51:26,066 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/checkpoint-1513\n","[INFO|configuration_utils.py:460] 2023-09-03 19:51:26,071 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/checkpoint-1513/config.json\n","[INFO|modeling_utils.py:1992] 2023-09-03 19:51:26,182 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/checkpoint-1513/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-03 19:51:26,185 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/checkpoint-1513/preprocessor_config.json\n","[INFO|trainer.py:2928] 2023-09-03 19:51:26,396 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/checkpoint-1335] due to args.save_total_limit\n","{'loss': 0.9025, 'learning_rate': 0.0009430711610486892, 'epoch': 17.08}\n","{'loss': 0.8414, 'learning_rate': 0.0009426966292134832, 'epoch': 17.19}\n","{'loss': 0.9281, 'learning_rate': 0.0009423220973782771, 'epoch': 17.3}\n","{'loss': 0.8638, 'learning_rate': 0.0009419475655430712, 'epoch': 17.42}\n","{'loss': 0.8593, 'learning_rate': 0.0009415730337078652, 'epoch': 17.53}\n","{'loss': 0.9359, 'learning_rate': 0.0009411985018726592, 'epoch': 17.64}\n","{'loss': 0.8979, 'learning_rate': 0.0009408239700374533, 'epoch': 17.75}\n","{'loss': 0.9485, 'learning_rate': 0.0009404494382022473, 'epoch': 17.87}\n","{'loss': 0.9056, 'learning_rate': 0.0009400749063670412, 'epoch': 17.98}\n","  6% 1601/26700 [1:38:56<12:50:00,  1.84s/it][INFO|trainer.py:3115] 2023-09-03 19:55:02,967 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3117] 2023-09-03 19:55:02,967 >>   Num examples = 22619\n","[INFO|trainer.py:3120] 2023-09-03 19:55:02,968 >>   Batch size = 512\n","\n","  0% 0/45 [00:00<?, ?it/s]\u001b[A\n","  4% 2/45 [00:02<00:54,  1.26s/it]\u001b[A\n","  7% 3/45 [00:05<01:19,  1.89s/it]\u001b[A\n","  9% 4/45 [00:07<01:26,  2.11s/it]\u001b[A\n"," 11% 5/45 [00:10<01:30,  2.27s/it]\u001b[A\n"," 13% 6/45 [00:13<01:39,  2.54s/it]\u001b[A\n"," 16% 7/45 [00:16<01:42,  2.70s/it]\u001b[A\n"," 18% 8/45 [00:19<01:44,  2.81s/it]\u001b[A\n"," 20% 9/45 [00:22<01:45,  2.94s/it]\u001b[A\n"," 22% 10/45 [00:26<01:47,  3.06s/it]\u001b[A\n"," 24% 11/45 [00:28<01:37,  2.87s/it]\u001b[A\n"," 27% 12/45 [00:31<01:32,  2.80s/it]\u001b[A\n"," 29% 13/45 [00:33<01:24,  2.65s/it]\u001b[A\n"," 31% 14/45 [00:36<01:23,  2.68s/it]\u001b[A\n"," 33% 15/45 [00:38<01:18,  2.61s/it]\u001b[A\n"," 36% 16/45 [00:41<01:16,  2.63s/it]\u001b[A\n"," 38% 17/45 [00:43<01:11,  2.57s/it]\u001b[A\n"," 40% 18/45 [00:45<01:04,  2.41s/it]\u001b[A\n"," 42% 19/45 [00:48<01:03,  2.43s/it]\u001b[A\n"," 44% 20/45 [00:51<01:05,  2.60s/it]\u001b[A\n"," 47% 21/45 [00:53<01:02,  2.60s/it]\u001b[A\n"," 49% 22/45 [00:56<00:58,  2.56s/it]\u001b[A\n"," 51% 23/45 [00:58<00:54,  2.46s/it]\u001b[A\n"," 53% 24/45 [01:01<00:54,  2.58s/it]\u001b[A\n"," 56% 25/45 [01:04<00:52,  2.63s/it]\u001b[A\n"," 58% 26/45 [01:06<00:45,  2.42s/it]\u001b[A\n"," 60% 27/45 [01:09<00:46,  2.60s/it]\u001b[A\n"," 62% 28/45 [01:12<00:46,  2.74s/it]\u001b[A\n"," 64% 29/45 [01:14<00:42,  2.64s/it]\u001b[A\n"," 67% 30/45 [01:17<00:39,  2.65s/it]\u001b[A\n"," 69% 31/45 [01:20<00:39,  2.79s/it]\u001b[A\n"," 71% 32/45 [01:23<00:37,  2.88s/it]\u001b[A\n"," 73% 33/45 [01:26<00:34,  2.85s/it]\u001b[A\n"," 76% 34/45 [01:29<00:31,  2.85s/it]\u001b[A\n"," 78% 35/45 [01:32<00:28,  2.85s/it]\u001b[A\n"," 80% 36/45 [01:34<00:25,  2.83s/it]\u001b[A\n"," 82% 37/45 [01:36<00:21,  2.63s/it]\u001b[A\n"," 84% 38/45 [01:39<00:17,  2.48s/it]\u001b[A\n"," 87% 39/45 [01:41<00:14,  2.42s/it]\u001b[A\n"," 89% 40/45 [01:44<00:12,  2.59s/it]\u001b[A\n"," 91% 41/45 [01:46<00:10,  2.52s/it]\u001b[A\n"," 93% 42/45 [01:49<00:07,  2.49s/it]\u001b[A\n"," 96% 43/45 [01:51<00:04,  2.40s/it]\u001b[A\n","                                             \n","\u001b[A{'eval_loss': 1.5828818082809448, 'eval_accuracy': 0.6316371192360405, 'eval_runtime': 117.5994, 'eval_samples_per_second': 192.339, 'eval_steps_per_second': 0.383, 'epoch': 18.0}\n","  6% 1602/26700 [1:40:54<12:49:59,  1.84s/it]\n","100% 45/45 [01:52<00:00,  1.86s/it]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2841] 2023-09-03 19:57:00,584 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/checkpoint-1602\n","[INFO|configuration_utils.py:460] 2023-09-03 19:57:00,592 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/checkpoint-1602/config.json\n","[INFO|modeling_utils.py:1992] 2023-09-03 19:57:00,706 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/checkpoint-1602/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-03 19:57:00,711 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/checkpoint-1602/preprocessor_config.json\n","[INFO|trainer.py:2928] 2023-09-03 19:57:00,933 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/checkpoint-1424] due to args.save_total_limit\n","{'loss': 0.8818, 'learning_rate': 0.0009397003745318353, 'epoch': 18.09}\n","{'loss': 0.8254, 'learning_rate': 0.0009393258426966292, 'epoch': 18.2}\n","{'loss': 0.8625, 'learning_rate': 0.0009389513108614232, 'epoch': 18.31}\n","{'loss': 0.8578, 'learning_rate': 0.0009385767790262173, 'epoch': 18.43}\n","{'loss': 0.8596, 'learning_rate': 0.0009382022471910112, 'epoch': 18.54}\n","{'loss': 0.8888, 'learning_rate': 0.0009378277153558052, 'epoch': 18.65}\n","{'loss': 0.8677, 'learning_rate': 0.0009374531835205993, 'epoch': 18.76}\n","{'loss': 0.8942, 'learning_rate': 0.0009370786516853933, 'epoch': 18.88}\n","{'loss': 0.8928, 'learning_rate': 0.0009367041198501873, 'epoch': 18.99}\n","  6% 1690/26700 [1:44:32<12:55:44,  1.86s/it][INFO|trainer.py:3115] 2023-09-03 20:00:38,968 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3117] 2023-09-03 20:00:38,968 >>   Num examples = 22619\n","[INFO|trainer.py:3120] 2023-09-03 20:00:38,968 >>   Batch size = 512\n","\n","  0% 0/45 [00:00<?, ?it/s]\u001b[A\n","  4% 2/45 [00:02<00:55,  1.29s/it]\u001b[A\n","  7% 3/45 [00:05<01:22,  1.97s/it]\u001b[A\n","  9% 4/45 [00:08<01:28,  2.17s/it]\u001b[A\n"," 11% 5/45 [00:10<01:32,  2.32s/it]\u001b[A\n"," 13% 6/45 [00:13<01:39,  2.55s/it]\u001b[A\n"," 16% 7/45 [00:16<01:43,  2.73s/it]\u001b[A\n"," 18% 8/45 [00:19<01:46,  2.87s/it]\u001b[A\n"," 20% 9/45 [00:23<01:47,  2.98s/it]\u001b[A\n"," 22% 10/45 [00:26<01:48,  3.09s/it]\u001b[A\n"," 24% 11/45 [00:28<01:37,  2.88s/it]\u001b[A\n"," 27% 12/45 [00:31<01:33,  2.82s/it]\u001b[A\n"," 29% 13/45 [00:33<01:26,  2.69s/it]\u001b[A\n"," 31% 14/45 [00:36<01:24,  2.71s/it]\u001b[A\n"," 33% 15/45 [00:39<01:19,  2.64s/it]\u001b[A\n"," 36% 16/45 [00:41<01:16,  2.65s/it]\u001b[A\n"," 38% 17/45 [00:44<01:12,  2.60s/it]\u001b[A\n"," 40% 18/45 [00:46<01:06,  2.46s/it]\u001b[A\n"," 42% 19/45 [00:49<01:04,  2.49s/it]\u001b[A\n"," 44% 20/45 [00:51<01:04,  2.57s/it]\u001b[A\n"," 47% 21/45 [00:54<01:01,  2.58s/it]\u001b[A\n"," 49% 22/45 [00:56<00:57,  2.52s/it]\u001b[A\n"," 51% 23/45 [00:58<00:53,  2.43s/it]\u001b[A\n"," 53% 24/45 [01:01<00:54,  2.58s/it]\u001b[A\n"," 56% 25/45 [01:04<00:52,  2.63s/it]\u001b[A\n"," 58% 26/45 [01:06<00:45,  2.41s/it]\u001b[A\n"," 60% 27/45 [01:09<00:46,  2.60s/it]\u001b[A\n"," 62% 28/45 [01:12<00:46,  2.74s/it]\u001b[A\n"," 64% 29/45 [01:15<00:42,  2.68s/it]\u001b[A\n"," 67% 30/45 [01:17<00:40,  2.68s/it]\u001b[A\n"," 69% 31/45 [01:21<00:39,  2.82s/it]\u001b[A\n"," 71% 32/45 [01:24<00:37,  2.90s/it]\u001b[A\n"," 73% 33/45 [01:26<00:34,  2.86s/it]\u001b[A\n"," 76% 34/45 [01:29<00:31,  2.89s/it]\u001b[A\n"," 78% 35/45 [01:32<00:28,  2.89s/it]\u001b[A\n"," 80% 36/45 [01:35<00:25,  2.85s/it]\u001b[A\n"," 82% 37/45 [01:37<00:21,  2.65s/it]\u001b[A\n"," 84% 38/45 [01:39<00:17,  2.48s/it]\u001b[A\n"," 87% 39/45 [01:42<00:14,  2.44s/it]\u001b[A\n"," 89% 40/45 [01:45<00:13,  2.62s/it]\u001b[A\n"," 91% 41/45 [01:47<00:10,  2.54s/it]\u001b[A\n"," 93% 42/45 [01:49<00:07,  2.50s/it]\u001b[A\n"," 96% 43/45 [01:52<00:04,  2.40s/it]\u001b[A\n","                                             \n","\u001b[A{'eval_loss': 1.5293278694152832, 'eval_accuracy': 0.639506609487599, 'eval_runtime': 118.3056, 'eval_samples_per_second': 191.191, 'eval_steps_per_second': 0.38, 'epoch': 19.0}\n","  6% 1691/26700 [1:46:30<12:55:42,  1.86s/it]\n","100% 45/45 [01:52<00:00,  1.86s/it]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2841] 2023-09-03 20:02:37,278 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/checkpoint-1691\n","[INFO|configuration_utils.py:460] 2023-09-03 20:02:37,283 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/checkpoint-1691/config.json\n","[INFO|modeling_utils.py:1992] 2023-09-03 20:02:37,392 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/checkpoint-1691/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-03 20:02:37,396 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/checkpoint-1691/preprocessor_config.json\n","[INFO|trainer.py:2928] 2023-09-03 20:02:37,625 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/checkpoint-1513] due to args.save_total_limit\n","[INFO|trainer.py:1960] 2023-09-03 20:02:37,643 >> \n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","[INFO|trainer.py:2122] 2023-09-03 20:02:37,644 >> Loading best model from drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/checkpoint-801 (score: 1.5120697021484375).\n","{'train_runtime': 6391.182, 'train_samples_per_second': 2116.745, 'train_steps_per_second': 4.178, 'train_loss': 1.3272419303638001, 'epoch': 19.0}\n","  6% 1691/26700 [1:46:31<26:15:22,  3.78s/it]\n","[INFO|trainer.py:2841] 2023-09-03 20:02:37,707 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/\n","[INFO|configuration_utils.py:460] 2023-09-03 20:02:37,712 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/config.json\n","[INFO|modeling_utils.py:1992] 2023-09-03 20:02:37,821 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-03 20:02:37,824 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/ip102_outputs_10/preprocessor_config.json\n","***** train metrics *****\n","  epoch                    =       19.0\n","  train_loss               =     1.3272\n","  train_runtime            = 1:46:31.18\n","  train_samples_per_second =   2116.745\n","  train_steps_per_second   =      4.178\n","[INFO|trainer.py:3115] 2023-09-03 20:02:37,841 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3117] 2023-09-03 20:02:37,841 >>   Num examples = 22619\n","[INFO|trainer.py:3120] 2023-09-03 20:02:37,841 >>   Batch size = 512\n","100% 45/45 [01:53<00:00,  2.51s/it]\n","***** eval metrics *****\n","  epoch                   =       19.0\n","  eval_accuracy           =     0.6105\n","  eval_loss               =     1.5121\n","  eval_runtime            = 0:01:58.74\n","  eval_samples_per_second =    190.477\n","  eval_steps_per_second   =      0.379\n","\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n","\u001b[34m\u001b[1mwandb\u001b[0m:                  eval/accuracy ▁▂▄▅▆▆▆▆▇▇▇▇▇▇█████▇\n","\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/loss █▇▄▃▂▂▂▂▁▁▁▂▁▁▁▁▁▂▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/runtime ▅▆▆▃▅▆█▆▅▂▇▆▃▁▃▃▇▁▅█\n","\u001b[34m\u001b[1mwandb\u001b[0m:        eval/samples_per_second ▄▃▃▆▄▃▁▃▄▇▂▃▆█▆▆▂█▄▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:          eval/steps_per_second ▃▃▃▆▅▃▁▃▃▆▁▃▅▆▅▆▁█▃▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███\n","\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███\n","\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate ███▇▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss █▆▅▅▅▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁▂▁▁▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n","\u001b[34m\u001b[1mwandb\u001b[0m:                  eval/accuracy 0.61046\n","\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/loss 1.51207\n","\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/runtime 118.7493\n","\u001b[34m\u001b[1mwandb\u001b[0m:        eval/samples_per_second 190.477\n","\u001b[34m\u001b[1mwandb\u001b[0m:          eval/steps_per_second 0.379\n","\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch 19.0\n","\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step 1691\n","\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate 0.00094\n","\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss 0.8928\n","\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos 8.689311177281925e+18\n","\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss 1.32724\n","\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime 6391.182\n","\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second 2116.745\n","\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second 4.178\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mlikely-elevator-20\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/u15048366/colabCnnIp102Run1/runs/q9iyy5f8\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n","\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230903_181541-q9iyy5f8/logs\u001b[0m\n"]}],"source":["!python drive/MyDrive/hons-research/script/cnn-run8.py \\\n","    --model_type efficientnet \\\n","    --dataset_name mnist \\\n","    --output_dir drive/MyDrive/hons-research/output/mnist_outputs_8/ \\\n","    --remove_unused_columns False \\\n","    --do_train \\\n","    --do_eval \\\n","    --push_to_hub False \\\n","    --learning_rate 0.001 \\\n","    --num_train_epochs 50 \\\n","    --per_device_train_batch_size 64 \\\n","    --per_device_eval_batch_size 64 \\\n","    --logging_strategy steps \\\n","    --logging_steps 10 \\\n","    --evaluation_strategy epoch \\\n","    --save_strategy epoch \\\n","    --load_best_model_at_end True \\\n","    --save_total_limit 3 \\\n","    --save_steps 500 \\\n","    --data_seed 8 \\\n","    --seed 8\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1693166189327,"user":{"displayName":"Andreas Louw","userId":"11183032721846533402"},"user_tz":-120},"id":"jLPgVSaRFd--","outputId":"ec4b1236-69a1-47bf-fe89-964ab15cbc42"},"outputs":[{"name":"stdout","output_type":"stream","text":["python3: can't open file '/content/drive/MyDrive/hons-research/script/cnn-run9.py': [Errno 2] No such file or directory\n"]}],"source":["!python drive/MyDrive/hons-research/script/cnn-run9.py \\\n","    --model_type efficientnet \\\n","    --dataset_name mnist \\\n","    --output_dir drive/MyDrive/hons-research/output/mnist_outputs_9/ \\\n","    --remove_unused_columns False \\\n","    --do_train \\\n","    --do_eval \\\n","    --push_to_hub False \\\n","    --learning_rate 0.001 \\\n","    --num_train_epochs 50 \\\n","    --per_device_train_batch_size 64 \\\n","    --per_device_eval_batch_size 64 \\\n","    --logging_strategy steps \\\n","    --logging_steps 10 \\\n","    --evaluation_strategy epoch \\\n","    --save_strategy epoch \\\n","    --load_best_model_at_end True \\\n","    --save_total_limit 3 \\\n","    --save_steps 500 \\\n","    --data_seed 9 \\\n","    --seed 9\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1693166189328,"user":{"displayName":"Andreas Louw","userId":"11183032721846533402"},"user_tz":-120},"id":"3PTS2JTqFgJM","outputId":"621c9280-5806-4f16-b02d-bf0de2ccb5f3"},"outputs":[{"name":"stdout","output_type":"stream","text":["python3: can't open file '/content/drive/MyDrive/hons-research/script/cnn-run10.py': [Errno 2] No such file or directory\n"]}],"source":["!python drive/MyDrive/hons-research/script/cnn-run10.py \\\n","    --model_type efficientnet \\\n","    --dataset_name mnist \\\n","    --output_dir drive/MyDrive/hons-research/output/mnist_outputs_10/ \\\n","    --remove_unused_columns False \\\n","    --do_train \\\n","    --do_eval \\\n","    --push_to_hub False \\\n","    --learning_rate 0.001 \\\n","    --num_train_epochs 50 \\\n","    --per_device_train_batch_size 64 \\\n","    --per_device_eval_batch_size 64 \\\n","    --logging_strategy steps \\\n","    --logging_steps 10 \\\n","    --evaluation_strategy epoch \\\n","    --save_strategy epoch \\\n","    --load_best_model_at_end True \\\n","    --save_total_limit 3 \\\n","    --save_steps 500 \\\n","    --data_seed 10 \\\n","    --seed 10\n"]},{"cell_type":"code","source":["# End run\n","\n","from google.colab import runtime\n","runtime.unassign()"],"metadata":{"id":"J-wcB2jSY7H1"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[{"file_id":"17Xhtplfpdqdz1TwipHI60aqky1CvSd1x","timestamp":1693214691473}],"gpuType":"A100"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}