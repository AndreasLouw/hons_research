{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":48838,"status":"ok","timestamp":1695144703490,"user":{"displayName":"Andreas Louw","userId":"11183032721846533402"},"user_tz":-120},"id":"sMTacwHyZP-0","outputId":"058285b5-30ae-4fc2-aa2f-c67eb802bb4d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.2+cu118)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.27.4.1)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.6)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.23.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2023.7.22)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n","Collecting datasets\n","  Downloading datasets-2.14.5-py3-none-any.whl (519 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.6/519.6 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting evaluate\n","  Downloading evaluate-0.4.0-py3-none-any.whl (81 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.4/81.4 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting wandb\n","  Downloading wandb-0.15.10-py3-none-any.whl (2.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n","Collecting dill<0.3.8,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n","Collecting xxhash (from datasets)\n","  Downloading xxhash-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting multiprocess (from datasets)\n","  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]<2023.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.5)\n","Collecting huggingface-hub<1.0.0,>=0.14.0 (from datasets)\n","  Downloading huggingface_hub-0.17.2-py3-none-any.whl (294 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n","Collecting responses<0.19 (from evaluate)\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n","Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n","  Downloading GitPython-3.1.36-py3-none-any.whl (189 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.5/189.5 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n","Collecting sentry-sdk>=1.0.0 (from wandb)\n","  Downloading sentry_sdk-1.31.0-py2.py3-none-any.whl (224 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.8/224.8 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb)\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Collecting pathtools (from wandb)\n","  Downloading pathtools-0.1.2.tar.gz (11 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting setproctitle (from wandb)\n","  Downloading setproctitle-1.3.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n","Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n","Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n","Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.2.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n","  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.12.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.5.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.7.22)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n","Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n","  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n","Building wheels for collected packages: pathtools\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8791 sha256=3dd4c005a126ad3ced48c2d8a9752f3955bf2ff9a96e2d7a0f4699338f968eb7\n","  Stored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n","Successfully built pathtools\n","Installing collected packages: pathtools, xxhash, smmap, setproctitle, sentry-sdk, docker-pycreds, dill, responses, multiprocess, huggingface-hub, gitdb, GitPython, wandb, datasets, evaluate\n","Successfully installed GitPython-3.1.36 datasets-2.14.5 dill-0.3.7 docker-pycreds-0.4.0 evaluate-0.4.0 gitdb-4.0.10 huggingface-hub-0.17.2 multiprocess-0.70.15 pathtools-0.1.2 responses-0.18.0 sentry-sdk-1.31.0 setproctitle-1.3.2 smmap-5.0.1 wandb-0.15.10 xxhash-3.3.0\n","Collecting git+https://github.com/huggingface/transformers\n","  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-wr_i96zk\n","  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-wr_i96zk\n","  Resolved https://github.com/huggingface/transformers to commit 39df4eca739b0870f73dbcfdfa09179e3135c75d\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.0.dev0) (3.12.2)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.0.dev0) (0.17.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.0.dev0) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.0.dev0) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.0.dev0) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.0.dev0) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.0.dev0) (2.31.0)\n","Collecting tokenizers<0.15,>=0.14 (from transformers==4.34.0.dev0)\n","  Downloading tokenizers-0.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.3.1 (from transformers==4.34.0.dev0)\n","  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.0.dev0) (4.66.1)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers==4.34.0.dev0) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers==4.34.0.dev0) (4.5.0)\n","Collecting huggingface-hub<1.0,>=0.15.1 (from transformers==4.34.0.dev0)\n","  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.34.0.dev0) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.34.0.dev0) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.34.0.dev0) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.34.0.dev0) (2023.7.22)\n","Building wheels for collected packages: transformers\n","  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for transformers: filename=transformers-4.34.0.dev0-py3-none-any.whl size=7700260 sha256=ed79264949f8167f930730d3ed89ea6baa6e47b32c178798818c9a2a1cb44f08\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-01u7fidr/wheels/c0/14/d6/6c9a5582d2ac191ec0a483be151a4495fe1eb2a6706ca49f1b\n","Successfully built transformers\n","Installing collected packages: safetensors, huggingface-hub, tokenizers, transformers\n","  Attempting uninstall: huggingface-hub\n","    Found existing installation: huggingface-hub 0.17.2\n","    Uninstalling huggingface-hub-0.17.2:\n","      Successfully uninstalled huggingface-hub-0.17.2\n","Successfully installed huggingface-hub-0.16.4 safetensors-0.3.3 tokenizers-0.14.0 transformers-4.34.0.dev0\n","Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.15.10)\n","Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n","Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.36)\n","Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n","Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.31.0)\n","Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n","Requirement already satisfied: pathtools in /usr/local/lib/python3.10/dist-packages (from wandb) (0.1.2)\n","Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n","Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n","Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n","Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.10)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2023.7.22)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n","Collecting accelerate\n","  Downloading accelerate-0.23.0-py3-none-any.whl (258 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.1/258.1 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n","Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.1+cu118)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.16.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.12.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (3.27.4.1)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (16.0.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2023.6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2023.7.22)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n","Installing collected packages: accelerate\n","Successfully installed accelerate-0.23.0\n"]}],"source":["!pip install torch torchvision\n","!pip install datasets evaluate wandb\n","!pip install git+https://github.com/huggingface/transformers\n","!pip install wandb\n","!pip install accelerate"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27629,"status":"ok","timestamp":1695144731110,"user":{"displayName":"Andreas Louw","userId":"11183032721846533402"},"user_tz":-120},"id":"EFvpsHyFu1Nj","outputId":"a9ef8a14-1b5e-4b14-8188-e9c329f57a6f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1617,"status":"ok","timestamp":1694709687533,"user":{"displayName":"Andreas Louw","userId":"11183032721846533402"},"user_tz":-120},"id":"TNiM3mmXeeqS","outputId":"d893bbae-8ab5-47e0-ae05-a0bbc9bcb725"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-09-14 16:41:26--  https://docs.google.com/uc?export=download&confirm=&id=1tRz38DckvY3K437jd_jmml9las3le7pE\n","Resolving docs.google.com (docs.google.com)... 64.233.189.138, 64.233.189.113, 64.233.189.101, ...\n","Connecting to docs.google.com (docs.google.com)|64.233.189.138|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://accounts.google.com/ServiceLogin?service=wise&passive=1209600&continue=https://docs.google.com/uc?export%3Ddownload%26confirm%26id%3D1tRz38DckvY3K437jd_jmml9las3le7pE&followup=https://docs.google.com/uc?export%3Ddownload%26confirm%26id%3D1tRz38DckvY3K437jd_jmml9las3le7pE [following]\n","--2023-09-14 16:41:26--  https://accounts.google.com/ServiceLogin?service=wise&passive=1209600&continue=https://docs.google.com/uc?export%3Ddownload%26confirm%26id%3D1tRz38DckvY3K437jd_jmml9las3le7pE&followup=https://docs.google.com/uc?export%3Ddownload%26confirm%26id%3D1tRz38DckvY3K437jd_jmml9las3le7pE\n","Resolving accounts.google.com (accounts.google.com)... 108.177.125.84, 2404:6800:4008:c06::54\n","Connecting to accounts.google.com (accounts.google.com)|108.177.125.84|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://accounts.google.com/InteractiveLogin?continue=https://docs.google.com/uc?export%3Ddownload%26confirm%26id%3D1tRz38DckvY3K437jd_jmml9las3le7pE&followup=https://docs.google.com/uc?export%3Ddownload%26confirm%26id%3D1tRz38DckvY3K437jd_jmml9las3le7pE&passive=1209600&service=wise&ifkv=AYZoVhfRS6W6ayS26XzIyC5LFfMZd_KVvZYshUFzy0fRy2yQALEEZbMHnAqTaO5tdjZPp6BaQSCBXA [following]\n","--2023-09-14 16:41:26--  https://accounts.google.com/InteractiveLogin?continue=https://docs.google.com/uc?export%3Ddownload%26confirm%26id%3D1tRz38DckvY3K437jd_jmml9las3le7pE&followup=https://docs.google.com/uc?export%3Ddownload%26confirm%26id%3D1tRz38DckvY3K437jd_jmml9las3le7pE&passive=1209600&service=wise&ifkv=AYZoVhfRS6W6ayS26XzIyC5LFfMZd_KVvZYshUFzy0fRy2yQALEEZbMHnAqTaO5tdjZPp6BaQSCBXA\n","Reusing existing connection to accounts.google.com:443.\n","HTTP request sent, awaiting response... 302 Moved Temporarily\n","Location: https://accounts.google.com/v3/signin/identifier?continue=https%3A%2F%2Fdocs.google.com%2Fuc%3Fexport%3Ddownload%26confirm%26id%3D1tRz38DckvY3K437jd_jmml9las3le7pE&followup=https%3A%2F%2Fdocs.google.com%2Fuc%3Fexport%3Ddownload%26confirm%26id%3D1tRz38DckvY3K437jd_jmml9las3le7pE&ifkv=AYZoVhcbvic5OmqanHQd9lIt9v-6UZxyK9YswROBONbE_K6rkWBNB_nwWZBwlStxNRHQ-Q4URgwoLQ&passive=1209600&service=wise&flowName=WebLiteSignIn&flowEntry=ServiceLogin&dsh=S-1240692885%3A1694709686552835 [following]\n","--2023-09-14 16:41:26--  https://accounts.google.com/v3/signin/identifier?continue=https%3A%2F%2Fdocs.google.com%2Fuc%3Fexport%3Ddownload%26confirm%26id%3D1tRz38DckvY3K437jd_jmml9las3le7pE&followup=https%3A%2F%2Fdocs.google.com%2Fuc%3Fexport%3Ddownload%26confirm%26id%3D1tRz38DckvY3K437jd_jmml9las3le7pE&ifkv=AYZoVhcbvic5OmqanHQd9lIt9v-6UZxyK9YswROBONbE_K6rkWBNB_nwWZBwlStxNRHQ-Q4URgwoLQ&passive=1209600&service=wise&flowName=WebLiteSignIn&flowEntry=ServiceLogin&dsh=S-1240692885%3A1694709686552835\n","Reusing existing connection to accounts.google.com:443.\n","HTTP request sent, awaiting response... 200 OK\n","Length: unspecified [text/html]\n","Saving to: ‘cnn.py’\n","\n","cnn.py                  [ <=>                ] 572.38K  --.-KB/s    in 0.06s   \n","\n","2023-09-14 16:41:26 (8.69 MB/s) - ‘cnn.py’ saved [586114]\n","\n"]}],"source":["!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1tRz38DckvY3K437jd_jmml9las3le7pE' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1tRz38DckvY3K437jd_jmml9las3le7pE\" -O cnn.py && rm -rf /tmp/cookies.txt\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1919,"status":"ok","timestamp":1694709689450,"user":{"displayName":"Andreas Louw","userId":"11183032721846533402"},"user_tz":-120},"id":"20sHhOg9u425","outputId":"f5acfcdf-8551-4ab6-9a78-740bdbe25645"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-09-14 16:41:28--  https://docs.google.com/uc?export=download&confirm=&id=1tRz38DckvY3K437jd_jmml9las3le7pE\n","Resolving docs.google.com (docs.google.com)... 64.233.189.138, 64.233.189.113, 64.233.189.101, ...\n","Connecting to docs.google.com (docs.google.com)|64.233.189.138|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://accounts.google.com/ServiceLogin?service=wise&passive=1209600&continue=https://docs.google.com/uc?export%3Ddownload%26confirm%26id%3D1tRz38DckvY3K437jd_jmml9las3le7pE&followup=https://docs.google.com/uc?export%3Ddownload%26confirm%26id%3D1tRz38DckvY3K437jd_jmml9las3le7pE [following]\n","--2023-09-14 16:41:28--  https://accounts.google.com/ServiceLogin?service=wise&passive=1209600&continue=https://docs.google.com/uc?export%3Ddownload%26confirm%26id%3D1tRz38DckvY3K437jd_jmml9las3le7pE&followup=https://docs.google.com/uc?export%3Ddownload%26confirm%26id%3D1tRz38DckvY3K437jd_jmml9las3le7pE\n","Resolving accounts.google.com (accounts.google.com)... 108.177.125.84, 2404:6800:4008:c06::54\n","Connecting to accounts.google.com (accounts.google.com)|108.177.125.84|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://accounts.google.com/InteractiveLogin?continue=https://docs.google.com/uc?export%3Ddownload%26confirm%26id%3D1tRz38DckvY3K437jd_jmml9las3le7pE&followup=https://docs.google.com/uc?export%3Ddownload%26confirm%26id%3D1tRz38DckvY3K437jd_jmml9las3le7pE&passive=1209600&service=wise&ifkv=AYZoVhdYfvlVXen0UNVhAEkM_MWJU8q8crk-AcRalf7InywggzFDHSF-4i_19JYw9KrcW0LJE_llcQ [following]\n","--2023-09-14 16:41:28--  https://accounts.google.com/InteractiveLogin?continue=https://docs.google.com/uc?export%3Ddownload%26confirm%26id%3D1tRz38DckvY3K437jd_jmml9las3le7pE&followup=https://docs.google.com/uc?export%3Ddownload%26confirm%26id%3D1tRz38DckvY3K437jd_jmml9las3le7pE&passive=1209600&service=wise&ifkv=AYZoVhdYfvlVXen0UNVhAEkM_MWJU8q8crk-AcRalf7InywggzFDHSF-4i_19JYw9KrcW0LJE_llcQ\n","Reusing existing connection to accounts.google.com:443.\n","HTTP request sent, awaiting response... 302 Moved Temporarily\n","Location: https://accounts.google.com/v3/signin/identifier?continue=https%3A%2F%2Fdocs.google.com%2Fuc%3Fexport%3Ddownload%26confirm%26id%3D1tRz38DckvY3K437jd_jmml9las3le7pE&followup=https%3A%2F%2Fdocs.google.com%2Fuc%3Fexport%3Ddownload%26confirm%26id%3D1tRz38DckvY3K437jd_jmml9las3le7pE&ifkv=AYZoVhfSqXoVn69PZcDyYI923r8-EAkjcOzRttvbhfWOxkQCMgQjBYBH0JrwXL8aL-dyggofHZQBHQ&passive=1209600&service=wise&flowName=WebLiteSignIn&flowEntry=ServiceLogin&dsh=S118431352%3A1694709688342923 [following]\n","--2023-09-14 16:41:28--  https://accounts.google.com/v3/signin/identifier?continue=https%3A%2F%2Fdocs.google.com%2Fuc%3Fexport%3Ddownload%26confirm%26id%3D1tRz38DckvY3K437jd_jmml9las3le7pE&followup=https%3A%2F%2Fdocs.google.com%2Fuc%3Fexport%3Ddownload%26confirm%26id%3D1tRz38DckvY3K437jd_jmml9las3le7pE&ifkv=AYZoVhfSqXoVn69PZcDyYI923r8-EAkjcOzRttvbhfWOxkQCMgQjBYBH0JrwXL8aL-dyggofHZQBHQ&passive=1209600&service=wise&flowName=WebLiteSignIn&flowEntry=ServiceLogin&dsh=S118431352%3A1694709688342923\n","Reusing existing connection to accounts.google.com:443.\n","HTTP request sent, awaiting response... 200 OK\n","Length: unspecified [text/html]\n","Saving to: ‘cnn-mnist.py’\n","\n","cnn-mnist.py            [ <=>                ] 572.21K  --.-KB/s    in 0.07s   \n","\n","2023-09-14 16:41:28 (8.15 MB/s) - ‘cnn-mnist.py’ saved [585945]\n","\n"]}],"source":["# Downlaod cnn script\n","!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1tRz38DckvY3K437jd_jmml9las3le7pE' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1tRz38DckvY3K437jd_jmml9las3le7pE\" -O cnn-mnist.py && rm -rf /tmp/cookies.txt\n","\n","#https://drive.google.com/file/d/1tRz38DckvY3K437jd_jmml9las3le7pE/view?usp=drive_link"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gAU8ZpJXhnFG","outputId":"fa2a433f-7c06-4c90-a383-f1b1a15f860b"},"outputs":[{"output_type":"stream","name":"stdout","text":["2023-09-14 17:00:16.042934: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mu15048366\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.10\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20230914_170021-15g8189u\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mwandering-jazz-22\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/u15048366/colabCnnMnist\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/u15048366/colabCnnMnist/runs/15g8189u\u001b[0m\n","09/14/2023 17:00:22 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n","09/14/2023 17:00:22 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n","_n_gpu=1,\n","adafactor=False,\n","adam_beta1=0.9,\n","adam_beta2=0.999,\n","adam_epsilon=1e-08,\n","auto_find_batch_size=False,\n","bf16=False,\n","bf16_full_eval=False,\n","data_seed=1,\n","dataloader_drop_last=False,\n","dataloader_num_workers=0,\n","dataloader_pin_memory=True,\n","ddp_backend=None,\n","ddp_broadcast_buffers=None,\n","ddp_bucket_cap_mb=None,\n","ddp_find_unused_parameters=None,\n","ddp_timeout=1800,\n","debug=[],\n","deepspeed=None,\n","disable_tqdm=False,\n","dispatch_batches=None,\n","do_eval=True,\n","do_predict=False,\n","do_train=True,\n","eval_accumulation_steps=None,\n","eval_delay=0,\n","eval_steps=None,\n","evaluation_strategy=epoch,\n","fp16=False,\n","fp16_backend=auto,\n","fp16_full_eval=False,\n","fp16_opt_level=O1,\n","fsdp=[],\n","fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n","fsdp_min_num_params=0,\n","fsdp_transformer_layer_cls_to_wrap=None,\n","full_determinism=False,\n","gradient_accumulation_steps=1,\n","gradient_checkpointing=False,\n","greater_is_better=False,\n","group_by_length=False,\n","half_precision_backend=auto,\n","hub_always_push=False,\n","hub_model_id=None,\n","hub_private_repo=False,\n","hub_strategy=every_save,\n","hub_token=<HUB_TOKEN>,\n","ignore_data_skip=False,\n","include_inputs_for_metrics=False,\n","include_tokens_per_second=False,\n","jit_mode_eval=False,\n","label_names=None,\n","label_smoothing_factor=0.0,\n","learning_rate=0.001,\n","length_column_name=length,\n","load_best_model_at_end=True,\n","local_rank=0,\n","log_level=passive,\n","log_level_replica=warning,\n","log_on_each_node=True,\n","logging_dir=drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_1/runs/Sep14_17-00-22_a9e0c6ac3cfb,\n","logging_first_step=False,\n","logging_nan_inf_filter=True,\n","logging_steps=10,\n","logging_strategy=steps,\n","lr_scheduler_type=linear,\n","max_grad_norm=1.0,\n","max_steps=-1,\n","metric_for_best_model=loss,\n","mp_parameters=,\n","no_cuda=False,\n","num_train_epochs=300.0,\n","optim=adamw_torch,\n","optim_args=None,\n","output_dir=drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_1/,\n","overwrite_output_dir=False,\n","past_index=-1,\n","per_device_eval_batch_size=512,\n","per_device_train_batch_size=512,\n","prediction_loss_only=False,\n","push_to_hub=False,\n","push_to_hub_model_id=None,\n","push_to_hub_organization=None,\n","push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n","ray_scope=last,\n","remove_unused_columns=False,\n","report_to=['wandb'],\n","resume_from_checkpoint=None,\n","run_name=drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_1/,\n","save_on_each_node=False,\n","save_safetensors=False,\n","save_steps=500.0,\n","save_strategy=epoch,\n","save_total_limit=3,\n","seed=1,\n","sharded_ddp=[],\n","skip_memory_metrics=True,\n","tf32=None,\n","torch_compile=False,\n","torch_compile_backend=None,\n","torch_compile_mode=None,\n","torchdynamo=None,\n","tpu_metrics_debug=False,\n","tpu_num_cores=None,\n","use_cpu=False,\n","use_ipex=False,\n","use_legacy_prediction_loop=False,\n","use_mps_device=False,\n","warmup_ratio=0.0,\n","warmup_steps=0,\n","weight_decay=0.0,\n",")\n","/usr/local/lib/python3.10/dist-packages/datasets/load.py:2103: FutureWarning: 'task' was deprecated in version 2.13.0 and will be removed in 3.0.0.\n","\n","  warnings.warn(\n","Downloading builder script: 100% 3.98k/3.98k [00:00<00:00, 9.74MB/s]\n","Downloading metadata: 100% 2.21k/2.21k [00:00<00:00, 4.86MB/s]\n","Downloading readme: 100% 6.83k/6.83k [00:00<00:00, 13.5MB/s]\n","Downloading data files:   0% 0/4 [00:00<?, ?it/s]\n","Downloading data:   0% 0.00/9.91M [00:00<?, ?B/s]\u001b[A\n","Downloading data:   0% 48.1k/9.91M [00:00<00:27, 353kB/s]\u001b[A\n","Downloading data:   1% 84.0k/9.91M [00:00<00:29, 329kB/s]\u001b[A\n","Downloading data:   2% 196k/9.91M [00:00<00:15, 641kB/s] \u001b[A\n","Downloading data:   3% 343k/9.91M [00:00<00:10, 927kB/s]\u001b[A\n","Downloading data:   7% 654k/9.91M [00:00<00:05, 1.66MB/s]\u001b[A\n","Downloading data:  12% 1.20M/9.91M [00:00<00:03, 2.86MB/s]\u001b[A\n","Downloading data:  22% 2.23M/9.91M [00:00<00:01, 5.22MB/s]\u001b[A\n","Downloading data:  43% 4.23M/9.91M [00:00<00:00, 9.80MB/s]\u001b[A\n","Downloading data: 100% 9.91M/9.91M [00:01<00:00, 9.64MB/s]\n","Downloading data files:  25% 1/4 [00:02<00:07,  2.57s/it]\n","Downloading data: 100% 28.9k/28.9k [00:00<00:00, 2.06MB/s]\n","Downloading data files:  50% 2/4 [00:04<00:03,  1.96s/it]\n","Downloading data:   0% 0.00/1.65M [00:00<?, ?B/s]\u001b[A\n","Downloading data:   3% 48.1k/1.65M [00:00<00:04, 353kB/s]\u001b[A\n","Downloading data:   5% 84.0k/1.65M [00:00<00:04, 328kB/s]\u001b[A\n","Downloading data:  12% 196k/1.65M [00:00<00:02, 639kB/s] \u001b[A\n","Downloading data:  21% 343k/1.65M [00:00<00:01, 926kB/s]\u001b[A\n","Downloading data:  40% 654k/1.65M [00:00<00:00, 1.65MB/s]\u001b[A\n","Downloading data: 100% 1.65M/1.65M [00:00<00:00, 2.32MB/s]\n","Downloading data files:  75% 3/4 [00:06<00:02,  2.12s/it]\n","Downloading data: 100% 4.54k/4.54k [00:00<00:00, 8.11MB/s]\n","Downloading data files: 100% 4/4 [00:07<00:00,  1.98s/it]\n","Extracting data files: 100% 4/4 [00:00<00:00, 12.31it/s]\n","Generating train split: 100% 60000/60000 [00:10<00:00, 5634.75 examples/s]\n","Generating test split: 100% 10000/10000 [00:01<00:00, 5694.13 examples/s]\n","Casting the dataset: 100% 60000/60000 [00:00<00:00, 1657358.19 examples/s]\n","Casting the dataset: 100% 10000/10000 [00:00<00:00, 1376535.61 examples/s]\n","Downloading builder script: 100% 4.20k/4.20k [00:00<00:00, 9.57MB/s]\n","\n","\n","\n","None\n","\n","\n","\n","Downloading (…)lve/main/config.json: 100% 69.5k/69.5k [00:00<00:00, 22.3MB/s]\n","[INFO|configuration_utils.py:715] 2023-09-14 17:00:47,833 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--resnet-18/snapshots/f45a6faa12e0381f5620c5c8d7e916bca90f2c44/config.json\n","[INFO|configuration_utils.py:775] 2023-09-14 17:00:47,835 >> Model config ResNetConfig {\n","  \"_name_or_path\": \"microsoft/resnet-18\",\n","  \"architectures\": [\n","    \"ResNetForImageClassification\"\n","  ],\n","  \"depths\": [\n","    2,\n","    2,\n","    2,\n","    2\n","  ],\n","  \"downsample_in_first_stage\": false,\n","  \"embedding_size\": 64,\n","  \"finetuning_task\": \"image-classification\",\n","  \"hidden_act\": \"relu\",\n","  \"hidden_sizes\": [\n","    64,\n","    128,\n","    256,\n","    512\n","  ],\n","  \"id2label\": {\n","    \"0\": \"0\",\n","    \"1\": \"1\",\n","    \"2\": \"2\",\n","    \"3\": \"3\",\n","    \"4\": \"4\",\n","    \"5\": \"5\",\n","    \"6\": \"6\",\n","    \"7\": \"7\",\n","    \"8\": \"8\",\n","    \"9\": \"9\"\n","  },\n","  \"label2id\": {\n","    \"0\": \"0\",\n","    \"1\": \"1\",\n","    \"2\": \"2\",\n","    \"3\": \"3\",\n","    \"4\": \"4\",\n","    \"5\": \"5\",\n","    \"6\": \"6\",\n","    \"7\": \"7\",\n","    \"8\": \"8\",\n","    \"9\": \"9\"\n","  },\n","  \"layer_type\": \"basic\",\n","  \"model_type\": \"resnet\",\n","  \"num_channels\": 3,\n","  \"out_features\": [\n","    \"stage4\"\n","  ],\n","  \"out_indices\": [\n","    4\n","  ],\n","  \"stage_names\": [\n","    \"stem\",\n","    \"stage1\",\n","    \"stage2\",\n","    \"stage3\",\n","    \"stage4\"\n","  ],\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.34.0.dev0\"\n","}\n","\n","Downloading model.safetensors: 100% 46.8M/46.8M [00:00<00:00, 281MB/s]\n","[INFO|modeling_utils.py:2897] 2023-09-14 17:00:48,616 >> loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--microsoft--resnet-18/snapshots/f45a6faa12e0381f5620c5c8d7e916bca90f2c44/model.safetensors\n","[INFO|modeling_utils.py:3683] 2023-09-14 17:00:48,813 >> All model checkpoint weights were used when initializing ResNetForImageClassification.\n","\n","[WARNING|modeling_utils.py:3704] 2023-09-14 17:00:48,814 >> Some weights of ResNetForImageClassification were not initialized from the model checkpoint at microsoft/resnet-18 and are newly initialized because the shapes did not match:\n","- classifier.1.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([10]) in the model instantiated\n","- classifier.1.weight: found shape torch.Size([1000, 512]) in the checkpoint and torch.Size([10, 512]) in the model instantiated\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Downloading (…)rocessor_config.json: 100% 266/266 [00:00<00:00, 536kB/s]\n","[INFO|image_processing_utils.py:369] 2023-09-14 17:00:49,011 >> loading configuration file preprocessor_config.json from cache at /root/.cache/huggingface/hub/models--microsoft--resnet-18/snapshots/f45a6faa12e0381f5620c5c8d7e916bca90f2c44/preprocessor_config.json\n","[WARNING|image_processing_auto.py:355] 2023-09-14 17:00:49,012 >> Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n","[INFO|image_processing_utils.py:732] 2023-09-14 17:00:49,014 >> size should be a dictionary on of the following set of keys: ({'width', 'height'}, {'shortest_edge'}, {'longest_edge', 'shortest_edge'}, {'longest_edge'}), got 224. Converted to {'shortest_edge': 224}.\n","[INFO|image_processing_utils.py:419] 2023-09-14 17:00:49,014 >> Image processor ConvNextImageProcessor {\n","  \"crop_pct\": 0.875,\n","  \"do_normalize\": true,\n","  \"do_rescale\": true,\n","  \"do_resize\": true,\n","  \"image_mean\": [\n","    0.485,\n","    0.456,\n","    0.406\n","  ],\n","  \"image_processor_type\": \"ConvNextImageProcessor\",\n","  \"image_std\": [\n","    0.229,\n","    0.224,\n","    0.225\n","  ],\n","  \"resample\": 3,\n","  \"rescale_factor\": 0.00392156862745098,\n","  \"size\": {\n","    \"shortest_edge\": 224\n","  }\n","}\n","\n","[INFO|trainer.py:1743] 2023-09-14 17:00:54,431 >> ***** Running training *****\n","[INFO|trainer.py:1744] 2023-09-14 17:00:54,432 >>   Num examples = 51,000\n","[INFO|trainer.py:1745] 2023-09-14 17:00:54,432 >>   Num Epochs = 300\n","[INFO|trainer.py:1746] 2023-09-14 17:00:54,432 >>   Instantaneous batch size per device = 512\n","[INFO|trainer.py:1749] 2023-09-14 17:00:54,432 >>   Total train batch size (w. parallel, distributed & accumulation) = 512\n","[INFO|trainer.py:1750] 2023-09-14 17:00:54,432 >>   Gradient Accumulation steps = 1\n","[INFO|trainer.py:1751] 2023-09-14 17:00:54,432 >>   Total optimization steps = 30,000\n","[INFO|trainer.py:1752] 2023-09-14 17:00:54,433 >>   Number of trainable parameters = 11,181,642\n","[INFO|integration_utils.py:722] 2023-09-14 17:00:54,433 >> Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n","{'loss': 1.1238, 'learning_rate': 0.0009996666666666667, 'epoch': 0.1}\n","{'loss': 0.5891, 'learning_rate': 0.0009993333333333334, 'epoch': 0.2}\n","{'loss': 0.5306, 'learning_rate': 0.000999, 'epoch': 0.3}\n","{'loss': 0.5269, 'learning_rate': 0.0009986666666666668, 'epoch': 0.4}\n","{'loss': 0.4894, 'learning_rate': 0.0009983333333333333, 'epoch': 0.5}\n","{'loss': 0.462, 'learning_rate': 0.000998, 'epoch': 0.6}\n","{'loss': 0.458, 'learning_rate': 0.0009976666666666667, 'epoch': 0.7}\n","{'loss': 0.4591, 'learning_rate': 0.0009973333333333334, 'epoch': 0.8}\n","{'loss': 0.442, 'learning_rate': 0.000997, 'epoch': 0.9}\n","{'loss': 0.4641, 'learning_rate': 0.0009966666666666668, 'epoch': 1.0}\n","  0% 100/30000 [02:11<6:56:33,  1.20it/s][INFO|trainer.py:3177] 2023-09-14 17:03:05,548 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3179] 2023-09-14 17:03:05,548 >>   Num examples = 9000\n","[INFO|trainer.py:3182] 2023-09-14 17:03:05,548 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.33it/s]\u001b[A\n"," 17% 3/18 [00:01<00:09,  1.62it/s]\u001b[A\n"," 22% 4/18 [00:02<00:10,  1.34it/s]\u001b[A\n"," 28% 5/18 [00:03<00:10,  1.24it/s]\u001b[A\n"," 33% 6/18 [00:04<00:10,  1.18it/s]\u001b[A\n"," 39% 7/18 [00:05<00:09,  1.18it/s]\u001b[A\n"," 44% 8/18 [00:06<00:08,  1.20it/s]\u001b[A\n"," 50% 9/18 [00:07<00:07,  1.21it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.21it/s]\u001b[A\n"," 61% 11/18 [00:08<00:05,  1.21it/s]\u001b[A\n"," 67% 12/18 [00:09<00:04,  1.22it/s]\u001b[A\n"," 72% 13/18 [00:10<00:04,  1.23it/s]\u001b[A\n"," 78% 14/18 [00:11<00:03,  1.22it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.22it/s]\u001b[A\n"," 89% 16/18 [00:12<00:01,  1.21it/s]\u001b[A\n"," 94% 17/18 [00:13<00:00,  1.37it/s]\u001b[A\n","{'eval_loss': 0.15827181935310364, 'eval_accuracy': 0.9477777777777778, 'eval_runtime': 15.0638, 'eval_samples_per_second': 597.459, 'eval_steps_per_second': 1.195, 'epoch': 1.0}\n","\n","  0% 100/30000 [02:26<6:56:33,  1.20it/s]\n","                                   \u001b[A[INFO|trainer.py:2903] 2023-09-14 17:03:20,616 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_1/checkpoint-100\n","[INFO|configuration_utils.py:460] 2023-09-14 17:03:20,622 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_1/checkpoint-100/config.json\n","[INFO|modeling_utils.py:2028] 2023-09-14 17:03:20,746 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_1/checkpoint-100/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-14 17:03:20,750 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_1/checkpoint-100/preprocessor_config.json\n","{'loss': 0.4441, 'learning_rate': 0.0009963333333333332, 'epoch': 1.1}\n","{'loss': 0.4289, 'learning_rate': 0.000996, 'epoch': 1.2}\n","{'loss': 0.4268, 'learning_rate': 0.0009956666666666666, 'epoch': 1.3}\n","{'loss': 0.4206, 'learning_rate': 0.0009953333333333333, 'epoch': 1.4}\n","{'loss': 0.3914, 'learning_rate': 0.000995, 'epoch': 1.5}\n","{'loss': 0.3794, 'learning_rate': 0.0009946666666666667, 'epoch': 1.6}\n","{'loss': 0.406, 'learning_rate': 0.0009943333333333334, 'epoch': 1.7}\n","{'loss': 0.3838, 'learning_rate': 0.000994, 'epoch': 1.8}\n","{'loss': 0.4048, 'learning_rate': 0.0009936666666666668, 'epoch': 1.9}\n","{'loss': 0.418, 'learning_rate': 0.0009933333333333333, 'epoch': 2.0}\n","  1% 200/30000 [04:26<7:01:44,  1.18it/s][INFO|trainer.py:3177] 2023-09-14 17:05:20,675 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3179] 2023-09-14 17:05:20,675 >>   Num examples = 9000\n","[INFO|trainer.py:3182] 2023-09-14 17:05:20,675 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.51it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.77it/s]\u001b[A\n"," 22% 4/18 [00:02<00:10,  1.36it/s]\u001b[A\n"," 28% 5/18 [00:03<00:09,  1.30it/s]\u001b[A\n"," 33% 6/18 [00:04<00:09,  1.27it/s]\u001b[A\n"," 39% 7/18 [00:05<00:09,  1.21it/s]\u001b[A\n"," 44% 8/18 [00:06<00:08,  1.17it/s]\u001b[A\n"," 50% 9/18 [00:06<00:07,  1.15it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.17it/s]\u001b[A\n"," 61% 11/18 [00:08<00:05,  1.19it/s]\u001b[A\n"," 67% 12/18 [00:09<00:04,  1.21it/s]\u001b[A\n"," 72% 13/18 [00:10<00:04,  1.21it/s]\u001b[A\n"," 78% 14/18 [00:11<00:03,  1.22it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.22it/s]\u001b[A\n"," 89% 16/18 [00:12<00:01,  1.23it/s]\u001b[A\n"," 94% 17/18 [00:13<00:00,  1.39it/s]\u001b[A\n","{'eval_loss': 0.09386078268289566, 'eval_accuracy': 0.9726666666666667, 'eval_runtime': 14.7435, 'eval_samples_per_second': 610.44, 'eval_steps_per_second': 1.221, 'epoch': 2.0}\n","\n","  1% 200/30000 [04:40<7:01:44,  1.18it/s]\n","                                   \u001b[A[INFO|trainer.py:2903] 2023-09-14 17:05:35,424 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_1/checkpoint-200\n","[INFO|configuration_utils.py:460] 2023-09-14 17:05:35,429 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_1/checkpoint-200/config.json\n","[INFO|modeling_utils.py:2028] 2023-09-14 17:05:35,546 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_1/checkpoint-200/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-14 17:05:35,551 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_1/checkpoint-200/preprocessor_config.json\n","{'loss': 0.3874, 'learning_rate': 0.000993, 'epoch': 2.1}\n","{'loss': 0.3963, 'learning_rate': 0.0009926666666666667, 'epoch': 2.2}\n","{'loss': 0.3835, 'learning_rate': 0.0009923333333333333, 'epoch': 2.3}\n","{'loss': 0.3886, 'learning_rate': 0.000992, 'epoch': 2.4}\n","{'loss': 0.3718, 'learning_rate': 0.0009916666666666667, 'epoch': 2.5}\n","{'loss': 0.3722, 'learning_rate': 0.0009913333333333332, 'epoch': 2.6}\n","{'loss': 0.3941, 'learning_rate': 0.000991, 'epoch': 2.7}\n","{'loss': 0.379, 'learning_rate': 0.0009906666666666668, 'epoch': 2.8}\n","{'loss': 0.3808, 'learning_rate': 0.0009903333333333333, 'epoch': 2.9}\n","{'loss': 0.3701, 'learning_rate': 0.00099, 'epoch': 3.0}\n","  1% 300/30000 [06:39<6:50:20,  1.21it/s][INFO|trainer.py:3177] 2023-09-14 17:07:34,252 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3179] 2023-09-14 17:07:34,252 >>   Num examples = 9000\n","[INFO|trainer.py:3182] 2023-09-14 17:07:34,252 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.48it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.75it/s]\u001b[A\n"," 22% 4/18 [00:02<00:09,  1.53it/s]\u001b[A\n"," 28% 5/18 [00:03<00:09,  1.42it/s]\u001b[A\n"," 33% 6/18 [00:04<00:08,  1.35it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.28it/s]\u001b[A\n"," 44% 8/18 [00:05<00:08,  1.16it/s]\u001b[A\n"," 50% 9/18 [00:06<00:07,  1.17it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.16it/s]\u001b[A\n"," 61% 11/18 [00:08<00:06,  1.14it/s]\u001b[A\n"," 67% 12/18 [00:09<00:05,  1.13it/s]\u001b[A\n"," 72% 13/18 [00:10<00:04,  1.13it/s]\u001b[A\n"," 78% 14/18 [00:11<00:03,  1.17it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.19it/s]\u001b[A\n"," 89% 16/18 [00:12<00:01,  1.21it/s]\u001b[A\n"," 94% 17/18 [00:13<00:00,  1.38it/s]\u001b[A\n","{'eval_loss': 0.04941419139504433, 'eval_accuracy': 0.9867777777777778, 'eval_runtime': 14.8018, 'eval_samples_per_second': 608.033, 'eval_steps_per_second': 1.216, 'epoch': 3.0}\n","\n","  1% 300/30000 [06:54<6:50:20,  1.21it/s]\n","                                   \u001b[A[INFO|trainer.py:2903] 2023-09-14 17:07:49,058 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_1/checkpoint-300\n","[INFO|configuration_utils.py:460] 2023-09-14 17:07:49,063 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_1/checkpoint-300/config.json\n","[INFO|modeling_utils.py:2028] 2023-09-14 17:07:49,180 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_1/checkpoint-300/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-14 17:07:49,184 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_1/checkpoint-300/preprocessor_config.json\n","{'loss': 0.3575, 'learning_rate': 0.0009896666666666667, 'epoch': 3.1}\n","{'loss': 0.3258, 'learning_rate': 0.0009893333333333334, 'epoch': 3.2}\n","{'loss': 0.377, 'learning_rate': 0.000989, 'epoch': 3.3}\n","{'loss': 0.38, 'learning_rate': 0.0009886666666666668, 'epoch': 3.4}\n","{'loss': 0.3676, 'learning_rate': 0.0009883333333333333, 'epoch': 3.5}\n","{'loss': 0.3708, 'learning_rate': 0.000988, 'epoch': 3.6}\n","{'loss': 0.3546, 'learning_rate': 0.0009876666666666666, 'epoch': 3.7}\n","{'loss': 0.3661, 'learning_rate': 0.0009873333333333333, 'epoch': 3.8}\n","{'loss': 0.373, 'learning_rate': 0.000987, 'epoch': 3.9}\n","{'loss': 0.3669, 'learning_rate': 0.0009866666666666667, 'epoch': 4.0}\n","  1% 400/30000 [08:53<7:18:09,  1.13it/s][INFO|trainer.py:3177] 2023-09-14 17:09:48,222 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3179] 2023-09-14 17:09:48,222 >>   Num examples = 9000\n","[INFO|trainer.py:3182] 2023-09-14 17:09:48,222 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.47it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.76it/s]\u001b[A\n"," 22% 4/18 [00:02<00:09,  1.52it/s]\u001b[A\n"," 28% 5/18 [00:03<00:09,  1.41it/s]\u001b[A\n"," 33% 6/18 [00:04<00:08,  1.35it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.31it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.28it/s]\u001b[A\n"," 50% 9/18 [00:06<00:07,  1.26it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.26it/s]\u001b[A\n"," 61% 11/18 [00:08<00:06,  1.15it/s]\u001b[A\n"," 67% 12/18 [00:09<00:05,  1.11it/s]\u001b[A\n"," 72% 13/18 [00:10<00:04,  1.13it/s]\u001b[A\n"," 78% 14/18 [00:11<00:03,  1.12it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.11it/s]\u001b[A\n"," 89% 16/18 [00:12<00:01,  1.10it/s]\u001b[A\n"," 94% 17/18 [00:13<00:00,  1.28it/s]\u001b[A\n","{'eval_loss': 0.05981040373444557, 'eval_accuracy': 0.9807777777777777, 'eval_runtime': 15.0079, 'eval_samples_per_second': 599.685, 'eval_steps_per_second': 1.199, 'epoch': 4.0}\n","\n","  1% 400/30000 [09:08<7:18:09,  1.13it/s]\n","                                   \u001b[A[INFO|trainer.py:2903] 2023-09-14 17:10:03,235 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_1/checkpoint-400\n","[INFO|configuration_utils.py:460] 2023-09-14 17:10:03,240 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_1/checkpoint-400/config.json\n","[INFO|modeling_utils.py:2028] 2023-09-14 17:10:03,360 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_1/checkpoint-400/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-14 17:10:03,365 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_1/checkpoint-400/preprocessor_config.json\n","[INFO|trainer.py:2990] 2023-09-14 17:10:03,601 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_1/checkpoint-100] due to args.save_total_limit\n","{'loss': 0.3528, 'learning_rate': 0.0009863333333333332, 'epoch': 4.1}\n","{'loss': 0.3734, 'learning_rate': 0.0009860000000000001, 'epoch': 4.2}\n","{'loss': 0.3679, 'learning_rate': 0.0009856666666666668, 'epoch': 4.3}\n","{'loss': 0.3595, 'learning_rate': 0.0009853333333333333, 'epoch': 4.4}\n","{'loss': 0.3648, 'learning_rate': 0.000985, 'epoch': 4.5}\n","{'loss': 0.3594, 'learning_rate': 0.0009846666666666667, 'epoch': 4.6}\n","{'loss': 0.3612, 'learning_rate': 0.0009843333333333334, 'epoch': 4.7}\n","{'loss': 0.3429, 'learning_rate': 0.000984, 'epoch': 4.8}\n","{'loss': 0.3419, 'learning_rate': 0.0009836666666666668, 'epoch': 4.9}\n","{'loss': 0.3474, 'learning_rate': 0.0009833333333333332, 'epoch': 5.0}\n","  2% 500/30000 [11:08<7:06:13,  1.15it/s][INFO|trainer.py:3177] 2023-09-14 17:12:03,175 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3179] 2023-09-14 17:12:03,175 >>   Num examples = 9000\n","[INFO|trainer.py:3182] 2023-09-14 17:12:03,175 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.50it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.75it/s]\u001b[A\n"," 22% 4/18 [00:02<00:09,  1.50it/s]\u001b[A\n"," 28% 5/18 [00:03<00:09,  1.39it/s]\u001b[A\n"," 33% 6/18 [00:04<00:09,  1.33it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.30it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.27it/s]\u001b[A\n"," 50% 9/18 [00:06<00:07,  1.25it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.25it/s]\u001b[A\n"," 61% 11/18 [00:08<00:05,  1.24it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.24it/s]\u001b[A\n"," 72% 13/18 [00:09<00:04,  1.21it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.17it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.14it/s]\u001b[A\n"," 89% 16/18 [00:12<00:01,  1.03it/s]\u001b[A\n"," 94% 17/18 [00:13<00:00,  1.19it/s]\u001b[A\n","{'eval_loss': 0.0436931848526001, 'eval_accuracy': 0.9863333333333333, 'eval_runtime': 15.112, 'eval_samples_per_second': 595.553, 'eval_steps_per_second': 1.191, 'epoch': 5.0}\n","\n","  2% 500/30000 [11:23<7:06:13,  1.15it/s]\n","                                   \u001b[A[INFO|trainer.py:2903] 2023-09-14 17:12:18,291 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_1/checkpoint-500\n","[INFO|configuration_utils.py:460] 2023-09-14 17:12:18,297 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_1/checkpoint-500/config.json\n","[INFO|modeling_utils.py:2028] 2023-09-14 17:12:18,418 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_1/checkpoint-500/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-14 17:12:18,423 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_1/checkpoint-500/preprocessor_config.json\n","[INFO|trainer.py:2990] 2023-09-14 17:12:18,693 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_1/checkpoint-200] due to args.save_total_limit\n","{'loss': 0.3288, 'learning_rate': 0.000983, 'epoch': 5.1}\n","{'loss': 0.3506, 'learning_rate': 0.0009826666666666666, 'epoch': 5.2}\n","{'loss': 0.3566, 'learning_rate': 0.0009823333333333333, 'epoch': 5.3}\n","{'loss': 0.3373, 'learning_rate': 0.000982, 'epoch': 5.4}\n","{'loss': 0.3158, 'learning_rate': 0.0009816666666666667, 'epoch': 5.5}\n","{'loss': 0.3434, 'learning_rate': 0.0009813333333333334, 'epoch': 5.6}\n","{'loss': 0.3513, 'learning_rate': 0.000981, 'epoch': 5.7}\n","{'loss': 0.3279, 'learning_rate': 0.0009806666666666668, 'epoch': 5.8}\n","{'loss': 0.3415, 'learning_rate': 0.0009803333333333333, 'epoch': 5.9}\n","{'loss': 0.3253, 'learning_rate': 0.00098, 'epoch': 6.0}\n","  2% 600/30000 [13:24<7:00:23,  1.17it/s][INFO|trainer.py:3177] 2023-09-14 17:14:18,760 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3179] 2023-09-14 17:14:18,761 >>   Num examples = 9000\n","[INFO|trainer.py:3182] 2023-09-14 17:14:18,761 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:07,  2.17it/s]\u001b[A\n"," 17% 3/18 [00:01<00:09,  1.55it/s]\u001b[A\n"," 22% 4/18 [00:02<00:09,  1.42it/s]\u001b[A\n"," 28% 5/18 [00:03<00:09,  1.35it/s]\u001b[A\n"," 33% 6/18 [00:04<00:09,  1.32it/s]\u001b[A\n"," 39% 7/18 [00:05<00:08,  1.30it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.28it/s]\u001b[A\n"," 50% 9/18 [00:06<00:07,  1.28it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.27it/s]\u001b[A\n"," 61% 11/18 [00:08<00:05,  1.26it/s]\u001b[A\n"," 67% 12/18 [00:09<00:04,  1.25it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.25it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.25it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.25it/s]\u001b[A\n"," 89% 16/18 [00:12<00:01,  1.22it/s]\u001b[A\n"," 94% 17/18 [00:12<00:00,  1.37it/s]\u001b[A\n","{'eval_loss': 0.05361109972000122, 'eval_accuracy': 0.9833333333333333, 'eval_runtime': 14.5719, 'eval_samples_per_second': 617.626, 'eval_steps_per_second': 1.235, 'epoch': 6.0}\n","\n","  2% 600/30000 [13:38<7:00:23,  1.17it/s]\n","                                   \u001b[A[INFO|trainer.py:2903] 2023-09-14 17:14:33,337 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_1/checkpoint-600\n","[INFO|configuration_utils.py:460] 2023-09-14 17:14:33,343 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_1/checkpoint-600/config.json\n","[INFO|modeling_utils.py:2028] 2023-09-14 17:14:33,466 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_1/checkpoint-600/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-14 17:14:33,471 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_1/checkpoint-600/preprocessor_config.json\n","[INFO|trainer.py:2990] 2023-09-14 17:14:33,708 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_1/checkpoint-300] due to args.save_total_limit\n","{'loss': 0.3294, 'learning_rate': 0.0009796666666666667, 'epoch': 6.1}\n","{'loss': 0.3404, 'learning_rate': 0.0009793333333333334, 'epoch': 6.2}\n","{'loss': 0.3394, 'learning_rate': 0.000979, 'epoch': 6.3}\n","{'loss': 0.3457, 'learning_rate': 0.0009786666666666667, 'epoch': 6.4}\n","{'loss': 0.3239, 'learning_rate': 0.0009783333333333334, 'epoch': 6.5}\n","{'loss': 0.329, 'learning_rate': 0.000978, 'epoch': 6.6}\n","{'loss': 0.3331, 'learning_rate': 0.0009776666666666666, 'epoch': 6.7}\n","{'loss': 0.3278, 'learning_rate': 0.0009773333333333333, 'epoch': 6.8}\n","{'loss': 0.3237, 'learning_rate': 0.000977, 'epoch': 6.9}\n","{'loss': 0.3186, 'learning_rate': 0.0009766666666666667, 'epoch': 7.0}\n","  2% 700/30000 [15:37<6:44:52,  1.21it/s][INFO|trainer.py:3177] 2023-09-14 17:16:32,437 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3179] 2023-09-14 17:16:32,437 >>   Num examples = 9000\n","[INFO|trainer.py:3182] 2023-09-14 17:16:32,437 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.42it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.67it/s]\u001b[A\n"," 22% 4/18 [00:02<00:09,  1.47it/s]\u001b[A\n"," 28% 5/18 [00:03<00:09,  1.32it/s]\u001b[A\n"," 33% 6/18 [00:04<00:09,  1.24it/s]\u001b[A\n"," 39% 7/18 [00:05<00:09,  1.19it/s]\u001b[A\n"," 44% 8/18 [00:06<00:08,  1.19it/s]\u001b[A\n"," 50% 9/18 [00:06<00:07,  1.20it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.22it/s]\u001b[A\n"," 61% 11/18 [00:08<00:05,  1.23it/s]\u001b[A\n"," 67% 12/18 [00:09<00:04,  1.23it/s]\u001b[A\n"," 72% 13/18 [00:10<00:04,  1.23it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.23it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.24it/s]\u001b[A\n"," 89% 16/18 [00:12<00:01,  1.24it/s]\u001b[A\n"," 94% 17/18 [00:13<00:00,  1.40it/s]\u001b[A\n","{'eval_loss': 0.03252604603767395, 'eval_accuracy': 0.9905555555555555, 'eval_runtime': 14.5958, 'eval_samples_per_second': 616.616, 'eval_steps_per_second': 1.233, 'epoch': 7.0}\n","\n","  2% 700/30000 [15:52<6:44:52,  1.21it/s]\n","                                   \u001b[A[INFO|trainer.py:2903] 2023-09-14 17:16:47,037 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_1/checkpoint-700\n","[INFO|configuration_utils.py:460] 2023-09-14 17:16:47,043 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_1/checkpoint-700/config.json\n","[INFO|modeling_utils.py:2028] 2023-09-14 17:16:47,160 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_1/checkpoint-700/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-14 17:16:47,165 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_1/checkpoint-700/preprocessor_config.json\n","[INFO|trainer.py:2990] 2023-09-14 17:16:47,395 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_1/checkpoint-400] due to args.save_total_limit\n","{'loss': 0.3357, 'learning_rate': 0.0009763333333333334, 'epoch': 7.1}\n","{'loss': 0.3416, 'learning_rate': 0.000976, 'epoch': 7.2}\n","{'loss': 0.3327, 'learning_rate': 0.0009756666666666667, 'epoch': 7.3}\n","{'loss': 0.3217, 'learning_rate': 0.0009753333333333334, 'epoch': 7.4}\n","{'loss': 0.3212, 'learning_rate': 0.000975, 'epoch': 7.5}\n","{'loss': 0.3308, 'learning_rate': 0.0009746666666666666, 'epoch': 7.6}\n","{'loss': 0.3216, 'learning_rate': 0.0009743333333333335, 'epoch': 7.7}\n","{'loss': 0.3397, 'learning_rate': 0.000974, 'epoch': 7.8}\n","{'loss': 0.3198, 'learning_rate': 0.0009736666666666667, 'epoch': 7.9}\n","{'loss': 0.3104, 'learning_rate': 0.0009733333333333334, 'epoch': 8.0}\n","  3% 800/30000 [17:53<6:46:31,  1.20it/s][INFO|trainer.py:3177] 2023-09-14 17:18:47,538 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3179] 2023-09-14 17:18:47,538 >>   Num examples = 9000\n","[INFO|trainer.py:3182] 2023-09-14 17:18:47,538 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.46it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.73it/s]\u001b[A\n"," 22% 4/18 [00:02<00:09,  1.50it/s]\u001b[A\n"," 28% 5/18 [00:03<00:09,  1.38it/s]\u001b[A\n"," 33% 6/18 [00:04<00:09,  1.30it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.27it/s]\u001b[A\n"," 44% 8/18 [00:05<00:08,  1.21it/s]\u001b[A\n"," 50% 9/18 [00:06<00:07,  1.17it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.15it/s]\u001b[A\n"," 61% 11/18 [00:08<00:06,  1.16it/s]\u001b[A\n"," 67% 12/18 [00:09<00:05,  1.19it/s]\u001b[A\n"," 72% 13/18 [00:10<00:04,  1.20it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.21it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.22it/s]\u001b[A\n"," 89% 16/18 [00:12<00:01,  1.23it/s]\u001b[A\n"," 94% 17/18 [00:13<00:00,  1.39it/s]\u001b[A\n","{'eval_loss': 0.9661647081375122, 'eval_accuracy': 0.672, 'eval_runtime': 14.6873, 'eval_samples_per_second': 612.776, 'eval_steps_per_second': 1.226, 'epoch': 8.0}\n","\n","  3% 800/30000 [18:07<6:46:31,  1.20it/s]\n","                                   \u001b[A[INFO|trainer.py:2903] 2023-09-14 17:19:02,230 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_1/checkpoint-800\n","[INFO|configuration_utils.py:460] 2023-09-14 17:19:02,237 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_1/checkpoint-800/config.json\n","[INFO|modeling_utils.py:2028] 2023-09-14 17:19:02,368 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_1/checkpoint-800/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-14 17:19:02,373 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_1/checkpoint-800/preprocessor_config.json\n","[INFO|trainer.py:2990] 2023-09-14 17:19:02,611 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_1/checkpoint-500] due to args.save_total_limit\n","{'loss': 0.3235, 'learning_rate': 0.000973, 'epoch': 8.1}\n","{'loss': 0.3032, 'learning_rate': 0.0009726666666666667, 'epoch': 8.2}\n","{'loss': 0.316, 'learning_rate': 0.0009723333333333334, 'epoch': 8.3}\n","{'loss': 0.3235, 'learning_rate': 0.000972, 'epoch': 8.4}\n","{'loss': 0.3038, 'learning_rate': 0.0009716666666666667, 'epoch': 8.5}\n","{'loss': 0.3267, 'learning_rate': 0.0009713333333333334, 'epoch': 8.6}\n","{'loss': 0.3217, 'learning_rate': 0.000971, 'epoch': 8.7}\n","{'loss': 0.3132, 'learning_rate': 0.0009706666666666667, 'epoch': 8.8}\n","{'loss': 0.3354, 'learning_rate': 0.0009703333333333334, 'epoch': 8.9}\n","  3% 892/30000 [20:00<9:32:30,  1.18s/it]"]}],"source":["!python cnn-mnist.py \\\n","    --model_name microsoft/resnet-18 \\\n","    --model_type resnet \\\n","    --dataset_name mnist \\\n","    --output_dir drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_1/ \\\n","    --remove_unused_columns False \\\n","    --do_train \\\n","    --do_eval \\\n","    --push_to_hub False \\\n","    --learning_rate 0.001 \\\n","    --num_train_epochs 300 \\\n","    --per_device_train_batch_size 512 \\\n","    --per_device_eval_batch_size 512 \\\n","    --logging_strategy steps \\\n","    --logging_steps 10 \\\n","    --evaluation_strategy epoch \\\n","    --save_strategy epoch \\\n","    --load_best_model_at_end True \\\n","    --save_total_limit 3 \\\n","    --save_steps 500 \\\n","    --data_seed 1 \\\n","    --seed 1 \\\n","    --report_to wandb \\\n","    --ignore_mismatched_sizes\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"EuAxN-9TFIeO","outputId":"ac6f3502-ac4c-4938-87a5-f0feb283f905"},"outputs":[{"name":"stdout","output_type":"stream","text":["2023-09-06 19:31:48.486772: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mu15048366\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.9\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20230906_193152-ut8gtnes\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mwoven-moon-3\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/u15048366/colabCnnMnist\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/u15048366/colabCnnMnist/runs/ut8gtnes\u001b[0m\n","09/06/2023 19:31:53 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n","09/06/2023 19:31:53 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n","_n_gpu=1,\n","adafactor=False,\n","adam_beta1=0.9,\n","adam_beta2=0.999,\n","adam_epsilon=1e-08,\n","auto_find_batch_size=False,\n","bf16=False,\n","bf16_full_eval=False,\n","data_seed=2,\n","dataloader_drop_last=False,\n","dataloader_num_workers=0,\n","dataloader_pin_memory=True,\n","ddp_backend=None,\n","ddp_broadcast_buffers=None,\n","ddp_bucket_cap_mb=None,\n","ddp_find_unused_parameters=None,\n","ddp_timeout=1800,\n","debug=[],\n","deepspeed=None,\n","disable_tqdm=False,\n","dispatch_batches=None,\n","do_eval=True,\n","do_predict=False,\n","do_train=True,\n","eval_accumulation_steps=None,\n","eval_delay=0,\n","eval_steps=None,\n","evaluation_strategy=epoch,\n","fp16=False,\n","fp16_backend=auto,\n","fp16_full_eval=False,\n","fp16_opt_level=O1,\n","fsdp=[],\n","fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n","fsdp_min_num_params=0,\n","fsdp_transformer_layer_cls_to_wrap=None,\n","full_determinism=False,\n","gradient_accumulation_steps=1,\n","gradient_checkpointing=False,\n","greater_is_better=False,\n","group_by_length=False,\n","half_precision_backend=auto,\n","hub_always_push=False,\n","hub_model_id=None,\n","hub_private_repo=False,\n","hub_strategy=every_save,\n","hub_token=<HUB_TOKEN>,\n","ignore_data_skip=False,\n","include_inputs_for_metrics=False,\n","jit_mode_eval=False,\n","label_names=None,\n","label_smoothing_factor=0.0,\n","learning_rate=0.001,\n","length_column_name=length,\n","load_best_model_at_end=True,\n","local_rank=0,\n","log_level=passive,\n","log_level_replica=warning,\n","log_on_each_node=True,\n","logging_dir=drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/runs/Sep06_19-31-53_6262af7af510,\n","logging_first_step=False,\n","logging_nan_inf_filter=True,\n","logging_steps=10,\n","logging_strategy=steps,\n","lr_scheduler_type=linear,\n","max_grad_norm=1.0,\n","max_steps=-1,\n","metric_for_best_model=loss,\n","mp_parameters=,\n","no_cuda=False,\n","num_train_epochs=300.0,\n","optim=adamw_torch,\n","optim_args=None,\n","output_dir=drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/,\n","overwrite_output_dir=False,\n","past_index=-1,\n","per_device_eval_batch_size=512,\n","per_device_train_batch_size=512,\n","prediction_loss_only=False,\n","push_to_hub=False,\n","push_to_hub_model_id=None,\n","push_to_hub_organization=None,\n","push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n","ray_scope=last,\n","remove_unused_columns=False,\n","report_to=['wandb'],\n","resume_from_checkpoint=None,\n","run_name=drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/,\n","save_on_each_node=False,\n","save_safetensors=False,\n","save_steps=500.0,\n","save_strategy=epoch,\n","save_total_limit=3,\n","seed=2,\n","sharded_ddp=[],\n","skip_memory_metrics=True,\n","tf32=None,\n","torch_compile=False,\n","torch_compile_backend=None,\n","torch_compile_mode=None,\n","torchdynamo=None,\n","tpu_metrics_debug=False,\n","tpu_num_cores=None,\n","use_cpu=False,\n","use_ipex=False,\n","use_legacy_prediction_loop=False,\n","use_mps_device=False,\n","warmup_ratio=0.0,\n","warmup_steps=0,\n","weight_decay=0.0,\n",")\n","/usr/local/lib/python3.10/dist-packages/datasets/load.py:2103: FutureWarning: 'task' was deprecated in version 2.13.0 and will be removed in 3.0.0.\n","\n","  warnings.warn(\n","\n","\n","\n","None\n","\n","\n","\n","[INFO|configuration_utils.py:715] 2023-09-06 19:31:55,802 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--resnet-18/snapshots/f45a6faa12e0381f5620c5c8d7e916bca90f2c44/config.json\n","[INFO|configuration_utils.py:775] 2023-09-06 19:31:55,804 >> Model config ResNetConfig {\n","  \"_name_or_path\": \"microsoft/resnet-18\",\n","  \"architectures\": [\n","    \"ResNetForImageClassification\"\n","  ],\n","  \"depths\": [\n","    2,\n","    2,\n","    2,\n","    2\n","  ],\n","  \"downsample_in_first_stage\": false,\n","  \"embedding_size\": 64,\n","  \"finetuning_task\": \"image-classification\",\n","  \"hidden_act\": \"relu\",\n","  \"hidden_sizes\": [\n","    64,\n","    128,\n","    256,\n","    512\n","  ],\n","  \"id2label\": {\n","    \"0\": \"0\",\n","    \"1\": \"1\",\n","    \"2\": \"2\",\n","    \"3\": \"3\",\n","    \"4\": \"4\",\n","    \"5\": \"5\",\n","    \"6\": \"6\",\n","    \"7\": \"7\",\n","    \"8\": \"8\",\n","    \"9\": \"9\"\n","  },\n","  \"label2id\": {\n","    \"0\": \"0\",\n","    \"1\": \"1\",\n","    \"2\": \"2\",\n","    \"3\": \"3\",\n","    \"4\": \"4\",\n","    \"5\": \"5\",\n","    \"6\": \"6\",\n","    \"7\": \"7\",\n","    \"8\": \"8\",\n","    \"9\": \"9\"\n","  },\n","  \"layer_type\": \"basic\",\n","  \"model_type\": \"resnet\",\n","  \"num_channels\": 3,\n","  \"out_features\": [\n","    \"stage4\"\n","  ],\n","  \"out_indices\": [\n","    4\n","  ],\n","  \"stage_names\": [\n","    \"stem\",\n","    \"stage1\",\n","    \"stage2\",\n","    \"stage3\",\n","    \"stage4\"\n","  ],\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.34.0.dev0\"\n","}\n","\n","[INFO|modeling_utils.py:2847] 2023-09-06 19:31:55,806 >> loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--microsoft--resnet-18/snapshots/f45a6faa12e0381f5620c5c8d7e916bca90f2c44/model.safetensors\n","[INFO|modeling_utils.py:3633] 2023-09-06 19:31:55,923 >> All model checkpoint weights were used when initializing ResNetForImageClassification.\n","\n","[WARNING|modeling_utils.py:3654] 2023-09-06 19:31:55,923 >> Some weights of ResNetForImageClassification were not initialized from the model checkpoint at microsoft/resnet-18 and are newly initialized because the shapes did not match:\n","- classifier.1.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([10]) in the model instantiated\n","- classifier.1.weight: found shape torch.Size([1000, 512]) in the checkpoint and torch.Size([10, 512]) in the model instantiated\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","[INFO|image_processing_utils.py:369] 2023-09-06 19:31:56,025 >> loading configuration file preprocessor_config.json from cache at /root/.cache/huggingface/hub/models--microsoft--resnet-18/snapshots/f45a6faa12e0381f5620c5c8d7e916bca90f2c44/preprocessor_config.json\n","[WARNING|image_processing_auto.py:355] 2023-09-06 19:31:56,026 >> Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n","[INFO|image_processing_utils.py:732] 2023-09-06 19:31:56,028 >> size should be a dictionary on of the following set of keys: ({'height', 'width'}, {'shortest_edge'}, {'longest_edge', 'shortest_edge'}, {'longest_edge'}), got 224. Converted to {'shortest_edge': 224}.\n","[INFO|image_processing_utils.py:419] 2023-09-06 19:31:56,028 >> Image processor ConvNextImageProcessor {\n","  \"crop_pct\": 0.875,\n","  \"do_normalize\": true,\n","  \"do_rescale\": true,\n","  \"do_resize\": true,\n","  \"image_mean\": [\n","    0.485,\n","    0.456,\n","    0.406\n","  ],\n","  \"image_processor_type\": \"ConvNextImageProcessor\",\n","  \"image_std\": [\n","    0.229,\n","    0.224,\n","    0.225\n","  ],\n","  \"resample\": 3,\n","  \"rescale_factor\": 0.00392156862745098,\n","  \"size\": {\n","    \"shortest_edge\": 224\n","  }\n","}\n","\n","[INFO|trainer.py:1715] 2023-09-06 19:31:57,943 >> ***** Running training *****\n","[INFO|trainer.py:1716] 2023-09-06 19:31:57,944 >>   Num examples = 51,000\n","[INFO|trainer.py:1717] 2023-09-06 19:31:57,944 >>   Num Epochs = 300\n","[INFO|trainer.py:1718] 2023-09-06 19:31:57,944 >>   Instantaneous batch size per device = 512\n","[INFO|trainer.py:1721] 2023-09-06 19:31:57,944 >>   Total train batch size (w. parallel, distributed & accumulation) = 512\n","[INFO|trainer.py:1722] 2023-09-06 19:31:57,944 >>   Gradient Accumulation steps = 1\n","[INFO|trainer.py:1723] 2023-09-06 19:31:57,945 >>   Total optimization steps = 30,000\n","[INFO|trainer.py:1724] 2023-09-06 19:31:57,945 >>   Number of trainable parameters = 11,181,642\n","[INFO|integration_utils.py:716] 2023-09-06 19:31:57,946 >> Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n","{'loss': 1.168, 'learning_rate': 0.0009996666666666667, 'epoch': 0.1}\n","{'loss': 0.6387, 'learning_rate': 0.0009993333333333334, 'epoch': 0.2}\n","{'loss': 0.5365, 'learning_rate': 0.000999, 'epoch': 0.3}\n","{'loss': 0.5008, 'learning_rate': 0.0009986666666666668, 'epoch': 0.4}\n","{'loss': 0.498, 'learning_rate': 0.0009983333333333333, 'epoch': 0.5}\n","{'loss': 0.4926, 'learning_rate': 0.000998, 'epoch': 0.6}\n","{'loss': 0.4554, 'learning_rate': 0.0009976666666666667, 'epoch': 0.7}\n","{'loss': 0.4571, 'learning_rate': 0.0009973333333333334, 'epoch': 0.8}\n","{'loss': 0.4692, 'learning_rate': 0.000997, 'epoch': 0.9}\n","{'loss': 0.4499, 'learning_rate': 0.0009966666666666668, 'epoch': 1.0}\n","  0% 100/30000 [01:59<6:58:31,  1.19it/s][INFO|trainer.py:3129] 2023-09-06 19:33:57,869 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3131] 2023-09-06 19:33:57,869 >>   Num examples = 9000\n","[INFO|trainer.py:3134] 2023-09-06 19:33:57,869 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.53it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.78it/s]\u001b[A\n"," 22% 4/18 [00:02<00:09,  1.51it/s]\u001b[A\n"," 28% 5/18 [00:03<00:09,  1.38it/s]\u001b[A\n"," 33% 6/18 [00:04<00:09,  1.31it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.26it/s]\u001b[A\n"," 44% 8/18 [00:05<00:08,  1.22it/s]\u001b[A\n"," 50% 9/18 [00:06<00:07,  1.19it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.21it/s]\u001b[A\n"," 61% 11/18 [00:08<00:05,  1.23it/s]\u001b[A\n"," 67% 12/18 [00:09<00:04,  1.23it/s]\u001b[A\n"," 72% 13/18 [00:09<00:04,  1.24it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.25it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.25it/s]\u001b[A\n"," 89% 16/18 [00:12<00:01,  1.26it/s]\u001b[A\n","                                         \n","\u001b[A{'eval_loss': 0.11911015957593918, 'eval_accuracy': 0.9658888888888889, 'eval_runtime': 14.4028, 'eval_samples_per_second': 624.879, 'eval_steps_per_second': 1.25, 'epoch': 1.0}\n","  0% 100/30000 [02:14<6:58:31,  1.19it/s]\n","100% 18/18 [00:12<00:00,  1.43it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2855] 2023-09-06 19:34:12,276 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-100\n","[INFO|configuration_utils.py:460] 2023-09-06 19:34:12,282 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-100/config.json\n","[INFO|modeling_utils.py:1978] 2023-09-06 19:34:12,403 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-100/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-06 19:34:12,407 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-100/preprocessor_config.json\n","{'loss': 0.4491, 'learning_rate': 0.0009963333333333332, 'epoch': 1.1}\n","{'loss': 0.438, 'learning_rate': 0.000996, 'epoch': 1.2}\n","{'loss': 0.4122, 'learning_rate': 0.0009956666666666666, 'epoch': 1.3}\n","{'loss': 0.4226, 'learning_rate': 0.0009953333333333333, 'epoch': 1.4}\n","{'loss': 0.4183, 'learning_rate': 0.000995, 'epoch': 1.5}\n","{'loss': 0.3967, 'learning_rate': 0.0009946666666666667, 'epoch': 1.6}\n","{'loss': 0.4025, 'learning_rate': 0.0009943333333333334, 'epoch': 1.7}\n","{'loss': 0.3843, 'learning_rate': 0.000994, 'epoch': 1.8}\n","{'loss': 0.4047, 'learning_rate': 0.0009936666666666668, 'epoch': 1.9}\n","{'loss': 0.4001, 'learning_rate': 0.0009933333333333333, 'epoch': 2.0}\n","  1% 200/30000 [04:11<6:50:42,  1.21it/s][INFO|trainer.py:3129] 2023-09-06 19:36:09,169 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3131] 2023-09-06 19:36:09,169 >>   Num examples = 9000\n","[INFO|trainer.py:3134] 2023-09-06 19:36:09,170 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.60it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.81it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.57it/s]\u001b[A\n"," 28% 5/18 [00:03<00:08,  1.46it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.40it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.35it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.32it/s]\u001b[A\n"," 50% 9/18 [00:06<00:07,  1.17it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.18it/s]\u001b[A\n"," 61% 11/18 [00:08<00:05,  1.18it/s]\u001b[A\n"," 67% 12/18 [00:09<00:05,  1.19it/s]\u001b[A\n"," 72% 13/18 [00:09<00:04,  1.18it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.17it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.21it/s]\u001b[A\n"," 89% 16/18 [00:12<00:01,  1.22it/s]\u001b[A\n","                                         \n","\u001b[A{'eval_loss': 0.0667564645409584, 'eval_accuracy': 0.9775555555555555, 'eval_runtime': 14.3432, 'eval_samples_per_second': 627.477, 'eval_steps_per_second': 1.255, 'epoch': 2.0}\n","  1% 200/30000 [04:25<6:50:42,  1.21it/s]\n","100% 18/18 [00:12<00:00,  1.40it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2855] 2023-09-06 19:36:23,517 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-200\n","[INFO|configuration_utils.py:460] 2023-09-06 19:36:23,523 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-200/config.json\n","[INFO|modeling_utils.py:1978] 2023-09-06 19:36:23,639 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-200/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-06 19:36:23,643 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-200/preprocessor_config.json\n","{'loss': 0.3751, 'learning_rate': 0.000993, 'epoch': 2.1}\n","{'loss': 0.3743, 'learning_rate': 0.0009926666666666667, 'epoch': 2.2}\n","{'loss': 0.3778, 'learning_rate': 0.0009923333333333333, 'epoch': 2.3}\n","{'loss': 0.38, 'learning_rate': 0.000992, 'epoch': 2.4}\n","{'loss': 0.384, 'learning_rate': 0.0009916666666666667, 'epoch': 2.5}\n","{'loss': 0.3798, 'learning_rate': 0.0009913333333333332, 'epoch': 2.6}\n","{'loss': 0.3675, 'learning_rate': 0.000991, 'epoch': 2.7}\n","{'loss': 0.3753, 'learning_rate': 0.0009906666666666668, 'epoch': 2.8}\n","{'loss': 0.3551, 'learning_rate': 0.0009903333333333333, 'epoch': 2.9}\n","{'loss': 0.3945, 'learning_rate': 0.00099, 'epoch': 3.0}\n","  1% 300/30000 [06:23<7:37:34,  1.08it/s][INFO|trainer.py:3129] 2023-09-06 19:38:21,214 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3131] 2023-09-06 19:38:21,214 >>   Num examples = 9000\n","[INFO|trainer.py:3134] 2023-09-06 19:38:21,214 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.49it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.74it/s]\u001b[A\n"," 22% 4/18 [00:02<00:09,  1.53it/s]\u001b[A\n"," 28% 5/18 [00:03<00:09,  1.42it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.37it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.32it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.30it/s]\u001b[A\n"," 50% 9/18 [00:06<00:07,  1.28it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.27it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.27it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.26it/s]\u001b[A\n"," 72% 13/18 [00:09<00:04,  1.25it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.24it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.14it/s]\u001b[A\n"," 89% 16/18 [00:12<00:01,  1.15it/s]\u001b[A\n","                                         \n","\u001b[A{'eval_loss': 0.816046416759491, 'eval_accuracy': 0.6728888888888889, 'eval_runtime': 14.5972, 'eval_samples_per_second': 616.557, 'eval_steps_per_second': 1.233, 'epoch': 3.0}\n","  1% 300/30000 [06:37<7:37:34,  1.08it/s]\n","100% 18/18 [00:13<00:00,  1.29it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2855] 2023-09-06 19:38:35,817 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-300\n","[INFO|configuration_utils.py:460] 2023-09-06 19:38:35,823 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-300/config.json\n","[INFO|modeling_utils.py:1978] 2023-09-06 19:38:35,951 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-300/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-06 19:38:35,957 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-300/preprocessor_config.json\n","{'loss': 0.3906, 'learning_rate': 0.0009896666666666667, 'epoch': 3.1}\n","{'loss': 0.3465, 'learning_rate': 0.0009893333333333334, 'epoch': 3.2}\n","{'loss': 0.3689, 'learning_rate': 0.000989, 'epoch': 3.3}\n","{'loss': 0.3519, 'learning_rate': 0.0009886666666666668, 'epoch': 3.4}\n","{'loss': 0.373, 'learning_rate': 0.0009883333333333333, 'epoch': 3.5}\n","{'loss': 0.3582, 'learning_rate': 0.000988, 'epoch': 3.6}\n","{'loss': 0.3618, 'learning_rate': 0.0009876666666666666, 'epoch': 3.7}\n","{'loss': 0.3266, 'learning_rate': 0.0009873333333333333, 'epoch': 3.8}\n","{'loss': 0.3737, 'learning_rate': 0.000987, 'epoch': 3.9}\n","{'loss': 0.3537, 'learning_rate': 0.0009866666666666667, 'epoch': 4.0}\n","  1% 400/30000 [08:35<6:37:06,  1.24it/s][INFO|trainer.py:3129] 2023-09-06 19:40:33,149 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3131] 2023-09-06 19:40:33,150 >>   Num examples = 9000\n","[INFO|trainer.py:3134] 2023-09-06 19:40:33,150 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:07,  2.20it/s]\u001b[A\n"," 17% 3/18 [00:01<00:09,  1.57it/s]\u001b[A\n"," 22% 4/18 [00:02<00:10,  1.38it/s]\u001b[A\n"," 28% 5/18 [00:03<00:10,  1.29it/s]\u001b[A\n"," 33% 6/18 [00:04<00:09,  1.27it/s]\u001b[A\n"," 39% 7/18 [00:05<00:08,  1.28it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.28it/s]\u001b[A\n"," 50% 9/18 [00:06<00:07,  1.26it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.25it/s]\u001b[A\n"," 61% 11/18 [00:08<00:05,  1.24it/s]\u001b[A\n"," 67% 12/18 [00:09<00:04,  1.24it/s]\u001b[A\n"," 72% 13/18 [00:09<00:04,  1.24it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.24it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.24it/s]\u001b[A\n"," 89% 16/18 [00:12<00:01,  1.24it/s]\u001b[A\n","                                         \n","\u001b[A{'eval_loss': 0.5008798837661743, 'eval_accuracy': 0.8064444444444444, 'eval_runtime': 14.6813, 'eval_samples_per_second': 613.025, 'eval_steps_per_second': 1.226, 'epoch': 4.0}\n","  1% 400/30000 [08:49<6:37:06,  1.24it/s]\n","100% 18/18 [00:13<00:00,  1.38it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2855] 2023-09-06 19:40:47,835 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-400\n","[INFO|configuration_utils.py:460] 2023-09-06 19:40:47,842 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-400/config.json\n","[INFO|modeling_utils.py:1978] 2023-09-06 19:40:47,963 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-400/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-06 19:40:47,968 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-400/preprocessor_config.json\n","[INFO|trainer.py:2942] 2023-09-06 19:40:48,218 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-100] due to args.save_total_limit\n","{'loss': 0.3358, 'learning_rate': 0.0009863333333333332, 'epoch': 4.1}\n","{'loss': 0.358, 'learning_rate': 0.0009860000000000001, 'epoch': 4.2}\n","{'loss': 0.3625, 'learning_rate': 0.0009856666666666668, 'epoch': 4.3}\n","{'loss': 0.3517, 'learning_rate': 0.0009853333333333333, 'epoch': 4.4}\n","{'loss': 0.3648, 'learning_rate': 0.000985, 'epoch': 4.5}\n","{'loss': 0.369, 'learning_rate': 0.0009846666666666667, 'epoch': 4.6}\n","{'loss': 0.3784, 'learning_rate': 0.0009843333333333334, 'epoch': 4.7}\n","{'loss': 0.3647, 'learning_rate': 0.000984, 'epoch': 4.8}\n","{'loss': 0.356, 'learning_rate': 0.0009836666666666668, 'epoch': 4.9}\n","{'loss': 0.3393, 'learning_rate': 0.0009833333333333332, 'epoch': 5.0}\n","  2% 500/30000 [10:46<6:43:33,  1.22it/s][INFO|trainer.py:3129] 2023-09-06 19:42:44,362 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3131] 2023-09-06 19:42:44,362 >>   Num examples = 9000\n","[INFO|trainer.py:3134] 2023-09-06 19:42:44,362 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.58it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.82it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.57it/s]\u001b[A\n"," 28% 5/18 [00:03<00:08,  1.46it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.40it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.33it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.31it/s]\u001b[A\n"," 50% 9/18 [00:06<00:07,  1.22it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.20it/s]\u001b[A\n"," 61% 11/18 [00:08<00:05,  1.18it/s]\u001b[A\n"," 67% 12/18 [00:09<00:05,  1.17it/s]\u001b[A\n"," 72% 13/18 [00:09<00:04,  1.20it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.23it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.25it/s]\u001b[A\n"," 89% 16/18 [00:12<00:01,  1.25it/s]\u001b[A\n","                                         \n","\u001b[A{'eval_loss': 1.0597455501556396, 'eval_accuracy': 0.6308888888888889, 'eval_runtime': 14.2196, 'eval_samples_per_second': 632.931, 'eval_steps_per_second': 1.266, 'epoch': 5.0}\n","  2% 500/30000 [11:00<6:43:33,  1.22it/s]\n","100% 18/18 [00:12<00:00,  1.43it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2855] 2023-09-06 19:42:58,586 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-500\n","[INFO|configuration_utils.py:460] 2023-09-06 19:42:58,592 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-500/config.json\n","[INFO|modeling_utils.py:1978] 2023-09-06 19:42:58,705 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-500/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-06 19:42:58,709 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-500/preprocessor_config.json\n","[INFO|trainer.py:2942] 2023-09-06 19:42:58,925 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-300] due to args.save_total_limit\n","{'loss': 0.3304, 'learning_rate': 0.000983, 'epoch': 5.1}\n","{'loss': 0.3496, 'learning_rate': 0.0009826666666666666, 'epoch': 5.2}\n","{'loss': 0.3437, 'learning_rate': 0.0009823333333333333, 'epoch': 5.3}\n","{'loss': 0.3355, 'learning_rate': 0.000982, 'epoch': 5.4}\n","{'loss': 0.3281, 'learning_rate': 0.0009816666666666667, 'epoch': 5.5}\n","{'loss': 0.3437, 'learning_rate': 0.0009813333333333334, 'epoch': 5.6}\n","{'loss': 0.3377, 'learning_rate': 0.000981, 'epoch': 5.7}\n","{'loss': 0.3254, 'learning_rate': 0.0009806666666666668, 'epoch': 5.8}\n","{'loss': 0.3254, 'learning_rate': 0.0009803333333333333, 'epoch': 5.9}\n","{'loss': 0.353, 'learning_rate': 0.00098, 'epoch': 6.0}\n","  2% 600/30000 [12:56<6:58:05,  1.17it/s][INFO|trainer.py:3129] 2023-09-06 19:44:54,223 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3131] 2023-09-06 19:44:54,223 >>   Num examples = 9000\n","[INFO|trainer.py:3134] 2023-09-06 19:44:54,223 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.54it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.80it/s]\u001b[A\n"," 22% 4/18 [00:02<00:09,  1.55it/s]\u001b[A\n"," 28% 5/18 [00:03<00:09,  1.44it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.38it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.34it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.32it/s]\u001b[A\n"," 50% 9/18 [00:06<00:06,  1.29it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.18it/s]\u001b[A\n"," 61% 11/18 [00:08<00:05,  1.20it/s]\u001b[A\n"," 67% 12/18 [00:09<00:05,  1.17it/s]\u001b[A\n"," 72% 13/18 [00:09<00:04,  1.15it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.13it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.15it/s]\u001b[A\n"," 89% 16/18 [00:12<00:01,  1.17it/s]\u001b[A\n","                                         \n","\u001b[A{'eval_loss': 1.4072139263153076, 'eval_accuracy': 0.6503333333333333, 'eval_runtime': 14.7014, 'eval_samples_per_second': 612.186, 'eval_steps_per_second': 1.224, 'epoch': 6.0}\n","  2% 600/30000 [13:10<6:58:05,  1.17it/s]\n","100% 18/18 [00:13<00:00,  1.31it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2855] 2023-09-06 19:45:08,929 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-600\n","[INFO|configuration_utils.py:460] 2023-09-06 19:45:08,934 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-600/config.json\n","[INFO|modeling_utils.py:1978] 2023-09-06 19:45:09,053 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-600/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-06 19:45:09,057 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-600/preprocessor_config.json\n","[INFO|trainer.py:2942] 2023-09-06 19:45:09,297 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-400] due to args.save_total_limit\n","{'loss': 0.3617, 'learning_rate': 0.0009796666666666667, 'epoch': 6.1}\n","{'loss': 0.3341, 'learning_rate': 0.0009793333333333334, 'epoch': 6.2}\n","{'loss': 0.3568, 'learning_rate': 0.000979, 'epoch': 6.3}\n","{'loss': 0.322, 'learning_rate': 0.0009786666666666667, 'epoch': 6.4}\n","{'loss': 0.3166, 'learning_rate': 0.0009783333333333334, 'epoch': 6.5}\n","{'loss': 0.3398, 'learning_rate': 0.000978, 'epoch': 6.6}\n","{'loss': 0.3302, 'learning_rate': 0.0009776666666666666, 'epoch': 6.7}\n","{'loss': 0.3246, 'learning_rate': 0.0009773333333333333, 'epoch': 6.8}\n","{'loss': 0.3219, 'learning_rate': 0.000977, 'epoch': 6.9}\n","{'loss': 0.3267, 'learning_rate': 0.0009766666666666667, 'epoch': 7.0}\n","  2% 700/30000 [15:07<6:32:00,  1.25it/s][INFO|trainer.py:3129] 2023-09-06 19:47:05,032 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3131] 2023-09-06 19:47:05,032 >>   Num examples = 9000\n","[INFO|trainer.py:3134] 2023-09-06 19:47:05,032 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.37it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.67it/s]\u001b[A\n"," 22% 4/18 [00:02<00:09,  1.41it/s]\u001b[A\n"," 28% 5/18 [00:03<00:09,  1.30it/s]\u001b[A\n"," 33% 6/18 [00:04<00:09,  1.29it/s]\u001b[A\n"," 39% 7/18 [00:05<00:08,  1.29it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.28it/s]\u001b[A\n"," 50% 9/18 [00:06<00:07,  1.28it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.28it/s]\u001b[A\n"," 61% 11/18 [00:08<00:05,  1.29it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.29it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.30it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.30it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.30it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.30it/s]\u001b[A\n","                                         \n","\u001b[A{'eval_loss': 2.9583981037139893, 'eval_accuracy': 0.4008888888888889, 'eval_runtime': 14.1041, 'eval_samples_per_second': 638.11, 'eval_steps_per_second': 1.276, 'epoch': 7.0}\n","  2% 700/30000 [15:21<6:32:00,  1.25it/s]\n","100% 18/18 [00:12<00:00,  1.45it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2855] 2023-09-06 19:47:19,141 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-700\n","[INFO|configuration_utils.py:460] 2023-09-06 19:47:19,147 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-700/config.json\n","[INFO|modeling_utils.py:1978] 2023-09-06 19:47:19,261 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-700/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-06 19:47:19,265 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-700/preprocessor_config.json\n","[INFO|trainer.py:2942] 2023-09-06 19:47:19,503 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-500] due to args.save_total_limit\n","{'loss': 0.3605, 'learning_rate': 0.0009763333333333334, 'epoch': 7.1}\n","{'loss': 0.3235, 'learning_rate': 0.000976, 'epoch': 7.2}\n","{'loss': 0.3073, 'learning_rate': 0.0009756666666666667, 'epoch': 7.3}\n","{'loss': 0.3188, 'learning_rate': 0.0009753333333333334, 'epoch': 7.4}\n","{'loss': 0.3242, 'learning_rate': 0.000975, 'epoch': 7.5}\n","{'loss': 0.3294, 'learning_rate': 0.0009746666666666666, 'epoch': 7.6}\n","{'loss': 0.3274, 'learning_rate': 0.0009743333333333335, 'epoch': 7.7}\n","{'loss': 0.3384, 'learning_rate': 0.000974, 'epoch': 7.8}\n","{'loss': 0.3116, 'learning_rate': 0.0009736666666666667, 'epoch': 7.9}\n","{'loss': 0.31, 'learning_rate': 0.0009733333333333334, 'epoch': 8.0}\n","  3% 800/30000 [17:17<6:34:41,  1.23it/s][INFO|trainer.py:3129] 2023-09-06 19:49:15,537 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3131] 2023-09-06 19:49:15,537 >>   Num examples = 9000\n","[INFO|trainer.py:3134] 2023-09-06 19:49:15,537 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:01<00:08,  1.89it/s]\u001b[A\n"," 17% 3/18 [00:01<00:09,  1.59it/s]\u001b[A\n"," 22% 4/18 [00:02<00:09,  1.46it/s]\u001b[A\n"," 28% 5/18 [00:03<00:09,  1.31it/s]\u001b[A\n"," 33% 6/18 [00:04<00:09,  1.27it/s]\u001b[A\n"," 39% 7/18 [00:05<00:08,  1.26it/s]\u001b[A\n"," 44% 8/18 [00:06<00:08,  1.24it/s]\u001b[A\n"," 50% 9/18 [00:06<00:07,  1.19it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.17it/s]\u001b[A\n"," 61% 11/18 [00:08<00:05,  1.20it/s]\u001b[A\n"," 67% 12/18 [00:09<00:04,  1.23it/s]\u001b[A\n"," 72% 13/18 [00:10<00:04,  1.24it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.26it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.26it/s]\u001b[A\n"," 89% 16/18 [00:12<00:01,  1.27it/s]\u001b[A\n","                                         \n","\u001b[A{'eval_loss': 0.051672231405973434, 'eval_accuracy': 0.9834444444444445, 'eval_runtime': 14.518, 'eval_samples_per_second': 619.92, 'eval_steps_per_second': 1.24, 'epoch': 8.0}\n","  3% 800/30000 [17:32<6:34:41,  1.23it/s]\n","100% 18/18 [00:13<00:00,  1.43it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2855] 2023-09-06 19:49:30,061 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-800\n","[INFO|configuration_utils.py:460] 2023-09-06 19:49:30,066 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-800/config.json\n","[INFO|modeling_utils.py:1978] 2023-09-06 19:49:30,178 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-800/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-06 19:49:30,183 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-800/preprocessor_config.json\n","[INFO|trainer.py:2942] 2023-09-06 19:49:30,409 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-200] due to args.save_total_limit\n","{'loss': 0.3135, 'learning_rate': 0.000973, 'epoch': 8.1}\n","{'loss': 0.3096, 'learning_rate': 0.0009726666666666667, 'epoch': 8.2}\n","{'loss': 0.3106, 'learning_rate': 0.0009723333333333334, 'epoch': 8.3}\n","{'loss': 0.3189, 'learning_rate': 0.000972, 'epoch': 8.4}\n","{'loss': 0.3195, 'learning_rate': 0.0009716666666666667, 'epoch': 8.5}\n","{'loss': 0.3294, 'learning_rate': 0.0009713333333333334, 'epoch': 8.6}\n","{'loss': 0.3146, 'learning_rate': 0.000971, 'epoch': 8.7}\n","{'loss': 0.3226, 'learning_rate': 0.0009706666666666667, 'epoch': 8.8}\n","{'loss': 0.3191, 'learning_rate': 0.0009703333333333334, 'epoch': 8.9}\n","{'loss': 0.299, 'learning_rate': 0.0009699999999999999, 'epoch': 9.0}\n","  3% 900/30000 [19:27<6:39:13,  1.21it/s][INFO|trainer.py:3129] 2023-09-06 19:51:25,521 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3131] 2023-09-06 19:51:25,521 >>   Num examples = 9000\n","[INFO|trainer.py:3134] 2023-09-06 19:51:25,522 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.30it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.75it/s]\u001b[A\n"," 22% 4/18 [00:02<00:09,  1.54it/s]\u001b[A\n"," 28% 5/18 [00:03<00:08,  1.45it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.39it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.36it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.33it/s]\u001b[A\n"," 50% 9/18 [00:06<00:07,  1.28it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.25it/s]\u001b[A\n"," 61% 11/18 [00:08<00:05,  1.23it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.21it/s]\u001b[A\n"," 72% 13/18 [00:09<00:04,  1.21it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.23it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.25it/s]\u001b[A\n"," 89% 16/18 [00:12<00:01,  1.26it/s]\u001b[A\n","                                         \n","\u001b[A{'eval_loss': 1.5487382411956787, 'eval_accuracy': 0.5611111111111111, 'eval_runtime': 14.2246, 'eval_samples_per_second': 632.707, 'eval_steps_per_second': 1.265, 'epoch': 9.0}\n","  3% 900/30000 [19:41<6:39:13,  1.21it/s]\n","100% 18/18 [00:12<00:00,  1.43it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2855] 2023-09-06 19:51:39,751 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-900\n","[INFO|configuration_utils.py:460] 2023-09-06 19:51:39,756 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-900/config.json\n","[INFO|modeling_utils.py:1978] 2023-09-06 19:51:39,870 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-900/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-06 19:51:39,874 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-900/preprocessor_config.json\n","[INFO|trainer.py:2942] 2023-09-06 19:51:40,092 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-600] due to args.save_total_limit\n","{'loss': 0.3037, 'learning_rate': 0.0009696666666666667, 'epoch': 9.1}\n","{'loss': 0.3269, 'learning_rate': 0.0009693333333333334, 'epoch': 9.2}\n","{'loss': 0.3301, 'learning_rate': 0.000969, 'epoch': 9.3}\n","{'loss': 0.3159, 'learning_rate': 0.0009686666666666667, 'epoch': 9.4}\n","{'loss': 0.3348, 'learning_rate': 0.0009683333333333334, 'epoch': 9.5}\n","{'loss': 0.3151, 'learning_rate': 0.000968, 'epoch': 9.6}\n","{'loss': 0.3101, 'learning_rate': 0.0009676666666666667, 'epoch': 9.7}\n","{'loss': 0.3091, 'learning_rate': 0.0009673333333333334, 'epoch': 9.8}\n","{'loss': 0.3122, 'learning_rate': 0.000967, 'epoch': 9.9}\n","{'loss': 0.3135, 'learning_rate': 0.0009666666666666667, 'epoch': 10.0}\n","  3% 1000/30000 [21:36<6:33:14,  1.23it/s][INFO|trainer.py:3129] 2023-09-06 19:53:34,640 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3131] 2023-09-06 19:53:34,640 >>   Num examples = 9000\n","[INFO|trainer.py:3134] 2023-09-06 19:53:34,640 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.58it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.83it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.61it/s]\u001b[A\n"," 28% 5/18 [00:03<00:08,  1.49it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.43it/s]\u001b[A\n"," 39% 7/18 [00:04<00:07,  1.39it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.36it/s]\u001b[A\n"," 50% 9/18 [00:06<00:06,  1.34it/s]\u001b[A\n"," 56% 10/18 [00:06<00:06,  1.30it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.26it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.23it/s]\u001b[A\n"," 72% 13/18 [00:09<00:04,  1.21it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.18it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.19it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.23it/s]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 0.03274811431765556, 'eval_accuracy': 0.9894444444444445, 'eval_runtime': 14.229, 'eval_samples_per_second': 632.511, 'eval_steps_per_second': 1.265, 'epoch': 10.0}\n","  3% 1000/30000 [21:50<6:33:14,  1.23it/s]\n","100% 18/18 [00:12<00:00,  1.26it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2855] 2023-09-06 19:53:48,873 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-1000\n","[INFO|configuration_utils.py:460] 2023-09-06 19:53:48,879 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-1000/config.json\n","[INFO|modeling_utils.py:1978] 2023-09-06 19:53:48,987 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-1000/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-06 19:53:49,002 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-1000/preprocessor_config.json\n","[INFO|trainer.py:2942] 2023-09-06 19:53:49,224 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-700] due to args.save_total_limit\n","{'loss': 0.3121, 'learning_rate': 0.0009663333333333334, 'epoch': 10.1}\n","{'loss': 0.2901, 'learning_rate': 0.000966, 'epoch': 10.2}\n","{'loss': 0.3005, 'learning_rate': 0.0009656666666666666, 'epoch': 10.3}\n","{'loss': 0.297, 'learning_rate': 0.0009653333333333333, 'epoch': 10.4}\n","{'loss': 0.322, 'learning_rate': 0.000965, 'epoch': 10.5}\n","{'loss': 0.3502, 'learning_rate': 0.0009646666666666667, 'epoch': 10.6}\n","{'loss': 0.3283, 'learning_rate': 0.0009643333333333334, 'epoch': 10.7}\n","{'loss': 0.3289, 'learning_rate': 0.000964, 'epoch': 10.8}\n","{'loss': 0.3205, 'learning_rate': 0.0009636666666666667, 'epoch': 10.9}\n","{'loss': 0.3187, 'learning_rate': 0.0009633333333333334, 'epoch': 11.0}\n","  4% 1100/30000 [23:45<6:43:39,  1.19it/s][INFO|trainer.py:3129] 2023-09-06 19:55:43,258 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3131] 2023-09-06 19:55:43,258 >>   Num examples = 9000\n","[INFO|trainer.py:3134] 2023-09-06 19:55:43,259 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.61it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.83it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.59it/s]\u001b[A\n"," 28% 5/18 [00:03<00:08,  1.48it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.41it/s]\u001b[A\n"," 39% 7/18 [00:04<00:07,  1.38it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.36it/s]\u001b[A\n"," 50% 9/18 [00:06<00:06,  1.35it/s]\u001b[A\n"," 56% 10/18 [00:06<00:05,  1.34it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.33it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.27it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.25it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.24it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.22it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.19it/s]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 0.026513949036598206, 'eval_accuracy': 0.9912222222222222, 'eval_runtime': 13.8995, 'eval_samples_per_second': 647.505, 'eval_steps_per_second': 1.295, 'epoch': 11.0}\n","  4% 1100/30000 [23:59<6:43:39,  1.19it/s]\n","100% 18/18 [00:12<00:00,  1.36it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2855] 2023-09-06 19:55:57,162 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-1100\n","[INFO|configuration_utils.py:460] 2023-09-06 19:55:57,168 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-1100/config.json\n","[INFO|modeling_utils.py:1978] 2023-09-06 19:55:57,281 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-1100/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-06 19:55:57,285 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-1100/preprocessor_config.json\n","[INFO|trainer.py:2942] 2023-09-06 19:55:57,509 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-800] due to args.save_total_limit\n","{'loss': 0.3178, 'learning_rate': 0.000963, 'epoch': 11.1}\n","{'loss': 0.3008, 'learning_rate': 0.0009626666666666667, 'epoch': 11.2}\n","{'loss': 0.2921, 'learning_rate': 0.0009623333333333334, 'epoch': 11.3}\n","{'loss': 0.3022, 'learning_rate': 0.000962, 'epoch': 11.4}\n","{'loss': 0.312, 'learning_rate': 0.0009616666666666667, 'epoch': 11.5}\n","{'loss': 0.2925, 'learning_rate': 0.0009613333333333334, 'epoch': 11.6}\n","{'loss': 0.3263, 'learning_rate': 0.0009609999999999999, 'epoch': 11.7}\n","{'loss': 0.3083, 'learning_rate': 0.0009606666666666666, 'epoch': 11.8}\n","{'loss': 0.3166, 'learning_rate': 0.0009603333333333334, 'epoch': 11.9}\n","{'loss': 0.2915, 'learning_rate': 0.00096, 'epoch': 12.0}\n","  4% 1200/30000 [25:55<6:45:49,  1.18it/s][INFO|trainer.py:3129] 2023-09-06 19:57:53,052 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3131] 2023-09-06 19:57:53,052 >>   Num examples = 9000\n","[INFO|trainer.py:3134] 2023-09-06 19:57:53,052 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.33it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.68it/s]\u001b[A\n"," 22% 4/18 [00:02<00:09,  1.52it/s]\u001b[A\n"," 28% 5/18 [00:03<00:09,  1.43it/s]\u001b[A\n"," 33% 6/18 [00:04<00:08,  1.37it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.34it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.32it/s]\u001b[A\n"," 50% 9/18 [00:06<00:06,  1.32it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.31it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.28it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.26it/s]\u001b[A\n"," 72% 13/18 [00:09<00:04,  1.24it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.22it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.20it/s]\u001b[A\n"," 89% 16/18 [00:12<00:01,  1.22it/s]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 0.04779769852757454, 'eval_accuracy': 0.9853333333333333, 'eval_runtime': 14.3114, 'eval_samples_per_second': 628.87, 'eval_steps_per_second': 1.258, 'epoch': 12.0}\n","  4% 1200/30000 [26:09<6:45:49,  1.18it/s]\n","100% 18/18 [00:12<00:00,  1.39it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2855] 2023-09-06 19:58:07,369 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-1200\n","[INFO|configuration_utils.py:460] 2023-09-06 19:58:07,375 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-1200/config.json\n","[INFO|modeling_utils.py:1978] 2023-09-06 19:58:07,492 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-1200/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-06 19:58:07,496 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-1200/preprocessor_config.json\n","[INFO|trainer.py:2942] 2023-09-06 19:58:07,717 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-900] due to args.save_total_limit\n","{'loss': 0.2979, 'learning_rate': 0.0009596666666666667, 'epoch': 12.1}\n","{'loss': 0.3025, 'learning_rate': 0.0009593333333333334, 'epoch': 12.2}\n","{'loss': 0.3066, 'learning_rate': 0.000959, 'epoch': 12.3}\n","{'loss': 0.3095, 'learning_rate': 0.0009586666666666667, 'epoch': 12.4}\n","{'loss': 0.3039, 'learning_rate': 0.0009583333333333334, 'epoch': 12.5}\n","{'loss': 0.2879, 'learning_rate': 0.000958, 'epoch': 12.6}\n","{'loss': 0.2886, 'learning_rate': 0.0009576666666666667, 'epoch': 12.7}\n","{'loss': 0.2987, 'learning_rate': 0.0009573333333333334, 'epoch': 12.8}\n","{'loss': 0.3028, 'learning_rate': 0.000957, 'epoch': 12.9}\n","{'loss': 0.3187, 'learning_rate': 0.0009566666666666666, 'epoch': 13.0}\n","  4% 1300/30000 [28:04<6:36:48,  1.21it/s][INFO|trainer.py:3129] 2023-09-06 20:00:02,709 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3131] 2023-09-06 20:00:02,709 >>   Num examples = 9000\n","[INFO|trainer.py:3134] 2023-09-06 20:00:02,709 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.64it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.84it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.58it/s]\u001b[A\n"," 28% 5/18 [00:03<00:08,  1.45it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.39it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.36it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.33it/s]\u001b[A\n"," 50% 9/18 [00:06<00:06,  1.32it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.29it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.23it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.21it/s]\u001b[A\n"," 72% 13/18 [00:09<00:04,  1.19it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.18it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.18it/s]\u001b[A\n"," 89% 16/18 [00:12<00:01,  1.21it/s]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 0.7888051271438599, 'eval_accuracy': 0.7281111111111112, 'eval_runtime': 14.1517, 'eval_samples_per_second': 635.966, 'eval_steps_per_second': 1.272, 'epoch': 13.0}\n","  4% 1300/30000 [28:18<6:36:48,  1.21it/s]\n","100% 18/18 [00:12<00:00,  1.39it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2855] 2023-09-06 20:00:16,866 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-1300\n","[INFO|configuration_utils.py:460] 2023-09-06 20:00:16,871 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-1300/config.json\n","[INFO|modeling_utils.py:1978] 2023-09-06 20:00:16,984 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-1300/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-06 20:00:16,989 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-1300/preprocessor_config.json\n","[INFO|trainer.py:2942] 2023-09-06 20:00:17,216 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-1000] due to args.save_total_limit\n","{'loss': 0.2961, 'learning_rate': 0.0009563333333333333, 'epoch': 13.1}\n","{'loss': 0.2888, 'learning_rate': 0.0009559999999999999, 'epoch': 13.2}\n","{'loss': 0.302, 'learning_rate': 0.0009556666666666667, 'epoch': 13.3}\n","{'loss': 0.3014, 'learning_rate': 0.0009553333333333334, 'epoch': 13.4}\n","{'loss': 0.3151, 'learning_rate': 0.000955, 'epoch': 13.5}\n","{'loss': 0.2978, 'learning_rate': 0.0009546666666666667, 'epoch': 13.6}\n","{'loss': 0.2828, 'learning_rate': 0.0009543333333333334, 'epoch': 13.7}\n","{'loss': 0.2987, 'learning_rate': 0.000954, 'epoch': 13.8}\n","{'loss': 0.3092, 'learning_rate': 0.0009536666666666667, 'epoch': 13.9}\n","{'loss': 0.3007, 'learning_rate': 0.0009533333333333334, 'epoch': 14.0}\n","  5% 1400/30000 [30:15<6:37:15,  1.20it/s][INFO|trainer.py:3129] 2023-09-06 20:02:13,092 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3131] 2023-09-06 20:02:13,092 >>   Num examples = 9000\n","[INFO|trainer.py:3134] 2023-09-06 20:02:13,092 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.55it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.79it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.56it/s]\u001b[A\n"," 28% 5/18 [00:03<00:09,  1.43it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.38it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.34it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.32it/s]\u001b[A\n"," 50% 9/18 [00:06<00:06,  1.30it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.28it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.27it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.26it/s]\u001b[A\n"," 72% 13/18 [00:09<00:04,  1.22it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.20it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.18it/s]\u001b[A\n"," 89% 16/18 [00:12<00:01,  1.21it/s]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 1.2436636686325073, 'eval_accuracy': 0.607, 'eval_runtime': 14.1536, 'eval_samples_per_second': 635.88, 'eval_steps_per_second': 1.272, 'epoch': 14.0}\n","  5% 1400/30000 [30:29<6:37:15,  1.20it/s]\n","100% 18/18 [00:12<00:00,  1.38it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2855] 2023-09-06 20:02:27,250 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-1400\n","[INFO|configuration_utils.py:460] 2023-09-06 20:02:27,257 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-1400/config.json\n","[INFO|modeling_utils.py:1978] 2023-09-06 20:02:27,371 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-1400/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-06 20:02:27,375 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-1400/preprocessor_config.json\n","[INFO|trainer.py:2942] 2023-09-06 20:02:27,618 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-1200] due to args.save_total_limit\n","{'loss': 0.2909, 'learning_rate': 0.000953, 'epoch': 14.1}\n","{'loss': 0.3085, 'learning_rate': 0.0009526666666666667, 'epoch': 14.2}\n","{'loss': 0.3122, 'learning_rate': 0.0009523333333333334, 'epoch': 14.3}\n","{'loss': 0.2919, 'learning_rate': 0.0009519999999999999, 'epoch': 14.4}\n","{'loss': 0.293, 'learning_rate': 0.0009516666666666666, 'epoch': 14.5}\n","{'loss': 0.3047, 'learning_rate': 0.0009513333333333334, 'epoch': 14.6}\n","{'loss': 0.3019, 'learning_rate': 0.000951, 'epoch': 14.7}\n","{'loss': 0.2824, 'learning_rate': 0.0009506666666666667, 'epoch': 14.8}\n","{'loss': 0.293, 'learning_rate': 0.0009503333333333334, 'epoch': 14.9}\n","{'loss': 0.3132, 'learning_rate': 0.00095, 'epoch': 15.0}\n","  5% 1500/30000 [32:24<6:41:03,  1.18it/s][INFO|trainer.py:3129] 2023-09-06 20:04:22,869 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3131] 2023-09-06 20:04:22,869 >>   Num examples = 9000\n","[INFO|trainer.py:3134] 2023-09-06 20:04:22,870 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.63it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.84it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.61it/s]\u001b[A\n"," 28% 5/18 [00:03<00:08,  1.48it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.41it/s]\u001b[A\n"," 39% 7/18 [00:04<00:07,  1.38it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.35it/s]\u001b[A\n"," 50% 9/18 [00:06<00:06,  1.33it/s]\u001b[A\n"," 56% 10/18 [00:06<00:06,  1.33it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.32it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.30it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.27it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.24it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.20it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.18it/s]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 0.24582791328430176, 'eval_accuracy': 0.9092222222222223, 'eval_runtime': 14.0811, 'eval_samples_per_second': 639.153, 'eval_steps_per_second': 1.278, 'epoch': 15.0}\n","  5% 1500/30000 [32:38<6:41:03,  1.18it/s]\n","100% 18/18 [00:12<00:00,  1.30it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2855] 2023-09-06 20:04:36,955 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-1500\n","[INFO|configuration_utils.py:460] 2023-09-06 20:04:36,961 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-1500/config.json\n","[INFO|modeling_utils.py:1978] 2023-09-06 20:04:37,084 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-1500/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-06 20:04:37,089 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-1500/preprocessor_config.json\n","[INFO|trainer.py:2942] 2023-09-06 20:04:37,318 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-1300] due to args.save_total_limit\n","{'loss': 0.2963, 'learning_rate': 0.0009496666666666667, 'epoch': 15.1}\n","{'loss': 0.2821, 'learning_rate': 0.0009493333333333334, 'epoch': 15.2}\n","{'loss': 0.2947, 'learning_rate': 0.000949, 'epoch': 15.3}\n","{'loss': 0.2802, 'learning_rate': 0.0009486666666666667, 'epoch': 15.4}\n","{'loss': 0.3097, 'learning_rate': 0.0009483333333333334, 'epoch': 15.5}\n","{'loss': 0.2858, 'learning_rate': 0.000948, 'epoch': 15.6}\n","{'loss': 0.3025, 'learning_rate': 0.0009476666666666666, 'epoch': 15.7}\n","{'loss': 0.2832, 'learning_rate': 0.0009473333333333333, 'epoch': 15.8}\n","{'loss': 0.3124, 'learning_rate': 0.0009469999999999999, 'epoch': 15.9}\n","{'loss': 0.3036, 'learning_rate': 0.0009466666666666667, 'epoch': 16.0}\n","  5% 1600/30000 [34:35<6:36:06,  1.19it/s][INFO|trainer.py:3129] 2023-09-06 20:06:32,970 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3131] 2023-09-06 20:06:32,970 >>   Num examples = 9000\n","[INFO|trainer.py:3134] 2023-09-06 20:06:32,970 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.56it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.81it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.57it/s]\u001b[A\n"," 28% 5/18 [00:03<00:08,  1.45it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.40it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.35it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.33it/s]\u001b[A\n"," 50% 9/18 [00:06<00:06,  1.31it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.30it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.27it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.25it/s]\u001b[A\n"," 72% 13/18 [00:09<00:04,  1.23it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.20it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.17it/s]\u001b[A\n"," 89% 16/18 [00:12<00:01,  1.20it/s]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 0.04398476704955101, 'eval_accuracy': 0.9854444444444445, 'eval_runtime': 14.1194, 'eval_samples_per_second': 637.419, 'eval_steps_per_second': 1.275, 'epoch': 16.0}\n","  5% 1600/30000 [34:49<6:36:06,  1.19it/s]\n","100% 18/18 [00:12<00:00,  1.37it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2855] 2023-09-06 20:06:47,094 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-1600\n","[INFO|configuration_utils.py:460] 2023-09-06 20:06:47,113 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-1600/config.json\n","[INFO|modeling_utils.py:1978] 2023-09-06 20:06:47,227 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-1600/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-06 20:06:47,233 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-1600/preprocessor_config.json\n","[INFO|trainer.py:2942] 2023-09-06 20:06:47,472 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-1400] due to args.save_total_limit\n","{'loss': 0.2866, 'learning_rate': 0.0009463333333333334, 'epoch': 16.1}\n","{'loss': 0.27, 'learning_rate': 0.000946, 'epoch': 16.2}\n","{'loss': 0.3081, 'learning_rate': 0.0009456666666666667, 'epoch': 16.3}\n","{'loss': 0.2918, 'learning_rate': 0.0009453333333333334, 'epoch': 16.4}\n","{'loss': 0.2947, 'learning_rate': 0.000945, 'epoch': 16.5}\n","{'loss': 0.2897, 'learning_rate': 0.0009446666666666667, 'epoch': 16.6}\n","{'loss': 0.2948, 'learning_rate': 0.0009443333333333334, 'epoch': 16.7}\n","{'loss': 0.2939, 'learning_rate': 0.000944, 'epoch': 16.8}\n","{'loss': 0.2816, 'learning_rate': 0.0009436666666666667, 'epoch': 16.9}\n","{'loss': 0.279, 'learning_rate': 0.0009433333333333334, 'epoch': 17.0}\n","  6% 1700/30000 [36:44<6:37:13,  1.19it/s][INFO|trainer.py:3129] 2023-09-06 20:08:42,111 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3131] 2023-09-06 20:08:42,111 >>   Num examples = 9000\n","[INFO|trainer.py:3134] 2023-09-06 20:08:42,111 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.51it/s]\u001b[A\n"," 17% 3/18 [00:01<00:10,  1.50it/s]\u001b[A\n"," 22% 4/18 [00:02<00:09,  1.41it/s]\u001b[A\n"," 28% 5/18 [00:03<00:09,  1.36it/s]\u001b[A\n"," 33% 6/18 [00:04<00:08,  1.34it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.33it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.31it/s]\u001b[A\n"," 50% 9/18 [00:06<00:06,  1.30it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.30it/s]\u001b[A\n"," 61% 11/18 [00:08<00:05,  1.28it/s]\u001b[A\n"," 67% 12/18 [00:09<00:04,  1.20it/s]\u001b[A\n"," 72% 13/18 [00:09<00:04,  1.18it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.17it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.16it/s]\u001b[A\n"," 89% 16/18 [00:12<00:01,  1.18it/s]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 1.4355970621109009, 'eval_accuracy': 0.629, 'eval_runtime': 14.5695, 'eval_samples_per_second': 617.727, 'eval_steps_per_second': 1.235, 'epoch': 17.0}\n","  6% 1700/30000 [36:58<6:37:13,  1.19it/s]\n","100% 18/18 [00:13<00:00,  1.35it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2855] 2023-09-06 20:08:56,686 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-1700\n","[INFO|configuration_utils.py:460] 2023-09-06 20:08:56,692 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-1700/config.json\n","[INFO|modeling_utils.py:1978] 2023-09-06 20:08:56,813 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-1700/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-06 20:08:56,818 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-1700/preprocessor_config.json\n","[INFO|trainer.py:2942] 2023-09-06 20:08:57,065 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-1500] due to args.save_total_limit\n","{'loss': 0.2963, 'learning_rate': 0.0009429999999999999, 'epoch': 17.1}\n","{'loss': 0.2949, 'learning_rate': 0.0009426666666666666, 'epoch': 17.2}\n","{'loss': 0.2981, 'learning_rate': 0.0009423333333333333, 'epoch': 17.3}\n","{'loss': 0.2867, 'learning_rate': 0.000942, 'epoch': 17.4}\n","{'loss': 0.2858, 'learning_rate': 0.0009416666666666667, 'epoch': 17.5}\n","{'loss': 0.2881, 'learning_rate': 0.0009413333333333334, 'epoch': 17.6}\n","{'loss': 0.27, 'learning_rate': 0.000941, 'epoch': 17.7}\n","{'loss': 0.2917, 'learning_rate': 0.0009406666666666667, 'epoch': 17.8}\n","{'loss': 0.2898, 'learning_rate': 0.0009403333333333334, 'epoch': 17.9}\n","{'loss': 0.2792, 'learning_rate': 0.00094, 'epoch': 18.0}\n","  6% 1800/30000 [38:55<6:33:47,  1.19it/s][INFO|trainer.py:3129] 2023-09-06 20:10:53,078 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3131] 2023-09-06 20:10:53,078 >>   Num examples = 9000\n","[INFO|trainer.py:3134] 2023-09-06 20:10:53,078 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.58it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.81it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.57it/s]\u001b[A\n"," 28% 5/18 [00:03<00:08,  1.45it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.38it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.34it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.31it/s]\u001b[A\n"," 50% 9/18 [00:06<00:06,  1.30it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.26it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.23it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.21it/s]\u001b[A\n"," 72% 13/18 [00:09<00:04,  1.19it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.17it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.18it/s]\u001b[A\n"," 89% 16/18 [00:12<00:01,  1.20it/s]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 1.0067126750946045, 'eval_accuracy': 0.6873333333333334, 'eval_runtime': 14.307, 'eval_samples_per_second': 629.062, 'eval_steps_per_second': 1.258, 'epoch': 18.0}\n","  6% 1800/30000 [39:09<6:33:47,  1.19it/s]\n","100% 18/18 [00:12<00:00,  1.37it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2855] 2023-09-06 20:11:07,390 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-1800\n","[INFO|configuration_utils.py:460] 2023-09-06 20:11:07,396 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-1800/config.json\n","[INFO|modeling_utils.py:1978] 2023-09-06 20:11:07,514 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-1800/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-06 20:11:07,518 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-1800/preprocessor_config.json\n","[INFO|trainer.py:2942] 2023-09-06 20:11:07,747 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-1600] due to args.save_total_limit\n","{'loss': 0.2969, 'learning_rate': 0.0009396666666666667, 'epoch': 18.1}\n","{'loss': 0.3004, 'learning_rate': 0.0009393333333333334, 'epoch': 18.2}\n","{'loss': 0.284, 'learning_rate': 0.000939, 'epoch': 18.3}\n","{'loss': 0.2819, 'learning_rate': 0.0009386666666666666, 'epoch': 18.4}\n","{'loss': 0.3123, 'learning_rate': 0.0009383333333333333, 'epoch': 18.5}\n","{'loss': 0.2937, 'learning_rate': 0.0009379999999999999, 'epoch': 18.6}\n","{'loss': 0.305, 'learning_rate': 0.0009376666666666666, 'epoch': 18.7}\n","{'loss': 0.2911, 'learning_rate': 0.0009373333333333334, 'epoch': 18.8}\n","{'loss': 0.2788, 'learning_rate': 0.0009370000000000001, 'epoch': 18.9}\n","{'loss': 0.2817, 'learning_rate': 0.0009366666666666667, 'epoch': 19.0}\n","  6% 1900/30000 [41:06<6:32:14,  1.19it/s][INFO|trainer.py:3129] 2023-09-06 20:13:04,304 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3131] 2023-09-06 20:13:04,304 >>   Num examples = 9000\n","[INFO|trainer.py:3134] 2023-09-06 20:13:04,304 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.62it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.85it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.59it/s]\u001b[A\n"," 28% 5/18 [00:03<00:08,  1.46it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.39it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.34it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.31it/s]\u001b[A\n"," 50% 9/18 [00:06<00:06,  1.29it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.26it/s]\u001b[A\n"," 61% 11/18 [00:08<00:06,  1.16it/s]\u001b[A\n"," 67% 12/18 [00:09<00:05,  1.15it/s]\u001b[A\n"," 72% 13/18 [00:09<00:04,  1.13it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.12it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.14it/s]\u001b[A\n"," 89% 16/18 [00:12<00:01,  1.16it/s]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 0.12828892469406128, 'eval_accuracy': 0.9618888888888889, 'eval_runtime': 14.5566, 'eval_samples_per_second': 618.276, 'eval_steps_per_second': 1.237, 'epoch': 19.0}\n","  6% 1900/30000 [41:20<6:32:14,  1.19it/s]\n","100% 18/18 [00:13<00:00,  1.33it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2855] 2023-09-06 20:13:18,867 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-1900\n","[INFO|configuration_utils.py:460] 2023-09-06 20:13:18,874 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-1900/config.json\n","[INFO|modeling_utils.py:1978] 2023-09-06 20:13:19,003 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-1900/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-06 20:13:19,007 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-1900/preprocessor_config.json\n","[INFO|trainer.py:2942] 2023-09-06 20:13:19,245 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-1700] due to args.save_total_limit\n","{'loss': 0.2801, 'learning_rate': 0.0009363333333333334, 'epoch': 19.1}\n","{'loss': 0.2828, 'learning_rate': 0.0009360000000000001, 'epoch': 19.2}\n","{'loss': 0.2654, 'learning_rate': 0.0009356666666666667, 'epoch': 19.3}\n","{'loss': 0.2707, 'learning_rate': 0.0009353333333333334, 'epoch': 19.4}\n","{'loss': 0.2889, 'learning_rate': 0.0009350000000000001, 'epoch': 19.5}\n","{'loss': 0.2888, 'learning_rate': 0.0009346666666666667, 'epoch': 19.6}\n","{'loss': 0.2781, 'learning_rate': 0.0009343333333333333, 'epoch': 19.7}\n","{'loss': 0.2796, 'learning_rate': 0.000934, 'epoch': 19.8}\n","{'loss': 0.2779, 'learning_rate': 0.0009336666666666666, 'epoch': 19.9}\n","{'loss': 0.2827, 'learning_rate': 0.0009333333333333333, 'epoch': 20.0}\n","  7% 2000/30000 [43:18<6:24:02,  1.22it/s][INFO|trainer.py:3129] 2023-09-06 20:15:16,614 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3131] 2023-09-06 20:15:16,614 >>   Num examples = 9000\n","[INFO|trainer.py:3134] 2023-09-06 20:15:16,614 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.55it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.76it/s]\u001b[A\n"," 22% 4/18 [00:02<00:09,  1.54it/s]\u001b[A\n"," 28% 5/18 [00:03<00:09,  1.43it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.38it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.35it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.34it/s]\u001b[A\n"," 50% 9/18 [00:06<00:06,  1.29it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.22it/s]\u001b[A\n"," 61% 11/18 [00:08<00:05,  1.18it/s]\u001b[A\n"," 67% 12/18 [00:09<00:05,  1.16it/s]\u001b[A\n"," 72% 13/18 [00:09<00:04,  1.14it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.18it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.20it/s]\u001b[A\n"," 89% 16/18 [00:12<00:01,  1.23it/s]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 0.043761905282735825, 'eval_accuracy': 0.986, 'eval_runtime': 14.3823, 'eval_samples_per_second': 625.769, 'eval_steps_per_second': 1.252, 'epoch': 20.0}\n","  7% 2000/30000 [43:33<6:24:02,  1.22it/s]\n","100% 18/18 [00:12<00:00,  1.40it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2855] 2023-09-06 20:15:31,000 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-2000\n","[INFO|configuration_utils.py:460] 2023-09-06 20:15:31,006 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-2000/config.json\n","[INFO|modeling_utils.py:1978] 2023-09-06 20:15:31,121 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-2000/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-06 20:15:31,125 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-2000/preprocessor_config.json\n","[INFO|trainer.py:2942] 2023-09-06 20:15:31,371 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-1800] due to args.save_total_limit\n","{'loss': 0.2692, 'learning_rate': 0.000933, 'epoch': 20.1}\n","{'loss': 0.2927, 'learning_rate': 0.0009326666666666667, 'epoch': 20.2}\n","{'loss': 0.2869, 'learning_rate': 0.0009323333333333334, 'epoch': 20.3}\n","{'loss': 0.28, 'learning_rate': 0.0009320000000000001, 'epoch': 20.4}\n","{'loss': 0.2865, 'learning_rate': 0.0009316666666666667, 'epoch': 20.5}\n","{'loss': 0.2869, 'learning_rate': 0.0009313333333333334, 'epoch': 20.6}\n","{'loss': 0.2658, 'learning_rate': 0.0009310000000000001, 'epoch': 20.7}\n","{'loss': 0.282, 'learning_rate': 0.0009306666666666667, 'epoch': 20.8}\n","{'loss': 0.2787, 'learning_rate': 0.0009303333333333334, 'epoch': 20.9}\n","{'loss': 0.2863, 'learning_rate': 0.00093, 'epoch': 21.0}\n","  7% 2100/30000 [45:29<6:18:27,  1.23it/s][INFO|trainer.py:3129] 2023-09-06 20:17:27,344 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3131] 2023-09-06 20:17:27,344 >>   Num examples = 9000\n","[INFO|trainer.py:3134] 2023-09-06 20:17:27,344 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.62it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.83it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.58it/s]\u001b[A\n"," 28% 5/18 [00:03<00:08,  1.46it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.38it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.33it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.26it/s]\u001b[A\n"," 50% 9/18 [00:06<00:07,  1.22it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.19it/s]\u001b[A\n"," 61% 11/18 [00:08<00:05,  1.19it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.22it/s]\u001b[A\n"," 72% 13/18 [00:09<00:04,  1.24it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.25it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.26it/s]\u001b[A\n"," 89% 16/18 [00:12<00:01,  1.26it/s]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 0.0485859252512455, 'eval_accuracy': 0.9834444444444445, 'eval_runtime': 14.1562, 'eval_samples_per_second': 635.763, 'eval_steps_per_second': 1.272, 'epoch': 21.0}\n","  7% 2100/30000 [45:43<6:18:27,  1.23it/s]\n","100% 18/18 [00:12<00:00,  1.43it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2855] 2023-09-06 20:17:41,505 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-2100\n","[INFO|configuration_utils.py:460] 2023-09-06 20:17:41,511 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-2100/config.json\n","[INFO|modeling_utils.py:1978] 2023-09-06 20:17:41,623 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-2100/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-06 20:17:41,627 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-2100/preprocessor_config.json\n","[INFO|trainer.py:2942] 2023-09-06 20:17:41,859 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-1900] due to args.save_total_limit\n","[INFO|trainer.py:1963] 2023-09-06 20:17:41,877 >> \n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","[INFO|trainer.py:2125] 2023-09-06 20:17:41,877 >> Loading best model from drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/checkpoint-1100 (score: 0.026513949036598206).\n","{'train_runtime': 2743.9965, 'train_samples_per_second': 5575.809, 'train_steps_per_second': 10.933, 'train_loss': 0.331027626991272, 'epoch': 21.0}\n","  7% 2100/30000 [45:43<10:07:35,  1.31s/it]\n","[INFO|trainer.py:2855] 2023-09-06 20:17:41,946 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/\n","[INFO|configuration_utils.py:460] 2023-09-06 20:17:41,952 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/config.json\n","[INFO|modeling_utils.py:1978] 2023-09-06 20:17:42,068 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-06 20:17:42,072 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/preprocessor_config.json\n","***** train metrics *****\n","  epoch                    =       21.0\n","  train_loss               =      0.331\n","  train_runtime            = 0:45:43.99\n","  train_samples_per_second =   5575.809\n","  train_steps_per_second   =     10.933\n","[INFO|trainer.py:3129] 2023-09-06 20:17:42,110 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3131] 2023-09-06 20:17:42,110 >>   Num examples = 9000\n","[INFO|trainer.py:3134] 2023-09-06 20:17:42,111 >>   Batch size = 512\n","100% 18/18 [00:12<00:00,  1.40it/s]\n","***** eval metrics *****\n","  epoch                   =       21.0\n","  eval_accuracy           =     0.9912\n","  eval_loss               =     0.0265\n","  eval_runtime            = 0:00:14.27\n","  eval_samples_per_second =    630.265\n","  eval_steps_per_second   =      1.261\n","\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n","\u001b[34m\u001b[1mwandb\u001b[0m:                  eval/accuracy ██▄▆▄▄▁█▃███▅▃▇█▄▄████\n","\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/loss ▁▁▃▂▃▄█▁▅▁▁▁▃▄▂▁▄▃▁▁▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/runtime ▅▅▇█▄█▃▆▄▄▁▅▃▃▃▃▇▅▇▅▃▄\n","\u001b[34m\u001b[1mwandb\u001b[0m:        eval/samples_per_second ▄▄▂▁▅▁▆▃▅▅█▄▆▆▆▆▂▄▂▄▆▅\n","\u001b[34m\u001b[1mwandb\u001b[0m:          eval/steps_per_second ▄▄▂▁▅▁▆▃▅▅█▄▆▆▆▆▂▄▂▄▆▅\n","\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\n","\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\n","\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate ███▇▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss █▅▄▃▃▃▃▂▃▂▂▃▂▂▂▂▂▂▂▁▂▂▂▂▂▂▂▂▂▁▁▁▁▁▂▁▁▁▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n","\u001b[34m\u001b[1mwandb\u001b[0m:                  eval/accuracy 0.99122\n","\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/loss 0.02651\n","\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/runtime 14.2797\n","\u001b[34m\u001b[1mwandb\u001b[0m:        eval/samples_per_second 630.265\n","\u001b[34m\u001b[1mwandb\u001b[0m:          eval/steps_per_second 1.261\n","\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch 21.0\n","\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step 2100\n","\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate 0.00093\n","\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss 0.2863\n","\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos 1.0815923230027776e+19\n","\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss 0.33103\n","\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime 2743.9965\n","\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second 5575.809\n","\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second 10.933\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mwoven-moon-3\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/u15048366/colabCnnMnist/runs/ut8gtnes\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n","\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230906_193152-ut8gtnes/logs\u001b[0m\n"]}],"source":["!python cnn-mnist.py \\\n","    --model_name microsoft/resnet-18 \\\n","    --model_type resnet \\\n","    --dataset_name mnist \\\n","    --output_dir drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_2/ \\\n","    --remove_unused_columns False \\\n","    --do_train \\\n","    --do_eval \\\n","    --push_to_hub False \\\n","    --learning_rate 0.001 \\\n","    --num_train_epochs 300 \\\n","    --per_device_train_batch_size 512 \\\n","    --per_device_eval_batch_size 512 \\\n","    --logging_strategy steps \\\n","    --logging_steps 10 \\\n","    --evaluation_strategy epoch \\\n","    --save_strategy epoch \\\n","    --load_best_model_at_end True \\\n","    --save_total_limit 3 \\\n","    --save_steps 500 \\\n","    --data_seed 2 \\\n","    --seed 2 \\\n","    --report_to wandb \\\n","    --ignore_mismatched_sizes\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":38727,"status":"ok","timestamp":1693166260250,"user":{"displayName":"Andreas Louw","userId":"11183032721846533402"},"user_tz":-120},"id":"xu5wBqMkkf62","outputId":"11f3a80d-c549-43cf-aaf6-b03d9f1d9112"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"hw_zqhJyFKun","outputId":"3073442d-b4d7-48c4-841c-f6363eeaa3c6"},"outputs":[{"name":"stdout","output_type":"stream","text":["2023-09-07 07:25:33.494112: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mu15048366\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.10\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20230907_072536-9r6qcixl\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mexalted-frog-9\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/u15048366/colabCnnMnist\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/u15048366/colabCnnMnist/runs/9r6qcixl\u001b[0m\n","09/07/2023 07:25:37 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n","09/07/2023 07:25:37 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n","_n_gpu=1,\n","adafactor=False,\n","adam_beta1=0.9,\n","adam_beta2=0.999,\n","adam_epsilon=1e-08,\n","auto_find_batch_size=False,\n","bf16=False,\n","bf16_full_eval=False,\n","data_seed=3,\n","dataloader_drop_last=False,\n","dataloader_num_workers=0,\n","dataloader_pin_memory=True,\n","ddp_backend=None,\n","ddp_broadcast_buffers=None,\n","ddp_bucket_cap_mb=None,\n","ddp_find_unused_parameters=None,\n","ddp_timeout=1800,\n","debug=[],\n","deepspeed=None,\n","disable_tqdm=False,\n","dispatch_batches=None,\n","do_eval=True,\n","do_predict=False,\n","do_train=True,\n","eval_accumulation_steps=None,\n","eval_delay=0,\n","eval_steps=None,\n","evaluation_strategy=epoch,\n","fp16=False,\n","fp16_backend=auto,\n","fp16_full_eval=False,\n","fp16_opt_level=O1,\n","fsdp=[],\n","fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n","fsdp_min_num_params=0,\n","fsdp_transformer_layer_cls_to_wrap=None,\n","full_determinism=False,\n","gradient_accumulation_steps=1,\n","gradient_checkpointing=False,\n","greater_is_better=False,\n","group_by_length=False,\n","half_precision_backend=auto,\n","hub_always_push=False,\n","hub_model_id=None,\n","hub_private_repo=False,\n","hub_strategy=every_save,\n","hub_token=<HUB_TOKEN>,\n","ignore_data_skip=False,\n","include_inputs_for_metrics=False,\n","jit_mode_eval=False,\n","label_names=None,\n","label_smoothing_factor=0.0,\n","learning_rate=0.001,\n","length_column_name=length,\n","load_best_model_at_end=True,\n","local_rank=0,\n","log_level=passive,\n","log_level_replica=warning,\n","log_on_each_node=True,\n","logging_dir=drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/runs/Sep07_07-25-37_76fe2c15e2a8,\n","logging_first_step=False,\n","logging_nan_inf_filter=True,\n","logging_steps=10,\n","logging_strategy=steps,\n","lr_scheduler_type=linear,\n","max_grad_norm=1.0,\n","max_steps=-1,\n","metric_for_best_model=loss,\n","mp_parameters=,\n","no_cuda=False,\n","num_train_epochs=300.0,\n","optim=adamw_torch,\n","optim_args=None,\n","output_dir=drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/,\n","overwrite_output_dir=False,\n","past_index=-1,\n","per_device_eval_batch_size=512,\n","per_device_train_batch_size=512,\n","prediction_loss_only=False,\n","push_to_hub=False,\n","push_to_hub_model_id=None,\n","push_to_hub_organization=None,\n","push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n","ray_scope=last,\n","remove_unused_columns=False,\n","report_to=['wandb'],\n","resume_from_checkpoint=None,\n","run_name=drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/,\n","save_on_each_node=False,\n","save_safetensors=False,\n","save_steps=500.0,\n","save_strategy=epoch,\n","save_total_limit=3,\n","seed=3,\n","sharded_ddp=[],\n","skip_memory_metrics=True,\n","tf32=None,\n","torch_compile=False,\n","torch_compile_backend=None,\n","torch_compile_mode=None,\n","torchdynamo=None,\n","tpu_metrics_debug=False,\n","tpu_num_cores=None,\n","use_cpu=False,\n","use_ipex=False,\n","use_legacy_prediction_loop=False,\n","use_mps_device=False,\n","warmup_ratio=0.0,\n","warmup_steps=0,\n","weight_decay=0.0,\n",")\n","/usr/local/lib/python3.10/dist-packages/datasets/load.py:2103: FutureWarning: 'task' was deprecated in version 2.13.0 and will be removed in 3.0.0.\n","\n","  warnings.warn(\n","\n","\n","\n","None\n","\n","\n","\n","[INFO|configuration_utils.py:715] 2023-09-07 07:25:39,611 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--resnet-18/snapshots/f45a6faa12e0381f5620c5c8d7e916bca90f2c44/config.json\n","[INFO|configuration_utils.py:775] 2023-09-07 07:25:39,612 >> Model config ResNetConfig {\n","  \"_name_or_path\": \"microsoft/resnet-18\",\n","  \"architectures\": [\n","    \"ResNetForImageClassification\"\n","  ],\n","  \"depths\": [\n","    2,\n","    2,\n","    2,\n","    2\n","  ],\n","  \"downsample_in_first_stage\": false,\n","  \"embedding_size\": 64,\n","  \"finetuning_task\": \"image-classification\",\n","  \"hidden_act\": \"relu\",\n","  \"hidden_sizes\": [\n","    64,\n","    128,\n","    256,\n","    512\n","  ],\n","  \"id2label\": {\n","    \"0\": \"0\",\n","    \"1\": \"1\",\n","    \"2\": \"2\",\n","    \"3\": \"3\",\n","    \"4\": \"4\",\n","    \"5\": \"5\",\n","    \"6\": \"6\",\n","    \"7\": \"7\",\n","    \"8\": \"8\",\n","    \"9\": \"9\"\n","  },\n","  \"label2id\": {\n","    \"0\": \"0\",\n","    \"1\": \"1\",\n","    \"2\": \"2\",\n","    \"3\": \"3\",\n","    \"4\": \"4\",\n","    \"5\": \"5\",\n","    \"6\": \"6\",\n","    \"7\": \"7\",\n","    \"8\": \"8\",\n","    \"9\": \"9\"\n","  },\n","  \"layer_type\": \"basic\",\n","  \"model_type\": \"resnet\",\n","  \"num_channels\": 3,\n","  \"out_features\": [\n","    \"stage4\"\n","  ],\n","  \"out_indices\": [\n","    4\n","  ],\n","  \"stage_names\": [\n","    \"stem\",\n","    \"stage1\",\n","    \"stage2\",\n","    \"stage3\",\n","    \"stage4\"\n","  ],\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.34.0.dev0\"\n","}\n","\n","[INFO|modeling_utils.py:2847] 2023-09-07 07:25:39,614 >> loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--microsoft--resnet-18/snapshots/f45a6faa12e0381f5620c5c8d7e916bca90f2c44/model.safetensors\n","[INFO|modeling_utils.py:3633] 2023-09-07 07:25:39,734 >> All model checkpoint weights were used when initializing ResNetForImageClassification.\n","\n","[WARNING|modeling_utils.py:3654] 2023-09-07 07:25:39,734 >> Some weights of ResNetForImageClassification were not initialized from the model checkpoint at microsoft/resnet-18 and are newly initialized because the shapes did not match:\n","- classifier.1.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([10]) in the model instantiated\n","- classifier.1.weight: found shape torch.Size([1000, 512]) in the checkpoint and torch.Size([10, 512]) in the model instantiated\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","[INFO|image_processing_utils.py:369] 2023-09-07 07:25:39,832 >> loading configuration file preprocessor_config.json from cache at /root/.cache/huggingface/hub/models--microsoft--resnet-18/snapshots/f45a6faa12e0381f5620c5c8d7e916bca90f2c44/preprocessor_config.json\n","[WARNING|image_processing_auto.py:355] 2023-09-07 07:25:39,833 >> Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n","[INFO|image_processing_utils.py:732] 2023-09-07 07:25:39,836 >> size should be a dictionary on of the following set of keys: ({'height', 'width'}, {'shortest_edge'}, {'longest_edge', 'shortest_edge'}, {'longest_edge'}), got 224. Converted to {'shortest_edge': 224}.\n","[INFO|image_processing_utils.py:419] 2023-09-07 07:25:39,836 >> Image processor ConvNextImageProcessor {\n","  \"crop_pct\": 0.875,\n","  \"do_normalize\": true,\n","  \"do_rescale\": true,\n","  \"do_resize\": true,\n","  \"image_mean\": [\n","    0.485,\n","    0.456,\n","    0.406\n","  ],\n","  \"image_processor_type\": \"ConvNextImageProcessor\",\n","  \"image_std\": [\n","    0.229,\n","    0.224,\n","    0.225\n","  ],\n","  \"resample\": 3,\n","  \"rescale_factor\": 0.00392156862745098,\n","  \"size\": {\n","    \"shortest_edge\": 224\n","  }\n","}\n","\n","[INFO|trainer.py:1715] 2023-09-07 07:25:41,860 >> ***** Running training *****\n","[INFO|trainer.py:1716] 2023-09-07 07:25:41,861 >>   Num examples = 51,000\n","[INFO|trainer.py:1717] 2023-09-07 07:25:41,861 >>   Num Epochs = 300\n","[INFO|trainer.py:1718] 2023-09-07 07:25:41,861 >>   Instantaneous batch size per device = 512\n","[INFO|trainer.py:1721] 2023-09-07 07:25:41,861 >>   Total train batch size (w. parallel, distributed & accumulation) = 512\n","[INFO|trainer.py:1722] 2023-09-07 07:25:41,861 >>   Gradient Accumulation steps = 1\n","[INFO|trainer.py:1723] 2023-09-07 07:25:41,861 >>   Total optimization steps = 30,000\n","[INFO|trainer.py:1724] 2023-09-07 07:25:41,862 >>   Number of trainable parameters = 11,181,642\n","[INFO|integration_utils.py:716] 2023-09-07 07:25:41,863 >> Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n","{'loss': 1.119, 'learning_rate': 0.0009996666666666667, 'epoch': 0.1}\n","{'loss': 0.6205, 'learning_rate': 0.0009993333333333334, 'epoch': 0.2}\n","{'loss': 0.5706, 'learning_rate': 0.000999, 'epoch': 0.3}\n","{'loss': 0.4954, 'learning_rate': 0.0009986666666666668, 'epoch': 0.4}\n","{'loss': 0.4746, 'learning_rate': 0.0009983333333333333, 'epoch': 0.5}\n","{'loss': 0.4732, 'learning_rate': 0.000998, 'epoch': 0.6}\n","{'loss': 0.4735, 'learning_rate': 0.0009976666666666667, 'epoch': 0.7}\n","{'loss': 0.4754, 'learning_rate': 0.0009973333333333334, 'epoch': 0.8}\n","{'loss': 0.4565, 'learning_rate': 0.000997, 'epoch': 0.9}\n","{'loss': 0.4563, 'learning_rate': 0.0009966666666666668, 'epoch': 1.0}\n","  0% 100/30000 [02:05<7:10:10,  1.16it/s][INFO|trainer.py:3129] 2023-09-07 07:27:47,189 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3131] 2023-09-07 07:27:47,190 >>   Num examples = 9000\n","[INFO|trainer.py:3134] 2023-09-07 07:27:47,190 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.46it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.74it/s]\u001b[A\n"," 22% 4/18 [00:02<00:09,  1.53it/s]\u001b[A\n"," 28% 5/18 [00:03<00:09,  1.43it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.36it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.33it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.31it/s]\u001b[A\n"," 50% 9/18 [00:06<00:06,  1.29it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.28it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.27it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.26it/s]\u001b[A\n"," 72% 13/18 [00:09<00:04,  1.20it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.16it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.13it/s]\u001b[A\n"," 89% 16/18 [00:12<00:01,  1.12it/s]\u001b[A\n","                                         \n","\u001b[A{'eval_loss': 1.3704270124435425, 'eval_accuracy': 0.6046666666666667, 'eval_runtime': 14.7539, 'eval_samples_per_second': 610.007, 'eval_steps_per_second': 1.22, 'epoch': 1.0}\n","  0% 100/30000 [02:20<7:10:10,  1.16it/s]\n","100% 18/18 [00:13<00:00,  1.25it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2855] 2023-09-07 07:28:01,950 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-100\n","[INFO|configuration_utils.py:460] 2023-09-07 07:28:01,958 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-100/config.json\n","[INFO|modeling_utils.py:1978] 2023-09-07 07:28:02,099 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-100/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 07:28:02,105 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-100/preprocessor_config.json\n","{'loss': 0.4344, 'learning_rate': 0.0009963333333333332, 'epoch': 1.1}\n","{'loss': 0.4612, 'learning_rate': 0.000996, 'epoch': 1.2}\n","{'loss': 0.4305, 'learning_rate': 0.0009956666666666666, 'epoch': 1.3}\n","{'loss': 0.4166, 'learning_rate': 0.0009953333333333333, 'epoch': 1.4}\n","{'loss': 0.4161, 'learning_rate': 0.000995, 'epoch': 1.5}\n","{'loss': 0.3961, 'learning_rate': 0.0009946666666666667, 'epoch': 1.6}\n","{'loss': 0.3975, 'learning_rate': 0.0009943333333333334, 'epoch': 1.7}\n","{'loss': 0.4046, 'learning_rate': 0.000994, 'epoch': 1.8}\n","{'loss': 0.3855, 'learning_rate': 0.0009936666666666668, 'epoch': 1.9}\n","{'loss': 0.3862, 'learning_rate': 0.0009933333333333333, 'epoch': 2.0}\n","  1% 200/30000 [04:15<6:42:14,  1.23it/s][INFO|trainer.py:3129] 2023-09-07 07:29:57,780 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3131] 2023-09-07 07:29:57,780 >>   Num examples = 9000\n","[INFO|trainer.py:3134] 2023-09-07 07:29:57,780 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.43it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.68it/s]\u001b[A\n"," 22% 4/18 [00:02<00:09,  1.43it/s]\u001b[A\n"," 28% 5/18 [00:03<00:10,  1.30it/s]\u001b[A\n"," 33% 6/18 [00:04<00:09,  1.23it/s]\u001b[A\n"," 39% 7/18 [00:05<00:08,  1.23it/s]\u001b[A\n"," 44% 8/18 [00:05<00:08,  1.24it/s]\u001b[A\n"," 50% 9/18 [00:06<00:07,  1.24it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.24it/s]\u001b[A\n"," 61% 11/18 [00:08<00:05,  1.24it/s]\u001b[A\n"," 67% 12/18 [00:09<00:04,  1.24it/s]\u001b[A\n"," 72% 13/18 [00:09<00:04,  1.25it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.26it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.26it/s]\u001b[A\n"," 89% 16/18 [00:12<00:01,  1.27it/s]\u001b[A\n","                                         \n","\u001b[A{'eval_loss': 0.10235067456960678, 'eval_accuracy': 0.9683333333333334, 'eval_runtime': 14.4521, 'eval_samples_per_second': 622.745, 'eval_steps_per_second': 1.245, 'epoch': 2.0}\n","  1% 200/30000 [04:30<6:42:14,  1.23it/s]\n","100% 18/18 [00:12<00:00,  1.42it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2855] 2023-09-07 07:30:12,237 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-200\n","[INFO|configuration_utils.py:460] 2023-09-07 07:30:12,243 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-200/config.json\n","[INFO|modeling_utils.py:1978] 2023-09-07 07:30:12,356 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-200/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 07:30:12,360 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-200/preprocessor_config.json\n","{'loss': 0.3842, 'learning_rate': 0.000993, 'epoch': 2.1}\n","{'loss': 0.3727, 'learning_rate': 0.0009926666666666667, 'epoch': 2.2}\n","{'loss': 0.3996, 'learning_rate': 0.0009923333333333333, 'epoch': 2.3}\n","{'loss': 0.3564, 'learning_rate': 0.000992, 'epoch': 2.4}\n","{'loss': 0.3851, 'learning_rate': 0.0009916666666666667, 'epoch': 2.5}\n","{'loss': 0.3854, 'learning_rate': 0.0009913333333333332, 'epoch': 2.6}\n","{'loss': 0.367, 'learning_rate': 0.000991, 'epoch': 2.7}\n","{'loss': 0.3711, 'learning_rate': 0.0009906666666666668, 'epoch': 2.8}\n","{'loss': 0.3675, 'learning_rate': 0.0009903333333333333, 'epoch': 2.9}\n","{'loss': 0.361, 'learning_rate': 0.00099, 'epoch': 3.0}\n","  1% 300/30000 [06:26<6:56:08,  1.19it/s][INFO|trainer.py:3129] 2023-09-07 07:32:08,745 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3131] 2023-09-07 07:32:08,745 >>   Num examples = 9000\n","[INFO|trainer.py:3134] 2023-09-07 07:32:08,745 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.50it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.76it/s]\u001b[A\n"," 22% 4/18 [00:02<00:09,  1.53it/s]\u001b[A\n"," 28% 5/18 [00:03<00:09,  1.42it/s]\u001b[A\n"," 33% 6/18 [00:04<00:08,  1.36it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.29it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.27it/s]\u001b[A\n"," 50% 9/18 [00:06<00:07,  1.20it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.18it/s]\u001b[A\n"," 61% 11/18 [00:08<00:06,  1.16it/s]\u001b[A\n"," 67% 12/18 [00:09<00:05,  1.19it/s]\u001b[A\n"," 72% 13/18 [00:09<00:04,  1.20it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.22it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.23it/s]\u001b[A\n"," 89% 16/18 [00:12<00:01,  1.24it/s]\u001b[A\n","                                         \n","\u001b[A{'eval_loss': 0.09913624078035355, 'eval_accuracy': 0.9678888888888889, 'eval_runtime': 14.4488, 'eval_samples_per_second': 622.891, 'eval_steps_per_second': 1.246, 'epoch': 3.0}\n","  1% 300/30000 [06:41<6:56:08,  1.19it/s]\n","100% 18/18 [00:12<00:00,  1.41it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2855] 2023-09-07 07:32:23,199 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-300\n","[INFO|configuration_utils.py:460] 2023-09-07 07:32:23,204 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-300/config.json\n","[INFO|modeling_utils.py:1978] 2023-09-07 07:32:23,326 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-300/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 07:32:23,331 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-300/preprocessor_config.json\n","{'loss': 0.3856, 'learning_rate': 0.0009896666666666667, 'epoch': 3.1}\n","{'loss': 0.3722, 'learning_rate': 0.0009893333333333334, 'epoch': 3.2}\n","{'loss': 0.358, 'learning_rate': 0.000989, 'epoch': 3.3}\n","{'loss': 0.3745, 'learning_rate': 0.0009886666666666668, 'epoch': 3.4}\n","{'loss': 0.3645, 'learning_rate': 0.0009883333333333333, 'epoch': 3.5}\n","{'loss': 0.3523, 'learning_rate': 0.000988, 'epoch': 3.6}\n","{'loss': 0.3556, 'learning_rate': 0.0009876666666666666, 'epoch': 3.7}\n","{'loss': 0.3554, 'learning_rate': 0.0009873333333333333, 'epoch': 3.8}\n","{'loss': 0.3532, 'learning_rate': 0.000987, 'epoch': 3.9}\n","{'loss': 0.3518, 'learning_rate': 0.0009866666666666667, 'epoch': 4.0}\n","  1% 400/30000 [08:36<7:01:04,  1.17it/s][INFO|trainer.py:3129] 2023-09-07 07:34:18,679 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3131] 2023-09-07 07:34:18,679 >>   Num examples = 9000\n","[INFO|trainer.py:3134] 2023-09-07 07:34:18,679 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.59it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.79it/s]\u001b[A\n"," 22% 4/18 [00:02<00:09,  1.54it/s]\u001b[A\n"," 28% 5/18 [00:03<00:09,  1.43it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.36it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.32it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.30it/s]\u001b[A\n"," 50% 9/18 [00:06<00:06,  1.29it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.28it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.28it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.27it/s]\u001b[A\n"," 72% 13/18 [00:09<00:04,  1.23it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.19it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.16it/s]\u001b[A\n"," 89% 16/18 [00:12<00:01,  1.16it/s]\u001b[A\n","                                         \n","\u001b[A{'eval_loss': 0.07841267436742783, 'eval_accuracy': 0.9753333333333334, 'eval_runtime': 14.3618, 'eval_samples_per_second': 626.66, 'eval_steps_per_second': 1.253, 'epoch': 4.0}\n","  1% 400/30000 [08:51<7:01:04,  1.17it/s]\n","100% 18/18 [00:12<00:00,  1.31it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2855] 2023-09-07 07:34:33,045 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-400\n","[INFO|configuration_utils.py:460] 2023-09-07 07:34:33,050 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-400/config.json\n","[INFO|modeling_utils.py:1978] 2023-09-07 07:34:33,182 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-400/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 07:34:33,187 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-400/preprocessor_config.json\n","[INFO|trainer.py:2942] 2023-09-07 07:34:33,419 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-100] due to args.save_total_limit\n","{'loss': 0.3586, 'learning_rate': 0.0009863333333333332, 'epoch': 4.1}\n","{'loss': 0.3471, 'learning_rate': 0.0009860000000000001, 'epoch': 4.2}\n","{'loss': 0.3522, 'learning_rate': 0.0009856666666666668, 'epoch': 4.3}\n","{'loss': 0.3583, 'learning_rate': 0.0009853333333333333, 'epoch': 4.4}\n","{'loss': 0.363, 'learning_rate': 0.000985, 'epoch': 4.5}\n","{'loss': 0.3582, 'learning_rate': 0.0009846666666666667, 'epoch': 4.6}\n","{'loss': 0.3541, 'learning_rate': 0.0009843333333333334, 'epoch': 4.7}\n","{'loss': 0.3324, 'learning_rate': 0.000984, 'epoch': 4.8}\n","{'loss': 0.3179, 'learning_rate': 0.0009836666666666668, 'epoch': 4.9}\n","{'loss': 0.3276, 'learning_rate': 0.0009833333333333332, 'epoch': 5.0}\n","  2% 500/30000 [10:47<6:31:23,  1.26it/s][INFO|trainer.py:3129] 2023-09-07 07:36:28,948 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3131] 2023-09-07 07:36:28,948 >>   Num examples = 9000\n","[INFO|trainer.py:3134] 2023-09-07 07:36:28,948 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.44it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.70it/s]\u001b[A\n"," 22% 4/18 [00:02<00:09,  1.43it/s]\u001b[A\n"," 28% 5/18 [00:03<00:09,  1.32it/s]\u001b[A\n"," 33% 6/18 [00:04<00:10,  1.15it/s]\u001b[A\n"," 39% 7/18 [00:05<00:09,  1.19it/s]\u001b[A\n"," 44% 8/18 [00:06<00:08,  1.22it/s]\u001b[A\n"," 50% 9/18 [00:06<00:07,  1.24it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.25it/s]\u001b[A\n"," 61% 11/18 [00:08<00:05,  1.27it/s]\u001b[A\n"," 67% 12/18 [00:09<00:04,  1.28it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.28it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.29it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.28it/s]\u001b[A\n"," 89% 16/18 [00:12<00:01,  1.29it/s]\u001b[A\n","                                         \n","\u001b[A{'eval_loss': 0.06537295132875443, 'eval_accuracy': 0.9804444444444445, 'eval_runtime': 14.3291, 'eval_samples_per_second': 628.093, 'eval_steps_per_second': 1.256, 'epoch': 5.0}\n","  2% 500/30000 [11:01<6:31:23,  1.26it/s]\n","100% 18/18 [00:12<00:00,  1.45it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2855] 2023-09-07 07:36:43,282 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-500\n","[INFO|configuration_utils.py:460] 2023-09-07 07:36:43,288 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-500/config.json\n","[INFO|modeling_utils.py:1978] 2023-09-07 07:36:43,405 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-500/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 07:36:43,410 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-500/preprocessor_config.json\n","[INFO|trainer.py:2942] 2023-09-07 07:36:43,635 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-200] due to args.save_total_limit\n","{'loss': 0.3205, 'learning_rate': 0.000983, 'epoch': 5.1}\n","{'loss': 0.3359, 'learning_rate': 0.0009826666666666666, 'epoch': 5.2}\n","{'loss': 0.3615, 'learning_rate': 0.0009823333333333333, 'epoch': 5.3}\n","{'loss': 0.3474, 'learning_rate': 0.000982, 'epoch': 5.4}\n","{'loss': 0.3287, 'learning_rate': 0.0009816666666666667, 'epoch': 5.5}\n","{'loss': 0.3308, 'learning_rate': 0.0009813333333333334, 'epoch': 5.6}\n","{'loss': 0.3315, 'learning_rate': 0.000981, 'epoch': 5.7}\n","{'loss': 0.341, 'learning_rate': 0.0009806666666666668, 'epoch': 5.8}\n","{'loss': 0.3389, 'learning_rate': 0.0009803333333333333, 'epoch': 5.9}\n","{'loss': 0.3377, 'learning_rate': 0.00098, 'epoch': 6.0}\n","  2% 600/30000 [12:56<6:37:30,  1.23it/s][INFO|trainer.py:3129] 2023-09-07 07:38:38,652 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3131] 2023-09-07 07:38:38,652 >>   Num examples = 9000\n","[INFO|trainer.py:3134] 2023-09-07 07:38:38,652 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.56it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.79it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.56it/s]\u001b[A\n"," 28% 5/18 [00:03<00:08,  1.46it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.39it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.28it/s]\u001b[A\n"," 44% 8/18 [00:05<00:08,  1.22it/s]\u001b[A\n"," 50% 9/18 [00:06<00:07,  1.18it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.16it/s]\u001b[A\n"," 61% 11/18 [00:08<00:06,  1.15it/s]\u001b[A\n"," 67% 12/18 [00:09<00:05,  1.18it/s]\u001b[A\n"," 72% 13/18 [00:09<00:04,  1.21it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.23it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.24it/s]\u001b[A\n"," 89% 16/18 [00:12<00:01,  1.26it/s]\u001b[A\n","                                         \n","\u001b[A{'eval_loss': 0.05730368196964264, 'eval_accuracy': 0.9816666666666667, 'eval_runtime': 14.3782, 'eval_samples_per_second': 625.949, 'eval_steps_per_second': 1.252, 'epoch': 6.0}\n","  2% 600/30000 [13:11<6:37:30,  1.23it/s]\n","100% 18/18 [00:12<00:00,  1.43it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2855] 2023-09-07 07:38:53,035 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-600\n","[INFO|configuration_utils.py:460] 2023-09-07 07:38:53,040 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-600/config.json\n","[INFO|modeling_utils.py:1978] 2023-09-07 07:38:53,154 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-600/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 07:38:53,159 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-600/preprocessor_config.json\n","[INFO|trainer.py:2942] 2023-09-07 07:38:53,383 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-300] due to args.save_total_limit\n","{'loss': 0.3465, 'learning_rate': 0.0009796666666666667, 'epoch': 6.1}\n","{'loss': 0.3502, 'learning_rate': 0.0009793333333333334, 'epoch': 6.2}\n","{'loss': 0.3317, 'learning_rate': 0.000979, 'epoch': 6.3}\n","{'loss': 0.3378, 'learning_rate': 0.0009786666666666667, 'epoch': 6.4}\n","{'loss': 0.3304, 'learning_rate': 0.0009783333333333334, 'epoch': 6.5}\n","{'loss': 0.3364, 'learning_rate': 0.000978, 'epoch': 6.6}\n","{'loss': 0.3238, 'learning_rate': 0.0009776666666666666, 'epoch': 6.7}\n","{'loss': 0.3361, 'learning_rate': 0.0009773333333333333, 'epoch': 6.8}\n","{'loss': 0.3516, 'learning_rate': 0.000977, 'epoch': 6.9}\n","{'loss': 0.3244, 'learning_rate': 0.0009766666666666667, 'epoch': 7.0}\n","  2% 700/30000 [15:07<6:50:55,  1.19it/s][INFO|trainer.py:3129] 2023-09-07 07:40:49,001 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3131] 2023-09-07 07:40:49,001 >>   Num examples = 9000\n","[INFO|trainer.py:3134] 2023-09-07 07:40:49,001 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.58it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.81it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.56it/s]\u001b[A\n"," 28% 5/18 [00:03<00:09,  1.44it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.38it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.34it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.33it/s]\u001b[A\n"," 50% 9/18 [00:06<00:06,  1.32it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.30it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.29it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.28it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.25it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.23it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.19it/s]\u001b[A\n"," 89% 16/18 [00:12<00:01,  1.15it/s]\u001b[A\n","                                         \n","\u001b[A{'eval_loss': 0.05302440747618675, 'eval_accuracy': 0.9827777777777778, 'eval_runtime': 14.2671, 'eval_samples_per_second': 630.822, 'eval_steps_per_second': 1.262, 'epoch': 7.0}\n","  2% 700/30000 [15:21<6:50:55,  1.19it/s]\n","100% 18/18 [00:12<00:00,  1.29it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2855] 2023-09-07 07:41:03,273 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-700\n","[INFO|configuration_utils.py:460] 2023-09-07 07:41:03,297 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-700/config.json\n","[INFO|modeling_utils.py:1978] 2023-09-07 07:41:03,418 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-700/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 07:41:03,423 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-700/preprocessor_config.json\n","[INFO|trainer.py:2942] 2023-09-07 07:41:03,664 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-400] due to args.save_total_limit\n","{'loss': 0.341, 'learning_rate': 0.0009763333333333334, 'epoch': 7.1}\n","{'loss': 0.3202, 'learning_rate': 0.000976, 'epoch': 7.2}\n","{'loss': 0.3244, 'learning_rate': 0.0009756666666666667, 'epoch': 7.3}\n","{'loss': 0.3224, 'learning_rate': 0.0009753333333333334, 'epoch': 7.4}\n","{'loss': 0.3231, 'learning_rate': 0.000975, 'epoch': 7.5}\n","{'loss': 0.3277, 'learning_rate': 0.0009746666666666666, 'epoch': 7.6}\n","{'loss': 0.3411, 'learning_rate': 0.0009743333333333335, 'epoch': 7.7}\n","{'loss': 0.3299, 'learning_rate': 0.000974, 'epoch': 7.8}\n","{'loss': 0.3071, 'learning_rate': 0.0009736666666666667, 'epoch': 7.9}\n","{'loss': 0.3134, 'learning_rate': 0.0009733333333333334, 'epoch': 8.0}\n","  3% 800/30000 [17:16<6:31:36,  1.24it/s][INFO|trainer.py:3129] 2023-09-07 07:42:58,309 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3131] 2023-09-07 07:42:58,309 >>   Num examples = 9000\n","[INFO|trainer.py:3134] 2023-09-07 07:42:58,309 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.29it/s]\u001b[A\n"," 17% 3/18 [00:01<00:09,  1.57it/s]\u001b[A\n"," 22% 4/18 [00:02<00:10,  1.34it/s]\u001b[A\n"," 28% 5/18 [00:03<00:10,  1.28it/s]\u001b[A\n"," 33% 6/18 [00:04<00:09,  1.27it/s]\u001b[A\n"," 39% 7/18 [00:05<00:08,  1.27it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.26it/s]\u001b[A\n"," 50% 9/18 [00:06<00:07,  1.26it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.25it/s]\u001b[A\n"," 61% 11/18 [00:08<00:06,  1.14it/s]\u001b[A\n"," 67% 12/18 [00:09<00:05,  1.17it/s]\u001b[A\n"," 72% 13/18 [00:10<00:04,  1.20it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.23it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.25it/s]\u001b[A\n"," 89% 16/18 [00:12<00:01,  1.26it/s]\u001b[A\n","                                         \n","\u001b[A{'eval_loss': 0.1454898864030838, 'eval_accuracy': 0.955, 'eval_runtime': 14.7221, 'eval_samples_per_second': 611.326, 'eval_steps_per_second': 1.223, 'epoch': 8.0}\n","  3% 800/30000 [17:31<6:31:36,  1.24it/s]\n","100% 18/18 [00:13<00:00,  1.42it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2855] 2023-09-07 07:43:13,037 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-800\n","[INFO|configuration_utils.py:460] 2023-09-07 07:43:13,043 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-800/config.json\n","[INFO|modeling_utils.py:1978] 2023-09-07 07:43:13,168 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-800/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 07:43:13,173 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-800/preprocessor_config.json\n","[INFO|trainer.py:2942] 2023-09-07 07:43:13,424 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-500] due to args.save_total_limit\n","{'loss': 0.3346, 'learning_rate': 0.000973, 'epoch': 8.1}\n","{'loss': 0.3056, 'learning_rate': 0.0009726666666666667, 'epoch': 8.2}\n","{'loss': 0.3353, 'learning_rate': 0.0009723333333333334, 'epoch': 8.3}\n","{'loss': 0.3343, 'learning_rate': 0.000972, 'epoch': 8.4}\n","{'loss': 0.3403, 'learning_rate': 0.0009716666666666667, 'epoch': 8.5}\n","{'loss': 0.3262, 'learning_rate': 0.0009713333333333334, 'epoch': 8.6}\n","{'loss': 0.3128, 'learning_rate': 0.000971, 'epoch': 8.7}\n","{'loss': 0.3145, 'learning_rate': 0.0009706666666666667, 'epoch': 8.8}\n","{'loss': 0.3147, 'learning_rate': 0.0009703333333333334, 'epoch': 8.9}\n","{'loss': 0.3159, 'learning_rate': 0.0009699999999999999, 'epoch': 9.0}\n","  3% 900/30000 [19:27<6:48:32,  1.19it/s][INFO|trainer.py:3129] 2023-09-07 07:45:09,111 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3131] 2023-09-07 07:45:09,111 >>   Num examples = 9000\n","[INFO|trainer.py:3134] 2023-09-07 07:45:09,111 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.29it/s]\u001b[A\n"," 17% 3/18 [00:01<00:09,  1.61it/s]\u001b[A\n"," 22% 4/18 [00:02<00:09,  1.45it/s]\u001b[A\n"," 28% 5/18 [00:03<00:09,  1.39it/s]\u001b[A\n"," 33% 6/18 [00:04<00:08,  1.36it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.33it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.32it/s]\u001b[A\n"," 50% 9/18 [00:06<00:06,  1.31it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.30it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.30it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.29it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.28it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.29it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.28it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.28it/s]\u001b[A\n","                                         \n","\u001b[A{'eval_loss': 0.04040978476405144, 'eval_accuracy': 0.9868888888888889, 'eval_runtime': 14.1374, 'eval_samples_per_second': 636.609, 'eval_steps_per_second': 1.273, 'epoch': 9.0}\n","  3% 900/30000 [19:41<6:48:32,  1.19it/s]\n","100% 18/18 [00:12<00:00,  1.44it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2855] 2023-09-07 07:45:23,254 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-900\n","[INFO|configuration_utils.py:460] 2023-09-07 07:45:23,260 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-900/config.json\n","[INFO|modeling_utils.py:1978] 2023-09-07 07:45:23,377 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-900/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 07:45:23,382 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-900/preprocessor_config.json\n","[INFO|trainer.py:2942] 2023-09-07 07:45:23,631 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-600] due to args.save_total_limit\n","{'loss': 0.3304, 'learning_rate': 0.0009696666666666667, 'epoch': 9.1}\n","{'loss': 0.3242, 'learning_rate': 0.0009693333333333334, 'epoch': 9.2}\n","{'loss': 0.3274, 'learning_rate': 0.000969, 'epoch': 9.3}\n","{'loss': 0.2963, 'learning_rate': 0.0009686666666666667, 'epoch': 9.4}\n","{'loss': 0.3096, 'learning_rate': 0.0009683333333333334, 'epoch': 9.5}\n","{'loss': 0.2877, 'learning_rate': 0.000968, 'epoch': 9.6}\n","{'loss': 0.3078, 'learning_rate': 0.0009676666666666667, 'epoch': 9.7}\n","{'loss': 0.3344, 'learning_rate': 0.0009673333333333334, 'epoch': 9.8}\n","{'loss': 0.3245, 'learning_rate': 0.000967, 'epoch': 9.9}\n","{'loss': 0.3288, 'learning_rate': 0.0009666666666666667, 'epoch': 10.0}\n","  3% 1000/30000 [21:37<6:28:32,  1.24it/s][INFO|trainer.py:3129] 2023-09-07 07:47:19,073 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3131] 2023-09-07 07:47:19,073 >>   Num examples = 9000\n","[INFO|trainer.py:3134] 2023-09-07 07:47:19,073 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.40it/s]\u001b[A\n"," 17% 3/18 [00:01<00:09,  1.65it/s]\u001b[A\n"," 22% 4/18 [00:02<00:10,  1.40it/s]\u001b[A\n"," 28% 5/18 [00:03<00:09,  1.36it/s]\u001b[A\n"," 33% 6/18 [00:04<00:09,  1.33it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.31it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.30it/s]\u001b[A\n"," 50% 9/18 [00:06<00:06,  1.29it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.29it/s]\u001b[A\n"," 61% 11/18 [00:08<00:05,  1.29it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.29it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.28it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.28it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.28it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.28it/s]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 0.03927045688033104, 'eval_accuracy': 0.9878888888888889, 'eval_runtime': 14.1927, 'eval_samples_per_second': 634.127, 'eval_steps_per_second': 1.268, 'epoch': 10.0}\n","  3% 1000/30000 [21:51<6:28:32,  1.24it/s]\n","100% 18/18 [00:12<00:00,  1.44it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2855] 2023-09-07 07:47:33,270 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-1000\n","[INFO|configuration_utils.py:460] 2023-09-07 07:47:33,291 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-1000/config.json\n","[INFO|modeling_utils.py:1978] 2023-09-07 07:47:33,404 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-1000/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 07:47:33,409 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-1000/preprocessor_config.json\n","[INFO|trainer.py:2942] 2023-09-07 07:47:33,640 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-700] due to args.save_total_limit\n","{'loss': 0.3026, 'learning_rate': 0.0009663333333333334, 'epoch': 10.1}\n","{'loss': 0.3138, 'learning_rate': 0.000966, 'epoch': 10.2}\n","{'loss': 0.3126, 'learning_rate': 0.0009656666666666666, 'epoch': 10.3}\n","{'loss': 0.3087, 'learning_rate': 0.0009653333333333333, 'epoch': 10.4}\n","{'loss': 0.3143, 'learning_rate': 0.000965, 'epoch': 10.5}\n","{'loss': 0.2926, 'learning_rate': 0.0009646666666666667, 'epoch': 10.6}\n","{'loss': 0.3048, 'learning_rate': 0.0009643333333333334, 'epoch': 10.7}\n","{'loss': 0.3088, 'learning_rate': 0.000964, 'epoch': 10.8}\n","{'loss': 0.3201, 'learning_rate': 0.0009636666666666667, 'epoch': 10.9}\n","{'loss': 0.3084, 'learning_rate': 0.0009633333333333334, 'epoch': 11.0}\n","  4% 1100/30000 [23:47<6:24:34,  1.25it/s][INFO|trainer.py:3129] 2023-09-07 07:49:29,410 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3131] 2023-09-07 07:49:29,410 >>   Num examples = 9000\n","[INFO|trainer.py:3134] 2023-09-07 07:49:29,410 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:07,  2.27it/s]\u001b[A\n"," 17% 3/18 [00:01<00:09,  1.60it/s]\u001b[A\n"," 22% 4/18 [00:02<00:10,  1.37it/s]\u001b[A\n"," 28% 5/18 [00:03<00:09,  1.34it/s]\u001b[A\n"," 33% 6/18 [00:04<00:09,  1.31it/s]\u001b[A\n"," 39% 7/18 [00:05<00:08,  1.30it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.29it/s]\u001b[A\n"," 50% 9/18 [00:06<00:07,  1.27it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.27it/s]\u001b[A\n"," 61% 11/18 [00:08<00:05,  1.26it/s]\u001b[A\n"," 67% 12/18 [00:09<00:04,  1.26it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.26it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.25it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.25it/s]\u001b[A\n"," 89% 16/18 [00:12<00:01,  1.25it/s]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 0.04820820316672325, 'eval_accuracy': 0.9853333333333333, 'eval_runtime': 14.5205, 'eval_samples_per_second': 619.812, 'eval_steps_per_second': 1.24, 'epoch': 11.0}\n","  4% 1100/30000 [24:02<6:24:34,  1.25it/s]\n","100% 18/18 [00:12<00:00,  1.41it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2855] 2023-09-07 07:49:43,936 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-1100\n","[INFO|configuration_utils.py:460] 2023-09-07 07:49:43,942 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-1100/config.json\n","[INFO|modeling_utils.py:1978] 2023-09-07 07:49:44,065 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-1100/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 07:49:44,070 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-1100/preprocessor_config.json\n","[INFO|trainer.py:2942] 2023-09-07 07:49:44,327 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-800] due to args.save_total_limit\n","{'loss': 0.304, 'learning_rate': 0.000963, 'epoch': 11.1}\n","{'loss': 0.3093, 'learning_rate': 0.0009626666666666667, 'epoch': 11.2}\n","{'loss': 0.3067, 'learning_rate': 0.0009623333333333334, 'epoch': 11.3}\n","{'loss': 0.3115, 'learning_rate': 0.000962, 'epoch': 11.4}\n","{'loss': 0.3305, 'learning_rate': 0.0009616666666666667, 'epoch': 11.5}\n","{'loss': 0.3099, 'learning_rate': 0.0009613333333333334, 'epoch': 11.6}\n","{'loss': 0.3043, 'learning_rate': 0.0009609999999999999, 'epoch': 11.7}\n","{'loss': 0.3131, 'learning_rate': 0.0009606666666666666, 'epoch': 11.8}\n","{'loss': 0.2944, 'learning_rate': 0.0009603333333333334, 'epoch': 11.9}\n","{'loss': 0.3158, 'learning_rate': 0.00096, 'epoch': 12.0}\n","  4% 1200/30000 [25:59<6:48:55,  1.17it/s][INFO|trainer.py:3129] 2023-09-07 07:51:41,153 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3131] 2023-09-07 07:51:41,154 >>   Num examples = 9000\n","[INFO|trainer.py:3134] 2023-09-07 07:51:41,154 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.31it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.71it/s]\u001b[A\n"," 22% 4/18 [00:02<00:09,  1.53it/s]\u001b[A\n"," 28% 5/18 [00:03<00:08,  1.44it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.39it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.35it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.33it/s]\u001b[A\n"," 50% 9/18 [00:06<00:06,  1.31it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.17it/s]\u001b[A\n"," 61% 11/18 [00:08<00:05,  1.20it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.21it/s]\u001b[A\n"," 72% 13/18 [00:09<00:04,  1.23it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.25it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.24it/s]\u001b[A\n"," 89% 16/18 [00:12<00:01,  1.22it/s]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 0.0661122128367424, 'eval_accuracy': 0.9773333333333334, 'eval_runtime': 14.5177, 'eval_samples_per_second': 619.933, 'eval_steps_per_second': 1.24, 'epoch': 12.0}\n","  4% 1200/30000 [26:13<6:48:55,  1.17it/s]\n","100% 18/18 [00:12<00:00,  1.36it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2855] 2023-09-07 07:51:55,676 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-1200\n","[INFO|configuration_utils.py:460] 2023-09-07 07:51:55,682 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-1200/config.json\n","[INFO|modeling_utils.py:1978] 2023-09-07 07:51:55,799 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-1200/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 07:51:55,803 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-1200/preprocessor_config.json\n","[INFO|trainer.py:2942] 2023-09-07 07:51:56,045 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-900] due to args.save_total_limit\n","{'loss': 0.2972, 'learning_rate': 0.0009596666666666667, 'epoch': 12.1}\n","{'loss': 0.3018, 'learning_rate': 0.0009593333333333334, 'epoch': 12.2}\n","{'loss': 0.3014, 'learning_rate': 0.000959, 'epoch': 12.3}\n","{'loss': 0.3061, 'learning_rate': 0.0009586666666666667, 'epoch': 12.4}\n","{'loss': 0.2995, 'learning_rate': 0.0009583333333333334, 'epoch': 12.5}\n","{'loss': 0.3273, 'learning_rate': 0.000958, 'epoch': 12.6}\n","{'loss': 0.3066, 'learning_rate': 0.0009576666666666667, 'epoch': 12.7}\n","{'loss': 0.2881, 'learning_rate': 0.0009573333333333334, 'epoch': 12.8}\n","{'loss': 0.3065, 'learning_rate': 0.000957, 'epoch': 12.9}\n","{'loss': 0.3028, 'learning_rate': 0.0009566666666666666, 'epoch': 13.0}\n","  4% 1300/30000 [28:09<6:28:50,  1.23it/s][INFO|trainer.py:3129] 2023-09-07 07:53:51,825 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3131] 2023-09-07 07:53:51,825 >>   Num examples = 9000\n","[INFO|trainer.py:3134] 2023-09-07 07:53:51,825 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.33it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.72it/s]\u001b[A\n"," 22% 4/18 [00:02<00:09,  1.51it/s]\u001b[A\n"," 28% 5/18 [00:03<00:09,  1.42it/s]\u001b[A\n"," 33% 6/18 [00:04<00:08,  1.37it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.34it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.32it/s]\u001b[A\n"," 50% 9/18 [00:06<00:06,  1.30it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.29it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.28it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.28it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.26it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.25it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.24it/s]\u001b[A\n"," 89% 16/18 [00:12<00:01,  1.22it/s]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 0.0364195741713047, 'eval_accuracy': 0.9882222222222222, 'eval_runtime': 14.3738, 'eval_samples_per_second': 626.14, 'eval_steps_per_second': 1.252, 'epoch': 13.0}\n","  4% 1300/30000 [28:24<6:28:50,  1.23it/s]\n","100% 18/18 [00:12<00:00,  1.38it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2855] 2023-09-07 07:54:06,203 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-1300\n","[INFO|configuration_utils.py:460] 2023-09-07 07:54:06,210 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-1300/config.json\n","[INFO|modeling_utils.py:1978] 2023-09-07 07:54:06,333 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-1300/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 07:54:06,339 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-1300/preprocessor_config.json\n","[INFO|trainer.py:2942] 2023-09-07 07:54:06,593 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-1000] due to args.save_total_limit\n","{'loss': 0.3005, 'learning_rate': 0.0009563333333333333, 'epoch': 13.1}\n","{'loss': 0.2898, 'learning_rate': 0.0009559999999999999, 'epoch': 13.2}\n","{'loss': 0.2979, 'learning_rate': 0.0009556666666666667, 'epoch': 13.3}\n","{'loss': 0.3054, 'learning_rate': 0.0009553333333333334, 'epoch': 13.4}\n","{'loss': 0.3035, 'learning_rate': 0.000955, 'epoch': 13.5}\n","{'loss': 0.3083, 'learning_rate': 0.0009546666666666667, 'epoch': 13.6}\n","{'loss': 0.3031, 'learning_rate': 0.0009543333333333334, 'epoch': 13.7}\n","{'loss': 0.3068, 'learning_rate': 0.000954, 'epoch': 13.8}\n","{'loss': 0.2896, 'learning_rate': 0.0009536666666666667, 'epoch': 13.9}\n","{'loss': 0.2976, 'learning_rate': 0.0009533333333333334, 'epoch': 14.0}\n","  5% 1400/30000 [30:20<6:27:42,  1.23it/s][INFO|trainer.py:3129] 2023-09-07 07:56:02,252 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3131] 2023-09-07 07:56:02,252 >>   Num examples = 9000\n","[INFO|trainer.py:3134] 2023-09-07 07:56:02,253 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:07,  2.22it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.68it/s]\u001b[A\n"," 22% 4/18 [00:02<00:09,  1.49it/s]\u001b[A\n"," 28% 5/18 [00:03<00:09,  1.40it/s]\u001b[A\n"," 33% 6/18 [00:04<00:08,  1.35it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.32it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.30it/s]\u001b[A\n"," 50% 9/18 [00:06<00:06,  1.29it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.29it/s]\u001b[A\n"," 61% 11/18 [00:08<00:05,  1.28it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.27it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.27it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.27it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.24it/s]\u001b[A\n"," 89% 16/18 [00:12<00:01,  1.23it/s]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 0.04031720384955406, 'eval_accuracy': 0.9866666666666667, 'eval_runtime': 14.439, 'eval_samples_per_second': 623.313, 'eval_steps_per_second': 1.247, 'epoch': 14.0}\n","  5% 1400/30000 [30:34<6:27:42,  1.23it/s]\n","100% 18/18 [00:12<00:00,  1.38it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2855] 2023-09-07 07:56:16,696 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-1400\n","[INFO|configuration_utils.py:460] 2023-09-07 07:56:16,702 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-1400/config.json\n","[INFO|modeling_utils.py:1978] 2023-09-07 07:56:16,822 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-1400/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 07:56:16,828 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-1400/preprocessor_config.json\n","[INFO|trainer.py:2942] 2023-09-07 07:56:17,093 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-1100] due to args.save_total_limit\n","{'loss': 0.2909, 'learning_rate': 0.000953, 'epoch': 14.1}\n","{'loss': 0.2822, 'learning_rate': 0.0009526666666666667, 'epoch': 14.2}\n","{'loss': 0.2964, 'learning_rate': 0.0009523333333333334, 'epoch': 14.3}\n","{'loss': 0.2968, 'learning_rate': 0.0009519999999999999, 'epoch': 14.4}\n","{'loss': 0.283, 'learning_rate': 0.0009516666666666666, 'epoch': 14.5}\n","{'loss': 0.2903, 'learning_rate': 0.0009513333333333334, 'epoch': 14.6}\n","{'loss': 0.3038, 'learning_rate': 0.000951, 'epoch': 14.7}\n","{'loss': 0.3225, 'learning_rate': 0.0009506666666666667, 'epoch': 14.8}\n","{'loss': 0.2869, 'learning_rate': 0.0009503333333333334, 'epoch': 14.9}\n","{'loss': 0.2869, 'learning_rate': 0.00095, 'epoch': 15.0}\n","  5% 1500/30000 [32:32<6:48:01,  1.16it/s][INFO|trainer.py:3129] 2023-09-07 07:58:14,078 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3131] 2023-09-07 07:58:14,078 >>   Num examples = 9000\n","[INFO|trainer.py:3134] 2023-09-07 07:58:14,078 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.54it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.75it/s]\u001b[A\n"," 22% 4/18 [00:02<00:09,  1.52it/s]\u001b[A\n"," 28% 5/18 [00:03<00:09,  1.41it/s]\u001b[A\n"," 33% 6/18 [00:04<00:08,  1.35it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.32it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.30it/s]\u001b[A\n"," 50% 9/18 [00:06<00:07,  1.28it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.27it/s]\u001b[A\n"," 61% 11/18 [00:08<00:05,  1.26it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.26it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.25it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.20it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.18it/s]\u001b[A\n"," 89% 16/18 [00:12<00:01,  1.16it/s]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 0.04489239677786827, 'eval_accuracy': 0.9851111111111112, 'eval_runtime': 14.5549, 'eval_samples_per_second': 618.346, 'eval_steps_per_second': 1.237, 'epoch': 15.0}\n","  5% 1500/30000 [32:46<6:48:01,  1.16it/s]\n","100% 18/18 [00:12<00:00,  1.31it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2855] 2023-09-07 07:58:28,638 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-1500\n","[INFO|configuration_utils.py:460] 2023-09-07 07:58:28,644 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-1500/config.json\n","[INFO|modeling_utils.py:1978] 2023-09-07 07:58:28,770 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-1500/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 07:58:28,776 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-1500/preprocessor_config.json\n","[INFO|trainer.py:2942] 2023-09-07 07:58:29,028 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-1200] due to args.save_total_limit\n","{'loss': 0.2831, 'learning_rate': 0.0009496666666666667, 'epoch': 15.1}\n","{'loss': 0.3239, 'learning_rate': 0.0009493333333333334, 'epoch': 15.2}\n","{'loss': 0.2839, 'learning_rate': 0.000949, 'epoch': 15.3}\n","{'loss': 0.2914, 'learning_rate': 0.0009486666666666667, 'epoch': 15.4}\n","{'loss': 0.3079, 'learning_rate': 0.0009483333333333334, 'epoch': 15.5}\n","{'loss': 0.2927, 'learning_rate': 0.000948, 'epoch': 15.6}\n","{'loss': 0.2962, 'learning_rate': 0.0009476666666666666, 'epoch': 15.7}\n","{'loss': 0.2938, 'learning_rate': 0.0009473333333333333, 'epoch': 15.8}\n","{'loss': 0.2834, 'learning_rate': 0.0009469999999999999, 'epoch': 15.9}\n","{'loss': 0.2996, 'learning_rate': 0.0009466666666666667, 'epoch': 16.0}\n","  5% 1600/30000 [34:43<6:39:50,  1.18it/s][INFO|trainer.py:3129] 2023-09-07 08:00:25,424 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3131] 2023-09-07 08:00:25,424 >>   Num examples = 9000\n","[INFO|trainer.py:3134] 2023-09-07 08:00:25,424 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.51it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.76it/s]\u001b[A\n"," 22% 4/18 [00:02<00:09,  1.51it/s]\u001b[A\n"," 28% 5/18 [00:03<00:09,  1.38it/s]\u001b[A\n"," 33% 6/18 [00:04<00:09,  1.33it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.26it/s]\u001b[A\n"," 44% 8/18 [00:05<00:08,  1.21it/s]\u001b[A\n"," 50% 9/18 [00:06<00:07,  1.17it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.20it/s]\u001b[A\n"," 61% 11/18 [00:08<00:05,  1.21it/s]\u001b[A\n"," 67% 12/18 [00:09<00:05,  1.18it/s]\u001b[A\n"," 72% 13/18 [00:10<00:04,  1.15it/s]\u001b[A\n"," 78% 14/18 [00:11<00:03,  1.15it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.13it/s]\u001b[A\n"," 89% 16/18 [00:12<00:01,  1.13it/s]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 0.04239954054355621, 'eval_accuracy': 0.9865555555555555, 'eval_runtime': 14.9622, 'eval_samples_per_second': 601.514, 'eval_steps_per_second': 1.203, 'epoch': 16.0}\n","  5% 1600/30000 [34:58<6:39:50,  1.18it/s]\n","100% 18/18 [00:13<00:00,  1.30it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2855] 2023-09-07 08:00:40,392 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-1600\n","[INFO|configuration_utils.py:460] 2023-09-07 08:00:40,398 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-1600/config.json\n","[INFO|modeling_utils.py:1978] 2023-09-07 08:00:40,508 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-1600/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 08:00:40,513 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-1600/preprocessor_config.json\n","[INFO|trainer.py:2942] 2023-09-07 08:00:40,734 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-1400] due to args.save_total_limit\n","{'loss': 0.2789, 'learning_rate': 0.0009463333333333334, 'epoch': 16.1}\n","{'loss': 0.2948, 'learning_rate': 0.000946, 'epoch': 16.2}\n","{'loss': 0.2941, 'learning_rate': 0.0009456666666666667, 'epoch': 16.3}\n","{'loss': 0.2953, 'learning_rate': 0.0009453333333333334, 'epoch': 16.4}\n","{'loss': 0.3088, 'learning_rate': 0.000945, 'epoch': 16.5}\n","{'loss': 0.3014, 'learning_rate': 0.0009446666666666667, 'epoch': 16.6}\n","{'loss': 0.2932, 'learning_rate': 0.0009443333333333334, 'epoch': 16.7}\n","{'loss': 0.2934, 'learning_rate': 0.000944, 'epoch': 16.8}\n","{'loss': 0.3029, 'learning_rate': 0.0009436666666666667, 'epoch': 16.9}\n","{'loss': 0.2926, 'learning_rate': 0.0009433333333333334, 'epoch': 17.0}\n","  6% 1700/30000 [36:54<6:34:23,  1.20it/s][INFO|trainer.py:3129] 2023-09-07 08:02:35,928 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3131] 2023-09-07 08:02:35,928 >>   Num examples = 9000\n","[INFO|trainer.py:3134] 2023-09-07 08:02:35,929 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.55it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.80it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.58it/s]\u001b[A\n"," 28% 5/18 [00:03<00:08,  1.46it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.39it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.35it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.33it/s]\u001b[A\n"," 50% 9/18 [00:06<00:06,  1.32it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.30it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.29it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.28it/s]\u001b[A\n"," 72% 13/18 [00:09<00:04,  1.22it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.20it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.18it/s]\u001b[A\n"," 89% 16/18 [00:12<00:01,  1.15it/s]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 0.04055854678153992, 'eval_accuracy': 0.9865555555555555, 'eval_runtime': 14.2187, 'eval_samples_per_second': 632.968, 'eval_steps_per_second': 1.266, 'epoch': 17.0}\n","  6% 1700/30000 [37:08<6:34:23,  1.20it/s]\n","100% 18/18 [00:12<00:00,  1.33it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2855] 2023-09-07 08:02:50,151 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-1700\n","[INFO|configuration_utils.py:460] 2023-09-07 08:02:50,156 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-1700/config.json\n","[INFO|modeling_utils.py:1978] 2023-09-07 08:02:50,269 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-1700/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 08:02:50,273 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-1700/preprocessor_config.json\n","[INFO|trainer.py:2942] 2023-09-07 08:02:50,509 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-1500] due to args.save_total_limit\n","{'loss': 0.296, 'learning_rate': 0.0009429999999999999, 'epoch': 17.1}\n","{'loss': 0.3158, 'learning_rate': 0.0009426666666666666, 'epoch': 17.2}\n","{'loss': 0.2826, 'learning_rate': 0.0009423333333333333, 'epoch': 17.3}\n","{'loss': 0.2827, 'learning_rate': 0.000942, 'epoch': 17.4}\n","{'loss': 0.311, 'learning_rate': 0.0009416666666666667, 'epoch': 17.5}\n","{'loss': 0.3028, 'learning_rate': 0.0009413333333333334, 'epoch': 17.6}\n","{'loss': 0.2789, 'learning_rate': 0.000941, 'epoch': 17.7}\n","{'loss': 0.3036, 'learning_rate': 0.0009406666666666667, 'epoch': 17.8}\n","{'loss': 0.2786, 'learning_rate': 0.0009403333333333334, 'epoch': 17.9}\n","{'loss': 0.2976, 'learning_rate': 0.00094, 'epoch': 18.0}\n","  6% 1800/30000 [39:04<6:34:07,  1.19it/s][INFO|trainer.py:3129] 2023-09-07 08:04:46,027 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3131] 2023-09-07 08:04:46,027 >>   Num examples = 9000\n","[INFO|trainer.py:3134] 2023-09-07 08:04:46,027 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.55it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.82it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.59it/s]\u001b[A\n"," 28% 5/18 [00:03<00:08,  1.46it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.40it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.36it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.34it/s]\u001b[A\n"," 50% 9/18 [00:06<00:06,  1.32it/s]\u001b[A\n"," 56% 10/18 [00:06<00:06,  1.31it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.29it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.21it/s]\u001b[A\n"," 72% 13/18 [00:09<00:04,  1.19it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.19it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.16it/s]\u001b[A\n"," 89% 16/18 [00:12<00:01,  1.19it/s]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 0.04254894331097603, 'eval_accuracy': 0.9863333333333333, 'eval_runtime': 14.187, 'eval_samples_per_second': 634.383, 'eval_steps_per_second': 1.269, 'epoch': 18.0}\n","  6% 1800/30000 [39:18<6:34:07,  1.19it/s]\n","100% 18/18 [00:12<00:00,  1.37it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2855] 2023-09-07 08:05:00,218 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-1800\n","[INFO|configuration_utils.py:460] 2023-09-07 08:05:00,223 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-1800/config.json\n","[INFO|modeling_utils.py:1978] 2023-09-07 08:05:00,335 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-1800/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 08:05:00,339 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-1800/preprocessor_config.json\n","[INFO|trainer.py:2942] 2023-09-07 08:05:00,563 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-1600] due to args.save_total_limit\n","{'loss': 0.2713, 'learning_rate': 0.0009396666666666667, 'epoch': 18.1}\n","{'loss': 0.2904, 'learning_rate': 0.0009393333333333334, 'epoch': 18.2}\n","{'loss': 0.2757, 'learning_rate': 0.000939, 'epoch': 18.3}\n","{'loss': 0.2782, 'learning_rate': 0.0009386666666666666, 'epoch': 18.4}\n","{'loss': 0.2875, 'learning_rate': 0.0009383333333333333, 'epoch': 18.5}\n","{'loss': 0.2847, 'learning_rate': 0.0009379999999999999, 'epoch': 18.6}\n","{'loss': 0.2804, 'learning_rate': 0.0009376666666666666, 'epoch': 18.7}\n","{'loss': 0.3096, 'learning_rate': 0.0009373333333333334, 'epoch': 18.8}\n","{'loss': 0.285, 'learning_rate': 0.0009370000000000001, 'epoch': 18.9}\n","{'loss': 0.295, 'learning_rate': 0.0009366666666666667, 'epoch': 19.0}\n","  6% 1900/30000 [41:13<6:24:49,  1.22it/s][INFO|trainer.py:3129] 2023-09-07 08:06:55,587 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3131] 2023-09-07 08:06:55,587 >>   Num examples = 9000\n","[INFO|trainer.py:3134] 2023-09-07 08:06:55,587 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.61it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.83it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.59it/s]\u001b[A\n"," 28% 5/18 [00:03<00:08,  1.47it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.40it/s]\u001b[A\n"," 39% 7/18 [00:04<00:09,  1.21it/s]\u001b[A\n"," 44% 8/18 [00:05<00:08,  1.21it/s]\u001b[A\n"," 50% 9/18 [00:06<00:07,  1.22it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.22it/s]\u001b[A\n"," 61% 11/18 [00:08<00:06,  1.14it/s]\u001b[A\n"," 67% 12/18 [00:09<00:05,  1.13it/s]\u001b[A\n"," 72% 13/18 [00:10<00:04,  1.12it/s]\u001b[A\n"," 78% 14/18 [00:11<00:03,  1.11it/s]\u001b[A\n"," 83% 15/18 [00:12<00:02,  1.11it/s]\u001b[A\n"," 89% 16/18 [00:12<00:01,  1.16it/s]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 0.06766296923160553, 'eval_accuracy': 0.9801111111111112, 'eval_runtime': 14.8893, 'eval_samples_per_second': 604.46, 'eval_steps_per_second': 1.209, 'epoch': 19.0}\n","  6% 1900/30000 [41:28<6:24:49,  1.22it/s]\n","100% 18/18 [00:13<00:00,  1.32it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2855] 2023-09-07 08:07:10,480 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-1900\n","[INFO|configuration_utils.py:460] 2023-09-07 08:07:10,486 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-1900/config.json\n","[INFO|modeling_utils.py:1978] 2023-09-07 08:07:10,602 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-1900/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 08:07:10,607 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-1900/preprocessor_config.json\n","[INFO|trainer.py:2942] 2023-09-07 08:07:10,840 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-1700] due to args.save_total_limit\n","{'loss': 0.2791, 'learning_rate': 0.0009363333333333334, 'epoch': 19.1}\n","{'loss': 0.2707, 'learning_rate': 0.0009360000000000001, 'epoch': 19.2}\n","{'loss': 0.2745, 'learning_rate': 0.0009356666666666667, 'epoch': 19.3}\n","{'loss': 0.2995, 'learning_rate': 0.0009353333333333334, 'epoch': 19.4}\n","{'loss': 0.2802, 'learning_rate': 0.0009350000000000001, 'epoch': 19.5}\n","{'loss': 0.2908, 'learning_rate': 0.0009346666666666667, 'epoch': 19.6}\n","{'loss': 0.3068, 'learning_rate': 0.0009343333333333333, 'epoch': 19.7}\n","{'loss': 0.2765, 'learning_rate': 0.000934, 'epoch': 19.8}\n","{'loss': 0.272, 'learning_rate': 0.0009336666666666666, 'epoch': 19.9}\n","{'loss': 0.2582, 'learning_rate': 0.0009333333333333333, 'epoch': 20.0}\n","  7% 2000/30000 [43:24<6:34:23,  1.18it/s][INFO|trainer.py:3129] 2023-09-07 08:09:06,142 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3131] 2023-09-07 08:09:06,143 >>   Num examples = 9000\n","[INFO|trainer.py:3134] 2023-09-07 08:09:06,143 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.52it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.77it/s]\u001b[A\n"," 22% 4/18 [00:02<00:09,  1.53it/s]\u001b[A\n"," 28% 5/18 [00:03<00:09,  1.43it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.37it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.34it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.32it/s]\u001b[A\n"," 50% 9/18 [00:06<00:06,  1.29it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.28it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.27it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.22it/s]\u001b[A\n"," 72% 13/18 [00:09<00:04,  1.19it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.17it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.18it/s]\u001b[A\n"," 89% 16/18 [00:12<00:01,  1.21it/s]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 3.029195547103882, 'eval_accuracy': 0.35844444444444445, 'eval_runtime': 14.324, 'eval_samples_per_second': 628.315, 'eval_steps_per_second': 1.257, 'epoch': 20.0}\n","  7% 2000/30000 [43:38<6:34:23,  1.18it/s]\n","100% 18/18 [00:12<00:00,  1.38it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2855] 2023-09-07 08:09:20,471 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-2000\n","[INFO|configuration_utils.py:460] 2023-09-07 08:09:20,477 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-2000/config.json\n","[INFO|modeling_utils.py:1978] 2023-09-07 08:09:20,588 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-2000/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 08:09:20,593 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-2000/preprocessor_config.json\n","[INFO|trainer.py:2942] 2023-09-07 08:09:20,831 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-1800] due to args.save_total_limit\n","{'loss': 0.2901, 'learning_rate': 0.000933, 'epoch': 20.1}\n","{'loss': 0.2993, 'learning_rate': 0.0009326666666666667, 'epoch': 20.2}\n","{'loss': 0.2934, 'learning_rate': 0.0009323333333333334, 'epoch': 20.3}\n","{'loss': 0.2639, 'learning_rate': 0.0009320000000000001, 'epoch': 20.4}\n","{'loss': 0.288, 'learning_rate': 0.0009316666666666667, 'epoch': 20.5}\n","{'loss': 0.272, 'learning_rate': 0.0009313333333333334, 'epoch': 20.6}\n","{'loss': 0.2833, 'learning_rate': 0.0009310000000000001, 'epoch': 20.7}\n","{'loss': 0.2987, 'learning_rate': 0.0009306666666666667, 'epoch': 20.8}\n","{'loss': 0.271, 'learning_rate': 0.0009303333333333334, 'epoch': 20.9}\n","{'loss': 0.2829, 'learning_rate': 0.00093, 'epoch': 21.0}\n","  7% 2100/30000 [45:34<6:32:38,  1.18it/s][INFO|trainer.py:3129] 2023-09-07 08:11:16,528 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3131] 2023-09-07 08:11:16,529 >>   Num examples = 9000\n","[INFO|trainer.py:3134] 2023-09-07 08:11:16,529 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.53it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.76it/s]\u001b[A\n"," 22% 4/18 [00:02<00:09,  1.52it/s]\u001b[A\n"," 28% 5/18 [00:03<00:09,  1.42it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.37it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.33it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.31it/s]\u001b[A\n"," 50% 9/18 [00:06<00:06,  1.30it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.27it/s]\u001b[A\n"," 61% 11/18 [00:08<00:05,  1.19it/s]\u001b[A\n"," 67% 12/18 [00:08<00:05,  1.19it/s]\u001b[A\n"," 72% 13/18 [00:09<00:04,  1.17it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.16it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.18it/s]\u001b[A\n"," 89% 16/18 [00:12<00:01,  1.21it/s]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 0.03646218776702881, 'eval_accuracy': 0.9876666666666667, 'eval_runtime': 14.4415, 'eval_samples_per_second': 623.206, 'eval_steps_per_second': 1.246, 'epoch': 21.0}\n","  7% 2100/30000 [45:49<6:32:38,  1.18it/s]\n","100% 18/18 [00:12<00:00,  1.38it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2855] 2023-09-07 08:11:30,976 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-2100\n","[INFO|configuration_utils.py:460] 2023-09-07 08:11:30,982 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-2100/config.json\n","[INFO|modeling_utils.py:1978] 2023-09-07 08:11:31,104 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-2100/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 08:11:31,108 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-2100/preprocessor_config.json\n","[INFO|trainer.py:2942] 2023-09-07 08:11:31,336 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-1900] due to args.save_total_limit\n","{'loss': 0.2677, 'learning_rate': 0.0009296666666666666, 'epoch': 21.1}\n","{'loss': 0.2874, 'learning_rate': 0.0009293333333333333, 'epoch': 21.2}\n","{'loss': 0.2733, 'learning_rate': 0.000929, 'epoch': 21.3}\n","{'loss': 0.2728, 'learning_rate': 0.0009286666666666666, 'epoch': 21.4}\n","{'loss': 0.2823, 'learning_rate': 0.0009283333333333333, 'epoch': 21.5}\n","{'loss': 0.2636, 'learning_rate': 0.0009280000000000001, 'epoch': 21.6}\n","{'loss': 0.2797, 'learning_rate': 0.0009276666666666667, 'epoch': 21.7}\n","{'loss': 0.2654, 'learning_rate': 0.0009273333333333334, 'epoch': 21.8}\n","{'loss': 0.3067, 'learning_rate': 0.0009270000000000001, 'epoch': 21.9}\n","{'loss': 0.3008, 'learning_rate': 0.0009266666666666667, 'epoch': 22.0}\n","  7% 2200/30000 [47:46<6:19:56,  1.22it/s][INFO|trainer.py:3129] 2023-09-07 08:13:28,368 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3131] 2023-09-07 08:13:28,369 >>   Num examples = 9000\n","[INFO|trainer.py:3134] 2023-09-07 08:13:28,369 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.60it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.83it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.57it/s]\u001b[A\n"," 28% 5/18 [00:03<00:08,  1.45it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.38it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.34it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.31it/s]\u001b[A\n"," 50% 9/18 [00:06<00:07,  1.27it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.24it/s]\u001b[A\n"," 61% 11/18 [00:08<00:05,  1.22it/s]\u001b[A\n"," 67% 12/18 [00:08<00:05,  1.19it/s]\u001b[A\n"," 72% 13/18 [00:09<00:04,  1.17it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.20it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.22it/s]\u001b[A\n"," 89% 16/18 [00:12<00:01,  1.23it/s]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 1.014068365097046, 'eval_accuracy': 0.6481111111111111, 'eval_runtime': 14.2479, 'eval_samples_per_second': 631.67, 'eval_steps_per_second': 1.263, 'epoch': 22.0}\n","  7% 2200/30000 [48:00<6:19:56,  1.22it/s]\n","100% 18/18 [00:12<00:00,  1.40it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2855] 2023-09-07 08:13:42,622 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-2200\n","[INFO|configuration_utils.py:460] 2023-09-07 08:13:42,627 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-2200/config.json\n","[INFO|modeling_utils.py:1978] 2023-09-07 08:13:42,739 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-2200/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 08:13:42,744 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-2200/preprocessor_config.json\n","[INFO|trainer.py:2942] 2023-09-07 08:13:42,974 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-2000] due to args.save_total_limit\n","{'loss': 0.2734, 'learning_rate': 0.0009263333333333334, 'epoch': 22.1}\n","{'loss': 0.2704, 'learning_rate': 0.0009260000000000001, 'epoch': 22.2}\n","{'loss': 0.2904, 'learning_rate': 0.0009256666666666667, 'epoch': 22.3}\n","{'loss': 0.2828, 'learning_rate': 0.0009253333333333333, 'epoch': 22.4}\n","{'loss': 0.2656, 'learning_rate': 0.000925, 'epoch': 22.5}\n","{'loss': 0.2899, 'learning_rate': 0.0009246666666666666, 'epoch': 22.6}\n","{'loss': 0.2666, 'learning_rate': 0.0009243333333333333, 'epoch': 22.7}\n","{'loss': 0.2877, 'learning_rate': 0.000924, 'epoch': 22.8}\n","{'loss': 0.2633, 'learning_rate': 0.0009236666666666666, 'epoch': 22.9}\n","{'loss': 0.2853, 'learning_rate': 0.0009233333333333334, 'epoch': 23.0}\n","  8% 2300/30000 [49:56<6:19:40,  1.22it/s][INFO|trainer.py:3129] 2023-09-07 08:15:38,627 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3131] 2023-09-07 08:15:38,627 >>   Num examples = 9000\n","[INFO|trainer.py:3134] 2023-09-07 08:15:38,628 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.59it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.78it/s]\u001b[A\n"," 22% 4/18 [00:02<00:09,  1.52it/s]\u001b[A\n"," 28% 5/18 [00:03<00:09,  1.41it/s]\u001b[A\n"," 33% 6/18 [00:04<00:08,  1.35it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.31it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.30it/s]\u001b[A\n"," 50% 9/18 [00:06<00:07,  1.26it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.22it/s]\u001b[A\n"," 61% 11/18 [00:08<00:05,  1.21it/s]\u001b[A\n"," 67% 12/18 [00:09<00:05,  1.18it/s]\u001b[A\n"," 72% 13/18 [00:09<00:04,  1.17it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.15it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.18it/s]\u001b[A\n"," 89% 16/18 [00:12<00:01,  1.21it/s]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 0.039410971105098724, 'eval_accuracy': 0.9886666666666667, 'eval_runtime': 14.4864, 'eval_samples_per_second': 621.273, 'eval_steps_per_second': 1.243, 'epoch': 23.0}\n","  8% 2300/30000 [50:11<6:19:40,  1.22it/s]\n","100% 18/18 [00:13<00:00,  1.38it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2855] 2023-09-07 08:15:53,118 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-2300\n","[INFO|configuration_utils.py:460] 2023-09-07 08:15:53,124 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-2300/config.json\n","[INFO|modeling_utils.py:1978] 2023-09-07 08:15:53,248 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-2300/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 08:15:53,254 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-2300/preprocessor_config.json\n","[INFO|trainer.py:2942] 2023-09-07 08:15:53,497 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-2100] due to args.save_total_limit\n","[INFO|trainer.py:1963] 2023-09-07 08:15:53,514 >> \n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","[INFO|trainer.py:2125] 2023-09-07 08:15:53,514 >> Loading best model from drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/checkpoint-1300 (score: 0.0364195741713047).\n","{'train_runtime': 3011.7137, 'train_samples_per_second': 5080.164, 'train_steps_per_second': 9.961, 'train_loss': 0.32650035692297896, 'epoch': 23.0}\n","  8% 2300/30000 [50:11<10:04:31,  1.31s/it]\n","[INFO|trainer.py:2855] 2023-09-07 08:15:53,581 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/\n","[INFO|configuration_utils.py:460] 2023-09-07 08:15:53,586 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/config.json\n","[INFO|modeling_utils.py:1978] 2023-09-07 08:15:53,704 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 08:15:53,708 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/preprocessor_config.json\n","***** train metrics *****\n","  epoch                    =       23.0\n","  train_loss               =     0.3265\n","  train_runtime            = 0:50:11.71\n","  train_samples_per_second =   5080.164\n","  train_steps_per_second   =      9.961\n","[INFO|trainer.py:3129] 2023-09-07 08:15:53,729 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3131] 2023-09-07 08:15:53,729 >>   Num examples = 9000\n","[INFO|trainer.py:3134] 2023-09-07 08:15:53,729 >>   Batch size = 512\n","100% 18/18 [00:13<00:00,  1.36it/s]\n","***** eval metrics *****\n","  epoch                   =       23.0\n","  eval_accuracy           =     0.9882\n","  eval_loss               =     0.0364\n","  eval_runtime            = 0:00:14.64\n","  eval_samples_per_second =    614.635\n","  eval_steps_per_second   =      1.229\n","\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n","\u001b[34m\u001b[1mwandb\u001b[0m:                  eval/accuracy ▄██████████████████▁█▄██\n","\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/loss ▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▃▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/runtime ▆▄▄▃▃▃▂▆▁▁▄▄▃▄▅█▂▁▇▃▄▂▄▅\n","\u001b[34m\u001b[1mwandb\u001b[0m:        eval/samples_per_second ▃▅▅▆▆▆▇▃██▅▅▆▅▄▁▇█▂▆▅▇▅▄\n","\u001b[34m\u001b[1mwandb\u001b[0m:          eval/steps_per_second ▃▅▅▆▆▆▇▃██▅▅▆▅▄▁▇█▂▆▅▇▅▄\n","\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\n","\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\n","\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate ████▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss █▅▅▄▃▃▃▃▂▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▂▂▂▂▂▁▁▂▁▁▂\n","\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n","\u001b[34m\u001b[1mwandb\u001b[0m:                  eval/accuracy 0.98822\n","\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/loss 0.03642\n","\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/runtime 14.6428\n","\u001b[34m\u001b[1mwandb\u001b[0m:        eval/samples_per_second 614.635\n","\u001b[34m\u001b[1mwandb\u001b[0m:          eval/steps_per_second 1.229\n","\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch 23.0\n","\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step 2300\n","\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate 0.00092\n","\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss 0.2853\n","\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos 1.1846011156697088e+19\n","\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss 0.3265\n","\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime 3011.7137\n","\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second 5080.164\n","\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second 9.961\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mexalted-frog-9\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/u15048366/colabCnnMnist/runs/9r6qcixl\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n","\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230907_072536-9r6qcixl/logs\u001b[0m\n"]}],"source":["!python cnn-mnist.py \\\n","    --model_name microsoft/resnet-18 \\\n","    --model_type resnet \\\n","    --dataset_name mnist \\\n","    --output_dir drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_3/ \\\n","    --remove_unused_columns False \\\n","    --do_train \\\n","    --do_eval \\\n","    --push_to_hub False \\\n","    --learning_rate 0.001 \\\n","    --num_train_epochs 300 \\\n","    --per_device_train_batch_size 512 \\\n","    --per_device_eval_batch_size 512 \\\n","    --logging_strategy steps \\\n","    --logging_steps 10 \\\n","    --evaluation_strategy epoch \\\n","    --save_strategy epoch \\\n","    --load_best_model_at_end True \\\n","    --save_total_limit 3 \\\n","    --save_steps 500 \\\n","    --data_seed 3 \\\n","    --seed 3 \\\n","    --report_to wandb \\\n","    --ignore_mismatched_sizes\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"lGabtHrcFOTk","outputId":"3a9d1279-5586-48a1-b5f3-21b981d95cbf"},"outputs":[{"name":"stdout","output_type":"stream","text":["2023-09-07 08:16:21.095751: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mu15048366\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.10\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20230907_081624-76tjbjfh\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mexalted-glitter-10\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/u15048366/colabCnnMnist\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/u15048366/colabCnnMnist/runs/76tjbjfh\u001b[0m\n","09/07/2023 08:16:25 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n","09/07/2023 08:16:25 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n","_n_gpu=1,\n","adafactor=False,\n","adam_beta1=0.9,\n","adam_beta2=0.999,\n","adam_epsilon=1e-08,\n","auto_find_batch_size=False,\n","bf16=False,\n","bf16_full_eval=False,\n","data_seed=4,\n","dataloader_drop_last=False,\n","dataloader_num_workers=0,\n","dataloader_pin_memory=True,\n","ddp_backend=None,\n","ddp_broadcast_buffers=None,\n","ddp_bucket_cap_mb=None,\n","ddp_find_unused_parameters=None,\n","ddp_timeout=1800,\n","debug=[],\n","deepspeed=None,\n","disable_tqdm=False,\n","dispatch_batches=None,\n","do_eval=True,\n","do_predict=False,\n","do_train=True,\n","eval_accumulation_steps=None,\n","eval_delay=0,\n","eval_steps=None,\n","evaluation_strategy=epoch,\n","fp16=False,\n","fp16_backend=auto,\n","fp16_full_eval=False,\n","fp16_opt_level=O1,\n","fsdp=[],\n","fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n","fsdp_min_num_params=0,\n","fsdp_transformer_layer_cls_to_wrap=None,\n","full_determinism=False,\n","gradient_accumulation_steps=1,\n","gradient_checkpointing=False,\n","greater_is_better=False,\n","group_by_length=False,\n","half_precision_backend=auto,\n","hub_always_push=False,\n","hub_model_id=None,\n","hub_private_repo=False,\n","hub_strategy=every_save,\n","hub_token=<HUB_TOKEN>,\n","ignore_data_skip=False,\n","include_inputs_for_metrics=False,\n","jit_mode_eval=False,\n","label_names=None,\n","label_smoothing_factor=0.0,\n","learning_rate=0.001,\n","length_column_name=length,\n","load_best_model_at_end=True,\n","local_rank=0,\n","log_level=passive,\n","log_level_replica=warning,\n","log_on_each_node=True,\n","logging_dir=drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/runs/Sep07_08-16-25_76fe2c15e2a8,\n","logging_first_step=False,\n","logging_nan_inf_filter=True,\n","logging_steps=10,\n","logging_strategy=steps,\n","lr_scheduler_type=linear,\n","max_grad_norm=1.0,\n","max_steps=-1,\n","metric_for_best_model=loss,\n","mp_parameters=,\n","no_cuda=False,\n","num_train_epochs=300.0,\n","optim=adamw_torch,\n","optim_args=None,\n","output_dir=drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/,\n","overwrite_output_dir=False,\n","past_index=-1,\n","per_device_eval_batch_size=512,\n","per_device_train_batch_size=512,\n","prediction_loss_only=False,\n","push_to_hub=False,\n","push_to_hub_model_id=None,\n","push_to_hub_organization=None,\n","push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n","ray_scope=last,\n","remove_unused_columns=False,\n","report_to=['wandb'],\n","resume_from_checkpoint=None,\n","run_name=drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/,\n","save_on_each_node=False,\n","save_safetensors=False,\n","save_steps=500.0,\n","save_strategy=epoch,\n","save_total_limit=3,\n","seed=4,\n","sharded_ddp=[],\n","skip_memory_metrics=True,\n","tf32=None,\n","torch_compile=False,\n","torch_compile_backend=None,\n","torch_compile_mode=None,\n","torchdynamo=None,\n","tpu_metrics_debug=False,\n","tpu_num_cores=None,\n","use_cpu=False,\n","use_ipex=False,\n","use_legacy_prediction_loop=False,\n","use_mps_device=False,\n","warmup_ratio=0.0,\n","warmup_steps=0,\n","weight_decay=0.0,\n",")\n","/usr/local/lib/python3.10/dist-packages/datasets/load.py:2103: FutureWarning: 'task' was deprecated in version 2.13.0 and will be removed in 3.0.0.\n","\n","  warnings.warn(\n","\n","\n","\n","None\n","\n","\n","\n","[INFO|configuration_utils.py:715] 2023-09-07 08:16:27,302 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--resnet-18/snapshots/f45a6faa12e0381f5620c5c8d7e916bca90f2c44/config.json\n","[INFO|configuration_utils.py:775] 2023-09-07 08:16:27,303 >> Model config ResNetConfig {\n","  \"_name_or_path\": \"microsoft/resnet-18\",\n","  \"architectures\": [\n","    \"ResNetForImageClassification\"\n","  ],\n","  \"depths\": [\n","    2,\n","    2,\n","    2,\n","    2\n","  ],\n","  \"downsample_in_first_stage\": false,\n","  \"embedding_size\": 64,\n","  \"finetuning_task\": \"image-classification\",\n","  \"hidden_act\": \"relu\",\n","  \"hidden_sizes\": [\n","    64,\n","    128,\n","    256,\n","    512\n","  ],\n","  \"id2label\": {\n","    \"0\": \"0\",\n","    \"1\": \"1\",\n","    \"2\": \"2\",\n","    \"3\": \"3\",\n","    \"4\": \"4\",\n","    \"5\": \"5\",\n","    \"6\": \"6\",\n","    \"7\": \"7\",\n","    \"8\": \"8\",\n","    \"9\": \"9\"\n","  },\n","  \"label2id\": {\n","    \"0\": \"0\",\n","    \"1\": \"1\",\n","    \"2\": \"2\",\n","    \"3\": \"3\",\n","    \"4\": \"4\",\n","    \"5\": \"5\",\n","    \"6\": \"6\",\n","    \"7\": \"7\",\n","    \"8\": \"8\",\n","    \"9\": \"9\"\n","  },\n","  \"layer_type\": \"basic\",\n","  \"model_type\": \"resnet\",\n","  \"num_channels\": 3,\n","  \"out_features\": [\n","    \"stage4\"\n","  ],\n","  \"out_indices\": [\n","    4\n","  ],\n","  \"stage_names\": [\n","    \"stem\",\n","    \"stage1\",\n","    \"stage2\",\n","    \"stage3\",\n","    \"stage4\"\n","  ],\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.34.0.dev0\"\n","}\n","\n","[INFO|modeling_utils.py:2847] 2023-09-07 08:16:27,306 >> loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--microsoft--resnet-18/snapshots/f45a6faa12e0381f5620c5c8d7e916bca90f2c44/model.safetensors\n","[INFO|modeling_utils.py:3633] 2023-09-07 08:16:27,426 >> All model checkpoint weights were used when initializing ResNetForImageClassification.\n","\n","[WARNING|modeling_utils.py:3654] 2023-09-07 08:16:27,426 >> Some weights of ResNetForImageClassification were not initialized from the model checkpoint at microsoft/resnet-18 and are newly initialized because the shapes did not match:\n","- classifier.1.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([10]) in the model instantiated\n","- classifier.1.weight: found shape torch.Size([1000, 512]) in the checkpoint and torch.Size([10, 512]) in the model instantiated\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","[INFO|image_processing_utils.py:369] 2023-09-07 08:16:27,531 >> loading configuration file preprocessor_config.json from cache at /root/.cache/huggingface/hub/models--microsoft--resnet-18/snapshots/f45a6faa12e0381f5620c5c8d7e916bca90f2c44/preprocessor_config.json\n","[WARNING|image_processing_auto.py:355] 2023-09-07 08:16:27,531 >> Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n","[INFO|image_processing_utils.py:732] 2023-09-07 08:16:27,533 >> size should be a dictionary on of the following set of keys: ({'width', 'height'}, {'shortest_edge'}, {'shortest_edge', 'longest_edge'}, {'longest_edge'}), got 224. Converted to {'shortest_edge': 224}.\n","[INFO|image_processing_utils.py:419] 2023-09-07 08:16:27,533 >> Image processor ConvNextImageProcessor {\n","  \"crop_pct\": 0.875,\n","  \"do_normalize\": true,\n","  \"do_rescale\": true,\n","  \"do_resize\": true,\n","  \"image_mean\": [\n","    0.485,\n","    0.456,\n","    0.406\n","  ],\n","  \"image_processor_type\": \"ConvNextImageProcessor\",\n","  \"image_std\": [\n","    0.229,\n","    0.224,\n","    0.225\n","  ],\n","  \"resample\": 3,\n","  \"rescale_factor\": 0.00392156862745098,\n","  \"size\": {\n","    \"shortest_edge\": 224\n","  }\n","}\n","\n","[INFO|trainer.py:1715] 2023-09-07 08:16:29,497 >> ***** Running training *****\n","[INFO|trainer.py:1716] 2023-09-07 08:16:29,498 >>   Num examples = 51,000\n","[INFO|trainer.py:1717] 2023-09-07 08:16:29,498 >>   Num Epochs = 300\n","[INFO|trainer.py:1718] 2023-09-07 08:16:29,498 >>   Instantaneous batch size per device = 512\n","[INFO|trainer.py:1721] 2023-09-07 08:16:29,498 >>   Total train batch size (w. parallel, distributed & accumulation) = 512\n","[INFO|trainer.py:1722] 2023-09-07 08:16:29,498 >>   Gradient Accumulation steps = 1\n","[INFO|trainer.py:1723] 2023-09-07 08:16:29,499 >>   Total optimization steps = 30,000\n","[INFO|trainer.py:1724] 2023-09-07 08:16:29,499 >>   Number of trainable parameters = 11,181,642\n","[INFO|integration_utils.py:716] 2023-09-07 08:16:29,500 >> Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n","{'loss': 1.1625, 'learning_rate': 0.0009996666666666667, 'epoch': 0.1}\n","{'loss': 0.6075, 'learning_rate': 0.0009993333333333334, 'epoch': 0.2}\n","{'loss': 0.5594, 'learning_rate': 0.000999, 'epoch': 0.3}\n","{'loss': 0.4792, 'learning_rate': 0.0009986666666666668, 'epoch': 0.4}\n","{'loss': 0.4977, 'learning_rate': 0.0009983333333333333, 'epoch': 0.5}\n","{'loss': 0.4421, 'learning_rate': 0.000998, 'epoch': 0.6}\n","{'loss': 0.4511, 'learning_rate': 0.0009976666666666667, 'epoch': 0.7}\n","{'loss': 0.4319, 'learning_rate': 0.0009973333333333334, 'epoch': 0.8}\n","{'loss': 0.4372, 'learning_rate': 0.000997, 'epoch': 0.9}\n","{'loss': 0.4316, 'learning_rate': 0.0009966666666666668, 'epoch': 1.0}\n","  0% 100/30000 [01:58<6:46:02,  1.23it/s][INFO|trainer.py:3129] 2023-09-07 08:18:27,706 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3131] 2023-09-07 08:18:27,706 >>   Num examples = 9000\n","[INFO|trainer.py:3134] 2023-09-07 08:18:27,706 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:07,  2.22it/s]\u001b[A\n"," 17% 3/18 [00:01<00:09,  1.61it/s]\u001b[A\n"," 22% 4/18 [00:02<00:09,  1.46it/s]\u001b[A\n"," 28% 5/18 [00:03<00:09,  1.40it/s]\u001b[A\n"," 33% 6/18 [00:04<00:08,  1.35it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.32it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.30it/s]\u001b[A\n"," 50% 9/18 [00:06<00:06,  1.29it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.28it/s]\u001b[A\n"," 61% 11/18 [00:08<00:05,  1.28it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.27it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.26it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.26it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.25it/s]\u001b[A\n"," 89% 16/18 [00:12<00:01,  1.23it/s]\u001b[A\n","                                         \n","\u001b[A{'eval_loss': 0.17716601490974426, 'eval_accuracy': 0.9456666666666667, 'eval_runtime': 14.3956, 'eval_samples_per_second': 625.192, 'eval_steps_per_second': 1.25, 'epoch': 1.0}\n","  0% 100/30000 [02:12<6:46:02,  1.23it/s]\n","100% 18/18 [00:12<00:00,  1.39it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2855] 2023-09-07 08:18:42,107 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-100\n","[INFO|configuration_utils.py:460] 2023-09-07 08:18:42,114 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-100/config.json\n","[INFO|modeling_utils.py:1978] 2023-09-07 08:18:42,238 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-100/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 08:18:42,243 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-100/preprocessor_config.json\n","{'loss': 0.4437, 'learning_rate': 0.0009963333333333332, 'epoch': 1.1}\n","{'loss': 0.4651, 'learning_rate': 0.000996, 'epoch': 1.2}\n","{'loss': 0.4255, 'learning_rate': 0.0009956666666666666, 'epoch': 1.3}\n","{'loss': 0.4029, 'learning_rate': 0.0009953333333333333, 'epoch': 1.4}\n","{'loss': 0.4256, 'learning_rate': 0.000995, 'epoch': 1.5}\n","{'loss': 0.4196, 'learning_rate': 0.0009946666666666667, 'epoch': 1.6}\n","{'loss': 0.4092, 'learning_rate': 0.0009943333333333334, 'epoch': 1.7}\n","{'loss': 0.4062, 'learning_rate': 0.000994, 'epoch': 1.8}\n","{'loss': 0.399, 'learning_rate': 0.0009936666666666668, 'epoch': 1.9}\n","{'loss': 0.3694, 'learning_rate': 0.0009933333333333333, 'epoch': 2.0}\n","  1% 200/30000 [04:09<6:50:06,  1.21it/s][INFO|trainer.py:3129] 2023-09-07 08:20:38,765 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3131] 2023-09-07 08:20:38,765 >>   Num examples = 9000\n","[INFO|trainer.py:3134] 2023-09-07 08:20:38,765 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:07,  2.20it/s]\u001b[A\n"," 17% 3/18 [00:01<00:09,  1.66it/s]\u001b[A\n"," 22% 4/18 [00:02<00:09,  1.47it/s]\u001b[A\n"," 28% 5/18 [00:03<00:10,  1.23it/s]\u001b[A\n"," 33% 6/18 [00:04<00:09,  1.25it/s]\u001b[A\n"," 39% 7/18 [00:05<00:08,  1.25it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.26it/s]\u001b[A\n"," 50% 9/18 [00:06<00:07,  1.27it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.28it/s]\u001b[A\n"," 61% 11/18 [00:08<00:05,  1.28it/s]\u001b[A\n"," 67% 12/18 [00:09<00:04,  1.27it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.26it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.27it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.25it/s]\u001b[A\n"," 89% 16/18 [00:12<00:01,  1.23it/s]\u001b[A\n","                                         \n","\u001b[A{'eval_loss': 0.06668850034475327, 'eval_accuracy': 0.9788888888888889, 'eval_runtime': 14.6034, 'eval_samples_per_second': 616.293, 'eval_steps_per_second': 1.233, 'epoch': 2.0}\n","  1% 200/30000 [04:23<6:50:06,  1.21it/s]\n","100% 18/18 [00:12<00:00,  1.39it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2855] 2023-09-07 08:20:53,373 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-200\n","[INFO|configuration_utils.py:460] 2023-09-07 08:20:53,380 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-200/config.json\n","[INFO|modeling_utils.py:1978] 2023-09-07 08:20:53,499 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-200/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 08:20:53,504 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-200/preprocessor_config.json\n","{'loss': 0.375, 'learning_rate': 0.000993, 'epoch': 2.1}\n","{'loss': 0.3677, 'learning_rate': 0.0009926666666666667, 'epoch': 2.2}\n","{'loss': 0.4126, 'learning_rate': 0.0009923333333333333, 'epoch': 2.3}\n","{'loss': 0.3953, 'learning_rate': 0.000992, 'epoch': 2.4}\n","{'loss': 0.3841, 'learning_rate': 0.0009916666666666667, 'epoch': 2.5}\n","{'loss': 0.3898, 'learning_rate': 0.0009913333333333332, 'epoch': 2.6}\n","{'loss': 0.3808, 'learning_rate': 0.000991, 'epoch': 2.7}\n","{'loss': 0.378, 'learning_rate': 0.0009906666666666668, 'epoch': 2.8}\n","{'loss': 0.3759, 'learning_rate': 0.0009903333333333333, 'epoch': 2.9}\n","{'loss': 0.3719, 'learning_rate': 0.00099, 'epoch': 3.0}\n","  1% 300/30000 [06:21<6:57:02,  1.19it/s][INFO|trainer.py:3129] 2023-09-07 08:22:50,519 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3131] 2023-09-07 08:22:50,519 >>   Num examples = 9000\n","[INFO|trainer.py:3134] 2023-09-07 08:22:50,519 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.48it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.76it/s]\u001b[A\n"," 22% 4/18 [00:02<00:09,  1.52it/s]\u001b[A\n"," 28% 5/18 [00:03<00:09,  1.42it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.36it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.33it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.31it/s]\u001b[A\n"," 50% 9/18 [00:06<00:06,  1.29it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.27it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.27it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.27it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.27it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.23it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.22it/s]\u001b[A\n"," 89% 16/18 [00:12<00:01,  1.21it/s]\u001b[A\n","                                         \n","\u001b[A{'eval_loss': 0.3639414310455322, 'eval_accuracy': 0.8558888888888889, 'eval_runtime': 14.4112, 'eval_samples_per_second': 624.516, 'eval_steps_per_second': 1.249, 'epoch': 3.0}\n","  1% 300/30000 [06:35<6:57:02,  1.19it/s]\n","100% 18/18 [00:12<00:00,  1.36it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2855] 2023-09-07 08:23:04,935 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-300\n","[INFO|configuration_utils.py:460] 2023-09-07 08:23:04,941 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-300/config.json\n","[INFO|modeling_utils.py:1978] 2023-09-07 08:23:05,058 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-300/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 08:23:05,062 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-300/preprocessor_config.json\n","{'loss': 0.377, 'learning_rate': 0.0009896666666666667, 'epoch': 3.1}\n","{'loss': 0.3852, 'learning_rate': 0.0009893333333333334, 'epoch': 3.2}\n","{'loss': 0.39, 'learning_rate': 0.000989, 'epoch': 3.3}\n","{'loss': 0.3647, 'learning_rate': 0.0009886666666666668, 'epoch': 3.4}\n","{'loss': 0.3548, 'learning_rate': 0.0009883333333333333, 'epoch': 3.5}\n","{'loss': 0.3649, 'learning_rate': 0.000988, 'epoch': 3.6}\n","{'loss': 0.361, 'learning_rate': 0.0009876666666666666, 'epoch': 3.7}\n","{'loss': 0.3539, 'learning_rate': 0.0009873333333333333, 'epoch': 3.8}\n","{'loss': 0.3525, 'learning_rate': 0.000987, 'epoch': 3.9}\n","{'loss': 0.3682, 'learning_rate': 0.0009866666666666667, 'epoch': 4.0}\n","  1% 400/30000 [08:31<6:37:15,  1.24it/s][INFO|trainer.py:3129] 2023-09-07 08:25:00,563 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3131] 2023-09-07 08:25:00,564 >>   Num examples = 9000\n","[INFO|trainer.py:3134] 2023-09-07 08:25:00,564 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:07,  2.12it/s]\u001b[A\n"," 17% 3/18 [00:01<00:09,  1.51it/s]\u001b[A\n"," 22% 4/18 [00:02<00:10,  1.34it/s]\u001b[A\n"," 28% 5/18 [00:03<00:10,  1.24it/s]\u001b[A\n"," 33% 6/18 [00:04<00:09,  1.21it/s]\u001b[A\n"," 39% 7/18 [00:05<00:08,  1.22it/s]\u001b[A\n"," 44% 8/18 [00:06<00:08,  1.24it/s]\u001b[A\n"," 50% 9/18 [00:06<00:07,  1.25it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.25it/s]\u001b[A\n"," 61% 11/18 [00:08<00:05,  1.24it/s]\u001b[A\n"," 67% 12/18 [00:09<00:04,  1.24it/s]\u001b[A\n"," 72% 13/18 [00:10<00:04,  1.24it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.24it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.21it/s]\u001b[A\n"," 89% 16/18 [00:12<00:01,  1.17it/s]\u001b[A\n","                                         \n","\u001b[A{'eval_loss': 0.36483991146087646, 'eval_accuracy': 0.8654444444444445, 'eval_runtime': 15.1043, 'eval_samples_per_second': 595.858, 'eval_steps_per_second': 1.192, 'epoch': 4.0}\n","  1% 400/30000 [08:46<6:37:15,  1.24it/s]\n","100% 18/18 [00:13<00:00,  1.32it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2855] 2023-09-07 08:25:15,673 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-400\n","[INFO|configuration_utils.py:460] 2023-09-07 08:25:15,679 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-400/config.json\n","[INFO|modeling_utils.py:1978] 2023-09-07 08:25:15,797 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-400/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 08:25:15,802 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-400/preprocessor_config.json\n","[INFO|trainer.py:2942] 2023-09-07 08:25:16,036 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-100] due to args.save_total_limit\n","{'loss': 0.3291, 'learning_rate': 0.0009863333333333332, 'epoch': 4.1}\n","{'loss': 0.3572, 'learning_rate': 0.0009860000000000001, 'epoch': 4.2}\n","{'loss': 0.362, 'learning_rate': 0.0009856666666666668, 'epoch': 4.3}\n","{'loss': 0.3406, 'learning_rate': 0.0009853333333333333, 'epoch': 4.4}\n","{'loss': 0.353, 'learning_rate': 0.000985, 'epoch': 4.5}\n","{'loss': 0.3778, 'learning_rate': 0.0009846666666666667, 'epoch': 4.6}\n","{'loss': 0.3591, 'learning_rate': 0.0009843333333333334, 'epoch': 4.7}\n","{'loss': 0.3567, 'learning_rate': 0.000984, 'epoch': 4.8}\n","{'loss': 0.3379, 'learning_rate': 0.0009836666666666668, 'epoch': 4.9}\n","{'loss': 0.3321, 'learning_rate': 0.0009833333333333332, 'epoch': 5.0}\n","  2% 500/30000 [10:42<6:57:45,  1.18it/s][INFO|trainer.py:3129] 2023-09-07 08:27:11,936 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3131] 2023-09-07 08:27:11,936 >>   Num examples = 9000\n","[INFO|trainer.py:3134] 2023-09-07 08:27:11,936 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.53it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.79it/s]\u001b[A\n"," 22% 4/18 [00:02<00:09,  1.55it/s]\u001b[A\n"," 28% 5/18 [00:03<00:09,  1.44it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.36it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.31it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.29it/s]\u001b[A\n"," 50% 9/18 [00:06<00:07,  1.28it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.26it/s]\u001b[A\n"," 61% 11/18 [00:08<00:06,  1.14it/s]\u001b[A\n"," 67% 12/18 [00:09<00:05,  1.17it/s]\u001b[A\n"," 72% 13/18 [00:10<00:04,  1.10it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.12it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.12it/s]\u001b[A\n"," 89% 16/18 [00:12<00:01,  1.12it/s]\u001b[A\n","                                         \n","\u001b[A{'eval_loss': 0.05481456592679024, 'eval_accuracy': 0.9833333333333333, 'eval_runtime': 14.9638, 'eval_samples_per_second': 601.451, 'eval_steps_per_second': 1.203, 'epoch': 5.0}\n","  2% 500/30000 [10:57<6:57:45,  1.18it/s]\n","100% 18/18 [00:13<00:00,  1.27it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2855] 2023-09-07 08:27:26,904 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-500\n","[INFO|configuration_utils.py:460] 2023-09-07 08:27:26,910 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-500/config.json\n","[INFO|modeling_utils.py:1978] 2023-09-07 08:27:27,030 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-500/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 08:27:27,035 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-500/preprocessor_config.json\n","[INFO|trainer.py:2942] 2023-09-07 08:27:27,266 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-200] due to args.save_total_limit\n","{'loss': 0.3418, 'learning_rate': 0.000983, 'epoch': 5.1}\n","{'loss': 0.33, 'learning_rate': 0.0009826666666666666, 'epoch': 5.2}\n","{'loss': 0.3252, 'learning_rate': 0.0009823333333333333, 'epoch': 5.3}\n","{'loss': 0.3416, 'learning_rate': 0.000982, 'epoch': 5.4}\n","{'loss': 0.3505, 'learning_rate': 0.0009816666666666667, 'epoch': 5.5}\n","{'loss': 0.3737, 'learning_rate': 0.0009813333333333334, 'epoch': 5.6}\n","{'loss': 0.3507, 'learning_rate': 0.000981, 'epoch': 5.7}\n","{'loss': 0.3411, 'learning_rate': 0.0009806666666666668, 'epoch': 5.8}\n","{'loss': 0.3443, 'learning_rate': 0.0009803333333333333, 'epoch': 5.9}\n","{'loss': 0.3472, 'learning_rate': 0.00098, 'epoch': 6.0}\n","  2% 600/30000 [12:53<7:10:12,  1.14it/s][INFO|trainer.py:3129] 2023-09-07 08:29:23,339 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3131] 2023-09-07 08:29:23,339 >>   Num examples = 9000\n","[INFO|trainer.py:3134] 2023-09-07 08:29:23,339 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.46it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.77it/s]\u001b[A\n"," 22% 4/18 [00:02<00:09,  1.55it/s]\u001b[A\n"," 28% 5/18 [00:03<00:08,  1.45it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.39it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.35it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.32it/s]\u001b[A\n"," 50% 9/18 [00:06<00:06,  1.31it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.29it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.29it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.26it/s]\u001b[A\n"," 72% 13/18 [00:09<00:04,  1.25it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.22it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.20it/s]\u001b[A\n"," 89% 16/18 [00:12<00:01,  1.18it/s]\u001b[A\n","                                         \n","\u001b[A{'eval_loss': 0.045720361173152924, 'eval_accuracy': 0.9831111111111112, 'eval_runtime': 14.2539, 'eval_samples_per_second': 631.407, 'eval_steps_per_second': 1.263, 'epoch': 6.0}\n","  2% 600/30000 [13:08<7:10:12,  1.14it/s]\n","100% 18/18 [00:12<00:00,  1.32it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2855] 2023-09-07 08:29:37,597 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-600\n","[INFO|configuration_utils.py:460] 2023-09-07 08:29:37,603 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-600/config.json\n","[INFO|modeling_utils.py:1978] 2023-09-07 08:29:37,732 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-600/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 08:29:37,738 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-600/preprocessor_config.json\n","[INFO|trainer.py:2942] 2023-09-07 08:29:37,953 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-300] due to args.save_total_limit\n","{'loss': 0.3241, 'learning_rate': 0.0009796666666666667, 'epoch': 6.1}\n","{'loss': 0.3372, 'learning_rate': 0.0009793333333333334, 'epoch': 6.2}\n","{'loss': 0.3413, 'learning_rate': 0.000979, 'epoch': 6.3}\n","{'loss': 0.3231, 'learning_rate': 0.0009786666666666667, 'epoch': 6.4}\n","{'loss': 0.339, 'learning_rate': 0.0009783333333333334, 'epoch': 6.5}\n","{'loss': 0.3327, 'learning_rate': 0.000978, 'epoch': 6.6}\n","{'loss': 0.3332, 'learning_rate': 0.0009776666666666666, 'epoch': 6.7}\n","{'loss': 0.326, 'learning_rate': 0.0009773333333333333, 'epoch': 6.8}\n","{'loss': 0.3339, 'learning_rate': 0.000977, 'epoch': 6.9}\n","{'loss': 0.3448, 'learning_rate': 0.0009766666666666667, 'epoch': 7.0}\n","  2% 700/30000 [15:03<6:47:48,  1.20it/s][INFO|trainer.py:3129] 2023-09-07 08:31:33,171 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3131] 2023-09-07 08:31:33,171 >>   Num examples = 9000\n","[INFO|trainer.py:3134] 2023-09-07 08:31:33,171 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.52it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.77it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.56it/s]\u001b[A\n"," 28% 5/18 [00:03<00:09,  1.43it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.38it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.34it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.31it/s]\u001b[A\n"," 50% 9/18 [00:06<00:06,  1.29it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.28it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.28it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.26it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.26it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.25it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.21it/s]\u001b[A\n"," 89% 16/18 [00:12<00:01,  1.18it/s]\u001b[A\n","                                         \n","\u001b[A{'eval_loss': 0.05765035003423691, 'eval_accuracy': 0.9823333333333333, 'eval_runtime': 14.2539, 'eval_samples_per_second': 631.407, 'eval_steps_per_second': 1.263, 'epoch': 7.0}\n","  2% 700/30000 [15:17<6:47:48,  1.20it/s]\n","100% 18/18 [00:12<00:00,  1.32it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2855] 2023-09-07 08:31:47,430 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-700\n","[INFO|configuration_utils.py:460] 2023-09-07 08:31:47,436 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-700/config.json\n","[INFO|modeling_utils.py:1978] 2023-09-07 08:31:47,558 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-700/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 08:31:47,563 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-700/preprocessor_config.json\n","[INFO|trainer.py:2942] 2023-09-07 08:31:47,804 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-400] due to args.save_total_limit\n","{'loss': 0.345, 'learning_rate': 0.0009763333333333334, 'epoch': 7.1}\n","{'loss': 0.3274, 'learning_rate': 0.000976, 'epoch': 7.2}\n","{'loss': 0.3311, 'learning_rate': 0.0009756666666666667, 'epoch': 7.3}\n","{'loss': 0.3269, 'learning_rate': 0.0009753333333333334, 'epoch': 7.4}\n","{'loss': 0.3325, 'learning_rate': 0.000975, 'epoch': 7.5}\n","{'loss': 0.3214, 'learning_rate': 0.0009746666666666666, 'epoch': 7.6}\n","{'loss': 0.3181, 'learning_rate': 0.0009743333333333335, 'epoch': 7.7}\n","{'loss': 0.3301, 'learning_rate': 0.000974, 'epoch': 7.8}\n","{'loss': 0.3238, 'learning_rate': 0.0009736666666666667, 'epoch': 7.9}\n","{'loss': 0.3477, 'learning_rate': 0.0009733333333333334, 'epoch': 8.0}\n","  3% 800/30000 [17:14<6:50:54,  1.18it/s][INFO|trainer.py:3129] 2023-09-07 08:33:43,889 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3131] 2023-09-07 08:33:43,889 >>   Num examples = 9000\n","[INFO|trainer.py:3134] 2023-09-07 08:33:43,890 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.61it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.79it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.56it/s]\u001b[A\n"," 28% 5/18 [00:03<00:08,  1.46it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.41it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.37it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.34it/s]\u001b[A\n"," 50% 9/18 [00:06<00:06,  1.32it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.29it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.29it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.27it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.27it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.18it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.17it/s]\u001b[A\n"," 89% 16/18 [00:12<00:01,  1.15it/s]\u001b[A\n","                                         \n","\u001b[A{'eval_loss': 0.03440311178565025, 'eval_accuracy': 0.9888888888888889, 'eval_runtime': 14.2866, 'eval_samples_per_second': 629.961, 'eval_steps_per_second': 1.26, 'epoch': 8.0}\n","  3% 800/30000 [17:28<6:50:54,  1.18it/s]\n","100% 18/18 [00:12<00:00,  1.29it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2855] 2023-09-07 08:33:58,182 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-800\n","[INFO|configuration_utils.py:460] 2023-09-07 08:33:58,189 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-800/config.json\n","[INFO|modeling_utils.py:1978] 2023-09-07 08:33:58,317 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-800/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 08:33:58,322 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-800/preprocessor_config.json\n","[INFO|trainer.py:2942] 2023-09-07 08:33:58,561 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-500] due to args.save_total_limit\n","{'loss': 0.3177, 'learning_rate': 0.000973, 'epoch': 8.1}\n","{'loss': 0.324, 'learning_rate': 0.0009726666666666667, 'epoch': 8.2}\n","{'loss': 0.314, 'learning_rate': 0.0009723333333333334, 'epoch': 8.3}\n","{'loss': 0.3391, 'learning_rate': 0.000972, 'epoch': 8.4}\n","{'loss': 0.3292, 'learning_rate': 0.0009716666666666667, 'epoch': 8.5}\n","{'loss': 0.3232, 'learning_rate': 0.0009713333333333334, 'epoch': 8.6}\n","{'loss': 0.3347, 'learning_rate': 0.000971, 'epoch': 8.7}\n","{'loss': 0.3067, 'learning_rate': 0.0009706666666666667, 'epoch': 8.8}\n","{'loss': 0.3057, 'learning_rate': 0.0009703333333333334, 'epoch': 8.9}\n","{'loss': 0.3379, 'learning_rate': 0.0009699999999999999, 'epoch': 9.0}\n","  3% 900/30000 [19:23<6:53:13,  1.17it/s][INFO|trainer.py:3129] 2023-09-07 08:35:53,412 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3131] 2023-09-07 08:35:53,413 >>   Num examples = 9000\n","[INFO|trainer.py:3134] 2023-09-07 08:35:53,413 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.57it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.78it/s]\u001b[A\n"," 22% 4/18 [00:02<00:09,  1.54it/s]\u001b[A\n"," 28% 5/18 [00:03<00:09,  1.42it/s]\u001b[A\n"," 33% 6/18 [00:04<00:08,  1.34it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.31it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.29it/s]\u001b[A\n"," 50% 9/18 [00:06<00:07,  1.28it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.27it/s]\u001b[A\n"," 61% 11/18 [00:08<00:05,  1.26it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.24it/s]\u001b[A\n"," 72% 13/18 [00:09<00:04,  1.16it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.06it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.09it/s]\u001b[A\n"," 89% 16/18 [00:12<00:01,  1.11it/s]\u001b[A\n","                                         \n","\u001b[A{'eval_loss': 0.04584510251879692, 'eval_accuracy': 0.9865555555555555, 'eval_runtime': 14.7539, 'eval_samples_per_second': 610.007, 'eval_steps_per_second': 1.22, 'epoch': 9.0}\n","  3% 900/30000 [19:38<6:53:13,  1.17it/s]\n","100% 18/18 [00:13<00:00,  1.29it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2855] 2023-09-07 08:36:08,172 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-900\n","[INFO|configuration_utils.py:460] 2023-09-07 08:36:08,178 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-900/config.json\n","[INFO|modeling_utils.py:1978] 2023-09-07 08:36:08,309 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-900/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 08:36:08,315 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-900/preprocessor_config.json\n","[INFO|trainer.py:2942] 2023-09-07 08:36:08,543 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-600] due to args.save_total_limit\n","{'loss': 0.3012, 'learning_rate': 0.0009696666666666667, 'epoch': 9.1}\n","{'loss': 0.3209, 'learning_rate': 0.0009693333333333334, 'epoch': 9.2}\n","{'loss': 0.3188, 'learning_rate': 0.000969, 'epoch': 9.3}\n","{'loss': 0.3101, 'learning_rate': 0.0009686666666666667, 'epoch': 9.4}\n","{'loss': 0.3294, 'learning_rate': 0.0009683333333333334, 'epoch': 9.5}\n","{'loss': 0.3071, 'learning_rate': 0.000968, 'epoch': 9.6}\n","{'loss': 0.3282, 'learning_rate': 0.0009676666666666667, 'epoch': 9.7}\n","{'loss': 0.3063, 'learning_rate': 0.0009673333333333334, 'epoch': 9.8}\n","{'loss': 0.3197, 'learning_rate': 0.000967, 'epoch': 9.9}\n","{'loss': 0.3402, 'learning_rate': 0.0009666666666666667, 'epoch': 10.0}\n","  3% 1000/30000 [21:33<6:37:13,  1.22it/s][INFO|trainer.py:3129] 2023-09-07 08:38:03,184 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3131] 2023-09-07 08:38:03,184 >>   Num examples = 9000\n","[INFO|trainer.py:3134] 2023-09-07 08:38:03,184 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.56it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.79it/s]\u001b[A\n"," 22% 4/18 [00:02<00:09,  1.54it/s]\u001b[A\n"," 28% 5/18 [00:03<00:09,  1.44it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.38it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.34it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.33it/s]\u001b[A\n"," 50% 9/18 [00:06<00:06,  1.31it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.28it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.25it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.24it/s]\u001b[A\n"," 72% 13/18 [00:09<00:04,  1.20it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.18it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.17it/s]\u001b[A\n"," 89% 16/18 [00:12<00:01,  1.20it/s]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 2.8178510665893555, 'eval_accuracy': 0.4245555555555556, 'eval_runtime': 14.2637, 'eval_samples_per_second': 630.971, 'eval_steps_per_second': 1.262, 'epoch': 10.0}\n","  3% 1000/30000 [21:47<6:37:13,  1.22it/s]\n","100% 18/18 [00:12<00:00,  1.37it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2855] 2023-09-07 08:38:17,453 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-1000\n","[INFO|configuration_utils.py:460] 2023-09-07 08:38:17,458 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-1000/config.json\n","[INFO|modeling_utils.py:1978] 2023-09-07 08:38:17,567 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-1000/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 08:38:17,572 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-1000/preprocessor_config.json\n","[INFO|trainer.py:2942] 2023-09-07 08:38:17,791 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-700] due to args.save_total_limit\n","{'loss': 0.3145, 'learning_rate': 0.0009663333333333334, 'epoch': 10.1}\n","{'loss': 0.29, 'learning_rate': 0.000966, 'epoch': 10.2}\n","{'loss': 0.2896, 'learning_rate': 0.0009656666666666666, 'epoch': 10.3}\n","{'loss': 0.32, 'learning_rate': 0.0009653333333333333, 'epoch': 10.4}\n","{'loss': 0.3023, 'learning_rate': 0.000965, 'epoch': 10.5}\n","{'loss': 0.3321, 'learning_rate': 0.0009646666666666667, 'epoch': 10.6}\n","{'loss': 0.3229, 'learning_rate': 0.0009643333333333334, 'epoch': 10.7}\n","{'loss': 0.3318, 'learning_rate': 0.000964, 'epoch': 10.8}\n","{'loss': 0.3099, 'learning_rate': 0.0009636666666666667, 'epoch': 10.9}\n","{'loss': 0.3178, 'learning_rate': 0.0009633333333333334, 'epoch': 11.0}\n","  4% 1100/30000 [23:43<6:44:31,  1.19it/s][INFO|trainer.py:3129] 2023-09-07 08:40:13,427 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3131] 2023-09-07 08:40:13,428 >>   Num examples = 9000\n","[INFO|trainer.py:3134] 2023-09-07 08:40:13,428 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.57it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.80it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.57it/s]\u001b[A\n"," 28% 5/18 [00:03<00:08,  1.46it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.40it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.36it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.32it/s]\u001b[A\n"," 50% 9/18 [00:06<00:06,  1.30it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.17it/s]\u001b[A\n"," 61% 11/18 [00:08<00:06,  1.15it/s]\u001b[A\n"," 67% 12/18 [00:09<00:05,  1.14it/s]\u001b[A\n"," 72% 13/18 [00:09<00:04,  1.14it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.12it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.16it/s]\u001b[A\n"," 89% 16/18 [00:12<00:01,  1.20it/s]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 0.03051181696355343, 'eval_accuracy': 0.9896666666666667, 'eval_runtime': 14.5414, 'eval_samples_per_second': 618.923, 'eval_steps_per_second': 1.238, 'epoch': 11.0}\n","  4% 1100/30000 [23:58<6:44:31,  1.19it/s]\n","100% 18/18 [00:13<00:00,  1.36it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2855] 2023-09-07 08:40:27,973 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-1100\n","[INFO|configuration_utils.py:460] 2023-09-07 08:40:27,979 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-1100/config.json\n","[INFO|modeling_utils.py:1978] 2023-09-07 08:40:28,092 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-1100/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 08:40:28,096 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-1100/preprocessor_config.json\n","[INFO|trainer.py:2942] 2023-09-07 08:40:28,315 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-800] due to args.save_total_limit\n","{'loss': 0.3162, 'learning_rate': 0.000963, 'epoch': 11.1}\n","{'loss': 0.3165, 'learning_rate': 0.0009626666666666667, 'epoch': 11.2}\n","{'loss': 0.3015, 'learning_rate': 0.0009623333333333334, 'epoch': 11.3}\n","{'loss': 0.3015, 'learning_rate': 0.000962, 'epoch': 11.4}\n","{'loss': 0.2981, 'learning_rate': 0.0009616666666666667, 'epoch': 11.5}\n","{'loss': 0.3133, 'learning_rate': 0.0009613333333333334, 'epoch': 11.6}\n","{'loss': 0.3067, 'learning_rate': 0.0009609999999999999, 'epoch': 11.7}\n","{'loss': 0.2961, 'learning_rate': 0.0009606666666666666, 'epoch': 11.8}\n","{'loss': 0.2977, 'learning_rate': 0.0009603333333333334, 'epoch': 11.9}\n","{'loss': 0.306, 'learning_rate': 0.00096, 'epoch': 12.0}\n","  4% 1200/30000 [25:55<6:40:44,  1.20it/s][INFO|trainer.py:3129] 2023-09-07 08:42:25,095 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3131] 2023-09-07 08:42:25,096 >>   Num examples = 9000\n","[INFO|trainer.py:3134] 2023-09-07 08:42:25,096 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.51it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.73it/s]\u001b[A\n"," 22% 4/18 [00:02<00:09,  1.50it/s]\u001b[A\n"," 28% 5/18 [00:03<00:09,  1.40it/s]\u001b[A\n"," 33% 6/18 [00:04<00:08,  1.34it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.30it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.26it/s]\u001b[A\n"," 50% 9/18 [00:06<00:07,  1.20it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.15it/s]\u001b[A\n"," 61% 11/18 [00:08<00:06,  1.13it/s]\u001b[A\n"," 67% 12/18 [00:09<00:05,  1.12it/s]\u001b[A\n"," 72% 13/18 [00:10<00:04,  1.12it/s]\u001b[A\n"," 78% 14/18 [00:11<00:03,  1.16it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.19it/s]\u001b[A\n"," 89% 16/18 [00:12<00:01,  1.22it/s]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 0.03583241626620293, 'eval_accuracy': 0.9884444444444445, 'eval_runtime': 14.7356, 'eval_samples_per_second': 610.766, 'eval_steps_per_second': 1.222, 'epoch': 12.0}\n","  4% 1200/30000 [26:10<6:40:44,  1.20it/s]\n","100% 18/18 [00:13<00:00,  1.39it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2855] 2023-09-07 08:42:39,836 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-1200\n","[INFO|configuration_utils.py:460] 2023-09-07 08:42:39,842 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-1200/config.json\n","[INFO|modeling_utils.py:1978] 2023-09-07 08:42:39,953 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-1200/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 08:42:39,971 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-1200/preprocessor_config.json\n","[INFO|trainer.py:2942] 2023-09-07 08:42:40,196 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-900] due to args.save_total_limit\n","{'loss': 0.3132, 'learning_rate': 0.0009596666666666667, 'epoch': 12.1}\n","{'loss': 0.3056, 'learning_rate': 0.0009593333333333334, 'epoch': 12.2}\n","{'loss': 0.2786, 'learning_rate': 0.000959, 'epoch': 12.3}\n","{'loss': 0.31, 'learning_rate': 0.0009586666666666667, 'epoch': 12.4}\n","{'loss': 0.2954, 'learning_rate': 0.0009583333333333334, 'epoch': 12.5}\n","{'loss': 0.3107, 'learning_rate': 0.000958, 'epoch': 12.6}\n","{'loss': 0.3115, 'learning_rate': 0.0009576666666666667, 'epoch': 12.7}\n","{'loss': 0.2977, 'learning_rate': 0.0009573333333333334, 'epoch': 12.8}\n","{'loss': 0.302, 'learning_rate': 0.000957, 'epoch': 12.9}\n","{'loss': 0.2823, 'learning_rate': 0.0009566666666666666, 'epoch': 13.0}\n","  4% 1300/30000 [28:07<6:31:15,  1.22it/s][INFO|trainer.py:3129] 2023-09-07 08:44:37,084 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3131] 2023-09-07 08:44:37,084 >>   Num examples = 9000\n","[INFO|trainer.py:3134] 2023-09-07 08:44:37,084 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.54it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.79it/s]\u001b[A\n"," 22% 4/18 [00:02<00:09,  1.55it/s]\u001b[A\n"," 28% 5/18 [00:03<00:09,  1.42it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.36it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.30it/s]\u001b[A\n"," 44% 8/18 [00:05<00:08,  1.18it/s]\u001b[A\n"," 50% 9/18 [00:06<00:07,  1.19it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.17it/s]\u001b[A\n"," 61% 11/18 [00:08<00:06,  1.15it/s]\u001b[A\n"," 67% 12/18 [00:09<00:05,  1.13it/s]\u001b[A\n"," 72% 13/18 [00:10<00:04,  1.17it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.20it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.23it/s]\u001b[A\n"," 89% 16/18 [00:12<00:01,  1.24it/s]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 0.0533621609210968, 'eval_accuracy': 0.9821111111111112, 'eval_runtime': 14.5483, 'eval_samples_per_second': 618.627, 'eval_steps_per_second': 1.237, 'epoch': 13.0}\n","  4% 1300/30000 [28:22<6:31:15,  1.22it/s]\n","100% 18/18 [00:13<00:00,  1.41it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2855] 2023-09-07 08:44:51,637 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-1300\n","[INFO|configuration_utils.py:460] 2023-09-07 08:44:51,643 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-1300/config.json\n","[INFO|modeling_utils.py:1978] 2023-09-07 08:44:51,759 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-1300/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 08:44:51,764 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-1300/preprocessor_config.json\n","[INFO|trainer.py:2942] 2023-09-07 08:44:51,983 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-1000] due to args.save_total_limit\n","{'loss': 0.2803, 'learning_rate': 0.0009563333333333333, 'epoch': 13.1}\n","{'loss': 0.3021, 'learning_rate': 0.0009559999999999999, 'epoch': 13.2}\n","{'loss': 0.2997, 'learning_rate': 0.0009556666666666667, 'epoch': 13.3}\n","{'loss': 0.3071, 'learning_rate': 0.0009553333333333334, 'epoch': 13.4}\n","{'loss': 0.2997, 'learning_rate': 0.000955, 'epoch': 13.5}\n","{'loss': 0.3039, 'learning_rate': 0.0009546666666666667, 'epoch': 13.6}\n","{'loss': 0.318, 'learning_rate': 0.0009543333333333334, 'epoch': 13.7}\n","{'loss': 0.312, 'learning_rate': 0.000954, 'epoch': 13.8}\n","{'loss': 0.314, 'learning_rate': 0.0009536666666666667, 'epoch': 13.9}\n","{'loss': 0.3124, 'learning_rate': 0.0009533333333333334, 'epoch': 14.0}\n","  5% 1400/30000 [30:17<6:28:07,  1.23it/s][INFO|trainer.py:3129] 2023-09-07 08:46:47,453 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3131] 2023-09-07 08:46:47,453 >>   Num examples = 9000\n","[INFO|trainer.py:3134] 2023-09-07 08:46:47,454 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.49it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.79it/s]\u001b[A\n"," 22% 4/18 [00:02<00:09,  1.55it/s]\u001b[A\n"," 28% 5/18 [00:03<00:09,  1.44it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.38it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.30it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.25it/s]\u001b[A\n"," 50% 9/18 [00:06<00:07,  1.23it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.19it/s]\u001b[A\n"," 61% 11/18 [00:08<00:06,  1.16it/s]\u001b[A\n"," 67% 12/18 [00:09<00:05,  1.15it/s]\u001b[A\n"," 72% 13/18 [00:10<00:04,  1.19it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.20it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.22it/s]\u001b[A\n"," 89% 16/18 [00:12<00:01,  1.23it/s]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 0.05695437267422676, 'eval_accuracy': 0.9792222222222222, 'eval_runtime': 14.4554, 'eval_samples_per_second': 622.603, 'eval_steps_per_second': 1.245, 'epoch': 14.0}\n","  5% 1400/30000 [30:32<6:28:07,  1.23it/s]\n","100% 18/18 [00:13<00:00,  1.39it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2855] 2023-09-07 08:47:01,914 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-1400\n","[INFO|configuration_utils.py:460] 2023-09-07 08:47:01,919 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-1400/config.json\n","[INFO|modeling_utils.py:1978] 2023-09-07 08:47:02,043 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-1400/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 08:47:02,047 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-1400/preprocessor_config.json\n","[INFO|trainer.py:2942] 2023-09-07 08:47:02,289 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-1200] due to args.save_total_limit\n","{'loss': 0.3038, 'learning_rate': 0.000953, 'epoch': 14.1}\n","{'loss': 0.311, 'learning_rate': 0.0009526666666666667, 'epoch': 14.2}\n","{'loss': 0.2827, 'learning_rate': 0.0009523333333333334, 'epoch': 14.3}\n","{'loss': 0.302, 'learning_rate': 0.0009519999999999999, 'epoch': 14.4}\n","{'loss': 0.3052, 'learning_rate': 0.0009516666666666666, 'epoch': 14.5}\n","{'loss': 0.2844, 'learning_rate': 0.0009513333333333334, 'epoch': 14.6}\n","{'loss': 0.2977, 'learning_rate': 0.000951, 'epoch': 14.7}\n","{'loss': 0.3033, 'learning_rate': 0.0009506666666666667, 'epoch': 14.8}\n","{'loss': 0.2939, 'learning_rate': 0.0009503333333333334, 'epoch': 14.9}\n","{'loss': 0.3025, 'learning_rate': 0.00095, 'epoch': 15.0}\n","  5% 1500/30000 [32:28<6:32:28,  1.21it/s][INFO|trainer.py:3129] 2023-09-07 08:48:57,841 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3131] 2023-09-07 08:48:57,841 >>   Num examples = 9000\n","[INFO|trainer.py:3134] 2023-09-07 08:48:57,842 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.53it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.76it/s]\u001b[A\n"," 22% 4/18 [00:02<00:09,  1.51it/s]\u001b[A\n"," 28% 5/18 [00:03<00:09,  1.39it/s]\u001b[A\n"," 33% 6/18 [00:04<00:09,  1.32it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.27it/s]\u001b[A\n"," 44% 8/18 [00:05<00:08,  1.23it/s]\u001b[A\n"," 50% 9/18 [00:06<00:07,  1.21it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.17it/s]\u001b[A\n"," 61% 11/18 [00:08<00:06,  1.14it/s]\u001b[A\n"," 67% 12/18 [00:09<00:05,  1.12it/s]\u001b[A\n"," 72% 13/18 [00:10<00:04,  1.15it/s]\u001b[A\n"," 78% 14/18 [00:11<00:03,  1.17it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.19it/s]\u001b[A\n"," 89% 16/18 [00:12<00:01,  1.21it/s]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 0.031515900045633316, 'eval_accuracy': 0.9896666666666667, 'eval_runtime': 14.7371, 'eval_samples_per_second': 610.702, 'eval_steps_per_second': 1.221, 'epoch': 15.0}\n","  5% 1500/30000 [32:43<6:32:28,  1.21it/s]\n","100% 18/18 [00:13<00:00,  1.38it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2855] 2023-09-07 08:49:12,584 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-1500\n","[INFO|configuration_utils.py:460] 2023-09-07 08:49:12,590 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-1500/config.json\n","[INFO|modeling_utils.py:1978] 2023-09-07 08:49:12,715 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-1500/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 08:49:12,720 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-1500/preprocessor_config.json\n","[INFO|trainer.py:2942] 2023-09-07 08:49:12,944 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-1300] due to args.save_total_limit\n","{'loss': 0.2989, 'learning_rate': 0.0009496666666666667, 'epoch': 15.1}\n","{'loss': 0.2865, 'learning_rate': 0.0009493333333333334, 'epoch': 15.2}\n","{'loss': 0.3007, 'learning_rate': 0.000949, 'epoch': 15.3}\n","{'loss': 0.2783, 'learning_rate': 0.0009486666666666667, 'epoch': 15.4}\n","{'loss': 0.3091, 'learning_rate': 0.0009483333333333334, 'epoch': 15.5}\n","{'loss': 0.2919, 'learning_rate': 0.000948, 'epoch': 15.6}\n","{'loss': 0.2819, 'learning_rate': 0.0009476666666666666, 'epoch': 15.7}\n","{'loss': 0.2828, 'learning_rate': 0.0009473333333333333, 'epoch': 15.8}\n","{'loss': 0.2933, 'learning_rate': 0.0009469999999999999, 'epoch': 15.9}\n","{'loss': 0.2962, 'learning_rate': 0.0009466666666666667, 'epoch': 16.0}\n","  5% 1600/30000 [34:40<6:28:17,  1.22it/s][INFO|trainer.py:3129] 2023-09-07 08:51:09,882 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3131] 2023-09-07 08:51:09,882 >>   Num examples = 9000\n","[INFO|trainer.py:3134] 2023-09-07 08:51:09,882 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.59it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.83it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.58it/s]\u001b[A\n"," 28% 5/18 [00:03<00:08,  1.45it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.35it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.30it/s]\u001b[A\n"," 44% 8/18 [00:05<00:08,  1.24it/s]\u001b[A\n"," 50% 9/18 [00:06<00:07,  1.20it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.18it/s]\u001b[A\n"," 61% 11/18 [00:08<00:05,  1.21it/s]\u001b[A\n"," 67% 12/18 [00:09<00:04,  1.23it/s]\u001b[A\n"," 72% 13/18 [00:09<00:04,  1.24it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.24it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.25it/s]\u001b[A\n"," 89% 16/18 [00:12<00:01,  1.24it/s]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 0.7562996745109558, 'eval_accuracy': 0.7524444444444445, 'eval_runtime': 14.2349, 'eval_samples_per_second': 632.249, 'eval_steps_per_second': 1.264, 'epoch': 16.0}\n","  5% 1600/30000 [34:54<6:28:17,  1.22it/s]\n","100% 18/18 [00:12<00:00,  1.41it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2855] 2023-09-07 08:51:24,122 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-1600\n","[INFO|configuration_utils.py:460] 2023-09-07 08:51:24,128 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-1600/config.json\n","[INFO|modeling_utils.py:1978] 2023-09-07 08:51:24,516 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-1600/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 08:51:24,521 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-1600/preprocessor_config.json\n","[INFO|trainer.py:2942] 2023-09-07 08:51:24,751 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-1400] due to args.save_total_limit\n","{'loss': 0.2874, 'learning_rate': 0.0009463333333333334, 'epoch': 16.1}\n","{'loss': 0.2882, 'learning_rate': 0.000946, 'epoch': 16.2}\n","{'loss': 0.2904, 'learning_rate': 0.0009456666666666667, 'epoch': 16.3}\n","{'loss': 0.2914, 'learning_rate': 0.0009453333333333334, 'epoch': 16.4}\n","{'loss': 0.2844, 'learning_rate': 0.000945, 'epoch': 16.5}\n","{'loss': 0.3029, 'learning_rate': 0.0009446666666666667, 'epoch': 16.6}\n","{'loss': 0.2872, 'learning_rate': 0.0009443333333333334, 'epoch': 16.7}\n","{'loss': 0.2927, 'learning_rate': 0.000944, 'epoch': 16.8}\n","{'loss': 0.2941, 'learning_rate': 0.0009436666666666667, 'epoch': 16.9}\n","{'loss': 0.3133, 'learning_rate': 0.0009433333333333334, 'epoch': 17.0}\n","  6% 1700/30000 [36:51<6:23:10,  1.23it/s][INFO|trainer.py:3129] 2023-09-07 08:53:21,094 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3131] 2023-09-07 08:53:21,094 >>   Num examples = 9000\n","[INFO|trainer.py:3134] 2023-09-07 08:53:21,094 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.55it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.74it/s]\u001b[A\n"," 22% 4/18 [00:02<00:09,  1.48it/s]\u001b[A\n"," 28% 5/18 [00:03<00:09,  1.36it/s]\u001b[A\n"," 33% 6/18 [00:04<00:09,  1.29it/s]\u001b[A\n"," 39% 7/18 [00:05<00:08,  1.23it/s]\u001b[A\n"," 44% 8/18 [00:05<00:08,  1.19it/s]\u001b[A\n"," 50% 9/18 [00:06<00:07,  1.17it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.20it/s]\u001b[A\n"," 61% 11/18 [00:08<00:05,  1.21it/s]\u001b[A\n"," 67% 12/18 [00:09<00:04,  1.23it/s]\u001b[A\n"," 72% 13/18 [00:10<00:04,  1.23it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.23it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.23it/s]\u001b[A\n"," 89% 16/18 [00:12<00:01,  1.24it/s]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 0.040111392736434937, 'eval_accuracy': 0.9874444444444445, 'eval_runtime': 14.5283, 'eval_samples_per_second': 619.481, 'eval_steps_per_second': 1.239, 'epoch': 17.0}\n","  6% 1700/30000 [37:06<6:23:10,  1.23it/s]\n","100% 18/18 [00:13<00:00,  1.41it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2855] 2023-09-07 08:53:35,627 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-1700\n","[INFO|configuration_utils.py:460] 2023-09-07 08:53:35,633 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-1700/config.json\n","[INFO|modeling_utils.py:1978] 2023-09-07 08:53:35,748 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-1700/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 08:53:35,753 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-1700/preprocessor_config.json\n","[INFO|trainer.py:2942] 2023-09-07 08:53:35,983 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-1500] due to args.save_total_limit\n","{'loss': 0.2822, 'learning_rate': 0.0009429999999999999, 'epoch': 17.1}\n","{'loss': 0.29, 'learning_rate': 0.0009426666666666666, 'epoch': 17.2}\n","{'loss': 0.2886, 'learning_rate': 0.0009423333333333333, 'epoch': 17.3}\n","{'loss': 0.3016, 'learning_rate': 0.000942, 'epoch': 17.4}\n","{'loss': 0.3007, 'learning_rate': 0.0009416666666666667, 'epoch': 17.5}\n","{'loss': 0.3007, 'learning_rate': 0.0009413333333333334, 'epoch': 17.6}\n","{'loss': 0.29, 'learning_rate': 0.000941, 'epoch': 17.7}\n","{'loss': 0.2869, 'learning_rate': 0.0009406666666666667, 'epoch': 17.8}\n","{'loss': 0.284, 'learning_rate': 0.0009403333333333334, 'epoch': 17.9}\n","{'loss': 0.2942, 'learning_rate': 0.00094, 'epoch': 18.0}\n","  6% 1800/30000 [39:03<6:19:12,  1.24it/s][INFO|trainer.py:3129] 2023-09-07 08:55:32,594 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3131] 2023-09-07 08:55:32,594 >>   Num examples = 9000\n","[INFO|trainer.py:3134] 2023-09-07 08:55:32,594 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.53it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.77it/s]\u001b[A\n"," 22% 4/18 [00:02<00:09,  1.42it/s]\u001b[A\n"," 28% 5/18 [00:03<00:09,  1.31it/s]\u001b[A\n"," 33% 6/18 [00:04<00:09,  1.25it/s]\u001b[A\n"," 39% 7/18 [00:05<00:08,  1.22it/s]\u001b[A\n"," 44% 8/18 [00:05<00:08,  1.23it/s]\u001b[A\n"," 50% 9/18 [00:06<00:07,  1.23it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.25it/s]\u001b[A\n"," 61% 11/18 [00:08<00:05,  1.25it/s]\u001b[A\n"," 67% 12/18 [00:09<00:04,  1.25it/s]\u001b[A\n"," 72% 13/18 [00:09<00:04,  1.25it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.26it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.26it/s]\u001b[A\n"," 89% 16/18 [00:12<00:01,  1.26it/s]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 1.1312044858932495, 'eval_accuracy': 0.6491111111111111, 'eval_runtime': 14.3292, 'eval_samples_per_second': 628.09, 'eval_steps_per_second': 1.256, 'epoch': 18.0}\n","  6% 1800/30000 [39:17<6:19:12,  1.24it/s]\n","100% 18/18 [00:12<00:00,  1.43it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2855] 2023-09-07 08:55:46,928 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-1800\n","[INFO|configuration_utils.py:460] 2023-09-07 08:55:46,934 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-1800/config.json\n","[INFO|modeling_utils.py:1978] 2023-09-07 08:55:47,050 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-1800/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 08:55:47,069 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-1800/preprocessor_config.json\n","[INFO|trainer.py:2942] 2023-09-07 08:55:47,295 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-1600] due to args.save_total_limit\n","{'loss': 0.2817, 'learning_rate': 0.0009396666666666667, 'epoch': 18.1}\n","{'loss': 0.2933, 'learning_rate': 0.0009393333333333334, 'epoch': 18.2}\n","{'loss': 0.2888, 'learning_rate': 0.000939, 'epoch': 18.3}\n","{'loss': 0.2857, 'learning_rate': 0.0009386666666666666, 'epoch': 18.4}\n","{'loss': 0.3034, 'learning_rate': 0.0009383333333333333, 'epoch': 18.5}\n","{'loss': 0.2779, 'learning_rate': 0.0009379999999999999, 'epoch': 18.6}\n","{'loss': 0.2743, 'learning_rate': 0.0009376666666666666, 'epoch': 18.7}\n","{'loss': 0.2868, 'learning_rate': 0.0009373333333333334, 'epoch': 18.8}\n","{'loss': 0.2927, 'learning_rate': 0.0009370000000000001, 'epoch': 18.9}\n","{'loss': 0.2845, 'learning_rate': 0.0009366666666666667, 'epoch': 19.0}\n","  6% 1900/30000 [41:14<6:18:31,  1.24it/s][INFO|trainer.py:3129] 2023-09-07 08:57:44,063 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3131] 2023-09-07 08:57:44,063 >>   Num examples = 9000\n","[INFO|trainer.py:3134] 2023-09-07 08:57:44,063 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:07,  2.12it/s]\u001b[A\n"," 17% 3/18 [00:01<00:09,  1.62it/s]\u001b[A\n"," 22% 4/18 [00:02<00:10,  1.39it/s]\u001b[A\n"," 28% 5/18 [00:03<00:10,  1.29it/s]\u001b[A\n"," 33% 6/18 [00:04<00:09,  1.23it/s]\u001b[A\n"," 39% 7/18 [00:05<00:08,  1.22it/s]\u001b[A\n"," 44% 8/18 [00:06<00:08,  1.22it/s]\u001b[A\n"," 50% 9/18 [00:06<00:07,  1.21it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.21it/s]\u001b[A\n"," 61% 11/18 [00:08<00:05,  1.21it/s]\u001b[A\n"," 67% 12/18 [00:09<00:04,  1.21it/s]\u001b[A\n"," 72% 13/18 [00:10<00:04,  1.21it/s]\u001b[A\n"," 78% 14/18 [00:11<00:03,  1.21it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.21it/s]\u001b[A\n"," 89% 16/18 [00:12<00:01,  1.21it/s]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 0.0387837216258049, 'eval_accuracy': 0.9882222222222222, 'eval_runtime': 14.7584, 'eval_samples_per_second': 609.822, 'eval_steps_per_second': 1.22, 'epoch': 19.0}\n","  6% 1900/30000 [41:29<6:18:31,  1.24it/s]\n","100% 18/18 [00:13<00:00,  1.38it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2855] 2023-09-07 08:57:58,827 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-1900\n","[INFO|configuration_utils.py:460] 2023-09-07 08:57:58,833 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-1900/config.json\n","[INFO|modeling_utils.py:1978] 2023-09-07 08:57:58,951 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-1900/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 08:57:58,956 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-1900/preprocessor_config.json\n","[INFO|trainer.py:2942] 2023-09-07 08:57:59,198 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-1700] due to args.save_total_limit\n","{'loss': 0.2784, 'learning_rate': 0.0009363333333333334, 'epoch': 19.1}\n","{'loss': 0.283, 'learning_rate': 0.0009360000000000001, 'epoch': 19.2}\n","{'loss': 0.2893, 'learning_rate': 0.0009356666666666667, 'epoch': 19.3}\n","{'loss': 0.285, 'learning_rate': 0.0009353333333333334, 'epoch': 19.4}\n","{'loss': 0.2855, 'learning_rate': 0.0009350000000000001, 'epoch': 19.5}\n","{'loss': 0.2934, 'learning_rate': 0.0009346666666666667, 'epoch': 19.6}\n","{'loss': 0.2885, 'learning_rate': 0.0009343333333333333, 'epoch': 19.7}\n","{'loss': 0.2844, 'learning_rate': 0.000934, 'epoch': 19.8}\n","{'loss': 0.2769, 'learning_rate': 0.0009336666666666666, 'epoch': 19.9}\n","{'loss': 0.2822, 'learning_rate': 0.0009333333333333333, 'epoch': 20.0}\n","  7% 2000/30000 [43:26<6:23:50,  1.22it/s][INFO|trainer.py:3129] 2023-09-07 08:59:56,108 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3131] 2023-09-07 08:59:56,109 >>   Num examples = 9000\n","[INFO|trainer.py:3134] 2023-09-07 08:59:56,109 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.36it/s]\u001b[A\n"," 17% 3/18 [00:01<00:09,  1.63it/s]\u001b[A\n"," 22% 4/18 [00:02<00:10,  1.40it/s]\u001b[A\n"," 28% 5/18 [00:03<00:09,  1.31it/s]\u001b[A\n"," 33% 6/18 [00:04<00:09,  1.29it/s]\u001b[A\n"," 39% 7/18 [00:05<00:08,  1.26it/s]\u001b[A\n"," 44% 8/18 [00:05<00:08,  1.25it/s]\u001b[A\n"," 50% 9/18 [00:06<00:07,  1.23it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.23it/s]\u001b[A\n"," 61% 11/18 [00:08<00:05,  1.23it/s]\u001b[A\n"," 67% 12/18 [00:09<00:04,  1.23it/s]\u001b[A\n"," 72% 13/18 [00:09<00:04,  1.23it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.23it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.23it/s]\u001b[A\n"," 89% 16/18 [00:12<00:01,  1.23it/s]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 0.03078397549688816, 'eval_accuracy': 0.9904444444444445, 'eval_runtime': 14.6205, 'eval_samples_per_second': 615.574, 'eval_steps_per_second': 1.231, 'epoch': 20.0}\n","  7% 2000/30000 [43:41<6:23:50,  1.22it/s]\n","100% 18/18 [00:13<00:00,  1.40it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2855] 2023-09-07 09:00:10,735 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-2000\n","[INFO|configuration_utils.py:460] 2023-09-07 09:00:10,740 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-2000/config.json\n","[INFO|modeling_utils.py:1978] 2023-09-07 09:00:10,856 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-2000/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 09:00:10,861 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-2000/preprocessor_config.json\n","[INFO|trainer.py:2942] 2023-09-07 09:00:11,109 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-1800] due to args.save_total_limit\n","{'loss': 0.2774, 'learning_rate': 0.000933, 'epoch': 20.1}\n","{'loss': 0.2842, 'learning_rate': 0.0009326666666666667, 'epoch': 20.2}\n","{'loss': 0.2951, 'learning_rate': 0.0009323333333333334, 'epoch': 20.3}\n","{'loss': 0.2684, 'learning_rate': 0.0009320000000000001, 'epoch': 20.4}\n","{'loss': 0.2911, 'learning_rate': 0.0009316666666666667, 'epoch': 20.5}\n","{'loss': 0.286, 'learning_rate': 0.0009313333333333334, 'epoch': 20.6}\n","{'loss': 0.303, 'learning_rate': 0.0009310000000000001, 'epoch': 20.7}\n","{'loss': 0.2938, 'learning_rate': 0.0009306666666666667, 'epoch': 20.8}\n","{'loss': 0.268, 'learning_rate': 0.0009303333333333334, 'epoch': 20.9}\n","{'loss': 0.2771, 'learning_rate': 0.00093, 'epoch': 21.0}\n","  7% 2100/30000 [45:38<6:27:44,  1.20it/s][INFO|trainer.py:3129] 2023-09-07 09:02:08,358 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3131] 2023-09-07 09:02:08,358 >>   Num examples = 9000\n","[INFO|trainer.py:3134] 2023-09-07 09:02:08,358 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:07,  2.26it/s]\u001b[A\n"," 17% 3/18 [00:01<00:09,  1.63it/s]\u001b[A\n"," 22% 4/18 [00:02<00:09,  1.47it/s]\u001b[A\n"," 28% 5/18 [00:03<00:09,  1.40it/s]\u001b[A\n"," 33% 6/18 [00:04<00:08,  1.35it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.33it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.30it/s]\u001b[A\n"," 50% 9/18 [00:06<00:06,  1.29it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.28it/s]\u001b[A\n"," 61% 11/18 [00:08<00:05,  1.28it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.28it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.27it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.27it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.27it/s]\u001b[A\n"," 89% 16/18 [00:12<00:01,  1.19it/s]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 1.4808324575424194, 'eval_accuracy': 0.6294444444444445, 'eval_runtime': 14.4716, 'eval_samples_per_second': 621.908, 'eval_steps_per_second': 1.244, 'epoch': 21.0}\n","  7% 2100/30000 [45:53<6:27:44,  1.20it/s]\n","100% 18/18 [00:12<00:00,  1.30it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2855] 2023-09-07 09:02:22,834 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-2100\n","[INFO|configuration_utils.py:460] 2023-09-07 09:02:22,840 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-2100/config.json\n","[INFO|modeling_utils.py:1978] 2023-09-07 09:02:22,951 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-2100/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 09:02:22,957 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-2100/preprocessor_config.json\n","[INFO|trainer.py:2942] 2023-09-07 09:02:23,218 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-1900] due to args.save_total_limit\n","[INFO|trainer.py:1963] 2023-09-07 09:02:23,235 >> \n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","[INFO|trainer.py:2125] 2023-09-07 09:02:23,236 >> Loading best model from drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/checkpoint-1100 (score: 0.03051181696355343).\n","{'train_runtime': 2753.8106, 'train_samples_per_second': 5555.938, 'train_steps_per_second': 10.894, 'train_loss': 0.33205768857683454, 'epoch': 21.0}\n","  7% 2100/30000 [45:53<10:09:46,  1.31s/it]\n","[INFO|trainer.py:2855] 2023-09-07 09:02:23,315 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/\n","[INFO|configuration_utils.py:460] 2023-09-07 09:02:23,322 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/config.json\n","[INFO|modeling_utils.py:1978] 2023-09-07 09:02:23,446 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 09:02:23,451 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/preprocessor_config.json\n","***** train metrics *****\n","  epoch                    =       21.0\n","  train_loss               =     0.3321\n","  train_runtime            = 0:45:53.81\n","  train_samples_per_second =   5555.938\n","  train_steps_per_second   =     10.894\n","[INFO|trainer.py:3129] 2023-09-07 09:02:23,475 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3131] 2023-09-07 09:02:23,475 >>   Num examples = 9000\n","[INFO|trainer.py:3134] 2023-09-07 09:02:23,475 >>   Batch size = 512\n","100% 18/18 [00:13<00:00,  1.38it/s]\n","***** eval metrics *****\n","  epoch                   =       21.0\n","  eval_accuracy           =     0.9897\n","  eval_loss               =     0.0305\n","  eval_runtime            = 0:00:14.71\n","  eval_samples_per_second =      611.6\n","  eval_steps_per_second   =      1.223\n","\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n","\u001b[34m\u001b[1mwandb\u001b[0m:                  eval/accuracy ▇█▆▆█████▁█████▅█▄██▄█\n","\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/loss ▁▁▂▂▁▁▁▁▁█▁▁▁▁▁▃▁▄▁▁▅▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/runtime ▂▄▂█▇▁▁▁▅▁▃▅▄▃▅▁▃▂▅▄▃▅\n","\u001b[34m\u001b[1mwandb\u001b[0m:        eval/samples_per_second ▇▅▇▁▂███▄█▅▄▅▆▄█▆▇▄▅▆▄\n","\u001b[34m\u001b[1mwandb\u001b[0m:          eval/steps_per_second ▇▅▇▁▂███▄█▅▄▅▆▄█▆▇▄▅▆▄\n","\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\n","\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\n","\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate ███▇▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss █▅▅▄▃▃▃▃▂▂▃▃▂▃▂▂▂▂▂▁▂▂▂▂▁▂▂▁▂▁▁▂▁▁▂▁▁▁▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n","\u001b[34m\u001b[1mwandb\u001b[0m:                  eval/accuracy 0.98967\n","\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/loss 0.03051\n","\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/runtime 14.7155\n","\u001b[34m\u001b[1mwandb\u001b[0m:        eval/samples_per_second 611.6\n","\u001b[34m\u001b[1mwandb\u001b[0m:          eval/steps_per_second 1.223\n","\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch 21.0\n","\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step 2100\n","\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate 0.00093\n","\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss 0.2771\n","\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos 1.0815923230027776e+19\n","\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss 0.33206\n","\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime 2753.8106\n","\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second 5555.938\n","\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second 10.894\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mexalted-glitter-10\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/u15048366/colabCnnMnist/runs/76tjbjfh\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n","\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230907_081624-76tjbjfh/logs\u001b[0m\n"]}],"source":["!python cnn-mnist.py \\\n","    --model_name microsoft/resnet-18 \\\n","    --model_type resnet \\\n","    --dataset_name mnist \\\n","    --output_dir drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_4/ \\\n","    --remove_unused_columns False \\\n","    --do_train \\\n","    --do_eval \\\n","    --push_to_hub False \\\n","    --learning_rate 0.001 \\\n","    --num_train_epochs 300 \\\n","    --per_device_train_batch_size 512 \\\n","    --per_device_eval_batch_size 512 \\\n","    --logging_strategy steps \\\n","    --logging_steps 10 \\\n","    --evaluation_strategy epoch \\\n","    --save_strategy epoch \\\n","    --load_best_model_at_end True \\\n","    --save_total_limit 3 \\\n","    --save_steps 500 \\\n","    --data_seed 4 \\\n","    --seed 4 \\\n","    --report_to wandb \\\n","    --ignore_mismatched_sizes\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uWs01trKFRid"},"outputs":[],"source":["!python cnn-mnist.py \\\n","    --model_name microsoft/resnet-18 \\\n","    --model_type resnet \\\n","    --dataset_name mnist \\\n","    --output_dir drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_5/ \\\n","    --remove_unused_columns False \\\n","    --do_train \\\n","    --do_eval \\\n","    --push_to_hub False \\\n","    --learning_rate 0.001 \\\n","    --num_train_epochs 300 \\\n","    --per_device_train_batch_size 512 \\\n","    --per_device_eval_batch_size 512 \\\n","    --logging_strategy steps \\\n","    --logging_steps 10 \\\n","    --evaluation_strategy epoch \\\n","    --save_strategy epoch \\\n","    --load_best_model_at_end True \\\n","    --save_total_limit 3 \\\n","    --save_steps 500 \\\n","    --data_seed 5 \\\n","    --seed 5 \\\n","    --report_to wandb \\\n","    --ignore_mismatched_sizes\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":125629,"status":"ok","timestamp":1694107016136,"user":{"displayName":"Andreas Louw","userId":"11183032721846533402"},"user_tz":-120},"id":"C5cP8uzzFVIB","outputId":"33fcaf74-3d95-434a-e411-ff3a5dfc711b"},"outputs":[{"name":"stdout","output_type":"stream","text":["2023-09-07 16:31:17.023756: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mu15048366\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.10\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20230907_163121-6lkd183o\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33msummer-pond-15\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/u15048366/colabCnnMnist\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/u15048366/colabCnnMnist/runs/6lkd183o\u001b[0m\n","09/07/2023 16:31:22 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n","09/07/2023 16:31:22 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n","_n_gpu=1,\n","adafactor=False,\n","adam_beta1=0.9,\n","adam_beta2=0.999,\n","adam_epsilon=1e-08,\n","auto_find_batch_size=False,\n","bf16=False,\n","bf16_full_eval=False,\n","data_seed=6,\n","dataloader_drop_last=False,\n","dataloader_num_workers=0,\n","dataloader_pin_memory=True,\n","ddp_backend=None,\n","ddp_broadcast_buffers=None,\n","ddp_bucket_cap_mb=None,\n","ddp_find_unused_parameters=None,\n","ddp_timeout=1800,\n","debug=[],\n","deepspeed=None,\n","disable_tqdm=False,\n","dispatch_batches=None,\n","do_eval=True,\n","do_predict=False,\n","do_train=True,\n","eval_accumulation_steps=None,\n","eval_delay=0,\n","eval_steps=None,\n","evaluation_strategy=epoch,\n","fp16=False,\n","fp16_backend=auto,\n","fp16_full_eval=False,\n","fp16_opt_level=O1,\n","fsdp=[],\n","fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n","fsdp_min_num_params=0,\n","fsdp_transformer_layer_cls_to_wrap=None,\n","full_determinism=False,\n","gradient_accumulation_steps=1,\n","gradient_checkpointing=False,\n","greater_is_better=False,\n","group_by_length=False,\n","half_precision_backend=auto,\n","hub_always_push=False,\n","hub_model_id=None,\n","hub_private_repo=False,\n","hub_strategy=every_save,\n","hub_token=<HUB_TOKEN>,\n","ignore_data_skip=False,\n","include_inputs_for_metrics=False,\n","include_tokens_per_second=False,\n","jit_mode_eval=False,\n","label_names=None,\n","label_smoothing_factor=0.0,\n","learning_rate=0.001,\n","length_column_name=length,\n","load_best_model_at_end=True,\n","local_rank=0,\n","log_level=passive,\n","log_level_replica=warning,\n","log_on_each_node=True,\n","logging_dir=drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/runs/Sep07_16-31-22_67f6d3ae3f6c,\n","logging_first_step=False,\n","logging_nan_inf_filter=True,\n","logging_steps=10,\n","logging_strategy=steps,\n","lr_scheduler_type=linear,\n","max_grad_norm=1.0,\n","max_steps=-1,\n","metric_for_best_model=loss,\n","mp_parameters=,\n","no_cuda=False,\n","num_train_epochs=300.0,\n","optim=adamw_torch,\n","optim_args=None,\n","output_dir=drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/,\n","overwrite_output_dir=False,\n","past_index=-1,\n","per_device_eval_batch_size=512,\n","per_device_train_batch_size=512,\n","prediction_loss_only=False,\n","push_to_hub=False,\n","push_to_hub_model_id=None,\n","push_to_hub_organization=None,\n","push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n","ray_scope=last,\n","remove_unused_columns=False,\n","report_to=['wandb'],\n","resume_from_checkpoint=None,\n","run_name=drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/,\n","save_on_each_node=False,\n","save_safetensors=False,\n","save_steps=500.0,\n","save_strategy=epoch,\n","save_total_limit=3,\n","seed=6,\n","sharded_ddp=[],\n","skip_memory_metrics=True,\n","tf32=None,\n","torch_compile=False,\n","torch_compile_backend=None,\n","torch_compile_mode=None,\n","torchdynamo=None,\n","tpu_metrics_debug=False,\n","tpu_num_cores=None,\n","use_cpu=False,\n","use_ipex=False,\n","use_legacy_prediction_loop=False,\n","use_mps_device=False,\n","warmup_ratio=0.0,\n","warmup_steps=0,\n","weight_decay=0.0,\n",")\n","/usr/local/lib/python3.10/dist-packages/datasets/load.py:2103: FutureWarning: 'task' was deprecated in version 2.13.0 and will be removed in 3.0.0.\n","\n","  warnings.warn(\n","Downloading builder script: 100% 3.98k/3.98k [00:00<00:00, 14.0MB/s]\n","Downloading metadata: 100% 2.21k/2.21k [00:00<00:00, 8.85MB/s]\n","Downloading readme: 100% 6.83k/6.83k [00:00<00:00, 16.9MB/s]\n","Downloading data files:   0% 0/4 [00:00<?, ?it/s]\n","Downloading data:   0% 0.00/9.91M [00:00<?, ?B/s]\u001b[A\n","Downloading data:   0% 48.1k/9.91M [00:00<00:29, 337kB/s]\u001b[A\n","Downloading data:   1% 81.9k/9.91M [00:00<00:32, 306kB/s]\u001b[A\n","Downloading data:   2% 196k/9.91M [00:00<00:15, 617kB/s] \u001b[A\n","Downloading data:   3% 327k/9.91M [00:00<00:11, 854kB/s]\u001b[A\n","Downloading data:   6% 622k/9.91M [00:00<00:06, 1.54MB/s]\u001b[A\n","Downloading data:  11% 1.13M/9.91M [00:00<00:03, 2.66MB/s]\u001b[A\n","Downloading data:  21% 2.10M/9.91M [00:00<00:01, 4.87MB/s]\u001b[A\n","Downloading data:  40% 3.94M/9.91M [00:00<00:00, 9.05MB/s]\u001b[A\n","Downloading data: 100% 9.91M/9.91M [00:01<00:00, 9.40MB/s]\n","Downloading data files:  25% 1/4 [00:02<00:07,  2.62s/it]\n","Downloading data: 100% 28.9k/28.9k [00:00<00:00, 2.05MB/s]\n","Downloading data files:  50% 2/4 [00:04<00:03,  1.99s/it]\n","Downloading data:   0% 0.00/1.65M [00:00<?, ?B/s]\u001b[A\n","Downloading data:   3% 48.1k/1.65M [00:00<00:04, 341kB/s]\u001b[A\n","Downloading data:   5% 82.9k/1.65M [00:00<00:05, 313kB/s]\u001b[A\n","Downloading data:  12% 196k/1.65M [00:00<00:02, 620kB/s] \u001b[A\n","Downloading data:  20% 327k/1.65M [00:00<00:01, 859kB/s]\u001b[A\n","Downloading data:  38% 622k/1.65M [00:00<00:00, 1.55MB/s]\u001b[A\n","Downloading data: 100% 1.65M/1.65M [00:00<00:00, 2.26MB/s]\n","Downloading data files:  75% 3/4 [00:06<00:02,  2.11s/it]\n","Downloading data: 100% 4.54k/4.54k [00:00<00:00, 12.4MB/s]\n","Downloading data files: 100% 4/4 [00:07<00:00,  1.99s/it]\n","Extracting data files: 100% 4/4 [00:00<00:00, 13.96it/s]\n","Generating train split: 100% 60000/60000 [00:09<00:00, 6377.31 examples/s]\n","Generating test split: 100% 10000/10000 [00:01<00:00, 6163.32 examples/s]\n","Casting the dataset: 100% 60000/60000 [00:00<00:00, 1474246.15 examples/s]\n","Casting the dataset: 100% 10000/10000 [00:00<00:00, 1532389.76 examples/s]\n","Downloading builder script: 100% 4.20k/4.20k [00:00<00:00, 8.48MB/s]\n","\n","\n","\n","None\n","\n","\n","\n","Downloading (…)lve/main/config.json: 100% 69.5k/69.5k [00:00<00:00, 856kB/s]\n","[INFO|configuration_utils.py:715] 2023-09-07 16:31:46,887 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--resnet-18/snapshots/f45a6faa12e0381f5620c5c8d7e916bca90f2c44/config.json\n","[INFO|configuration_utils.py:775] 2023-09-07 16:31:46,888 >> Model config ResNetConfig {\n","  \"_name_or_path\": \"microsoft/resnet-18\",\n","  \"architectures\": [\n","    \"ResNetForImageClassification\"\n","  ],\n","  \"depths\": [\n","    2,\n","    2,\n","    2,\n","    2\n","  ],\n","  \"downsample_in_first_stage\": false,\n","  \"embedding_size\": 64,\n","  \"finetuning_task\": \"image-classification\",\n","  \"hidden_act\": \"relu\",\n","  \"hidden_sizes\": [\n","    64,\n","    128,\n","    256,\n","    512\n","  ],\n","  \"id2label\": {\n","    \"0\": \"0\",\n","    \"1\": \"1\",\n","    \"2\": \"2\",\n","    \"3\": \"3\",\n","    \"4\": \"4\",\n","    \"5\": \"5\",\n","    \"6\": \"6\",\n","    \"7\": \"7\",\n","    \"8\": \"8\",\n","    \"9\": \"9\"\n","  },\n","  \"label2id\": {\n","    \"0\": \"0\",\n","    \"1\": \"1\",\n","    \"2\": \"2\",\n","    \"3\": \"3\",\n","    \"4\": \"4\",\n","    \"5\": \"5\",\n","    \"6\": \"6\",\n","    \"7\": \"7\",\n","    \"8\": \"8\",\n","    \"9\": \"9\"\n","  },\n","  \"layer_type\": \"basic\",\n","  \"model_type\": \"resnet\",\n","  \"num_channels\": 3,\n","  \"out_features\": [\n","    \"stage4\"\n","  ],\n","  \"out_indices\": [\n","    4\n","  ],\n","  \"stage_names\": [\n","    \"stem\",\n","    \"stage1\",\n","    \"stage2\",\n","    \"stage3\",\n","    \"stage4\"\n","  ],\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.34.0.dev0\"\n","}\n","\n","Downloading model.safetensors: 100% 46.8M/46.8M [00:00<00:00, 316MB/s]\n","[INFO|modeling_utils.py:2857] 2023-09-07 16:31:47,252 >> loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--microsoft--resnet-18/snapshots/f45a6faa12e0381f5620c5c8d7e916bca90f2c44/model.safetensors\n","[INFO|modeling_utils.py:3643] 2023-09-07 16:31:47,440 >> All model checkpoint weights were used when initializing ResNetForImageClassification.\n","\n","[WARNING|modeling_utils.py:3664] 2023-09-07 16:31:47,440 >> Some weights of ResNetForImageClassification were not initialized from the model checkpoint at microsoft/resnet-18 and are newly initialized because the shapes did not match:\n","- classifier.1.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([10]) in the model instantiated\n","- classifier.1.weight: found shape torch.Size([1000, 512]) in the checkpoint and torch.Size([10, 512]) in the model instantiated\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Downloading (…)rocessor_config.json: 100% 266/266 [00:00<00:00, 777kB/s]\n","[INFO|image_processing_utils.py:369] 2023-09-07 16:31:47,638 >> loading configuration file preprocessor_config.json from cache at /root/.cache/huggingface/hub/models--microsoft--resnet-18/snapshots/f45a6faa12e0381f5620c5c8d7e916bca90f2c44/preprocessor_config.json\n","[WARNING|image_processing_auto.py:355] 2023-09-07 16:31:47,638 >> Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n","[INFO|image_processing_utils.py:732] 2023-09-07 16:31:47,640 >> size should be a dictionary on of the following set of keys: ({'height', 'width'}, {'shortest_edge'}, {'shortest_edge', 'longest_edge'}, {'longest_edge'}), got 224. Converted to {'shortest_edge': 224}.\n","[INFO|image_processing_utils.py:419] 2023-09-07 16:31:47,640 >> Image processor ConvNextImageProcessor {\n","  \"crop_pct\": 0.875,\n","  \"do_normalize\": true,\n","  \"do_rescale\": true,\n","  \"do_resize\": true,\n","  \"image_mean\": [\n","    0.485,\n","    0.456,\n","    0.406\n","  ],\n","  \"image_processor_type\": \"ConvNextImageProcessor\",\n","  \"image_std\": [\n","    0.229,\n","    0.224,\n","    0.225\n","  ],\n","  \"resample\": 3,\n","  \"rescale_factor\": 0.00392156862745098,\n","  \"size\": {\n","    \"shortest_edge\": 224\n","  }\n","}\n","\n","[INFO|trainer.py:1740] 2023-09-07 16:31:53,021 >> ***** Running training *****\n","[INFO|trainer.py:1741] 2023-09-07 16:31:53,022 >>   Num examples = 51,000\n","[INFO|trainer.py:1742] 2023-09-07 16:31:53,022 >>   Num Epochs = 300\n","[INFO|trainer.py:1743] 2023-09-07 16:31:53,022 >>   Instantaneous batch size per device = 512\n","[INFO|trainer.py:1746] 2023-09-07 16:31:53,022 >>   Total train batch size (w. parallel, distributed & accumulation) = 512\n","[INFO|trainer.py:1747] 2023-09-07 16:31:53,022 >>   Gradient Accumulation steps = 1\n","[INFO|trainer.py:1748] 2023-09-07 16:31:53,023 >>   Total optimization steps = 30,000\n","[INFO|trainer.py:1749] 2023-09-07 16:31:53,023 >>   Number of trainable parameters = 11,181,642\n","[INFO|integration_utils.py:716] 2023-09-07 16:31:53,024 >> Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n","{'loss': 1.1039, 'learning_rate': 0.0009996666666666667, 'epoch': 0.1}\n","{'loss': 0.6209, 'learning_rate': 0.0009993333333333334, 'epoch': 0.2}\n","{'loss': 0.5481, 'learning_rate': 0.000999, 'epoch': 0.3}\n","{'loss': 0.5303, 'learning_rate': 0.0009986666666666668, 'epoch': 0.4}\n","{'loss': 0.4927, 'learning_rate': 0.0009983333333333333, 'epoch': 0.5}\n","{'loss': 0.4802, 'learning_rate': 0.000998, 'epoch': 0.6}\n","{'loss': 0.4672, 'learning_rate': 0.0009976666666666667, 'epoch': 0.7}\n","{'loss': 0.4439, 'learning_rate': 0.0009973333333333334, 'epoch': 0.8}\n","{'loss': 0.4408, 'learning_rate': 0.000997, 'epoch': 0.9}\n","{'loss': 0.4544, 'learning_rate': 0.0009966666666666668, 'epoch': 1.0}\n","  0% 100/30000 [02:01<6:55:53,  1.20it/s][INFO|trainer.py:3160] 2023-09-07 16:33:54,767 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3162] 2023-09-07 16:33:54,767 >>   Num examples = 9000\n","[INFO|trainer.py:3165] 2023-09-07 16:33:54,767 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.53it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.86it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.62it/s]\u001b[A\n"," 28% 5/18 [00:03<00:08,  1.51it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.47it/s]\u001b[A\n"," 39% 7/18 [00:04<00:07,  1.44it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.41it/s]\u001b[A\n"," 50% 9/18 [00:05<00:06,  1.41it/s]\u001b[A\n"," 56% 10/18 [00:06<00:05,  1.38it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.36it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.35it/s]\u001b[A\n"," 72% 13/18 [00:08<00:03,  1.34it/s]\u001b[A\n"," 78% 14/18 [00:09<00:02,  1.34it/s]\u001b[A\n"," 83% 15/18 [00:10<00:02,  1.34it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.25it/s]\u001b[A\n","                                         \n","\u001b[A{'eval_loss': 0.059951964765787125, 'eval_accuracy': 0.982, 'eval_runtime': 13.5249, 'eval_samples_per_second': 665.44, 'eval_steps_per_second': 1.331, 'epoch': 1.0}\n","  0% 100/30000 [02:15<6:55:53,  1.20it/s]\n","100% 18/18 [00:11<00:00,  1.41it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2886] 2023-09-07 16:34:08,296 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-100\n","[INFO|configuration_utils.py:460] 2023-09-07 16:34:08,302 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-100/config.json\n","[INFO|modeling_utils.py:1988] 2023-09-07 16:34:08,417 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-100/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 16:34:08,422 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-100/preprocessor_config.json\n","{'loss': 0.431, 'learning_rate': 0.0009963333333333332, 'epoch': 1.1}\n","{'loss': 0.413, 'learning_rate': 0.000996, 'epoch': 1.2}\n","{'loss': 0.4075, 'learning_rate': 0.0009956666666666666, 'epoch': 1.3}\n","{'loss': 0.4116, 'learning_rate': 0.0009953333333333333, 'epoch': 1.4}\n","{'loss': 0.4273, 'learning_rate': 0.000995, 'epoch': 1.5}\n","{'loss': 0.3813, 'learning_rate': 0.0009946666666666667, 'epoch': 1.6}\n","{'loss': 0.3876, 'learning_rate': 0.0009943333333333334, 'epoch': 1.7}\n","{'loss': 0.4089, 'learning_rate': 0.000994, 'epoch': 1.8}\n","{'loss': 0.382, 'learning_rate': 0.0009936666666666668, 'epoch': 1.9}\n","{'loss': 0.3942, 'learning_rate': 0.0009933333333333333, 'epoch': 2.0}\n","  1% 200/30000 [04:08<6:38:32,  1.25it/s][INFO|trainer.py:3160] 2023-09-07 16:36:01,892 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3162] 2023-09-07 16:36:01,893 >>   Num examples = 9000\n","[INFO|trainer.py:3165] 2023-09-07 16:36:01,893 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:05,  2.77it/s]\u001b[A\n"," 17% 3/18 [00:01<00:07,  1.88it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.60it/s]\u001b[A\n"," 28% 5/18 [00:03<00:08,  1.49it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.38it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.30it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.26it/s]\u001b[A\n"," 50% 9/18 [00:06<00:06,  1.30it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.31it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.32it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.33it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.33it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.32it/s]\u001b[A\n"," 83% 15/18 [00:10<00:02,  1.32it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.33it/s]\u001b[A\n","                                         \n","\u001b[A{'eval_loss': 1.5393223762512207, 'eval_accuracy': 0.6307777777777778, 'eval_runtime': 13.4928, 'eval_samples_per_second': 667.023, 'eval_steps_per_second': 1.334, 'epoch': 2.0}\n","  1% 200/30000 [04:22<6:38:32,  1.25it/s]\n","100% 18/18 [00:12<00:00,  1.52it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2886] 2023-09-07 16:36:15,407 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-200\n","[INFO|configuration_utils.py:460] 2023-09-07 16:36:15,412 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-200/config.json\n","[INFO|modeling_utils.py:1988] 2023-09-07 16:36:15,519 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-200/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 16:36:15,524 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-200/preprocessor_config.json\n","{'loss': 0.3854, 'learning_rate': 0.000993, 'epoch': 2.1}\n","{'loss': 0.4188, 'learning_rate': 0.0009926666666666667, 'epoch': 2.2}\n","{'loss': 0.3866, 'learning_rate': 0.0009923333333333333, 'epoch': 2.3}\n","{'loss': 0.3585, 'learning_rate': 0.000992, 'epoch': 2.4}\n","{'loss': 0.3677, 'learning_rate': 0.0009916666666666667, 'epoch': 2.5}\n","{'loss': 0.3876, 'learning_rate': 0.0009913333333333332, 'epoch': 2.6}\n","{'loss': 0.357, 'learning_rate': 0.000991, 'epoch': 2.7}\n","{'loss': 0.3886, 'learning_rate': 0.0009906666666666668, 'epoch': 2.8}\n","{'loss': 0.3868, 'learning_rate': 0.0009903333333333333, 'epoch': 2.9}\n","{'loss': 0.3808, 'learning_rate': 0.00099, 'epoch': 3.0}\n","  1% 300/30000 [06:15<6:44:38,  1.22it/s][INFO|trainer.py:3160] 2023-09-07 16:38:08,737 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3162] 2023-09-07 16:38:08,737 >>   Num examples = 9000\n","[INFO|trainer.py:3165] 2023-09-07 16:38:08,738 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:05,  2.77it/s]\u001b[A\n"," 17% 3/18 [00:01<00:07,  1.95it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.66it/s]\u001b[A\n"," 28% 5/18 [00:02<00:08,  1.57it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.49it/s]\u001b[A\n"," 39% 7/18 [00:04<00:07,  1.41it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.40it/s]\u001b[A\n"," 50% 9/18 [00:05<00:06,  1.37it/s]\u001b[A\n"," 56% 10/18 [00:06<00:06,  1.32it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.31it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.30it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.30it/s]\u001b[A\n"," 78% 14/18 [00:09<00:03,  1.26it/s]\u001b[A\n"," 83% 15/18 [00:10<00:02,  1.24it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.25it/s]\u001b[A\n","                                         \n","\u001b[A{'eval_loss': 0.05217766389250755, 'eval_accuracy': 0.9835555555555555, 'eval_runtime': 13.5475, 'eval_samples_per_second': 664.328, 'eval_steps_per_second': 1.329, 'epoch': 3.0}\n","  1% 300/30000 [06:29<6:44:38,  1.22it/s]\n","100% 18/18 [00:12<00:00,  1.44it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2886] 2023-09-07 16:38:22,289 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-300\n","[INFO|configuration_utils.py:460] 2023-09-07 16:38:22,294 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-300/config.json\n","[INFO|modeling_utils.py:1988] 2023-09-07 16:38:22,399 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-300/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 16:38:22,404 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-300/preprocessor_config.json\n","{'loss': 0.3822, 'learning_rate': 0.0009896666666666667, 'epoch': 3.1}\n","{'loss': 0.3773, 'learning_rate': 0.0009893333333333334, 'epoch': 3.2}\n","{'loss': 0.3682, 'learning_rate': 0.000989, 'epoch': 3.3}\n","{'loss': 0.3655, 'learning_rate': 0.0009886666666666668, 'epoch': 3.4}\n","{'loss': 0.3443, 'learning_rate': 0.0009883333333333333, 'epoch': 3.5}\n","{'loss': 0.3713, 'learning_rate': 0.000988, 'epoch': 3.6}\n","{'loss': 0.3886, 'learning_rate': 0.0009876666666666666, 'epoch': 3.7}\n","{'loss': 0.3416, 'learning_rate': 0.0009873333333333333, 'epoch': 3.8}\n","{'loss': 0.3671, 'learning_rate': 0.000987, 'epoch': 3.9}\n","{'loss': 0.3287, 'learning_rate': 0.0009866666666666667, 'epoch': 4.0}\n","  1% 400/30000 [08:20<6:23:32,  1.29it/s][INFO|trainer.py:3160] 2023-09-07 16:40:13,873 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3162] 2023-09-07 16:40:13,873 >>   Num examples = 9000\n","[INFO|trainer.py:3165] 2023-09-07 16:40:13,873 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:07,  2.26it/s]\u001b[A\n"," 17% 3/18 [00:01<00:09,  1.66it/s]\u001b[A\n"," 22% 4/18 [00:02<00:09,  1.48it/s]\u001b[A\n"," 28% 5/18 [00:03<00:09,  1.38it/s]\u001b[A\n"," 33% 6/18 [00:04<00:09,  1.32it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.32it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.33it/s]\u001b[A\n"," 50% 9/18 [00:06<00:07,  1.28it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.30it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.31it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.28it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.30it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.32it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.33it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.33it/s]\u001b[A\n","                                         \n","\u001b[A{'eval_loss': 0.1857987940311432, 'eval_accuracy': 0.9398888888888889, 'eval_runtime': 13.9844, 'eval_samples_per_second': 643.576, 'eval_steps_per_second': 1.287, 'epoch': 4.0}\n","  1% 400/30000 [08:34<6:23:32,  1.29it/s]\n","100% 18/18 [00:12<00:00,  1.49it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2886] 2023-09-07 16:40:27,862 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-400\n","[INFO|configuration_utils.py:460] 2023-09-07 16:40:27,867 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-400/config.json\n","[INFO|modeling_utils.py:1988] 2023-09-07 16:40:27,974 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-400/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 16:40:27,978 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-400/preprocessor_config.json\n","[INFO|trainer.py:2973] 2023-09-07 16:40:28,210 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-100] due to args.save_total_limit\n","{'loss': 0.3423, 'learning_rate': 0.0009863333333333332, 'epoch': 4.1}\n","{'loss': 0.323, 'learning_rate': 0.0009860000000000001, 'epoch': 4.2}\n","{'loss': 0.3625, 'learning_rate': 0.0009856666666666668, 'epoch': 4.3}\n","{'loss': 0.3395, 'learning_rate': 0.0009853333333333333, 'epoch': 4.4}\n","{'loss': 0.3466, 'learning_rate': 0.000985, 'epoch': 4.5}\n","{'loss': 0.3471, 'learning_rate': 0.0009846666666666667, 'epoch': 4.6}\n","{'loss': 0.3571, 'learning_rate': 0.0009843333333333334, 'epoch': 4.7}\n","{'loss': 0.3389, 'learning_rate': 0.000984, 'epoch': 4.8}\n","{'loss': 0.3361, 'learning_rate': 0.0009836666666666668, 'epoch': 4.9}\n","{'loss': 0.3417, 'learning_rate': 0.0009833333333333332, 'epoch': 5.0}\n","  2% 500/30000 [10:28<6:30:47,  1.26it/s][INFO|trainer.py:3160] 2023-09-07 16:42:21,556 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3162] 2023-09-07 16:42:21,556 >>   Num examples = 9000\n","[INFO|trainer.py:3165] 2023-09-07 16:42:21,556 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:01<00:08,  1.97it/s]\u001b[A\n"," 17% 3/18 [00:01<00:09,  1.55it/s]\u001b[A\n"," 22% 4/18 [00:02<00:09,  1.48it/s]\u001b[A\n"," 28% 5/18 [00:03<00:09,  1.32it/s]\u001b[A\n"," 33% 6/18 [00:04<00:09,  1.22it/s]\u001b[A\n"," 39% 7/18 [00:05<00:08,  1.26it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.26it/s]\u001b[A\n"," 50% 9/18 [00:06<00:07,  1.23it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.23it/s]\u001b[A\n"," 61% 11/18 [00:08<00:05,  1.22it/s]\u001b[A\n"," 67% 12/18 [00:09<00:05,  1.16it/s]\u001b[A\n"," 72% 13/18 [00:10<00:04,  1.13it/s]\u001b[A\n"," 78% 14/18 [00:11<00:03,  1.00it/s]\u001b[A\n"," 83% 15/18 [00:12<00:02,  1.02it/s]\u001b[A\n"," 89% 16/18 [00:13<00:02,  1.04s/it]\u001b[A\n","                                         \n","\u001b[A{'eval_loss': 0.08026368916034698, 'eval_accuracy': 0.9757777777777777, 'eval_runtime': 16.3801, 'eval_samples_per_second': 549.449, 'eval_steps_per_second': 1.099, 'epoch': 5.0}\n","  2% 500/30000 [10:44<6:30:47,  1.26it/s]\n","100% 18/18 [00:14<00:00,  1.09it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2886] 2023-09-07 16:42:37,941 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-500\n","[INFO|configuration_utils.py:460] 2023-09-07 16:42:37,947 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-500/config.json\n","[INFO|modeling_utils.py:1988] 2023-09-07 16:42:38,064 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-500/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 16:42:38,069 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-500/preprocessor_config.json\n","[INFO|trainer.py:2973] 2023-09-07 16:42:38,301 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-200] due to args.save_total_limit\n","{'loss': 0.3485, 'learning_rate': 0.000983, 'epoch': 5.1}\n","{'loss': 0.3283, 'learning_rate': 0.0009826666666666666, 'epoch': 5.2}\n","{'loss': 0.3327, 'learning_rate': 0.0009823333333333333, 'epoch': 5.3}\n","{'loss': 0.3451, 'learning_rate': 0.000982, 'epoch': 5.4}\n","{'loss': 0.3296, 'learning_rate': 0.0009816666666666667, 'epoch': 5.5}\n","{'loss': 0.3535, 'learning_rate': 0.0009813333333333334, 'epoch': 5.6}\n","{'loss': 0.3371, 'learning_rate': 0.000981, 'epoch': 5.7}\n","{'loss': 0.3437, 'learning_rate': 0.0009806666666666668, 'epoch': 5.8}\n","{'loss': 0.3265, 'learning_rate': 0.0009803333333333333, 'epoch': 5.9}\n","{'loss': 0.332, 'learning_rate': 0.00098, 'epoch': 6.0}\n","  2% 600/30000 [12:35<6:38:22,  1.23it/s][INFO|trainer.py:3160] 2023-09-07 16:44:28,925 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3162] 2023-09-07 16:44:28,925 >>   Num examples = 9000\n","[INFO|trainer.py:3165] 2023-09-07 16:44:28,925 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.66it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.86it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.61it/s]\u001b[A\n"," 28% 5/18 [00:03<00:08,  1.50it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.45it/s]\u001b[A\n"," 39% 7/18 [00:04<00:07,  1.41it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.38it/s]\u001b[A\n"," 50% 9/18 [00:06<00:06,  1.37it/s]\u001b[A\n"," 56% 10/18 [00:06<00:05,  1.36it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.35it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.33it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.31it/s]\u001b[A\n"," 78% 14/18 [00:09<00:03,  1.27it/s]\u001b[A\n"," 83% 15/18 [00:10<00:02,  1.24it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.23it/s]\u001b[A\n","                                         \n","\u001b[A{'eval_loss': 0.04365480691194534, 'eval_accuracy': 0.9864444444444445, 'eval_runtime': 13.7301, 'eval_samples_per_second': 655.494, 'eval_steps_per_second': 1.311, 'epoch': 6.0}\n","  2% 600/30000 [12:49<6:38:22,  1.23it/s]\n","100% 18/18 [00:12<00:00,  1.39it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2886] 2023-09-07 16:44:42,660 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-600\n","[INFO|configuration_utils.py:460] 2023-09-07 16:44:42,667 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-600/config.json\n","[INFO|modeling_utils.py:1988] 2023-09-07 16:44:42,775 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-600/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 16:44:42,780 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-600/preprocessor_config.json\n","[INFO|trainer.py:2973] 2023-09-07 16:44:42,992 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-300] due to args.save_total_limit\n","{'loss': 0.3557, 'learning_rate': 0.0009796666666666667, 'epoch': 6.1}\n","{'loss': 0.3407, 'learning_rate': 0.0009793333333333334, 'epoch': 6.2}\n","{'loss': 0.337, 'learning_rate': 0.000979, 'epoch': 6.3}\n","{'loss': 0.3415, 'learning_rate': 0.0009786666666666667, 'epoch': 6.4}\n","{'loss': 0.3125, 'learning_rate': 0.0009783333333333334, 'epoch': 6.5}\n","{'loss': 0.3308, 'learning_rate': 0.000978, 'epoch': 6.6}\n","{'loss': 0.3047, 'learning_rate': 0.0009776666666666666, 'epoch': 6.7}\n","{'loss': 0.3342, 'learning_rate': 0.0009773333333333333, 'epoch': 6.8}\n","{'loss': 0.3278, 'learning_rate': 0.000977, 'epoch': 6.9}\n","{'loss': 0.3236, 'learning_rate': 0.0009766666666666667, 'epoch': 7.0}\n","  2% 700/30000 [14:42<6:44:17,  1.21it/s][INFO|trainer.py:3160] 2023-09-07 16:46:35,876 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3162] 2023-09-07 16:46:35,876 >>   Num examples = 9000\n","[INFO|trainer.py:3165] 2023-09-07 16:46:35,876 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.39it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.71it/s]\u001b[A\n"," 22% 4/18 [00:02<00:09,  1.51it/s]\u001b[A\n"," 28% 5/18 [00:03<00:08,  1.46it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.42it/s]\u001b[A\n"," 39% 7/18 [00:04<00:07,  1.39it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.37it/s]\u001b[A\n"," 50% 9/18 [00:06<00:06,  1.34it/s]\u001b[A\n"," 56% 10/18 [00:06<00:05,  1.34it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.34it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.34it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.34it/s]\u001b[A\n"," 78% 14/18 [00:09<00:03,  1.32it/s]\u001b[A\n"," 83% 15/18 [00:10<00:02,  1.33it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.32it/s]\u001b[A\n","                                         \n","\u001b[A{'eval_loss': 0.039462003856897354, 'eval_accuracy': 0.9878888888888889, 'eval_runtime': 13.6942, 'eval_samples_per_second': 657.211, 'eval_steps_per_second': 1.314, 'epoch': 7.0}\n","  2% 700/30000 [14:56<6:44:17,  1.21it/s]\n","100% 18/18 [00:12<00:00,  1.49it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2886] 2023-09-07 16:46:49,575 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-700\n","[INFO|configuration_utils.py:460] 2023-09-07 16:46:49,581 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-700/config.json\n","[INFO|modeling_utils.py:1988] 2023-09-07 16:46:49,720 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-700/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 16:46:49,725 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-700/preprocessor_config.json\n","[INFO|trainer.py:2973] 2023-09-07 16:46:49,940 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-400] due to args.save_total_limit\n","{'loss': 0.3219, 'learning_rate': 0.0009763333333333334, 'epoch': 7.1}\n","{'loss': 0.3464, 'learning_rate': 0.000976, 'epoch': 7.2}\n","{'loss': 0.333, 'learning_rate': 0.0009756666666666667, 'epoch': 7.3}\n","{'loss': 0.3318, 'learning_rate': 0.0009753333333333334, 'epoch': 7.4}\n","{'loss': 0.3229, 'learning_rate': 0.000975, 'epoch': 7.5}\n","{'loss': 0.3279, 'learning_rate': 0.0009746666666666666, 'epoch': 7.6}\n","{'loss': 0.2978, 'learning_rate': 0.0009743333333333335, 'epoch': 7.7}\n","{'loss': 0.3165, 'learning_rate': 0.000974, 'epoch': 7.8}\n","{'loss': 0.3588, 'learning_rate': 0.0009736666666666667, 'epoch': 7.9}\n","{'loss': 0.3168, 'learning_rate': 0.0009733333333333334, 'epoch': 8.0}\n","  3% 800/30000 [16:50<6:30:50,  1.25it/s][INFO|trainer.py:3160] 2023-09-07 16:48:43,632 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3162] 2023-09-07 16:48:43,632 >>   Num examples = 9000\n","[INFO|trainer.py:3165] 2023-09-07 16:48:43,632 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.30it/s]\u001b[A\n"," 17% 3/18 [00:01<00:09,  1.59it/s]\u001b[A\n"," 22% 4/18 [00:02<00:09,  1.45it/s]\u001b[A\n"," 28% 5/18 [00:03<00:09,  1.40it/s]\u001b[A\n"," 33% 6/18 [00:04<00:09,  1.31it/s]\u001b[A\n"," 39% 7/18 [00:05<00:08,  1.27it/s]\u001b[A\n"," 44% 8/18 [00:05<00:08,  1.24it/s]\u001b[A\n"," 50% 9/18 [00:06<00:07,  1.27it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.29it/s]\u001b[A\n"," 61% 11/18 [00:08<00:05,  1.29it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.30it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.29it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.31it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.32it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.32it/s]\u001b[A\n","                                         \n","\u001b[A{'eval_loss': 0.05523703992366791, 'eval_accuracy': 0.9834444444444445, 'eval_runtime': 14.0504, 'eval_samples_per_second': 640.551, 'eval_steps_per_second': 1.281, 'epoch': 8.0}\n","  3% 800/30000 [17:04<6:30:50,  1.25it/s]\n","100% 18/18 [00:12<00:00,  1.46it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2886] 2023-09-07 16:48:57,687 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-800\n","[INFO|configuration_utils.py:460] 2023-09-07 16:48:57,693 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-800/config.json\n","[INFO|modeling_utils.py:1988] 2023-09-07 16:48:57,805 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-800/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 16:48:57,810 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-800/preprocessor_config.json\n","[INFO|trainer.py:2973] 2023-09-07 16:48:58,031 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-500] due to args.save_total_limit\n","{'loss': 0.3167, 'learning_rate': 0.000973, 'epoch': 8.1}\n","{'loss': 0.3422, 'learning_rate': 0.0009726666666666667, 'epoch': 8.2}\n","{'loss': 0.3495, 'learning_rate': 0.0009723333333333334, 'epoch': 8.3}\n","{'loss': 0.3162, 'learning_rate': 0.000972, 'epoch': 8.4}\n","{'loss': 0.329, 'learning_rate': 0.0009716666666666667, 'epoch': 8.5}\n","{'loss': 0.326, 'learning_rate': 0.0009713333333333334, 'epoch': 8.6}\n","{'loss': 0.3239, 'learning_rate': 0.000971, 'epoch': 8.7}\n","{'loss': 0.3095, 'learning_rate': 0.0009706666666666667, 'epoch': 8.8}\n","{'loss': 0.3253, 'learning_rate': 0.0009703333333333334, 'epoch': 8.9}\n","{'loss': 0.3117, 'learning_rate': 0.0009699999999999999, 'epoch': 9.0}\n","  3% 900/30000 [18:59<6:43:50,  1.20it/s][INFO|trainer.py:3160] 2023-09-07 16:50:52,390 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3162] 2023-09-07 16:50:52,390 >>   Num examples = 9000\n","[INFO|trainer.py:3165] 2023-09-07 16:50:52,391 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.61it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.87it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.63it/s]\u001b[A\n"," 28% 5/18 [00:03<00:08,  1.48it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.42it/s]\u001b[A\n"," 39% 7/18 [00:04<00:07,  1.38it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.30it/s]\u001b[A\n"," 50% 9/18 [00:06<00:06,  1.29it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.24it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.21it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.20it/s]\u001b[A\n"," 72% 13/18 [00:09<00:04,  1.22it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.25it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.28it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.29it/s]\u001b[A\n","                                         \n","\u001b[A{'eval_loss': 0.04949919134378433, 'eval_accuracy': 0.9846666666666667, 'eval_runtime': 13.9782, 'eval_samples_per_second': 643.861, 'eval_steps_per_second': 1.288, 'epoch': 9.0}\n","  3% 900/30000 [19:13<6:43:50,  1.20it/s]\n","100% 18/18 [00:12<00:00,  1.45it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2886] 2023-09-07 16:51:06,372 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-900\n","[INFO|configuration_utils.py:460] 2023-09-07 16:51:06,378 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-900/config.json\n","[INFO|modeling_utils.py:1988] 2023-09-07 16:51:06,487 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-900/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 16:51:06,493 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-900/preprocessor_config.json\n","[INFO|trainer.py:2973] 2023-09-07 16:51:06,713 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-600] due to args.save_total_limit\n","{'loss': 0.3119, 'learning_rate': 0.0009696666666666667, 'epoch': 9.1}\n","{'loss': 0.3323, 'learning_rate': 0.0009693333333333334, 'epoch': 9.2}\n","{'loss': 0.3229, 'learning_rate': 0.000969, 'epoch': 9.3}\n","{'loss': 0.3144, 'learning_rate': 0.0009686666666666667, 'epoch': 9.4}\n","{'loss': 0.3099, 'learning_rate': 0.0009683333333333334, 'epoch': 9.5}\n","{'loss': 0.3159, 'learning_rate': 0.000968, 'epoch': 9.6}\n","{'loss': 0.3382, 'learning_rate': 0.0009676666666666667, 'epoch': 9.7}\n","{'loss': 0.3169, 'learning_rate': 0.0009673333333333334, 'epoch': 9.8}\n","{'loss': 0.3137, 'learning_rate': 0.000967, 'epoch': 9.9}\n","{'loss': 0.3026, 'learning_rate': 0.0009666666666666667, 'epoch': 10.0}\n","  3% 1000/30000 [21:06<6:38:18,  1.21it/s][INFO|trainer.py:3160] 2023-09-07 16:52:59,975 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3162] 2023-09-07 16:52:59,975 >>   Num examples = 9000\n","[INFO|trainer.py:3165] 2023-09-07 16:52:59,975 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:05,  2.73it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.83it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.64it/s]\u001b[A\n"," 28% 5/18 [00:02<00:08,  1.54it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.47it/s]\u001b[A\n"," 39% 7/18 [00:04<00:07,  1.44it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.41it/s]\u001b[A\n"," 50% 9/18 [00:05<00:06,  1.40it/s]\u001b[A\n"," 56% 10/18 [00:06<00:06,  1.32it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.32it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.32it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.26it/s]\u001b[A\n"," 78% 14/18 [00:09<00:03,  1.25it/s]\u001b[A\n"," 83% 15/18 [00:10<00:02,  1.25it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.24it/s]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 0.0435301698744297, 'eval_accuracy': 0.9853333333333333, 'eval_runtime': 13.5936, 'eval_samples_per_second': 662.076, 'eval_steps_per_second': 1.324, 'epoch': 10.0}\n","  3% 1000/30000 [21:20<6:38:18,  1.21it/s]\n","100% 18/18 [00:12<00:00,  1.40it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2886] 2023-09-07 16:53:13,574 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-1000\n","[INFO|configuration_utils.py:460] 2023-09-07 16:53:13,580 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-1000/config.json\n","[INFO|modeling_utils.py:1988] 2023-09-07 16:53:13,694 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-1000/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 16:53:13,699 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-1000/preprocessor_config.json\n","[INFO|trainer.py:2973] 2023-09-07 16:53:13,918 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-800] due to args.save_total_limit\n","{'loss': 0.3147, 'learning_rate': 0.0009663333333333334, 'epoch': 10.1}\n","{'loss': 0.2974, 'learning_rate': 0.000966, 'epoch': 10.2}\n","{'loss': 0.3112, 'learning_rate': 0.0009656666666666666, 'epoch': 10.3}\n","{'loss': 0.3113, 'learning_rate': 0.0009653333333333333, 'epoch': 10.4}\n","{'loss': 0.3094, 'learning_rate': 0.000965, 'epoch': 10.5}\n","{'loss': 0.3197, 'learning_rate': 0.0009646666666666667, 'epoch': 10.6}\n","{'loss': 0.3181, 'learning_rate': 0.0009643333333333334, 'epoch': 10.7}\n","{'loss': 0.2931, 'learning_rate': 0.000964, 'epoch': 10.8}\n","{'loss': 0.299, 'learning_rate': 0.0009636666666666667, 'epoch': 10.9}\n","{'loss': 0.3161, 'learning_rate': 0.0009633333333333334, 'epoch': 11.0}\n","  4% 1100/30000 [23:11<6:21:06,  1.26it/s][INFO|trainer.py:3160] 2023-09-07 16:55:05,000 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3162] 2023-09-07 16:55:05,001 >>   Num examples = 9000\n","[INFO|trainer.py:3165] 2023-09-07 16:55:05,001 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.53it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.78it/s]\u001b[A\n"," 22% 4/18 [00:02<00:09,  1.53it/s]\u001b[A\n"," 28% 5/18 [00:03<00:09,  1.41it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.39it/s]\u001b[A\n"," 39% 7/18 [00:04<00:07,  1.38it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.36it/s]\u001b[A\n"," 50% 9/18 [00:06<00:06,  1.33it/s]\u001b[A\n"," 56% 10/18 [00:06<00:05,  1.34it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.35it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.35it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.34it/s]\u001b[A\n"," 78% 14/18 [00:09<00:02,  1.36it/s]\u001b[A\n"," 83% 15/18 [00:10<00:02,  1.36it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.36it/s]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 0.03461219742894173, 'eval_accuracy': 0.9895555555555555, 'eval_runtime': 13.4516, 'eval_samples_per_second': 669.067, 'eval_steps_per_second': 1.338, 'epoch': 11.0}\n","  4% 1100/30000 [23:25<6:21:06,  1.26it/s]\n","100% 18/18 [00:11<00:00,  1.53it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2886] 2023-09-07 16:55:18,456 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-1100\n","[INFO|configuration_utils.py:460] 2023-09-07 16:55:18,461 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-1100/config.json\n","[INFO|modeling_utils.py:1988] 2023-09-07 16:55:18,567 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-1100/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 16:55:18,571 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-1100/preprocessor_config.json\n","[INFO|trainer.py:2973] 2023-09-07 16:55:18,798 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-700] due to args.save_total_limit\n","{'loss': 0.3074, 'learning_rate': 0.000963, 'epoch': 11.1}\n","{'loss': 0.3059, 'learning_rate': 0.0009626666666666667, 'epoch': 11.2}\n","{'loss': 0.3184, 'learning_rate': 0.0009623333333333334, 'epoch': 11.3}\n","{'loss': 0.3099, 'learning_rate': 0.000962, 'epoch': 11.4}\n","{'loss': 0.3166, 'learning_rate': 0.0009616666666666667, 'epoch': 11.5}\n","{'loss': 0.3128, 'learning_rate': 0.0009613333333333334, 'epoch': 11.6}\n","{'loss': 0.3208, 'learning_rate': 0.0009609999999999999, 'epoch': 11.7}\n","{'loss': 0.3175, 'learning_rate': 0.0009606666666666666, 'epoch': 11.8}\n","{'loss': 0.3042, 'learning_rate': 0.0009603333333333334, 'epoch': 11.9}\n","{'loss': 0.2921, 'learning_rate': 0.00096, 'epoch': 12.0}\n","  4% 1200/30000 [25:18<6:26:01,  1.24it/s][INFO|trainer.py:3160] 2023-09-07 16:57:11,374 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3162] 2023-09-07 16:57:11,374 >>   Num examples = 9000\n","[INFO|trainer.py:3165] 2023-09-07 16:57:11,374 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.66it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.74it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.58it/s]\u001b[A\n"," 28% 5/18 [00:03<00:08,  1.48it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.42it/s]\u001b[A\n"," 39% 7/18 [00:04<00:07,  1.40it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.29it/s]\u001b[A\n"," 50% 9/18 [00:06<00:06,  1.30it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.27it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.25it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.24it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.27it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.29it/s]\u001b[A\n"," 83% 15/18 [00:10<00:02,  1.31it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.33it/s]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 0.07777218520641327, 'eval_accuracy': 0.9743333333333334, 'eval_runtime': 13.7472, 'eval_samples_per_second': 654.68, 'eval_steps_per_second': 1.309, 'epoch': 12.0}\n","  4% 1200/30000 [25:32<6:26:01,  1.24it/s]\n","100% 18/18 [00:12<00:00,  1.50it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2886] 2023-09-07 16:57:25,125 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-1200\n","[INFO|configuration_utils.py:460] 2023-09-07 16:57:25,130 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-1200/config.json\n","[INFO|modeling_utils.py:1988] 2023-09-07 16:57:25,236 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-1200/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 16:57:25,241 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-1200/preprocessor_config.json\n","[INFO|trainer.py:2973] 2023-09-07 16:57:25,458 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-900] due to args.save_total_limit\n","{'loss': 0.2959, 'learning_rate': 0.0009596666666666667, 'epoch': 12.1}\n","{'loss': 0.2959, 'learning_rate': 0.0009593333333333334, 'epoch': 12.2}\n","{'loss': 0.2822, 'learning_rate': 0.000959, 'epoch': 12.3}\n","{'loss': 0.3014, 'learning_rate': 0.0009586666666666667, 'epoch': 12.4}\n","{'loss': 0.3025, 'learning_rate': 0.0009583333333333334, 'epoch': 12.5}\n","{'loss': 0.3066, 'learning_rate': 0.000958, 'epoch': 12.6}\n","{'loss': 0.3107, 'learning_rate': 0.0009576666666666667, 'epoch': 12.7}\n","{'loss': 0.2843, 'learning_rate': 0.0009573333333333334, 'epoch': 12.8}\n","{'loss': 0.3133, 'learning_rate': 0.000957, 'epoch': 12.9}\n","{'loss': 0.3082, 'learning_rate': 0.0009566666666666666, 'epoch': 13.0}\n","  4% 1300/30000 [27:25<6:44:14,  1.18it/s][INFO|trainer.py:3160] 2023-09-07 16:59:18,031 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3162] 2023-09-07 16:59:18,031 >>   Num examples = 9000\n","[INFO|trainer.py:3165] 2023-09-07 16:59:18,031 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:05,  2.68it/s]\u001b[A\n"," 17% 3/18 [00:01<00:07,  1.92it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.66it/s]\u001b[A\n"," 28% 5/18 [00:02<00:08,  1.52it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.44it/s]\u001b[A\n"," 39% 7/18 [00:04<00:07,  1.42it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.41it/s]\u001b[A\n"," 50% 9/18 [00:05<00:06,  1.40it/s]\u001b[A\n"," 56% 10/18 [00:06<00:05,  1.38it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.37it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.37it/s]\u001b[A\n"," 72% 13/18 [00:08<00:03,  1.37it/s]\u001b[A\n"," 78% 14/18 [00:09<00:02,  1.37it/s]\u001b[A\n"," 83% 15/18 [00:10<00:02,  1.34it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.33it/s]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 0.0422612726688385, 'eval_accuracy': 0.9872222222222222, 'eval_runtime': 13.3668, 'eval_samples_per_second': 673.312, 'eval_steps_per_second': 1.347, 'epoch': 13.0}\n","  4% 1300/30000 [27:38<6:44:14,  1.18it/s]\n","100% 18/18 [00:11<00:00,  1.46it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2886] 2023-09-07 16:59:31,402 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-1300\n","[INFO|configuration_utils.py:460] 2023-09-07 16:59:31,408 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-1300/config.json\n","[INFO|modeling_utils.py:1988] 2023-09-07 16:59:31,522 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-1300/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 16:59:31,527 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-1300/preprocessor_config.json\n","[INFO|trainer.py:2973] 2023-09-07 16:59:31,753 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-1000] due to args.save_total_limit\n","{'loss': 0.3105, 'learning_rate': 0.0009563333333333333, 'epoch': 13.1}\n","{'loss': 0.31, 'learning_rate': 0.0009559999999999999, 'epoch': 13.2}\n","{'loss': 0.2949, 'learning_rate': 0.0009556666666666667, 'epoch': 13.3}\n","{'loss': 0.3099, 'learning_rate': 0.0009553333333333334, 'epoch': 13.4}\n","{'loss': 0.2933, 'learning_rate': 0.000955, 'epoch': 13.5}\n","{'loss': 0.2755, 'learning_rate': 0.0009546666666666667, 'epoch': 13.6}\n","{'loss': 0.288, 'learning_rate': 0.0009543333333333334, 'epoch': 13.7}\n","{'loss': 0.2974, 'learning_rate': 0.000954, 'epoch': 13.8}\n","{'loss': 0.2998, 'learning_rate': 0.0009536666666666667, 'epoch': 13.9}\n","{'loss': 0.3237, 'learning_rate': 0.0009533333333333334, 'epoch': 14.0}\n","  5% 1400/30000 [29:32<6:28:59,  1.23it/s][INFO|trainer.py:3160] 2023-09-07 17:01:25,392 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3162] 2023-09-07 17:01:25,392 >>   Num examples = 9000\n","[INFO|trainer.py:3165] 2023-09-07 17:01:25,392 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.56it/s]\u001b[A\n"," 17% 3/18 [00:01<00:09,  1.53it/s]\u001b[A\n"," 22% 4/18 [00:02<00:09,  1.42it/s]\u001b[A\n"," 28% 5/18 [00:03<00:09,  1.33it/s]\u001b[A\n"," 33% 6/18 [00:04<00:09,  1.25it/s]\u001b[A\n"," 39% 7/18 [00:05<00:08,  1.25it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.27it/s]\u001b[A\n"," 50% 9/18 [00:06<00:06,  1.29it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.31it/s]\u001b[A\n"," 61% 11/18 [00:08<00:05,  1.31it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.32it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.33it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.32it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.33it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.34it/s]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 2.0391290187835693, 'eval_accuracy': 0.5496666666666666, 'eval_runtime': 13.9297, 'eval_samples_per_second': 646.102, 'eval_steps_per_second': 1.292, 'epoch': 14.0}\n","  5% 1400/30000 [29:46<6:28:59,  1.23it/s]\n","100% 18/18 [00:12<00:00,  1.51it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2886] 2023-09-07 17:01:39,326 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-1400\n","[INFO|configuration_utils.py:460] 2023-09-07 17:01:39,332 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-1400/config.json\n","[INFO|modeling_utils.py:1988] 2023-09-07 17:01:39,448 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-1400/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 17:01:39,452 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-1400/preprocessor_config.json\n","[INFO|trainer.py:2973] 2023-09-07 17:01:39,689 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-1200] due to args.save_total_limit\n","{'loss': 0.2885, 'learning_rate': 0.000953, 'epoch': 14.1}\n","{'loss': 0.2962, 'learning_rate': 0.0009526666666666667, 'epoch': 14.2}\n","{'loss': 0.3034, 'learning_rate': 0.0009523333333333334, 'epoch': 14.3}\n","{'loss': 0.3048, 'learning_rate': 0.0009519999999999999, 'epoch': 14.4}\n","{'loss': 0.2981, 'learning_rate': 0.0009516666666666666, 'epoch': 14.5}\n","{'loss': 0.2861, 'learning_rate': 0.0009513333333333334, 'epoch': 14.6}\n","{'loss': 0.2848, 'learning_rate': 0.000951, 'epoch': 14.7}\n","{'loss': 0.2919, 'learning_rate': 0.0009506666666666667, 'epoch': 14.8}\n","{'loss': 0.3281, 'learning_rate': 0.0009503333333333334, 'epoch': 14.9}\n","{'loss': 0.278, 'learning_rate': 0.00095, 'epoch': 15.0}\n","  5% 1500/30000 [31:41<6:19:29,  1.25it/s][INFO|trainer.py:3160] 2023-09-07 17:03:34,251 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3162] 2023-09-07 17:03:34,251 >>   Num examples = 9000\n","[INFO|trainer.py:3165] 2023-09-07 17:03:34,251 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.62it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.84it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.62it/s]\u001b[A\n"," 28% 5/18 [00:03<00:08,  1.51it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.39it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.25it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.27it/s]\u001b[A\n"," 50% 9/18 [00:06<00:07,  1.28it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.25it/s]\u001b[A\n"," 61% 11/18 [00:08<00:05,  1.25it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.23it/s]\u001b[A\n"," 72% 13/18 [00:09<00:04,  1.24it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.26it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.30it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.32it/s]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 0.03554382547736168, 'eval_accuracy': 0.9872222222222222, 'eval_runtime': 13.8917, 'eval_samples_per_second': 647.869, 'eval_steps_per_second': 1.296, 'epoch': 15.0}\n","  5% 1500/30000 [31:55<6:19:29,  1.25it/s]\n","100% 18/18 [00:12<00:00,  1.50it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2886] 2023-09-07 17:03:48,148 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-1500\n","[INFO|configuration_utils.py:460] 2023-09-07 17:03:48,152 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-1500/config.json\n","[INFO|modeling_utils.py:1988] 2023-09-07 17:03:48,256 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-1500/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 17:03:48,261 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-1500/preprocessor_config.json\n","[INFO|trainer.py:2973] 2023-09-07 17:03:48,472 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-1300] due to args.save_total_limit\n","{'loss': 0.2977, 'learning_rate': 0.0009496666666666667, 'epoch': 15.1}\n","{'loss': 0.2922, 'learning_rate': 0.0009493333333333334, 'epoch': 15.2}\n","{'loss': 0.2903, 'learning_rate': 0.000949, 'epoch': 15.3}\n","{'loss': 0.2842, 'learning_rate': 0.0009486666666666667, 'epoch': 15.4}\n","{'loss': 0.2856, 'learning_rate': 0.0009483333333333334, 'epoch': 15.5}\n","{'loss': 0.2792, 'learning_rate': 0.000948, 'epoch': 15.6}\n","{'loss': 0.31, 'learning_rate': 0.0009476666666666666, 'epoch': 15.7}\n","{'loss': 0.3082, 'learning_rate': 0.0009473333333333333, 'epoch': 15.8}\n","{'loss': 0.2872, 'learning_rate': 0.0009469999999999999, 'epoch': 15.9}\n","{'loss': 0.286, 'learning_rate': 0.0009466666666666667, 'epoch': 16.0}\n","  5% 1600/30000 [33:48<6:28:27,  1.22it/s][INFO|trainer.py:3160] 2023-09-07 17:05:41,538 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3162] 2023-09-07 17:05:41,538 >>   Num examples = 9000\n","[INFO|trainer.py:3165] 2023-09-07 17:05:41,538 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:05,  2.76it/s]\u001b[A\n"," 17% 3/18 [00:01<00:07,  1.92it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.68it/s]\u001b[A\n"," 28% 5/18 [00:02<00:08,  1.57it/s]\u001b[A\n"," 33% 6/18 [00:03<00:07,  1.51it/s]\u001b[A\n"," 39% 7/18 [00:04<00:07,  1.47it/s]\u001b[A\n"," 44% 8/18 [00:05<00:06,  1.43it/s]\u001b[A\n"," 50% 9/18 [00:05<00:06,  1.40it/s]\u001b[A\n"," 56% 10/18 [00:06<00:05,  1.40it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.38it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.38it/s]\u001b[A\n"," 72% 13/18 [00:08<00:03,  1.36it/s]\u001b[A\n"," 78% 14/18 [00:09<00:02,  1.35it/s]\u001b[A\n"," 83% 15/18 [00:10<00:02,  1.28it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.27it/s]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 0.0401669442653656, 'eval_accuracy': 0.9871111111111112, 'eval_runtime': 13.4884, 'eval_samples_per_second': 667.242, 'eval_steps_per_second': 1.334, 'epoch': 16.0}\n","  5% 1600/30000 [34:01<6:28:27,  1.22it/s]\n","100% 18/18 [00:11<00:00,  1.41it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2886] 2023-09-07 17:05:55,031 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-1600\n","[INFO|configuration_utils.py:460] 2023-09-07 17:05:55,037 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-1600/config.json\n","[INFO|modeling_utils.py:1988] 2023-09-07 17:05:55,151 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-1600/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 17:05:55,155 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-1600/preprocessor_config.json\n","[INFO|trainer.py:2973] 2023-09-07 17:05:55,374 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-1400] due to args.save_total_limit\n","{'loss': 0.3097, 'learning_rate': 0.0009463333333333334, 'epoch': 16.1}\n","{'loss': 0.2853, 'learning_rate': 0.000946, 'epoch': 16.2}\n","{'loss': 0.2981, 'learning_rate': 0.0009456666666666667, 'epoch': 16.3}\n","{'loss': 0.295, 'learning_rate': 0.0009453333333333334, 'epoch': 16.4}\n","{'loss': 0.3025, 'learning_rate': 0.000945, 'epoch': 16.5}\n","{'loss': 0.3017, 'learning_rate': 0.0009446666666666667, 'epoch': 16.6}\n","{'loss': 0.2798, 'learning_rate': 0.0009443333333333334, 'epoch': 16.7}\n","{'loss': 0.2895, 'learning_rate': 0.000944, 'epoch': 16.8}\n","{'loss': 0.2802, 'learning_rate': 0.0009436666666666667, 'epoch': 16.9}\n","{'loss': 0.2952, 'learning_rate': 0.0009433333333333334, 'epoch': 17.0}\n","  6% 1700/30000 [35:54<6:08:56,  1.28it/s][INFO|trainer.py:3160] 2023-09-07 17:07:47,568 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3162] 2023-09-07 17:07:47,568 >>   Num examples = 9000\n","[INFO|trainer.py:3165] 2023-09-07 17:07:47,568 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.31it/s]\u001b[A\n"," 17% 3/18 [00:01<00:09,  1.63it/s]\u001b[A\n"," 22% 4/18 [00:02<00:09,  1.42it/s]\u001b[A\n"," 28% 5/18 [00:03<00:09,  1.32it/s]\u001b[A\n"," 33% 6/18 [00:04<00:09,  1.32it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.32it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.32it/s]\u001b[A\n"," 50% 9/18 [00:06<00:06,  1.32it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.33it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.33it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.33it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.32it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.31it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.31it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.32it/s]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 2.9594595432281494, 'eval_accuracy': 0.43166666666666664, 'eval_runtime': 14.0244, 'eval_samples_per_second': 641.738, 'eval_steps_per_second': 1.283, 'epoch': 17.0}\n","  6% 1700/30000 [36:08<6:08:56,  1.28it/s]\n","100% 18/18 [00:12<00:00,  1.47it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2886] 2023-09-07 17:08:01,597 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-1700\n","[INFO|configuration_utils.py:460] 2023-09-07 17:08:01,603 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-1700/config.json\n","[INFO|modeling_utils.py:1988] 2023-09-07 17:08:01,715 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-1700/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 17:08:01,719 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-1700/preprocessor_config.json\n","[INFO|trainer.py:2973] 2023-09-07 17:08:01,954 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-1500] due to args.save_total_limit\n","{'loss': 0.3061, 'learning_rate': 0.0009429999999999999, 'epoch': 17.1}\n","{'loss': 0.2915, 'learning_rate': 0.0009426666666666666, 'epoch': 17.2}\n","{'loss': 0.3027, 'learning_rate': 0.0009423333333333333, 'epoch': 17.3}\n","{'loss': 0.2815, 'learning_rate': 0.000942, 'epoch': 17.4}\n","{'loss': 0.2873, 'learning_rate': 0.0009416666666666667, 'epoch': 17.5}\n","{'loss': 0.2809, 'learning_rate': 0.0009413333333333334, 'epoch': 17.6}\n","{'loss': 0.2755, 'learning_rate': 0.000941, 'epoch': 17.7}\n","{'loss': 0.3, 'learning_rate': 0.0009406666666666667, 'epoch': 17.8}\n","{'loss': 0.2801, 'learning_rate': 0.0009403333333333334, 'epoch': 17.9}\n","{'loss': 0.2845, 'learning_rate': 0.00094, 'epoch': 18.0}\n","  6% 1800/30000 [38:01<6:23:26,  1.23it/s][INFO|trainer.py:3160] 2023-09-07 17:09:54,655 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3162] 2023-09-07 17:09:54,655 >>   Num examples = 9000\n","[INFO|trainer.py:3165] 2023-09-07 17:09:54,655 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.36it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.72it/s]\u001b[A\n"," 22% 4/18 [00:02<00:09,  1.55it/s]\u001b[A\n"," 28% 5/18 [00:03<00:08,  1.48it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.44it/s]\u001b[A\n"," 39% 7/18 [00:04<00:07,  1.42it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.38it/s]\u001b[A\n"," 50% 9/18 [00:06<00:06,  1.36it/s]\u001b[A\n"," 56% 10/18 [00:06<00:05,  1.34it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.32it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.27it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.26it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.27it/s]\u001b[A\n"," 83% 15/18 [00:10<00:02,  1.29it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.30it/s]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 2.161073684692383, 'eval_accuracy': 0.533, 'eval_runtime': 13.656, 'eval_samples_per_second': 659.052, 'eval_steps_per_second': 1.318, 'epoch': 18.0}\n","  6% 1800/30000 [38:15<6:23:26,  1.23it/s]\n","100% 18/18 [00:12<00:00,  1.47it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2886] 2023-09-07 17:10:08,315 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-1800\n","[INFO|configuration_utils.py:460] 2023-09-07 17:10:08,321 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-1800/config.json\n","[INFO|modeling_utils.py:1988] 2023-09-07 17:10:08,427 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-1800/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 17:10:08,431 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-1800/preprocessor_config.json\n","[INFO|trainer.py:2973] 2023-09-07 17:10:08,648 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-1600] due to args.save_total_limit\n","{'loss': 0.2896, 'learning_rate': 0.0009396666666666667, 'epoch': 18.1}\n","{'loss': 0.2856, 'learning_rate': 0.0009393333333333334, 'epoch': 18.2}\n","{'loss': 0.2684, 'learning_rate': 0.000939, 'epoch': 18.3}\n","{'loss': 0.3009, 'learning_rate': 0.0009386666666666666, 'epoch': 18.4}\n","{'loss': 0.3104, 'learning_rate': 0.0009383333333333333, 'epoch': 18.5}\n","{'loss': 0.2669, 'learning_rate': 0.0009379999999999999, 'epoch': 18.6}\n","{'loss': 0.2766, 'learning_rate': 0.0009376666666666666, 'epoch': 18.7}\n","{'loss': 0.2897, 'learning_rate': 0.0009373333333333334, 'epoch': 18.8}\n","{'loss': 0.2964, 'learning_rate': 0.0009370000000000001, 'epoch': 18.9}\n","{'loss': 0.2928, 'learning_rate': 0.0009366666666666667, 'epoch': 19.0}\n","  6% 1900/30000 [40:08<6:25:55,  1.21it/s][INFO|trainer.py:3160] 2023-09-07 17:12:01,444 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3162] 2023-09-07 17:12:01,444 >>   Num examples = 9000\n","[INFO|trainer.py:3165] 2023-09-07 17:12:01,444 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.66it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.75it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.59it/s]\u001b[A\n"," 28% 5/18 [00:03<00:08,  1.51it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.46it/s]\u001b[A\n"," 39% 7/18 [00:04<00:07,  1.40it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.30it/s]\u001b[A\n"," 50% 9/18 [00:06<00:07,  1.25it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.16it/s]\u001b[A\n"," 61% 11/18 [00:08<00:05,  1.21it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.25it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.26it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.26it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.28it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.29it/s]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 3.1015875339508057, 'eval_accuracy': 0.3397777777777778, 'eval_runtime': 14.1797, 'eval_samples_per_second': 634.712, 'eval_steps_per_second': 1.269, 'epoch': 19.0}\n","  6% 1900/30000 [40:22<6:25:55,  1.21it/s]\n","100% 18/18 [00:12<00:00,  1.41it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2886] 2023-09-07 17:12:15,629 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-1900\n","[INFO|configuration_utils.py:460] 2023-09-07 17:12:15,635 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-1900/config.json\n","[INFO|modeling_utils.py:1988] 2023-09-07 17:12:15,760 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-1900/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 17:12:15,765 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-1900/preprocessor_config.json\n","[INFO|trainer.py:2973] 2023-09-07 17:12:15,992 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-1700] due to args.save_total_limit\n","{'loss': 0.2885, 'learning_rate': 0.0009363333333333334, 'epoch': 19.1}\n","{'loss': 0.2707, 'learning_rate': 0.0009360000000000001, 'epoch': 19.2}\n","{'loss': 0.2826, 'learning_rate': 0.0009356666666666667, 'epoch': 19.3}\n","{'loss': 0.301, 'learning_rate': 0.0009353333333333334, 'epoch': 19.4}\n","{'loss': 0.2736, 'learning_rate': 0.0009350000000000001, 'epoch': 19.5}\n","{'loss': 0.303, 'learning_rate': 0.0009346666666666667, 'epoch': 19.6}\n","{'loss': 0.2671, 'learning_rate': 0.0009343333333333333, 'epoch': 19.7}\n","{'loss': 0.2814, 'learning_rate': 0.000934, 'epoch': 19.8}\n","{'loss': 0.2784, 'learning_rate': 0.0009336666666666666, 'epoch': 19.9}\n","{'loss': 0.286, 'learning_rate': 0.0009333333333333333, 'epoch': 20.0}\n","  7% 2000/30000 [42:15<6:07:31,  1.27it/s][INFO|trainer.py:3160] 2023-09-07 17:14:08,510 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3162] 2023-09-07 17:14:08,511 >>   Num examples = 9000\n","[INFO|trainer.py:3165] 2023-09-07 17:14:08,511 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.59it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.85it/s]\u001b[A\n"," 22% 4/18 [00:02<00:09,  1.46it/s]\u001b[A\n"," 28% 5/18 [00:03<00:09,  1.36it/s]\u001b[A\n"," 33% 6/18 [00:04<00:09,  1.31it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.27it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.28it/s]\u001b[A\n"," 50% 9/18 [00:06<00:06,  1.30it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.31it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.33it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.35it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.36it/s]\u001b[A\n"," 78% 14/18 [00:10<00:02,  1.37it/s]\u001b[A\n"," 83% 15/18 [00:10<00:02,  1.35it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.36it/s]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 1.2023166418075562, 'eval_accuracy': 0.6362222222222222, 'eval_runtime': 13.5937, 'eval_samples_per_second': 662.07, 'eval_steps_per_second': 1.324, 'epoch': 20.0}\n","  7% 2000/30000 [42:29<6:07:31,  1.27it/s]\n","100% 18/18 [00:12<00:00,  1.53it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2886] 2023-09-07 17:14:22,108 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-2000\n","[INFO|configuration_utils.py:460] 2023-09-07 17:14:22,113 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-2000/config.json\n","[INFO|modeling_utils.py:1988] 2023-09-07 17:14:22,219 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-2000/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 17:14:22,238 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-2000/preprocessor_config.json\n","[INFO|trainer.py:2973] 2023-09-07 17:14:22,446 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-1800] due to args.save_total_limit\n","{'loss': 0.2813, 'learning_rate': 0.000933, 'epoch': 20.1}\n","{'loss': 0.2905, 'learning_rate': 0.0009326666666666667, 'epoch': 20.2}\n","{'loss': 0.296, 'learning_rate': 0.0009323333333333334, 'epoch': 20.3}\n","{'loss': 0.2892, 'learning_rate': 0.0009320000000000001, 'epoch': 20.4}\n","{'loss': 0.2949, 'learning_rate': 0.0009316666666666667, 'epoch': 20.5}\n","{'loss': 0.2802, 'learning_rate': 0.0009313333333333334, 'epoch': 20.6}\n","{'loss': 0.2781, 'learning_rate': 0.0009310000000000001, 'epoch': 20.7}\n","{'loss': 0.269, 'learning_rate': 0.0009306666666666667, 'epoch': 20.8}\n","{'loss': 0.2815, 'learning_rate': 0.0009303333333333334, 'epoch': 20.9}\n","{'loss': 0.2784, 'learning_rate': 0.00093, 'epoch': 21.0}\n","  7% 2100/30000 [44:21<6:16:42,  1.23it/s][INFO|trainer.py:3160] 2023-09-07 17:16:14,577 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3162] 2023-09-07 17:16:14,577 >>   Num examples = 9000\n","[INFO|trainer.py:3165] 2023-09-07 17:16:14,577 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.63it/s]\u001b[A\n"," 17% 3/18 [00:01<00:07,  1.96it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.69it/s]\u001b[A\n"," 28% 5/18 [00:02<00:08,  1.57it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.44it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.34it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.28it/s]\u001b[A\n"," 50% 9/18 [00:06<00:07,  1.27it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.26it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.24it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.22it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.25it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.28it/s]\u001b[A\n"," 83% 15/18 [00:10<00:02,  1.30it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.27it/s]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 0.09280741959810257, 'eval_accuracy': 0.9717777777777777, 'eval_runtime': 13.8378, 'eval_samples_per_second': 650.391, 'eval_steps_per_second': 1.301, 'epoch': 21.0}\n","  7% 2100/30000 [44:35<6:16:42,  1.23it/s]\n","100% 18/18 [00:12<00:00,  1.45it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2886] 2023-09-07 17:16:28,419 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-2100\n","[INFO|configuration_utils.py:460] 2023-09-07 17:16:28,425 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-2100/config.json\n","[INFO|modeling_utils.py:1988] 2023-09-07 17:16:28,534 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-2100/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 17:16:28,538 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-2100/preprocessor_config.json\n","[INFO|trainer.py:2973] 2023-09-07 17:16:28,746 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-1900] due to args.save_total_limit\n","[INFO|trainer.py:1988] 2023-09-07 17:16:28,786 >> \n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","[INFO|trainer.py:2156] 2023-09-07 17:16:28,786 >> Loading best model from drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/checkpoint-1100 (score: 0.03461219742894173).\n","{'train_runtime': 2675.8288, 'train_samples_per_second': 5717.855, 'train_steps_per_second': 11.211, 'train_loss': 0.3302770657766433, 'epoch': 21.0}\n","  7% 2100/30000 [44:35<9:52:30,  1.27s/it]\n","[INFO|trainer.py:2886] 2023-09-07 17:16:28,856 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/\n","[INFO|configuration_utils.py:460] 2023-09-07 17:16:28,861 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/config.json\n","[INFO|modeling_utils.py:1988] 2023-09-07 17:16:28,969 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 17:16:28,973 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/preprocessor_config.json\n","***** train metrics *****\n","  epoch                    =       21.0\n","  train_loss               =     0.3303\n","  train_runtime            = 0:44:35.82\n","  train_samples_per_second =   5717.855\n","  train_steps_per_second   =     11.211\n","[INFO|trainer.py:3160] 2023-09-07 17:16:28,993 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3162] 2023-09-07 17:16:28,993 >>   Num examples = 9000\n","[INFO|trainer.py:3165] 2023-09-07 17:16:28,993 >>   Batch size = 512\n","100% 18/18 [00:12<00:00,  1.47it/s]\n","***** eval metrics *****\n","  epoch                   =       21.0\n","  eval_accuracy           =     0.9896\n","  eval_loss               =     0.0346\n","  eval_runtime            = 0:00:13.64\n","  eval_samples_per_second =     659.59\n","  eval_steps_per_second   =      1.319\n","\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n","\u001b[34m\u001b[1mwandb\u001b[0m:                  eval/accuracy █▄█▇█████████▃██▂▃▁▄██\n","\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/loss ▁▄▁▁▁▁▁▁▁▁▁▁▁▆▁▁█▆█▄▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/runtime ▁▁▁▂█▂▂▃▂▂▁▂▁▂▂▁▃▂▃▂▂▂\n","\u001b[34m\u001b[1mwandb\u001b[0m:        eval/samples_per_second ██▇▆▁▇▇▆▆▇█▇█▆▇█▆▇▆▇▇▇\n","\u001b[34m\u001b[1mwandb\u001b[0m:          eval/steps_per_second ██▇▆▁▇▇▆▆▇█▇█▆▇█▆▇▆▇▇▇\n","\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\n","\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\n","\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate ███▇▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss █▅▄▄▄▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂▂▁▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n","\u001b[34m\u001b[1mwandb\u001b[0m:                  eval/accuracy 0.98956\n","\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/loss 0.03461\n","\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/runtime 13.6448\n","\u001b[34m\u001b[1mwandb\u001b[0m:        eval/samples_per_second 659.59\n","\u001b[34m\u001b[1mwandb\u001b[0m:          eval/steps_per_second 1.319\n","\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch 21.0\n","\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step 2100\n","\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate 0.00093\n","\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss 0.2784\n","\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos 1.0815923230027776e+19\n","\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss 0.33028\n","\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime 2675.8288\n","\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second 5717.855\n","\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second 11.211\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33msummer-pond-15\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/u15048366/colabCnnMnist/runs/6lkd183o\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n","\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230907_163121-6lkd183o/logs\u001b[0m\n"]}],"source":["!python cnn-mnist.py \\\n","    --model_name microsoft/resnet-18 \\\n","    --model_type resnet \\\n","    --dataset_name mnist \\\n","    --output_dir drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_6/ \\\n","    --remove_unused_columns False \\\n","    --do_train \\\n","    --do_eval \\\n","    --push_to_hub False \\\n","    --learning_rate 0.001 \\\n","    --num_train_epochs 300 \\\n","    --per_device_train_batch_size 512 \\\n","    --per_device_eval_batch_size 512 \\\n","    --logging_strategy steps \\\n","    --logging_steps 10 \\\n","    --evaluation_strategy epoch \\\n","    --save_strategy epoch \\\n","    --load_best_model_at_end True \\\n","    --save_total_limit 3 \\\n","    --save_steps 500 \\\n","    --data_seed 6 \\\n","    --seed 6 \\\n","    --report_to wandb \\\n","    --ignore_mismatched_sizes\n"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3756027,"status":"ok","timestamp":1695148957593,"user":{"displayName":"Andreas Louw","userId":"11183032721846533402"},"user_tz":-120},"id":"-nDNgY-PFYRZ","outputId":"b9392eb1-acde-4048-fdf9-de33d65d17b9"},"outputs":[{"output_type":"stream","name":"stdout","text":["2023-09-19 17:34:57.498899: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mu15048366\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.10\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20230919_173502-edyzdasr\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mcerulean-pine-23\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/u15048366/colabCnnMnist\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/u15048366/colabCnnMnist/runs/edyzdasr\u001b[0m\n","09/19/2023 17:35:03 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n","09/19/2023 17:35:03 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n","_n_gpu=1,\n","adafactor=False,\n","adam_beta1=0.9,\n","adam_beta2=0.999,\n","adam_epsilon=1e-08,\n","auto_find_batch_size=False,\n","bf16=False,\n","bf16_full_eval=False,\n","data_seed=7,\n","dataloader_drop_last=False,\n","dataloader_num_workers=0,\n","dataloader_pin_memory=True,\n","ddp_backend=None,\n","ddp_broadcast_buffers=None,\n","ddp_bucket_cap_mb=None,\n","ddp_find_unused_parameters=None,\n","ddp_timeout=1800,\n","debug=[],\n","deepspeed=None,\n","disable_tqdm=False,\n","dispatch_batches=None,\n","do_eval=True,\n","do_predict=False,\n","do_train=True,\n","eval_accumulation_steps=None,\n","eval_delay=0,\n","eval_steps=None,\n","evaluation_strategy=epoch,\n","fp16=False,\n","fp16_backend=auto,\n","fp16_full_eval=False,\n","fp16_opt_level=O1,\n","fsdp=[],\n","fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n","fsdp_min_num_params=0,\n","fsdp_transformer_layer_cls_to_wrap=None,\n","full_determinism=False,\n","gradient_accumulation_steps=1,\n","gradient_checkpointing=False,\n","greater_is_better=False,\n","group_by_length=False,\n","half_precision_backend=auto,\n","hub_always_push=False,\n","hub_model_id=None,\n","hub_private_repo=False,\n","hub_strategy=every_save,\n","hub_token=<HUB_TOKEN>,\n","ignore_data_skip=False,\n","include_inputs_for_metrics=False,\n","include_tokens_per_second=False,\n","jit_mode_eval=False,\n","label_names=None,\n","label_smoothing_factor=0.0,\n","learning_rate=0.001,\n","length_column_name=length,\n","load_best_model_at_end=True,\n","local_rank=0,\n","log_level=passive,\n","log_level_replica=warning,\n","log_on_each_node=True,\n","logging_dir=drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/runs/Sep19_17-35-03_f62f086f2701,\n","logging_first_step=False,\n","logging_nan_inf_filter=True,\n","logging_steps=10,\n","logging_strategy=steps,\n","lr_scheduler_type=linear,\n","max_grad_norm=1.0,\n","max_steps=-1,\n","metric_for_best_model=loss,\n","mp_parameters=,\n","no_cuda=False,\n","num_train_epochs=300.0,\n","optim=adamw_torch,\n","optim_args=None,\n","output_dir=drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/,\n","overwrite_output_dir=False,\n","past_index=-1,\n","per_device_eval_batch_size=512,\n","per_device_train_batch_size=512,\n","prediction_loss_only=False,\n","push_to_hub=False,\n","push_to_hub_model_id=None,\n","push_to_hub_organization=None,\n","push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n","ray_scope=last,\n","remove_unused_columns=False,\n","report_to=['wandb'],\n","resume_from_checkpoint=None,\n","run_name=drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/,\n","save_on_each_node=False,\n","save_safetensors=False,\n","save_steps=500.0,\n","save_strategy=epoch,\n","save_total_limit=3,\n","seed=7,\n","sharded_ddp=[],\n","skip_memory_metrics=True,\n","tf32=None,\n","torch_compile=False,\n","torch_compile_backend=None,\n","torch_compile_mode=None,\n","torchdynamo=None,\n","tpu_metrics_debug=False,\n","tpu_num_cores=None,\n","use_cpu=False,\n","use_ipex=False,\n","use_legacy_prediction_loop=False,\n","use_mps_device=False,\n","warmup_ratio=0.0,\n","warmup_steps=0,\n","weight_decay=0.0,\n",")\n","/usr/local/lib/python3.10/dist-packages/datasets/load.py:2103: FutureWarning: 'task' was deprecated in version 2.13.0 and will be removed in 3.0.0.\n","\n","  warnings.warn(\n","Downloading builder script: 100% 3.98k/3.98k [00:00<00:00, 11.6MB/s]\n","Downloading metadata: 100% 2.21k/2.21k [00:00<00:00, 6.32MB/s]\n","Downloading readme: 100% 6.83k/6.83k [00:00<00:00, 15.5MB/s]\n","Downloading data files:   0% 0/4 [00:00<?, ?it/s]\n","Downloading data:   0% 0.00/9.91M [00:00<?, ?B/s]\u001b[A\n","Downloading data:   0% 48.1k/9.91M [00:00<00:28, 343kB/s]\u001b[A\n","Downloading data:   1% 82.9k/9.91M [00:00<00:31, 315kB/s]\u001b[A\n","Downloading data:   2% 196k/9.91M [00:00<00:15, 623kB/s] \u001b[A\n","Downloading data:   3% 327k/9.91M [00:00<00:11, 864kB/s]\u001b[A\n","Downloading data:   6% 622k/9.91M [00:00<00:05, 1.55MB/s]\u001b[A\n","Downloading data:  11% 1.13M/9.91M [00:00<00:03, 2.68MB/s]\u001b[A\n","Downloading data:  21% 2.11M/9.91M [00:00<00:01, 4.93MB/s]\u001b[A\n","Downloading data:  40% 4.00M/9.91M [00:00<00:00, 9.23MB/s]\u001b[A\n","Downloading data: 100% 9.91M/9.91M [00:01<00:00, 9.37MB/s]\n","Downloading data files:  25% 1/4 [00:01<00:04,  1.51s/it]\n","Downloading data: 100% 28.9k/28.9k [00:00<00:00, 2.07MB/s]\n","Downloading data files:  50% 2/4 [00:02<00:02,  1.27s/it]\n","Downloading data:   0% 0.00/1.65M [00:00<?, ?B/s]\u001b[A\n","Downloading data:   3% 48.1k/1.65M [00:00<00:04, 339kB/s]\u001b[A\n","Downloading data:   5% 82.9k/1.65M [00:00<00:05, 311kB/s]\u001b[A\n","Downloading data:  12% 196k/1.65M [00:00<00:02, 616kB/s] \u001b[A\n","Downloading data:  20% 327k/1.65M [00:00<00:01, 853kB/s]\u001b[A\n","Downloading data:  38% 622k/1.65M [00:00<00:00, 1.54MB/s]\u001b[A\n","Downloading data: 100% 1.65M/1.65M [00:00<00:00, 2.24MB/s]\n","Downloading data files:  75% 3/4 [00:04<00:01,  1.48s/it]\n","Downloading data: 100% 4.54k/4.54k [00:00<00:00, 11.5MB/s]\n","Downloading data files: 100% 4/4 [00:05<00:00,  1.33s/it]\n","Extracting data files: 100% 4/4 [00:00<00:00, 14.22it/s]\n","Generating train split: 100% 60000/60000 [00:09<00:00, 6417.74 examples/s]\n","Generating test split: 100% 10000/10000 [00:01<00:00, 6655.29 examples/s]\n","Casting the dataset: 100% 60000/60000 [00:00<00:00, 1788984.51 examples/s]\n","Casting the dataset: 100% 10000/10000 [00:00<00:00, 1486182.41 examples/s]\n","Downloading builder script: 100% 4.20k/4.20k [00:00<00:00, 10.9MB/s]\n","\n","\n","\n","None\n","\n","\n","\n","Downloading (…)lve/main/config.json: 100% 69.5k/69.5k [00:00<00:00, 16.1MB/s]\n","[INFO|configuration_utils.py:715] 2023-09-19 17:35:24,511 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--resnet-18/snapshots/f45a6faa12e0381f5620c5c8d7e916bca90f2c44/config.json\n","[INFO|configuration_utils.py:775] 2023-09-19 17:35:24,513 >> Model config ResNetConfig {\n","  \"_name_or_path\": \"microsoft/resnet-18\",\n","  \"architectures\": [\n","    \"ResNetForImageClassification\"\n","  ],\n","  \"depths\": [\n","    2,\n","    2,\n","    2,\n","    2\n","  ],\n","  \"downsample_in_first_stage\": false,\n","  \"embedding_size\": 64,\n","  \"finetuning_task\": \"image-classification\",\n","  \"hidden_act\": \"relu\",\n","  \"hidden_sizes\": [\n","    64,\n","    128,\n","    256,\n","    512\n","  ],\n","  \"id2label\": {\n","    \"0\": \"0\",\n","    \"1\": \"1\",\n","    \"2\": \"2\",\n","    \"3\": \"3\",\n","    \"4\": \"4\",\n","    \"5\": \"5\",\n","    \"6\": \"6\",\n","    \"7\": \"7\",\n","    \"8\": \"8\",\n","    \"9\": \"9\"\n","  },\n","  \"label2id\": {\n","    \"0\": \"0\",\n","    \"1\": \"1\",\n","    \"2\": \"2\",\n","    \"3\": \"3\",\n","    \"4\": \"4\",\n","    \"5\": \"5\",\n","    \"6\": \"6\",\n","    \"7\": \"7\",\n","    \"8\": \"8\",\n","    \"9\": \"9\"\n","  },\n","  \"layer_type\": \"basic\",\n","  \"model_type\": \"resnet\",\n","  \"num_channels\": 3,\n","  \"out_features\": [\n","    \"stage4\"\n","  ],\n","  \"out_indices\": [\n","    4\n","  ],\n","  \"stage_names\": [\n","    \"stem\",\n","    \"stage1\",\n","    \"stage2\",\n","    \"stage3\",\n","    \"stage4\"\n","  ],\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.34.0.dev0\"\n","}\n","\n","Downloading model.safetensors: 100% 46.8M/46.8M [00:01<00:00, 28.0MB/s]\n","[INFO|modeling_utils.py:2899] 2023-09-19 17:35:26,975 >> loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--microsoft--resnet-18/snapshots/f45a6faa12e0381f5620c5c8d7e916bca90f2c44/model.safetensors\n","[INFO|modeling_utils.py:3685] 2023-09-19 17:35:27,164 >> All model checkpoint weights were used when initializing ResNetForImageClassification.\n","\n","[WARNING|modeling_utils.py:3706] 2023-09-19 17:35:27,164 >> Some weights of ResNetForImageClassification were not initialized from the model checkpoint at microsoft/resnet-18 and are newly initialized because the shapes did not match:\n","- classifier.1.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([10]) in the model instantiated\n","- classifier.1.weight: found shape torch.Size([1000, 512]) in the checkpoint and torch.Size([10, 512]) in the model instantiated\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Downloading (…)rocessor_config.json: 100% 266/266 [00:00<00:00, 997kB/s]\n","[INFO|image_processing_utils.py:369] 2023-09-19 17:35:27,385 >> loading configuration file preprocessor_config.json from cache at /root/.cache/huggingface/hub/models--microsoft--resnet-18/snapshots/f45a6faa12e0381f5620c5c8d7e916bca90f2c44/preprocessor_config.json\n","[WARNING|image_processing_auto.py:356] 2023-09-19 17:35:27,385 >> Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n","[INFO|image_processing_utils.py:732] 2023-09-19 17:35:27,387 >> size should be a dictionary on of the following set of keys: ({'height', 'width'}, {'shortest_edge'}, {'longest_edge', 'shortest_edge'}, {'longest_edge'}), got 224. Converted to {'shortest_edge': 224}.\n","[INFO|image_processing_utils.py:419] 2023-09-19 17:35:27,387 >> Image processor ConvNextImageProcessor {\n","  \"crop_pct\": 0.875,\n","  \"do_normalize\": true,\n","  \"do_rescale\": true,\n","  \"do_resize\": true,\n","  \"image_mean\": [\n","    0.485,\n","    0.456,\n","    0.406\n","  ],\n","  \"image_processor_type\": \"ConvNextImageProcessor\",\n","  \"image_std\": [\n","    0.229,\n","    0.224,\n","    0.225\n","  ],\n","  \"resample\": 3,\n","  \"rescale_factor\": 0.00392156862745098,\n","  \"size\": {\n","    \"shortest_edge\": 224\n","  }\n","}\n","\n","[INFO|trainer.py:1753] 2023-09-19 17:35:32,999 >> ***** Running training *****\n","[INFO|trainer.py:1754] 2023-09-19 17:35:33,000 >>   Num examples = 51,000\n","[INFO|trainer.py:1755] 2023-09-19 17:35:33,000 >>   Num Epochs = 300\n","[INFO|trainer.py:1756] 2023-09-19 17:35:33,000 >>   Instantaneous batch size per device = 512\n","[INFO|trainer.py:1759] 2023-09-19 17:35:33,000 >>   Total train batch size (w. parallel, distributed & accumulation) = 512\n","[INFO|trainer.py:1760] 2023-09-19 17:35:33,000 >>   Gradient Accumulation steps = 1\n","[INFO|trainer.py:1761] 2023-09-19 17:35:33,001 >>   Total optimization steps = 30,000\n","[INFO|trainer.py:1762] 2023-09-19 17:35:33,001 >>   Number of trainable parameters = 11,181,642\n","[INFO|integration_utils.py:722] 2023-09-19 17:35:33,002 >> Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n","{'loss': 1.0939, 'learning_rate': 0.0009996666666666667, 'epoch': 0.1}\n","{'loss': 0.5861, 'learning_rate': 0.0009993333333333334, 'epoch': 0.2}\n","{'loss': 0.5347, 'learning_rate': 0.000999, 'epoch': 0.3}\n","{'loss': 0.5284, 'learning_rate': 0.0009986666666666668, 'epoch': 0.4}\n","{'loss': 0.4951, 'learning_rate': 0.0009983333333333333, 'epoch': 0.5}\n","{'loss': 0.5091, 'learning_rate': 0.000998, 'epoch': 0.6}\n","{'loss': 0.462, 'learning_rate': 0.0009976666666666667, 'epoch': 0.7}\n","{'loss': 0.4538, 'learning_rate': 0.0009973333333333334, 'epoch': 0.8}\n","{'loss': 0.4219, 'learning_rate': 0.000997, 'epoch': 0.9}\n","{'loss': 0.4338, 'learning_rate': 0.0009966666666666668, 'epoch': 1.0}\n","  0% 100/30000 [01:58<6:46:24,  1.23it/s][INFO|trainer.py:3187] 2023-09-19 17:37:31,792 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3189] 2023-09-19 17:37:31,793 >>   Num examples = 9000\n","[INFO|trainer.py:3192] 2023-09-19 17:37:31,793 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.63it/s]\u001b[A\n"," 17% 3/18 [00:01<00:07,  1.92it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.67it/s]\u001b[A\n"," 28% 5/18 [00:02<00:08,  1.54it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.48it/s]\u001b[A\n"," 39% 7/18 [00:04<00:07,  1.44it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.40it/s]\u001b[A\n"," 50% 9/18 [00:05<00:06,  1.39it/s]\u001b[A\n"," 56% 10/18 [00:06<00:05,  1.37it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.38it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.31it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.26it/s]\u001b[A\n"," 78% 14/18 [00:09<00:03,  1.23it/s]\u001b[A\n"," 83% 15/18 [00:10<00:02,  1.21it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.21it/s]\u001b[A\n"," 94% 17/18 [00:12<00:00,  1.38it/s]\u001b[A\n","{'eval_loss': 0.11131517589092255, 'eval_accuracy': 0.9702222222222222, 'eval_runtime': 13.5502, 'eval_samples_per_second': 664.198, 'eval_steps_per_second': 1.328, 'epoch': 1.0}\n","\n","  0% 100/30000 [02:12<6:46:24,  1.23it/s]\n","                                   \u001b[A[INFO|trainer.py:2913] 2023-09-19 17:37:45,347 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-100\n","[INFO|configuration_utils.py:460] 2023-09-19 17:37:45,353 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-100/config.json\n","[INFO|modeling_utils.py:2030] 2023-09-19 17:37:45,465 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-100/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-19 17:37:45,470 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-100/preprocessor_config.json\n","{'loss': 0.4351, 'learning_rate': 0.0009963333333333332, 'epoch': 1.1}\n","{'loss': 0.4363, 'learning_rate': 0.000996, 'epoch': 1.2}\n","{'loss': 0.4221, 'learning_rate': 0.0009956666666666666, 'epoch': 1.3}\n","{'loss': 0.4169, 'learning_rate': 0.0009953333333333333, 'epoch': 1.4}\n","{'loss': 0.4093, 'learning_rate': 0.000995, 'epoch': 1.5}\n","{'loss': 0.3921, 'learning_rate': 0.0009946666666666667, 'epoch': 1.6}\n","{'loss': 0.428, 'learning_rate': 0.0009943333333333334, 'epoch': 1.7}\n","{'loss': 0.4325, 'learning_rate': 0.000994, 'epoch': 1.8}\n","{'loss': 0.4143, 'learning_rate': 0.0009936666666666668, 'epoch': 1.9}\n","{'loss': 0.3838, 'learning_rate': 0.0009933333333333333, 'epoch': 2.0}\n","  1% 200/30000 [04:00<6:32:45,  1.26it/s][INFO|trainer.py:3187] 2023-09-19 17:39:33,783 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3189] 2023-09-19 17:39:33,784 >>   Num examples = 9000\n","[INFO|trainer.py:3192] 2023-09-19 17:39:33,784 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:05,  2.73it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.70it/s]\u001b[A\n"," 22% 4/18 [00:02<00:09,  1.45it/s]\u001b[A\n"," 28% 5/18 [00:03<00:09,  1.41it/s]\u001b[A\n"," 33% 6/18 [00:04<00:08,  1.37it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.32it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.30it/s]\u001b[A\n"," 50% 9/18 [00:06<00:06,  1.32it/s]\u001b[A\n"," 56% 10/18 [00:07<00:05,  1.34it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.34it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.35it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.37it/s]\u001b[A\n"," 78% 14/18 [00:09<00:02,  1.38it/s]\u001b[A\n"," 83% 15/18 [00:10<00:02,  1.39it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.40it/s]\u001b[A\n","                                         \n","\u001b[A{'eval_loss': 0.08389299362897873, 'eval_accuracy': 0.9742222222222222, 'eval_runtime': 13.2565, 'eval_samples_per_second': 678.915, 'eval_steps_per_second': 1.358, 'epoch': 2.0}\n","  1% 200/30000 [04:14<6:32:45,  1.26it/s]\n","100% 18/18 [00:11<00:00,  1.57it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2913] 2023-09-19 17:39:47,044 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-200\n","[INFO|configuration_utils.py:460] 2023-09-19 17:39:47,049 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-200/config.json\n","[INFO|modeling_utils.py:2030] 2023-09-19 17:39:47,154 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-200/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-19 17:39:47,158 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-200/preprocessor_config.json\n","{'loss': 0.3897, 'learning_rate': 0.000993, 'epoch': 2.1}\n","{'loss': 0.3726, 'learning_rate': 0.0009926666666666667, 'epoch': 2.2}\n","{'loss': 0.3893, 'learning_rate': 0.0009923333333333333, 'epoch': 2.3}\n","{'loss': 0.3731, 'learning_rate': 0.000992, 'epoch': 2.4}\n","{'loss': 0.3844, 'learning_rate': 0.0009916666666666667, 'epoch': 2.5}\n","{'loss': 0.3785, 'learning_rate': 0.0009913333333333332, 'epoch': 2.6}\n","{'loss': 0.3753, 'learning_rate': 0.000991, 'epoch': 2.7}\n","{'loss': 0.3618, 'learning_rate': 0.0009906666666666668, 'epoch': 2.8}\n","{'loss': 0.3788, 'learning_rate': 0.0009903333333333333, 'epoch': 2.9}\n","{'loss': 0.3899, 'learning_rate': 0.00099, 'epoch': 3.0}\n","  1% 300/30000 [06:02<6:28:55,  1.27it/s][INFO|trainer.py:3187] 2023-09-19 17:41:35,459 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3189] 2023-09-19 17:41:35,459 >>   Num examples = 9000\n","[INFO|trainer.py:3192] 2023-09-19 17:41:35,459 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:05,  2.77it/s]\u001b[A\n"," 17% 3/18 [00:01<00:07,  1.98it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.71it/s]\u001b[A\n"," 28% 5/18 [00:02<00:08,  1.59it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.49it/s]\u001b[A\n"," 39% 7/18 [00:04<00:07,  1.46it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.43it/s]\u001b[A\n"," 50% 9/18 [00:05<00:06,  1.41it/s]\u001b[A\n"," 56% 10/18 [00:06<00:05,  1.39it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.34it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.32it/s]\u001b[A\n"," 72% 13/18 [00:08<00:03,  1.29it/s]\u001b[A\n"," 78% 14/18 [00:09<00:03,  1.28it/s]\u001b[A\n"," 83% 15/18 [00:10<00:02,  1.30it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.32it/s]\u001b[A\n"," 94% 17/18 [00:11<00:00,  1.51it/s]\u001b[A\n","{'eval_loss': 0.06555602699518204, 'eval_accuracy': 0.9803333333333333, 'eval_runtime': 13.0646, 'eval_samples_per_second': 688.882, 'eval_steps_per_second': 1.378, 'epoch': 3.0}\n","\n","  1% 300/30000 [06:15<6:28:55,  1.27it/s]\n","                                   \u001b[A[INFO|trainer.py:2913] 2023-09-19 17:41:48,529 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-300\n","[INFO|configuration_utils.py:460] 2023-09-19 17:41:48,535 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-300/config.json\n","[INFO|modeling_utils.py:2030] 2023-09-19 17:41:48,641 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-300/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-19 17:41:48,645 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-300/preprocessor_config.json\n","{'loss': 0.3555, 'learning_rate': 0.0009896666666666667, 'epoch': 3.1}\n","{'loss': 0.3501, 'learning_rate': 0.0009893333333333334, 'epoch': 3.2}\n","{'loss': 0.3898, 'learning_rate': 0.000989, 'epoch': 3.3}\n","{'loss': 0.372, 'learning_rate': 0.0009886666666666668, 'epoch': 3.4}\n","{'loss': 0.3685, 'learning_rate': 0.0009883333333333333, 'epoch': 3.5}\n","{'loss': 0.3773, 'learning_rate': 0.000988, 'epoch': 3.6}\n","{'loss': 0.3564, 'learning_rate': 0.0009876666666666666, 'epoch': 3.7}\n","{'loss': 0.3538, 'learning_rate': 0.0009873333333333333, 'epoch': 3.8}\n","{'loss': 0.3366, 'learning_rate': 0.000987, 'epoch': 3.9}\n","{'loss': 0.3457, 'learning_rate': 0.0009866666666666667, 'epoch': 4.0}\n","  1% 400/30000 [08:04<6:33:09,  1.25it/s][INFO|trainer.py:3187] 2023-09-19 17:43:37,604 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3189] 2023-09-19 17:43:37,604 >>   Num examples = 9000\n","[INFO|trainer.py:3192] 2023-09-19 17:43:37,604 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.64it/s]\u001b[A\n"," 17% 3/18 [00:01<00:07,  1.92it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.68it/s]\u001b[A\n"," 28% 5/18 [00:02<00:08,  1.56it/s]\u001b[A\n"," 33% 6/18 [00:03<00:07,  1.51it/s]\u001b[A\n"," 39% 7/18 [00:04<00:07,  1.43it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.40it/s]\u001b[A\n"," 50% 9/18 [00:05<00:06,  1.37it/s]\u001b[A\n"," 56% 10/18 [00:06<00:05,  1.38it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.37it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.37it/s]\u001b[A\n"," 72% 13/18 [00:08<00:03,  1.37it/s]\u001b[A\n"," 78% 14/18 [00:09<00:02,  1.37it/s]\u001b[A\n"," 83% 15/18 [00:10<00:02,  1.35it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.34it/s]\u001b[A\n"," 94% 17/18 [00:11<00:00,  1.50it/s]\u001b[A\n","{'eval_loss': 0.07882759720087051, 'eval_accuracy': 0.9761111111111112, 'eval_runtime': 13.2025, 'eval_samples_per_second': 681.69, 'eval_steps_per_second': 1.363, 'epoch': 4.0}\n","\n","  1% 400/30000 [08:17<6:33:09,  1.25it/s]\n","                                   \u001b[A[INFO|trainer.py:2913] 2023-09-19 17:43:50,811 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-400\n","[INFO|configuration_utils.py:460] 2023-09-19 17:43:50,817 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-400/config.json\n","[INFO|modeling_utils.py:2030] 2023-09-19 17:43:50,934 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-400/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-19 17:43:50,940 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-400/preprocessor_config.json\n","[INFO|trainer.py:3000] 2023-09-19 17:43:51,153 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-100] due to args.save_total_limit\n","{'loss': 0.3718, 'learning_rate': 0.0009863333333333332, 'epoch': 4.1}\n","{'loss': 0.3482, 'learning_rate': 0.0009860000000000001, 'epoch': 4.2}\n","{'loss': 0.3314, 'learning_rate': 0.0009856666666666668, 'epoch': 4.3}\n","{'loss': 0.3427, 'learning_rate': 0.0009853333333333333, 'epoch': 4.4}\n","{'loss': 0.3382, 'learning_rate': 0.000985, 'epoch': 4.5}\n","{'loss': 0.3514, 'learning_rate': 0.0009846666666666667, 'epoch': 4.6}\n","{'loss': 0.3525, 'learning_rate': 0.0009843333333333334, 'epoch': 4.7}\n","{'loss': 0.3576, 'learning_rate': 0.000984, 'epoch': 4.8}\n","{'loss': 0.3679, 'learning_rate': 0.0009836666666666668, 'epoch': 4.9}\n","{'loss': 0.3229, 'learning_rate': 0.0009833333333333332, 'epoch': 5.0}\n","  2% 500/30000 [10:07<6:16:33,  1.31it/s][INFO|trainer.py:3187] 2023-09-19 17:45:40,752 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3189] 2023-09-19 17:45:40,752 >>   Num examples = 9000\n","[INFO|trainer.py:3192] 2023-09-19 17:45:40,752 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.59it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.78it/s]\u001b[A\n"," 22% 4/18 [00:02<00:09,  1.51it/s]\u001b[A\n"," 28% 5/18 [00:03<00:09,  1.43it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.39it/s]\u001b[A\n"," 39% 7/18 [00:04<00:07,  1.38it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.38it/s]\u001b[A\n"," 50% 9/18 [00:06<00:06,  1.39it/s]\u001b[A\n"," 56% 10/18 [00:06<00:05,  1.39it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.38it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.39it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.38it/s]\u001b[A\n"," 78% 14/18 [00:09<00:02,  1.37it/s]\u001b[A\n"," 83% 15/18 [00:10<00:02,  1.38it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.25it/s]\u001b[A\n","                                         \n","\u001b[A{'eval_loss': 0.06147475913167, 'eval_accuracy': 0.9827777777777778, 'eval_runtime': 13.4315, 'eval_samples_per_second': 670.067, 'eval_steps_per_second': 1.34, 'epoch': 5.0}\n","  2% 500/30000 [10:21<6:16:33,  1.31it/s]\n","100% 18/18 [00:12<00:00,  1.44it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2913] 2023-09-19 17:45:54,187 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-500\n","[INFO|configuration_utils.py:460] 2023-09-19 17:45:54,192 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-500/config.json\n","[INFO|modeling_utils.py:2030] 2023-09-19 17:45:54,299 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-500/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-19 17:45:54,304 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-500/preprocessor_config.json\n","[INFO|trainer.py:3000] 2023-09-19 17:45:54,526 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-200] due to args.save_total_limit\n","{'loss': 0.3545, 'learning_rate': 0.000983, 'epoch': 5.1}\n","{'loss': 0.32, 'learning_rate': 0.0009826666666666666, 'epoch': 5.2}\n","{'loss': 0.3212, 'learning_rate': 0.0009823333333333333, 'epoch': 5.3}\n","{'loss': 0.3363, 'learning_rate': 0.000982, 'epoch': 5.4}\n","{'loss': 0.3509, 'learning_rate': 0.0009816666666666667, 'epoch': 5.5}\n","{'loss': 0.3475, 'learning_rate': 0.0009813333333333334, 'epoch': 5.6}\n","{'loss': 0.3205, 'learning_rate': 0.000981, 'epoch': 5.7}\n","{'loss': 0.3426, 'learning_rate': 0.0009806666666666668, 'epoch': 5.8}\n","{'loss': 0.3448, 'learning_rate': 0.0009803333333333333, 'epoch': 5.9}\n","{'loss': 0.3337, 'learning_rate': 0.00098, 'epoch': 6.0}\n","  2% 600/30000 [12:11<6:21:33,  1.28it/s][INFO|trainer.py:3187] 2023-09-19 17:47:44,639 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3189] 2023-09-19 17:47:44,639 >>   Num examples = 9000\n","[INFO|trainer.py:3192] 2023-09-19 17:47:44,639 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.64it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.87it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.66it/s]\u001b[A\n"," 28% 5/18 [00:03<00:08,  1.45it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.36it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.30it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.26it/s]\u001b[A\n"," 50% 9/18 [00:06<00:07,  1.26it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.29it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.32it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.34it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.34it/s]\u001b[A\n"," 78% 14/18 [00:10<00:02,  1.35it/s]\u001b[A\n"," 83% 15/18 [00:10<00:02,  1.34it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.34it/s]\u001b[A\n","                                         \n","\u001b[A{'eval_loss': 1.5997024774551392, 'eval_accuracy': 0.5364444444444444, 'eval_runtime': 13.4718, 'eval_samples_per_second': 668.06, 'eval_steps_per_second': 1.336, 'epoch': 6.0}\n","  2% 600/30000 [12:25<6:21:33,  1.28it/s]\n","100% 18/18 [00:12<00:00,  1.52it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2913] 2023-09-19 17:47:58,115 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-600\n","[INFO|configuration_utils.py:460] 2023-09-19 17:47:58,120 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-600/config.json\n","[INFO|modeling_utils.py:2030] 2023-09-19 17:47:58,225 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-600/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-19 17:47:58,230 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-600/preprocessor_config.json\n","[INFO|trainer.py:3000] 2023-09-19 17:47:58,438 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-300] due to args.save_total_limit\n","{'loss': 0.3279, 'learning_rate': 0.0009796666666666667, 'epoch': 6.1}\n","{'loss': 0.3457, 'learning_rate': 0.0009793333333333334, 'epoch': 6.2}\n","{'loss': 0.3444, 'learning_rate': 0.000979, 'epoch': 6.3}\n","{'loss': 0.3254, 'learning_rate': 0.0009786666666666667, 'epoch': 6.4}\n","{'loss': 0.3495, 'learning_rate': 0.0009783333333333334, 'epoch': 6.5}\n","{'loss': 0.3227, 'learning_rate': 0.000978, 'epoch': 6.6}\n","{'loss': 0.3333, 'learning_rate': 0.0009776666666666666, 'epoch': 6.7}\n","{'loss': 0.3251, 'learning_rate': 0.0009773333333333333, 'epoch': 6.8}\n","{'loss': 0.3246, 'learning_rate': 0.000977, 'epoch': 6.9}\n","{'loss': 0.3167, 'learning_rate': 0.0009766666666666667, 'epoch': 7.0}\n","  2% 700/30000 [14:15<6:27:09,  1.26it/s][INFO|trainer.py:3187] 2023-09-19 17:49:48,902 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3189] 2023-09-19 17:49:48,902 >>   Num examples = 9000\n","[INFO|trainer.py:3192] 2023-09-19 17:49:48,902 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:05,  2.73it/s]\u001b[A\n"," 17% 3/18 [00:01<00:07,  1.91it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.66it/s]\u001b[A\n"," 28% 5/18 [00:02<00:08,  1.54it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.48it/s]\u001b[A\n"," 39% 7/18 [00:04<00:07,  1.45it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.37it/s]\u001b[A\n"," 50% 9/18 [00:06<00:06,  1.33it/s]\u001b[A\n"," 56% 10/18 [00:06<00:06,  1.29it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.25it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.25it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.27it/s]\u001b[A\n"," 78% 14/18 [00:09<00:03,  1.30it/s]\u001b[A\n"," 83% 15/18 [00:10<00:02,  1.33it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.33it/s]\u001b[A\n"," 94% 17/18 [00:11<00:00,  1.51it/s]\u001b[A\n","{'eval_loss': 0.07991357147693634, 'eval_accuracy': 0.9754444444444444, 'eval_runtime': 13.3552, 'eval_samples_per_second': 673.897, 'eval_steps_per_second': 1.348, 'epoch': 7.0}\n","\n","  2% 700/30000 [14:29<6:27:09,  1.26it/s]\n","                                   \u001b[A[INFO|trainer.py:2913] 2023-09-19 17:50:02,261 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-700\n","[INFO|configuration_utils.py:460] 2023-09-19 17:50:02,266 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-700/config.json\n","[INFO|modeling_utils.py:2030] 2023-09-19 17:50:02,373 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-700/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-19 17:50:02,377 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-700/preprocessor_config.json\n","[INFO|trainer.py:3000] 2023-09-19 17:50:02,579 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-400] due to args.save_total_limit\n","{'loss': 0.3205, 'learning_rate': 0.0009763333333333334, 'epoch': 7.1}\n","{'loss': 0.3191, 'learning_rate': 0.000976, 'epoch': 7.2}\n","{'loss': 0.3261, 'learning_rate': 0.0009756666666666667, 'epoch': 7.3}\n","{'loss': 0.3244, 'learning_rate': 0.0009753333333333334, 'epoch': 7.4}\n","{'loss': 0.3197, 'learning_rate': 0.000975, 'epoch': 7.5}\n","{'loss': 0.314, 'learning_rate': 0.0009746666666666666, 'epoch': 7.6}\n","{'loss': 0.3161, 'learning_rate': 0.0009743333333333335, 'epoch': 7.7}\n","{'loss': 0.3336, 'learning_rate': 0.000974, 'epoch': 7.8}\n","{'loss': 0.3311, 'learning_rate': 0.0009736666666666667, 'epoch': 7.9}\n","{'loss': 0.3383, 'learning_rate': 0.0009733333333333334, 'epoch': 8.0}\n","  3% 800/30000 [16:20<6:31:56,  1.24it/s][INFO|trainer.py:3187] 2023-09-19 17:51:53,463 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3189] 2023-09-19 17:51:53,463 >>   Num examples = 9000\n","[INFO|trainer.py:3192] 2023-09-19 17:51:53,463 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:05,  2.73it/s]\u001b[A\n"," 17% 3/18 [00:01<00:07,  1.91it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.67it/s]\u001b[A\n"," 28% 5/18 [00:02<00:08,  1.52it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.46it/s]\u001b[A\n"," 39% 7/18 [00:04<00:07,  1.43it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.40it/s]\u001b[A\n"," 50% 9/18 [00:05<00:06,  1.39it/s]\u001b[A\n"," 56% 10/18 [00:06<00:05,  1.38it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.36it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.33it/s]\u001b[A\n"," 72% 13/18 [00:08<00:03,  1.31it/s]\u001b[A\n"," 78% 14/18 [00:09<00:03,  1.29it/s]\u001b[A\n"," 83% 15/18 [00:10<00:02,  1.27it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.27it/s]\u001b[A\n"," 94% 17/18 [00:11<00:00,  1.44it/s]\u001b[A\n","{'eval_loss': 0.21013596653938293, 'eval_accuracy': 0.9358888888888889, 'eval_runtime': 13.3538, 'eval_samples_per_second': 673.963, 'eval_steps_per_second': 1.348, 'epoch': 8.0}\n","\n","  3% 800/30000 [16:33<6:31:56,  1.24it/s]\n","                                   \u001b[A[INFO|trainer.py:2913] 2023-09-19 17:52:06,821 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-800\n","[INFO|configuration_utils.py:460] 2023-09-19 17:52:06,827 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-800/config.json\n","[INFO|modeling_utils.py:2030] 2023-09-19 17:52:06,934 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-800/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-19 17:52:06,938 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-800/preprocessor_config.json\n","[INFO|trainer.py:3000] 2023-09-19 17:52:07,167 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-600] due to args.save_total_limit\n","{'loss': 0.3169, 'learning_rate': 0.000973, 'epoch': 8.1}\n","{'loss': 0.3096, 'learning_rate': 0.0009726666666666667, 'epoch': 8.2}\n","{'loss': 0.3009, 'learning_rate': 0.0009723333333333334, 'epoch': 8.3}\n","{'loss': 0.3286, 'learning_rate': 0.000972, 'epoch': 8.4}\n","{'loss': 0.2916, 'learning_rate': 0.0009716666666666667, 'epoch': 8.5}\n","{'loss': 0.3319, 'learning_rate': 0.0009713333333333334, 'epoch': 8.6}\n","{'loss': 0.3457, 'learning_rate': 0.000971, 'epoch': 8.7}\n","{'loss': 0.3281, 'learning_rate': 0.0009706666666666667, 'epoch': 8.8}\n","{'loss': 0.3168, 'learning_rate': 0.0009703333333333334, 'epoch': 8.9}\n","{'loss': 0.3031, 'learning_rate': 0.0009699999999999999, 'epoch': 9.0}\n","  3% 900/30000 [18:25<6:43:34,  1.20it/s][INFO|trainer.py:3187] 2023-09-19 17:53:58,959 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3189] 2023-09-19 17:53:58,959 >>   Num examples = 9000\n","[INFO|trainer.py:3192] 2023-09-19 17:53:58,959 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:05,  2.71it/s]\u001b[A\n"," 17% 3/18 [00:01<00:07,  1.94it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.70it/s]\u001b[A\n"," 28% 5/18 [00:02<00:08,  1.57it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.49it/s]\u001b[A\n"," 39% 7/18 [00:04<00:07,  1.45it/s]\u001b[A\n"," 44% 8/18 [00:05<00:06,  1.43it/s]\u001b[A\n"," 50% 9/18 [00:05<00:06,  1.41it/s]\u001b[A\n"," 56% 10/18 [00:06<00:05,  1.40it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.40it/s]\u001b[A\n"," 67% 12/18 [00:07<00:04,  1.39it/s]\u001b[A\n"," 72% 13/18 [00:08<00:03,  1.35it/s]\u001b[A\n"," 78% 14/18 [00:09<00:02,  1.34it/s]\u001b[A\n"," 83% 15/18 [00:10<00:02,  1.30it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.28it/s]\u001b[A\n"," 94% 17/18 [00:11<00:00,  1.42it/s]\u001b[A\n","{'eval_loss': 0.055844563990831375, 'eval_accuracy': 0.9823333333333333, 'eval_runtime': 13.1363, 'eval_samples_per_second': 685.125, 'eval_steps_per_second': 1.37, 'epoch': 9.0}\n","\n","  3% 900/30000 [18:39<6:43:34,  1.20it/s]\n","                                   \u001b[A[INFO|trainer.py:2913] 2023-09-19 17:54:12,101 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-900\n","[INFO|configuration_utils.py:460] 2023-09-19 17:54:12,107 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-900/config.json\n","[INFO|modeling_utils.py:2030] 2023-09-19 17:54:12,221 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-900/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-19 17:54:12,226 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-900/preprocessor_config.json\n","[INFO|trainer.py:3000] 2023-09-19 17:54:12,440 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-500] due to args.save_total_limit\n","{'loss': 0.328, 'learning_rate': 0.0009696666666666667, 'epoch': 9.1}\n","{'loss': 0.3132, 'learning_rate': 0.0009693333333333334, 'epoch': 9.2}\n","{'loss': 0.3017, 'learning_rate': 0.000969, 'epoch': 9.3}\n","{'loss': 0.3057, 'learning_rate': 0.0009686666666666667, 'epoch': 9.4}\n","{'loss': 0.2898, 'learning_rate': 0.0009683333333333334, 'epoch': 9.5}\n","{'loss': 0.3335, 'learning_rate': 0.000968, 'epoch': 9.6}\n","{'loss': 0.3106, 'learning_rate': 0.0009676666666666667, 'epoch': 9.7}\n","{'loss': 0.3069, 'learning_rate': 0.0009673333333333334, 'epoch': 9.8}\n","{'loss': 0.323, 'learning_rate': 0.000967, 'epoch': 9.9}\n","{'loss': 0.3101, 'learning_rate': 0.0009666666666666667, 'epoch': 10.0}\n","  3% 1000/30000 [20:30<6:33:28,  1.23it/s][INFO|trainer.py:3187] 2023-09-19 17:56:03,635 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3189] 2023-09-19 17:56:03,635 >>   Num examples = 9000\n","[INFO|trainer.py:3192] 2023-09-19 17:56:03,635 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:05,  2.75it/s]\u001b[A\n"," 17% 3/18 [00:01<00:07,  1.96it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.68it/s]\u001b[A\n"," 28% 5/18 [00:02<00:08,  1.55it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.49it/s]\u001b[A\n"," 39% 7/18 [00:04<00:07,  1.45it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.42it/s]\u001b[A\n"," 50% 9/18 [00:05<00:06,  1.39it/s]\u001b[A\n"," 56% 10/18 [00:06<00:05,  1.37it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.37it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.37it/s]\u001b[A\n"," 72% 13/18 [00:08<00:03,  1.37it/s]\u001b[A\n"," 78% 14/18 [00:09<00:02,  1.37it/s]\u001b[A\n"," 83% 15/18 [00:10<00:02,  1.33it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.31it/s]\u001b[A\n"," 94% 17/18 [00:11<00:00,  1.46it/s]\u001b[A\n","{'eval_loss': 0.04408084601163864, 'eval_accuracy': 0.9848888888888889, 'eval_runtime': 13.2951, 'eval_samples_per_second': 676.943, 'eval_steps_per_second': 1.354, 'epoch': 10.0}\n","\n","  3% 1000/30000 [20:43<6:33:28,  1.23it/s]\n","                                   \u001b[A[INFO|trainer.py:2913] 2023-09-19 17:56:16,935 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-1000\n","[INFO|configuration_utils.py:460] 2023-09-19 17:56:16,942 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-1000/config.json\n","[INFO|modeling_utils.py:2030] 2023-09-19 17:56:17,055 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-1000/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-19 17:56:17,059 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-1000/preprocessor_config.json\n","[INFO|trainer.py:3000] 2023-09-19 17:56:17,284 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-700] due to args.save_total_limit\n","{'loss': 0.3111, 'learning_rate': 0.0009663333333333334, 'epoch': 10.1}\n","{'loss': 0.303, 'learning_rate': 0.000966, 'epoch': 10.2}\n","{'loss': 0.3098, 'learning_rate': 0.0009656666666666666, 'epoch': 10.3}\n","{'loss': 0.2992, 'learning_rate': 0.0009653333333333333, 'epoch': 10.4}\n","{'loss': 0.3058, 'learning_rate': 0.000965, 'epoch': 10.5}\n","{'loss': 0.3126, 'learning_rate': 0.0009646666666666667, 'epoch': 10.6}\n","{'loss': 0.3258, 'learning_rate': 0.0009643333333333334, 'epoch': 10.7}\n","{'loss': 0.3296, 'learning_rate': 0.000964, 'epoch': 10.8}\n","{'loss': 0.3074, 'learning_rate': 0.0009636666666666667, 'epoch': 10.9}\n","{'loss': 0.3031, 'learning_rate': 0.0009633333333333334, 'epoch': 11.0}\n","  4% 1100/30000 [22:34<6:16:53,  1.28it/s][INFO|trainer.py:3187] 2023-09-19 17:58:07,990 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3189] 2023-09-19 17:58:07,991 >>   Num examples = 9000\n","[INFO|trainer.py:3192] 2023-09-19 17:58:07,991 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.37it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.67it/s]\u001b[A\n"," 22% 4/18 [00:02<00:09,  1.44it/s]\u001b[A\n"," 28% 5/18 [00:03<00:09,  1.37it/s]\u001b[A\n"," 33% 6/18 [00:04<00:08,  1.37it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.36it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.35it/s]\u001b[A\n"," 50% 9/18 [00:06<00:06,  1.35it/s]\u001b[A\n"," 56% 10/18 [00:07<00:05,  1.35it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.35it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.36it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.35it/s]\u001b[A\n"," 78% 14/18 [00:10<00:02,  1.35it/s]\u001b[A\n"," 83% 15/18 [00:10<00:02,  1.35it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.35it/s]\u001b[A\n"," 94% 17/18 [00:11<00:00,  1.51it/s]\u001b[A\n","{'eval_loss': 0.31752315163612366, 'eval_accuracy': 0.8948888888888888, 'eval_runtime': 13.5311, 'eval_samples_per_second': 665.136, 'eval_steps_per_second': 1.33, 'epoch': 11.0}\n","\n","  4% 1100/30000 [22:48<6:16:53,  1.28it/s]\n","                                   \u001b[A[INFO|trainer.py:2913] 2023-09-19 17:58:21,526 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-1100\n","[INFO|configuration_utils.py:460] 2023-09-19 17:58:21,532 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-1100/config.json\n","[INFO|modeling_utils.py:2030] 2023-09-19 17:58:21,641 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-1100/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-19 17:58:21,661 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-1100/preprocessor_config.json\n","[INFO|trainer.py:3000] 2023-09-19 17:58:21,880 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-800] due to args.save_total_limit\n","{'loss': 0.3141, 'learning_rate': 0.000963, 'epoch': 11.1}\n","{'loss': 0.3227, 'learning_rate': 0.0009626666666666667, 'epoch': 11.2}\n","{'loss': 0.3017, 'learning_rate': 0.0009623333333333334, 'epoch': 11.3}\n","{'loss': 0.2982, 'learning_rate': 0.000962, 'epoch': 11.4}\n","{'loss': 0.3169, 'learning_rate': 0.0009616666666666667, 'epoch': 11.5}\n","{'loss': 0.3161, 'learning_rate': 0.0009613333333333334, 'epoch': 11.6}\n","{'loss': 0.2995, 'learning_rate': 0.0009609999999999999, 'epoch': 11.7}\n","{'loss': 0.2994, 'learning_rate': 0.0009606666666666666, 'epoch': 11.8}\n","{'loss': 0.2973, 'learning_rate': 0.0009603333333333334, 'epoch': 11.9}\n","{'loss': 0.3136, 'learning_rate': 0.00096, 'epoch': 12.0}\n","  4% 1200/30000 [24:40<6:15:11,  1.28it/s][INFO|trainer.py:3187] 2023-09-19 18:00:13,456 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3189] 2023-09-19 18:00:13,456 >>   Num examples = 9000\n","[INFO|trainer.py:3192] 2023-09-19 18:00:13,456 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.55it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.82it/s]\u001b[A\n"," 22% 4/18 [00:02<00:09,  1.55it/s]\u001b[A\n"," 28% 5/18 [00:03<00:09,  1.41it/s]\u001b[A\n"," 33% 6/18 [00:04<00:08,  1.34it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.35it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.34it/s]\u001b[A\n"," 50% 9/18 [00:06<00:06,  1.35it/s]\u001b[A\n"," 56% 10/18 [00:06<00:05,  1.35it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.35it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.34it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.34it/s]\u001b[A\n"," 78% 14/18 [00:09<00:03,  1.33it/s]\u001b[A\n"," 83% 15/18 [00:10<00:02,  1.33it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.33it/s]\u001b[A\n"," 94% 17/18 [00:11<00:00,  1.50it/s]\u001b[A\n","{'eval_loss': 0.0499030202627182, 'eval_accuracy': 0.9858888888888889, 'eval_runtime': 13.3962, 'eval_samples_per_second': 671.834, 'eval_steps_per_second': 1.344, 'epoch': 12.0}\n","\n","  4% 1200/30000 [24:53<6:15:11,  1.28it/s]\n","                                   \u001b[A[INFO|trainer.py:2913] 2023-09-19 18:00:26,857 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-1200\n","[INFO|configuration_utils.py:460] 2023-09-19 18:00:26,862 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-1200/config.json\n","[INFO|modeling_utils.py:2030] 2023-09-19 18:00:26,976 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-1200/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-19 18:00:26,980 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-1200/preprocessor_config.json\n","[INFO|trainer.py:3000] 2023-09-19 18:00:27,192 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-900] due to args.save_total_limit\n","{'loss': 0.3086, 'learning_rate': 0.0009596666666666667, 'epoch': 12.1}\n","{'loss': 0.2952, 'learning_rate': 0.0009593333333333334, 'epoch': 12.2}\n","{'loss': 0.3005, 'learning_rate': 0.000959, 'epoch': 12.3}\n","{'loss': 0.312, 'learning_rate': 0.0009586666666666667, 'epoch': 12.4}\n","{'loss': 0.2931, 'learning_rate': 0.0009583333333333334, 'epoch': 12.5}\n","{'loss': 0.2836, 'learning_rate': 0.000958, 'epoch': 12.6}\n","{'loss': 0.3043, 'learning_rate': 0.0009576666666666667, 'epoch': 12.7}\n","{'loss': 0.2896, 'learning_rate': 0.0009573333333333334, 'epoch': 12.8}\n","{'loss': 0.3031, 'learning_rate': 0.000957, 'epoch': 12.9}\n","{'loss': 0.2893, 'learning_rate': 0.0009566666666666666, 'epoch': 13.0}\n","  4% 1300/30000 [26:45<6:12:43,  1.28it/s][INFO|trainer.py:3187] 2023-09-19 18:02:18,856 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3189] 2023-09-19 18:02:18,856 >>   Num examples = 9000\n","[INFO|trainer.py:3192] 2023-09-19 18:02:18,856 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:05,  2.70it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.83it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.56it/s]\u001b[A\n"," 28% 5/18 [00:03<00:08,  1.45it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.36it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.31it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.31it/s]\u001b[A\n"," 50% 9/18 [00:06<00:06,  1.32it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.32it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.32it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.34it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.35it/s]\u001b[A\n"," 78% 14/18 [00:09<00:02,  1.35it/s]\u001b[A\n"," 83% 15/18 [00:10<00:02,  1.36it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.35it/s]\u001b[A\n"," 94% 17/18 [00:11<00:00,  1.52it/s]\u001b[A\n","{'eval_loss': 0.04949258267879486, 'eval_accuracy': 0.9854444444444445, 'eval_runtime': 13.364, 'eval_samples_per_second': 673.451, 'eval_steps_per_second': 1.347, 'epoch': 13.0}\n","\n","  4% 1300/30000 [26:59<6:12:43,  1.28it/s]\n","                                   \u001b[A[INFO|trainer.py:2913] 2023-09-19 18:02:32,224 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-1300\n","[INFO|configuration_utils.py:460] 2023-09-19 18:02:32,229 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-1300/config.json\n","[INFO|modeling_utils.py:2030] 2023-09-19 18:02:32,335 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-1300/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-19 18:02:32,340 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-1300/preprocessor_config.json\n","[INFO|trainer.py:3000] 2023-09-19 18:02:32,554 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-1100] due to args.save_total_limit\n","{'loss': 0.2991, 'learning_rate': 0.0009563333333333333, 'epoch': 13.1}\n","{'loss': 0.2857, 'learning_rate': 0.0009559999999999999, 'epoch': 13.2}\n","{'loss': 0.3057, 'learning_rate': 0.0009556666666666667, 'epoch': 13.3}\n","{'loss': 0.2807, 'learning_rate': 0.0009553333333333334, 'epoch': 13.4}\n","{'loss': 0.2927, 'learning_rate': 0.000955, 'epoch': 13.5}\n","{'loss': 0.2791, 'learning_rate': 0.0009546666666666667, 'epoch': 13.6}\n","{'loss': 0.2953, 'learning_rate': 0.0009543333333333334, 'epoch': 13.7}\n","{'loss': 0.2976, 'learning_rate': 0.000954, 'epoch': 13.8}\n","{'loss': 0.3113, 'learning_rate': 0.0009536666666666667, 'epoch': 13.9}\n","{'loss': 0.3052, 'learning_rate': 0.0009533333333333334, 'epoch': 14.0}\n","  5% 1400/30000 [28:50<6:17:12,  1.26it/s][INFO|trainer.py:3187] 2023-09-19 18:04:23,905 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3189] 2023-09-19 18:04:23,906 >>   Num examples = 9000\n","[INFO|trainer.py:3192] 2023-09-19 18:04:23,906 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:05,  2.68it/s]\u001b[A\n"," 17% 3/18 [00:01<00:07,  1.89it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.65it/s]\u001b[A\n"," 28% 5/18 [00:02<00:08,  1.51it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.42it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.37it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.32it/s]\u001b[A\n"," 50% 9/18 [00:06<00:07,  1.26it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.24it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.28it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.30it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.30it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.31it/s]\u001b[A\n"," 83% 15/18 [00:10<00:02,  1.33it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.34it/s]\u001b[A\n"," 94% 17/18 [00:11<00:00,  1.52it/s]\u001b[A\n","{'eval_loss': 0.7156779170036316, 'eval_accuracy': 0.7506666666666667, 'eval_runtime': 13.48, 'eval_samples_per_second': 667.656, 'eval_steps_per_second': 1.335, 'epoch': 14.0}\n","\n","  5% 1400/30000 [29:04<6:17:12,  1.26it/s]\n","                                   \u001b[A[INFO|trainer.py:2913] 2023-09-19 18:04:37,401 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-1400\n","[INFO|configuration_utils.py:460] 2023-09-19 18:04:37,408 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-1400/config.json\n","[INFO|modeling_utils.py:2030] 2023-09-19 18:04:37,516 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-1400/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-19 18:04:37,521 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-1400/preprocessor_config.json\n","[INFO|trainer.py:3000] 2023-09-19 18:04:37,741 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-1200] due to args.save_total_limit\n","{'loss': 0.2954, 'learning_rate': 0.000953, 'epoch': 14.1}\n","{'loss': 0.3061, 'learning_rate': 0.0009526666666666667, 'epoch': 14.2}\n","{'loss': 0.3059, 'learning_rate': 0.0009523333333333334, 'epoch': 14.3}\n","{'loss': 0.3024, 'learning_rate': 0.0009519999999999999, 'epoch': 14.4}\n","{'loss': 0.2938, 'learning_rate': 0.0009516666666666666, 'epoch': 14.5}\n","{'loss': 0.2936, 'learning_rate': 0.0009513333333333334, 'epoch': 14.6}\n","{'loss': 0.2818, 'learning_rate': 0.000951, 'epoch': 14.7}\n","{'loss': 0.2979, 'learning_rate': 0.0009506666666666667, 'epoch': 14.8}\n","{'loss': 0.3098, 'learning_rate': 0.0009503333333333334, 'epoch': 14.9}\n","{'loss': 0.2934, 'learning_rate': 0.00095, 'epoch': 15.0}\n","  5% 1500/30000 [30:55<6:19:33,  1.25it/s][INFO|trainer.py:3187] 2023-09-19 18:06:28,929 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3189] 2023-09-19 18:06:28,930 >>   Num examples = 9000\n","[INFO|trainer.py:3192] 2023-09-19 18:06:28,930 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:05,  2.73it/s]\u001b[A\n"," 17% 3/18 [00:01<00:07,  1.91it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.67it/s]\u001b[A\n"," 28% 5/18 [00:02<00:08,  1.55it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.47it/s]\u001b[A\n"," 39% 7/18 [00:04<00:07,  1.43it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.40it/s]\u001b[A\n"," 50% 9/18 [00:05<00:06,  1.35it/s]\u001b[A\n"," 56% 10/18 [00:06<00:06,  1.29it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.25it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.25it/s]\u001b[A\n"," 72% 13/18 [00:09<00:04,  1.25it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.26it/s]\u001b[A\n"," 83% 15/18 [00:10<00:02,  1.30it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.31it/s]\u001b[A\n"," 94% 17/18 [00:11<00:00,  1.50it/s]\u001b[A\n","{'eval_loss': 0.0462041012942791, 'eval_accuracy': 0.986, 'eval_runtime': 13.4158, 'eval_samples_per_second': 670.852, 'eval_steps_per_second': 1.342, 'epoch': 15.0}\n","\n","  5% 1500/30000 [31:09<6:19:33,  1.25it/s]\n","                                   \u001b[A[INFO|trainer.py:2913] 2023-09-19 18:06:42,349 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-1500\n","[INFO|configuration_utils.py:460] 2023-09-19 18:06:42,355 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-1500/config.json\n","[INFO|modeling_utils.py:2030] 2023-09-19 18:06:42,460 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-1500/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-19 18:06:42,466 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-1500/preprocessor_config.json\n","[INFO|trainer.py:3000] 2023-09-19 18:06:42,691 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-1300] due to args.save_total_limit\n","{'loss': 0.3062, 'learning_rate': 0.0009496666666666667, 'epoch': 15.1}\n","{'loss': 0.2914, 'learning_rate': 0.0009493333333333334, 'epoch': 15.2}\n","{'loss': 0.3147, 'learning_rate': 0.000949, 'epoch': 15.3}\n","{'loss': 0.2721, 'learning_rate': 0.0009486666666666667, 'epoch': 15.4}\n","{'loss': 0.2963, 'learning_rate': 0.0009483333333333334, 'epoch': 15.5}\n","{'loss': 0.2901, 'learning_rate': 0.000948, 'epoch': 15.6}\n","{'loss': 0.3194, 'learning_rate': 0.0009476666666666666, 'epoch': 15.7}\n","{'loss': 0.2916, 'learning_rate': 0.0009473333333333333, 'epoch': 15.8}\n","{'loss': 0.3047, 'learning_rate': 0.0009469999999999999, 'epoch': 15.9}\n","{'loss': 0.2734, 'learning_rate': 0.0009466666666666667, 'epoch': 16.0}\n","  5% 1600/30000 [33:00<6:32:43,  1.21it/s][INFO|trainer.py:3187] 2023-09-19 18:08:33,121 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3189] 2023-09-19 18:08:33,121 >>   Num examples = 9000\n","[INFO|trainer.py:3192] 2023-09-19 18:08:33,121 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:05,  2.69it/s]\u001b[A\n"," 17% 3/18 [00:01<00:07,  1.90it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.64it/s]\u001b[A\n"," 28% 5/18 [00:02<00:08,  1.53it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.47it/s]\u001b[A\n"," 39% 7/18 [00:04<00:07,  1.42it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.39it/s]\u001b[A\n"," 50% 9/18 [00:05<00:06,  1.39it/s]\u001b[A\n"," 56% 10/18 [00:06<00:05,  1.38it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.37it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.34it/s]\u001b[A\n"," 72% 13/18 [00:08<00:03,  1.34it/s]\u001b[A\n"," 78% 14/18 [00:09<00:03,  1.30it/s]\u001b[A\n"," 83% 15/18 [00:10<00:02,  1.29it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.27it/s]\u001b[A\n"," 94% 17/18 [00:11<00:00,  1.42it/s]\u001b[A\n","{'eval_loss': 0.04452584683895111, 'eval_accuracy': 0.9866666666666667, 'eval_runtime': 13.3302, 'eval_samples_per_second': 675.158, 'eval_steps_per_second': 1.35, 'epoch': 16.0}\n","\n","  5% 1600/30000 [33:13<6:32:43,  1.21it/s]\n","                                   \u001b[A[INFO|trainer.py:2913] 2023-09-19 18:08:46,455 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-1600\n","[INFO|configuration_utils.py:460] 2023-09-19 18:08:46,461 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-1600/config.json\n","[INFO|modeling_utils.py:2030] 2023-09-19 18:08:46,575 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-1600/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-19 18:08:46,580 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-1600/preprocessor_config.json\n","[INFO|trainer.py:3000] 2023-09-19 18:08:46,799 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-1400] due to args.save_total_limit\n","{'loss': 0.2844, 'learning_rate': 0.0009463333333333334, 'epoch': 16.1}\n","{'loss': 0.3168, 'learning_rate': 0.000946, 'epoch': 16.2}\n","{'loss': 0.2916, 'learning_rate': 0.0009456666666666667, 'epoch': 16.3}\n","{'loss': 0.2951, 'learning_rate': 0.0009453333333333334, 'epoch': 16.4}\n","{'loss': 0.2769, 'learning_rate': 0.000945, 'epoch': 16.5}\n","{'loss': 0.2973, 'learning_rate': 0.0009446666666666667, 'epoch': 16.6}\n","{'loss': 0.3008, 'learning_rate': 0.0009443333333333334, 'epoch': 16.7}\n","{'loss': 0.3101, 'learning_rate': 0.000944, 'epoch': 16.8}\n","{'loss': 0.2952, 'learning_rate': 0.0009436666666666667, 'epoch': 16.9}\n","{'loss': 0.2862, 'learning_rate': 0.0009433333333333334, 'epoch': 17.0}\n","  6% 1700/30000 [35:04<6:24:33,  1.23it/s][INFO|trainer.py:3187] 2023-09-19 18:10:37,254 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3189] 2023-09-19 18:10:37,254 >>   Num examples = 9000\n","[INFO|trainer.py:3192] 2023-09-19 18:10:37,255 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.38it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.80it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.59it/s]\u001b[A\n"," 28% 5/18 [00:03<00:08,  1.50it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.46it/s]\u001b[A\n"," 39% 7/18 [00:04<00:07,  1.41it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.40it/s]\u001b[A\n"," 50% 9/18 [00:06<00:06,  1.39it/s]\u001b[A\n"," 56% 10/18 [00:06<00:05,  1.38it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.38it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.36it/s]\u001b[A\n"," 72% 13/18 [00:08<00:03,  1.37it/s]\u001b[A\n"," 78% 14/18 [00:09<00:02,  1.36it/s]\u001b[A\n"," 83% 15/18 [00:10<00:02,  1.35it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.23it/s]\u001b[A\n"," 94% 17/18 [00:11<00:00,  1.40it/s]\u001b[A\n","{'eval_loss': 2.6414794921875, 'eval_accuracy': 0.39255555555555555, 'eval_runtime': 13.5752, 'eval_samples_per_second': 662.976, 'eval_steps_per_second': 1.326, 'epoch': 17.0}\n","\n","  6% 1700/30000 [35:17<6:24:33,  1.23it/s]\n","                                   \u001b[A[INFO|trainer.py:2913] 2023-09-19 18:10:50,834 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-1700\n","[INFO|configuration_utils.py:460] 2023-09-19 18:10:50,840 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-1700/config.json\n","[INFO|modeling_utils.py:2030] 2023-09-19 18:10:50,954 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-1700/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-19 18:10:50,959 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-1700/preprocessor_config.json\n","[INFO|trainer.py:3000] 2023-09-19 18:10:51,192 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-1500] due to args.save_total_limit\n","{'loss': 0.286, 'learning_rate': 0.0009429999999999999, 'epoch': 17.1}\n","{'loss': 0.3181, 'learning_rate': 0.0009426666666666666, 'epoch': 17.2}\n","{'loss': 0.2965, 'learning_rate': 0.0009423333333333333, 'epoch': 17.3}\n","{'loss': 0.2998, 'learning_rate': 0.000942, 'epoch': 17.4}\n","{'loss': 0.2768, 'learning_rate': 0.0009416666666666667, 'epoch': 17.5}\n","{'loss': 0.2651, 'learning_rate': 0.0009413333333333334, 'epoch': 17.6}\n","{'loss': 0.2756, 'learning_rate': 0.000941, 'epoch': 17.7}\n","{'loss': 0.2712, 'learning_rate': 0.0009406666666666667, 'epoch': 17.8}\n","{'loss': 0.2946, 'learning_rate': 0.0009403333333333334, 'epoch': 17.9}\n","{'loss': 0.2708, 'learning_rate': 0.00094, 'epoch': 18.0}\n","  6% 1800/30000 [37:08<6:06:59,  1.28it/s][INFO|trainer.py:3187] 2023-09-19 18:12:41,903 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3189] 2023-09-19 18:12:41,904 >>   Num examples = 9000\n","[INFO|trainer.py:3192] 2023-09-19 18:12:41,904 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:07,  2.24it/s]\u001b[A\n"," 17% 3/18 [00:01<00:09,  1.60it/s]\u001b[A\n"," 22% 4/18 [00:02<00:09,  1.42it/s]\u001b[A\n"," 28% 5/18 [00:03<00:09,  1.37it/s]\u001b[A\n"," 33% 6/18 [00:04<00:08,  1.36it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.35it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.35it/s]\u001b[A\n"," 50% 9/18 [00:06<00:06,  1.35it/s]\u001b[A\n"," 56% 10/18 [00:07<00:05,  1.35it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.36it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.35it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.35it/s]\u001b[A\n"," 78% 14/18 [00:10<00:02,  1.35it/s]\u001b[A\n"," 83% 15/18 [00:10<00:02,  1.34it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.35it/s]\u001b[A\n"," 94% 17/18 [00:12<00:00,  1.52it/s]\u001b[A\n","{'eval_loss': 0.04410013183951378, 'eval_accuracy': 0.9867777777777778, 'eval_runtime': 13.7547, 'eval_samples_per_second': 654.324, 'eval_steps_per_second': 1.309, 'epoch': 18.0}\n","\n","  6% 1800/30000 [37:22<6:06:59,  1.28it/s]\n","                                   \u001b[A[INFO|trainer.py:2913] 2023-09-19 18:12:55,662 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-1800\n","[INFO|configuration_utils.py:460] 2023-09-19 18:12:55,668 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-1800/config.json\n","[INFO|modeling_utils.py:2030] 2023-09-19 18:12:55,779 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-1800/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-19 18:12:55,784 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-1800/preprocessor_config.json\n","[INFO|trainer.py:3000] 2023-09-19 18:12:56,000 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-1600] due to args.save_total_limit\n","{'loss': 0.2876, 'learning_rate': 0.0009396666666666667, 'epoch': 18.1}\n","{'loss': 0.2727, 'learning_rate': 0.0009393333333333334, 'epoch': 18.2}\n","{'loss': 0.2873, 'learning_rate': 0.000939, 'epoch': 18.3}\n","{'loss': 0.2642, 'learning_rate': 0.0009386666666666666, 'epoch': 18.4}\n","{'loss': 0.2991, 'learning_rate': 0.0009383333333333333, 'epoch': 18.5}\n","{'loss': 0.2771, 'learning_rate': 0.0009379999999999999, 'epoch': 18.6}\n","{'loss': 0.2939, 'learning_rate': 0.0009376666666666666, 'epoch': 18.7}\n","{'loss': 0.2936, 'learning_rate': 0.0009373333333333334, 'epoch': 18.8}\n","{'loss': 0.2947, 'learning_rate': 0.0009370000000000001, 'epoch': 18.9}\n","{'loss': 0.2917, 'learning_rate': 0.0009366666666666667, 'epoch': 19.0}\n","  6% 1900/30000 [39:15<6:10:36,  1.26it/s][INFO|trainer.py:3187] 2023-09-19 18:14:48,578 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3189] 2023-09-19 18:14:48,578 >>   Num examples = 9000\n","[INFO|trainer.py:3192] 2023-09-19 18:14:48,578 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.56it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.78it/s]\u001b[A\n"," 22% 4/18 [00:02<00:09,  1.54it/s]\u001b[A\n"," 28% 5/18 [00:03<00:09,  1.42it/s]\u001b[A\n"," 33% 6/18 [00:04<00:08,  1.34it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.34it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.35it/s]\u001b[A\n"," 50% 9/18 [00:06<00:06,  1.34it/s]\u001b[A\n"," 56% 10/18 [00:07<00:05,  1.34it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.33it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.34it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.35it/s]\u001b[A\n"," 78% 14/18 [00:09<00:02,  1.34it/s]\u001b[A\n"," 83% 15/18 [00:10<00:02,  1.34it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.22it/s]\u001b[A\n"," 94% 17/18 [00:12<00:00,  1.41it/s]\u001b[A\n","{'eval_loss': 0.03302377834916115, 'eval_accuracy': 0.9888888888888889, 'eval_runtime': 13.6325, 'eval_samples_per_second': 660.187, 'eval_steps_per_second': 1.32, 'epoch': 19.0}\n","\n","  6% 1900/30000 [39:29<6:10:36,  1.26it/s]\n","                                   \u001b[A[INFO|trainer.py:2913] 2023-09-19 18:15:02,214 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-1900\n","[INFO|configuration_utils.py:460] 2023-09-19 18:15:02,220 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-1900/config.json\n","[INFO|modeling_utils.py:2030] 2023-09-19 18:15:02,325 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-1900/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-19 18:15:02,329 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-1900/preprocessor_config.json\n","[INFO|trainer.py:3000] 2023-09-19 18:15:02,549 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-1000] due to args.save_total_limit\n","{'loss': 0.2707, 'learning_rate': 0.0009363333333333334, 'epoch': 19.1}\n","{'loss': 0.2934, 'learning_rate': 0.0009360000000000001, 'epoch': 19.2}\n","{'loss': 0.2907, 'learning_rate': 0.0009356666666666667, 'epoch': 19.3}\n","{'loss': 0.2729, 'learning_rate': 0.0009353333333333334, 'epoch': 19.4}\n","{'loss': 0.2717, 'learning_rate': 0.0009350000000000001, 'epoch': 19.5}\n","{'loss': 0.2855, 'learning_rate': 0.0009346666666666667, 'epoch': 19.6}\n","{'loss': 0.2858, 'learning_rate': 0.0009343333333333333, 'epoch': 19.7}\n","{'loss': 0.292, 'learning_rate': 0.000934, 'epoch': 19.8}\n","{'loss': 0.2842, 'learning_rate': 0.0009336666666666666, 'epoch': 19.9}\n","{'loss': 0.289, 'learning_rate': 0.0009333333333333333, 'epoch': 20.0}\n","  7% 2000/30000 [41:21<6:11:52,  1.25it/s][INFO|trainer.py:3187] 2023-09-19 18:16:54,935 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3189] 2023-09-19 18:16:54,935 >>   Num examples = 9000\n","[INFO|trainer.py:3192] 2023-09-19 18:16:54,936 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.66it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.72it/s]\u001b[A\n"," 22% 4/18 [00:02<00:09,  1.44it/s]\u001b[A\n"," 28% 5/18 [00:03<00:09,  1.35it/s]\u001b[A\n"," 33% 6/18 [00:04<00:09,  1.27it/s]\u001b[A\n"," 39% 7/18 [00:05<00:08,  1.25it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.27it/s]\u001b[A\n"," 50% 9/18 [00:06<00:06,  1.29it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.29it/s]\u001b[A\n"," 61% 11/18 [00:08<00:05,  1.30it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.31it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.31it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.32it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.31it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.32it/s]\u001b[A\n"," 94% 17/18 [00:12<00:00,  1.49it/s]\u001b[A\n","{'eval_loss': 0.06632715463638306, 'eval_accuracy': 0.9804444444444445, 'eval_runtime': 13.8294, 'eval_samples_per_second': 650.785, 'eval_steps_per_second': 1.302, 'epoch': 20.0}\n","\n","  7% 2000/30000 [41:35<6:11:52,  1.25it/s]\n","                                   \u001b[A[INFO|trainer.py:2913] 2023-09-19 18:17:08,769 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-2000\n","[INFO|configuration_utils.py:460] 2023-09-19 18:17:08,774 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-2000/config.json\n","[INFO|modeling_utils.py:2030] 2023-09-19 18:17:08,881 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-2000/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-19 18:17:08,885 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-2000/preprocessor_config.json\n","[INFO|trainer.py:3000] 2023-09-19 18:17:09,102 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-1700] due to args.save_total_limit\n","{'loss': 0.2687, 'learning_rate': 0.000933, 'epoch': 20.1}\n","{'loss': 0.2874, 'learning_rate': 0.0009326666666666667, 'epoch': 20.2}\n","{'loss': 0.2882, 'learning_rate': 0.0009323333333333334, 'epoch': 20.3}\n","{'loss': 0.2936, 'learning_rate': 0.0009320000000000001, 'epoch': 20.4}\n","{'loss': 0.2917, 'learning_rate': 0.0009316666666666667, 'epoch': 20.5}\n","{'loss': 0.2817, 'learning_rate': 0.0009313333333333334, 'epoch': 20.6}\n","{'loss': 0.2776, 'learning_rate': 0.0009310000000000001, 'epoch': 20.7}\n","{'loss': 0.2975, 'learning_rate': 0.0009306666666666667, 'epoch': 20.8}\n","{'loss': 0.2819, 'learning_rate': 0.0009303333333333334, 'epoch': 20.9}\n","{'loss': 0.28, 'learning_rate': 0.00093, 'epoch': 21.0}\n","  7% 2100/30000 [43:30<6:05:25,  1.27it/s][INFO|trainer.py:3187] 2023-09-19 18:19:03,379 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3189] 2023-09-19 18:19:03,379 >>   Num examples = 9000\n","[INFO|trainer.py:3192] 2023-09-19 18:19:03,379 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.64it/s]\u001b[A\n"," 17% 3/18 [00:01<00:07,  1.89it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.60it/s]\u001b[A\n"," 28% 5/18 [00:03<00:09,  1.41it/s]\u001b[A\n"," 33% 6/18 [00:04<00:09,  1.31it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.26it/s]\u001b[A\n"," 44% 8/18 [00:05<00:08,  1.22it/s]\u001b[A\n"," 50% 9/18 [00:06<00:07,  1.25it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.27it/s]\u001b[A\n"," 61% 11/18 [00:08<00:05,  1.29it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.30it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.31it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.31it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.33it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.33it/s]\u001b[A\n"," 94% 17/18 [00:12<00:00,  1.50it/s]\u001b[A\n","{'eval_loss': 0.554004967212677, 'eval_accuracy': 0.7994444444444444, 'eval_runtime': 13.7385, 'eval_samples_per_second': 655.094, 'eval_steps_per_second': 1.31, 'epoch': 21.0}\n","\n","  7% 2100/30000 [43:44<6:05:25,  1.27it/s]\n","                                   \u001b[A[INFO|trainer.py:2913] 2023-09-19 18:19:17,122 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-2100\n","[INFO|configuration_utils.py:460] 2023-09-19 18:19:17,127 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-2100/config.json\n","[INFO|modeling_utils.py:2030] 2023-09-19 18:19:17,234 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-2100/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-19 18:19:17,238 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-2100/preprocessor_config.json\n","[INFO|trainer.py:3000] 2023-09-19 18:19:17,464 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-1800] due to args.save_total_limit\n","{'loss': 0.2735, 'learning_rate': 0.0009296666666666666, 'epoch': 21.1}\n","{'loss': 0.263, 'learning_rate': 0.0009293333333333333, 'epoch': 21.2}\n","{'loss': 0.2821, 'learning_rate': 0.000929, 'epoch': 21.3}\n","{'loss': 0.2962, 'learning_rate': 0.0009286666666666666, 'epoch': 21.4}\n","{'loss': 0.2867, 'learning_rate': 0.0009283333333333333, 'epoch': 21.5}\n","{'loss': 0.2908, 'learning_rate': 0.0009280000000000001, 'epoch': 21.6}\n","{'loss': 0.2768, 'learning_rate': 0.0009276666666666667, 'epoch': 21.7}\n","{'loss': 0.2713, 'learning_rate': 0.0009273333333333334, 'epoch': 21.8}\n","{'loss': 0.2719, 'learning_rate': 0.0009270000000000001, 'epoch': 21.9}\n","{'loss': 0.3016, 'learning_rate': 0.0009266666666666667, 'epoch': 22.0}\n","  7% 2200/30000 [45:36<6:10:13,  1.25it/s][INFO|trainer.py:3187] 2023-09-19 18:21:09,479 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3189] 2023-09-19 18:21:09,480 >>   Num examples = 9000\n","[INFO|trainer.py:3192] 2023-09-19 18:21:09,480 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:05,  2.75it/s]\u001b[A\n"," 17% 3/18 [00:01<00:07,  1.93it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.66it/s]\u001b[A\n"," 28% 5/18 [00:02<00:08,  1.54it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.43it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.33it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.29it/s]\u001b[A\n"," 50% 9/18 [00:06<00:07,  1.23it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.23it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.22it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.24it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.27it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.29it/s]\u001b[A\n"," 83% 15/18 [00:10<00:02,  1.31it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.32it/s]\u001b[A\n"," 94% 17/18 [00:12<00:00,  1.49it/s]\u001b[A\n","{'eval_loss': 0.03203807771205902, 'eval_accuracy': 0.99, 'eval_runtime': 13.6679, 'eval_samples_per_second': 658.475, 'eval_steps_per_second': 1.317, 'epoch': 22.0}\n","\n","  7% 2200/30000 [45:50<6:10:13,  1.25it/s]\n","                                   \u001b[A[INFO|trainer.py:2913] 2023-09-19 18:21:23,152 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-2200\n","[INFO|configuration_utils.py:460] 2023-09-19 18:21:23,157 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-2200/config.json\n","[INFO|modeling_utils.py:2030] 2023-09-19 18:21:23,265 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-2200/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-19 18:21:23,268 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-2200/preprocessor_config.json\n","[INFO|trainer.py:3000] 2023-09-19 18:21:23,483 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-1900] due to args.save_total_limit\n","{'loss': 0.2823, 'learning_rate': 0.0009263333333333334, 'epoch': 22.1}\n","{'loss': 0.2796, 'learning_rate': 0.0009260000000000001, 'epoch': 22.2}\n","{'loss': 0.309, 'learning_rate': 0.0009256666666666667, 'epoch': 22.3}\n","{'loss': 0.2921, 'learning_rate': 0.0009253333333333333, 'epoch': 22.4}\n","{'loss': 0.2771, 'learning_rate': 0.000925, 'epoch': 22.5}\n","{'loss': 0.2859, 'learning_rate': 0.0009246666666666666, 'epoch': 22.6}\n","{'loss': 0.2829, 'learning_rate': 0.0009243333333333333, 'epoch': 22.7}\n","{'loss': 0.2717, 'learning_rate': 0.000924, 'epoch': 22.8}\n","{'loss': 0.2776, 'learning_rate': 0.0009236666666666666, 'epoch': 22.9}\n","{'loss': 0.2896, 'learning_rate': 0.0009233333333333334, 'epoch': 23.0}\n","  8% 2300/30000 [47:42<6:08:05,  1.25it/s][INFO|trainer.py:3187] 2023-09-19 18:23:15,286 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3189] 2023-09-19 18:23:15,286 >>   Num examples = 9000\n","[INFO|trainer.py:3192] 2023-09-19 18:23:15,287 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.66it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.87it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.63it/s]\u001b[A\n"," 28% 5/18 [00:02<00:08,  1.52it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.45it/s]\u001b[A\n"," 39% 7/18 [00:04<00:07,  1.40it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.37it/s]\u001b[A\n"," 50% 9/18 [00:06<00:07,  1.25it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.24it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.23it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.21it/s]\u001b[A\n"," 72% 13/18 [00:09<00:04,  1.24it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.26it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.28it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.30it/s]\u001b[A\n"," 94% 17/18 [00:12<00:00,  1.48it/s]\u001b[A\n","{'eval_loss': 0.03641437739133835, 'eval_accuracy': 0.9895555555555555, 'eval_runtime': 13.693, 'eval_samples_per_second': 657.269, 'eval_steps_per_second': 1.315, 'epoch': 23.0}\n","\n","  8% 2300/30000 [47:55<6:08:05,  1.25it/s]\n","                                   \u001b[A[INFO|trainer.py:2913] 2023-09-19 18:23:28,984 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-2300\n","[INFO|configuration_utils.py:460] 2023-09-19 18:23:28,990 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-2300/config.json\n","[INFO|modeling_utils.py:2030] 2023-09-19 18:23:29,108 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-2300/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-19 18:23:29,112 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-2300/preprocessor_config.json\n","[INFO|trainer.py:3000] 2023-09-19 18:23:29,338 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-2000] due to args.save_total_limit\n","{'loss': 0.2971, 'learning_rate': 0.0009230000000000001, 'epoch': 23.1}\n","{'loss': 0.2796, 'learning_rate': 0.0009226666666666667, 'epoch': 23.2}\n","{'loss': 0.2803, 'learning_rate': 0.0009223333333333334, 'epoch': 23.3}\n","{'loss': 0.2754, 'learning_rate': 0.0009220000000000001, 'epoch': 23.4}\n","{'loss': 0.2836, 'learning_rate': 0.0009216666666666667, 'epoch': 23.5}\n","{'loss': 0.282, 'learning_rate': 0.0009213333333333334, 'epoch': 23.6}\n","{'loss': 0.2725, 'learning_rate': 0.000921, 'epoch': 23.7}\n","{'loss': 0.2686, 'learning_rate': 0.0009206666666666666, 'epoch': 23.8}\n","{'loss': 0.2846, 'learning_rate': 0.0009203333333333333, 'epoch': 23.9}\n","{'loss': 0.275, 'learning_rate': 0.00092, 'epoch': 24.0}\n","  8% 2400/30000 [49:47<6:14:49,  1.23it/s][INFO|trainer.py:3187] 2023-09-19 18:25:20,285 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3189] 2023-09-19 18:25:20,286 >>   Num examples = 9000\n","[INFO|trainer.py:3192] 2023-09-19 18:25:20,286 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.65it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.87it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.62it/s]\u001b[A\n"," 28% 5/18 [00:03<00:08,  1.50it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.44it/s]\u001b[A\n"," 39% 7/18 [00:04<00:07,  1.38it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.36it/s]\u001b[A\n"," 50% 9/18 [00:06<00:06,  1.36it/s]\u001b[A\n"," 56% 10/18 [00:06<00:05,  1.35it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.30it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.24it/s]\u001b[A\n"," 72% 13/18 [00:09<00:04,  1.21it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.20it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.20it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.23it/s]\u001b[A\n"," 94% 17/18 [00:12<00:00,  1.41it/s]\u001b[A\n","{'eval_loss': 0.0406053327023983, 'eval_accuracy': 0.9878888888888889, 'eval_runtime': 13.8184, 'eval_samples_per_second': 651.307, 'eval_steps_per_second': 1.303, 'epoch': 24.0}\n","\n","  8% 2400/30000 [50:01<6:14:49,  1.23it/s]\n","                                   \u001b[A[INFO|trainer.py:2913] 2023-09-19 18:25:34,108 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-2400\n","[INFO|configuration_utils.py:460] 2023-09-19 18:25:34,113 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-2400/config.json\n","[INFO|modeling_utils.py:2030] 2023-09-19 18:25:34,222 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-2400/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-19 18:25:34,226 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-2400/preprocessor_config.json\n","[INFO|trainer.py:3000] 2023-09-19 18:25:34,458 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-2100] due to args.save_total_limit\n","{'loss': 0.2839, 'learning_rate': 0.0009196666666666666, 'epoch': 24.1}\n","{'loss': 0.2874, 'learning_rate': 0.0009193333333333333, 'epoch': 24.2}\n","{'loss': 0.2503, 'learning_rate': 0.0009190000000000001, 'epoch': 24.3}\n","{'loss': 0.257, 'learning_rate': 0.0009186666666666667, 'epoch': 24.4}\n","{'loss': 0.2755, 'learning_rate': 0.0009183333333333334, 'epoch': 24.5}\n","{'loss': 0.2576, 'learning_rate': 0.0009180000000000001, 'epoch': 24.6}\n","{'loss': 0.2672, 'learning_rate': 0.0009176666666666667, 'epoch': 24.7}\n","{'loss': 0.2734, 'learning_rate': 0.0009173333333333334, 'epoch': 24.8}\n","{'loss': 0.2672, 'learning_rate': 0.0009170000000000001, 'epoch': 24.9}\n","{'loss': 0.2831, 'learning_rate': 0.0009166666666666666, 'epoch': 25.0}\n","  8% 2500/30000 [51:53<6:21:55,  1.20it/s][INFO|trainer.py:3187] 2023-09-19 18:27:26,067 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3189] 2023-09-19 18:27:26,068 >>   Num examples = 9000\n","[INFO|trainer.py:3192] 2023-09-19 18:27:26,068 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.63it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.84it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.60it/s]\u001b[A\n"," 28% 5/18 [00:03<00:08,  1.48it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.41it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.37it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.35it/s]\u001b[A\n"," 50% 9/18 [00:06<00:06,  1.33it/s]\u001b[A\n"," 56% 10/18 [00:06<00:06,  1.31it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.31it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.31it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.25it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.17it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.17it/s]\u001b[A\n"," 89% 16/18 [00:12<00:01,  1.16it/s]\u001b[A\n"," 94% 17/18 [00:12<00:00,  1.32it/s]\u001b[A\n","{'eval_loss': 0.037393033504486084, 'eval_accuracy': 0.989, 'eval_runtime': 14.1326, 'eval_samples_per_second': 636.824, 'eval_steps_per_second': 1.274, 'epoch': 25.0}\n","\n","  8% 2500/30000 [52:07<6:21:55,  1.20it/s]\n","                                   \u001b[A[INFO|trainer.py:2913] 2023-09-19 18:27:40,205 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-2500\n","[INFO|configuration_utils.py:460] 2023-09-19 18:27:40,211 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-2500/config.json\n","[INFO|modeling_utils.py:2030] 2023-09-19 18:27:40,329 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-2500/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-19 18:27:40,334 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-2500/preprocessor_config.json\n","[INFO|trainer.py:3000] 2023-09-19 18:27:40,574 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-2300] due to args.save_total_limit\n","{'loss': 0.2594, 'learning_rate': 0.0009163333333333333, 'epoch': 25.1}\n","{'loss': 0.2865, 'learning_rate': 0.000916, 'epoch': 25.2}\n","{'loss': 0.2766, 'learning_rate': 0.0009156666666666666, 'epoch': 25.3}\n","{'loss': 0.2669, 'learning_rate': 0.0009153333333333333, 'epoch': 25.4}\n","{'loss': 0.2635, 'learning_rate': 0.000915, 'epoch': 25.5}\n","{'loss': 0.2784, 'learning_rate': 0.0009146666666666666, 'epoch': 25.6}\n","{'loss': 0.2815, 'learning_rate': 0.0009143333333333334, 'epoch': 25.7}\n","{'loss': 0.2719, 'learning_rate': 0.0009140000000000001, 'epoch': 25.8}\n","{'loss': 0.2664, 'learning_rate': 0.0009136666666666667, 'epoch': 25.9}\n","{'loss': 0.2654, 'learning_rate': 0.0009133333333333334, 'epoch': 26.0}\n","  9% 2600/30000 [54:01<6:19:53,  1.20it/s][INFO|trainer.py:3187] 2023-09-19 18:29:34,026 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3189] 2023-09-19 18:29:34,026 >>   Num examples = 9000\n","[INFO|trainer.py:3192] 2023-09-19 18:29:34,026 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.55it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.76it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.57it/s]\u001b[A\n"," 28% 5/18 [00:03<00:08,  1.48it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.42it/s]\u001b[A\n"," 39% 7/18 [00:04<00:07,  1.38it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.36it/s]\u001b[A\n"," 50% 9/18 [00:06<00:06,  1.37it/s]\u001b[A\n"," 56% 10/18 [00:06<00:05,  1.37it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.36it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.35it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.33it/s]\u001b[A\n"," 78% 14/18 [00:09<00:03,  1.32it/s]\u001b[A\n"," 83% 15/18 [00:10<00:02,  1.30it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.28it/s]\u001b[A\n"," 94% 17/18 [00:11<00:00,  1.44it/s]\u001b[A\n","{'eval_loss': 0.08924563229084015, 'eval_accuracy': 0.9724444444444444, 'eval_runtime': 13.5372, 'eval_samples_per_second': 664.834, 'eval_steps_per_second': 1.33, 'epoch': 26.0}\n","\n","  9% 2600/30000 [54:14<6:19:53,  1.20it/s]\n","                                   \u001b[A[INFO|trainer.py:2913] 2023-09-19 18:29:47,567 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-2600\n","[INFO|configuration_utils.py:460] 2023-09-19 18:29:47,573 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-2600/config.json\n","[INFO|modeling_utils.py:2030] 2023-09-19 18:29:47,685 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-2600/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-19 18:29:47,689 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-2600/preprocessor_config.json\n","[INFO|trainer.py:3000] 2023-09-19 18:29:47,915 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-2400] due to args.save_total_limit\n","{'loss': 0.273, 'learning_rate': 0.0009130000000000001, 'epoch': 26.1}\n","{'loss': 0.2659, 'learning_rate': 0.0009126666666666667, 'epoch': 26.2}\n","{'loss': 0.2611, 'learning_rate': 0.0009123333333333334, 'epoch': 26.3}\n","{'loss': 0.2664, 'learning_rate': 0.000912, 'epoch': 26.4}\n","{'loss': 0.27, 'learning_rate': 0.0009116666666666666, 'epoch': 26.5}\n","{'loss': 0.2889, 'learning_rate': 0.0009113333333333333, 'epoch': 26.6}\n","{'loss': 0.2668, 'learning_rate': 0.000911, 'epoch': 26.7}\n","{'loss': 0.2508, 'learning_rate': 0.0009106666666666666, 'epoch': 26.8}\n","{'loss': 0.2939, 'learning_rate': 0.0009103333333333333, 'epoch': 26.9}\n","{'loss': 0.2847, 'learning_rate': 0.00091, 'epoch': 27.0}\n","  9% 2700/30000 [56:06<6:10:05,  1.23it/s][INFO|trainer.py:3187] 2023-09-19 18:31:39,161 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3189] 2023-09-19 18:31:39,162 >>   Num examples = 9000\n","[INFO|trainer.py:3192] 2023-09-19 18:31:39,162 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:05,  2.82it/s]\u001b[A\n"," 17% 3/18 [00:01<00:07,  1.99it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.71it/s]\u001b[A\n"," 28% 5/18 [00:02<00:08,  1.58it/s]\u001b[A\n"," 33% 6/18 [00:03<00:07,  1.50it/s]\u001b[A\n"," 39% 7/18 [00:04<00:07,  1.47it/s]\u001b[A\n"," 44% 8/18 [00:05<00:06,  1.45it/s]\u001b[A\n"," 50% 9/18 [00:05<00:06,  1.43it/s]\u001b[A\n"," 56% 10/18 [00:06<00:05,  1.41it/s]\u001b[A\n"," 61% 11/18 [00:07<00:04,  1.41it/s]\u001b[A\n"," 67% 12/18 [00:07<00:04,  1.40it/s]\u001b[A\n"," 72% 13/18 [00:08<00:03,  1.40it/s]\u001b[A\n"," 78% 14/18 [00:09<00:02,  1.39it/s]\u001b[A\n"," 83% 15/18 [00:10<00:02,  1.38it/s]\u001b[A\n"," 89% 16/18 [00:10<00:01,  1.32it/s]\u001b[A\n"," 94% 17/18 [00:11<00:00,  1.49it/s]\u001b[A\n","{'eval_loss': 0.045377857983112335, 'eval_accuracy': 0.9865555555555555, 'eval_runtime': 12.9927, 'eval_samples_per_second': 692.699, 'eval_steps_per_second': 1.385, 'epoch': 27.0}\n","\n","  9% 2700/30000 [56:19<6:10:05,  1.23it/s]\n","                                   \u001b[A[INFO|trainer.py:2913] 2023-09-19 18:31:52,158 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-2700\n","[INFO|configuration_utils.py:460] 2023-09-19 18:31:52,164 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-2700/config.json\n","[INFO|modeling_utils.py:2030] 2023-09-19 18:31:52,294 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-2700/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-19 18:31:52,299 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-2700/preprocessor_config.json\n","[INFO|trainer.py:3000] 2023-09-19 18:31:52,543 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-2500] due to args.save_total_limit\n","{'loss': 0.2699, 'learning_rate': 0.0009096666666666667, 'epoch': 27.1}\n","{'loss': 0.2473, 'learning_rate': 0.0009093333333333334, 'epoch': 27.2}\n","{'loss': 0.2837, 'learning_rate': 0.0009090000000000001, 'epoch': 27.3}\n","{'loss': 0.2699, 'learning_rate': 0.0009086666666666667, 'epoch': 27.4}\n","{'loss': 0.2679, 'learning_rate': 0.0009083333333333334, 'epoch': 27.5}\n","{'loss': 0.2807, 'learning_rate': 0.0009080000000000001, 'epoch': 27.6}\n","{'loss': 0.2567, 'learning_rate': 0.0009076666666666666, 'epoch': 27.7}\n","{'loss': 0.2619, 'learning_rate': 0.0009073333333333333, 'epoch': 27.8}\n","{'loss': 0.2612, 'learning_rate': 0.000907, 'epoch': 27.9}\n","{'loss': 0.2655, 'learning_rate': 0.0009066666666666666, 'epoch': 28.0}\n","  9% 2800/30000 [58:09<5:54:52,  1.28it/s][INFO|trainer.py:3187] 2023-09-19 18:33:42,584 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3189] 2023-09-19 18:33:42,584 >>   Num examples = 9000\n","[INFO|trainer.py:3192] 2023-09-19 18:33:42,585 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.64it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.71it/s]\u001b[A\n"," 22% 4/18 [00:02<00:09,  1.49it/s]\u001b[A\n"," 28% 5/18 [00:03<00:09,  1.38it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.38it/s]\u001b[A\n"," 39% 7/18 [00:04<00:07,  1.38it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.39it/s]\u001b[A\n"," 50% 9/18 [00:06<00:06,  1.39it/s]\u001b[A\n"," 56% 10/18 [00:06<00:05,  1.38it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.37it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.37it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.38it/s]\u001b[A\n"," 78% 14/18 [00:09<00:02,  1.38it/s]\u001b[A\n"," 83% 15/18 [00:10<00:02,  1.38it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.38it/s]\u001b[A\n"," 94% 17/18 [00:11<00:00,  1.55it/s]\u001b[A\n","{'eval_loss': 0.037937358021736145, 'eval_accuracy': 0.9881111111111112, 'eval_runtime': 13.2758, 'eval_samples_per_second': 677.926, 'eval_steps_per_second': 1.356, 'epoch': 28.0}\n","\n","  9% 2800/30000 [58:22<5:54:52,  1.28it/s]\n","                                   \u001b[A[INFO|trainer.py:2913] 2023-09-19 18:33:55,864 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-2800\n","[INFO|configuration_utils.py:460] 2023-09-19 18:33:55,869 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-2800/config.json\n","[INFO|modeling_utils.py:2030] 2023-09-19 18:33:55,972 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-2800/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-19 18:33:55,977 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-2800/preprocessor_config.json\n","[INFO|trainer.py:3000] 2023-09-19 18:33:56,202 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-2600] due to args.save_total_limit\n","{'loss': 0.269, 'learning_rate': 0.0009063333333333333, 'epoch': 28.1}\n","{'loss': 0.2564, 'learning_rate': 0.000906, 'epoch': 28.2}\n","{'loss': 0.2666, 'learning_rate': 0.0009056666666666666, 'epoch': 28.3}\n","{'loss': 0.2679, 'learning_rate': 0.0009053333333333333, 'epoch': 28.4}\n","{'loss': 0.2729, 'learning_rate': 0.0009050000000000001, 'epoch': 28.5}\n","{'loss': 0.259, 'learning_rate': 0.0009046666666666667, 'epoch': 28.6}\n","{'loss': 0.2718, 'learning_rate': 0.0009043333333333334, 'epoch': 28.7}\n","{'loss': 0.2459, 'learning_rate': 0.0009040000000000001, 'epoch': 28.8}\n","{'loss': 0.248, 'learning_rate': 0.0009036666666666667, 'epoch': 28.9}\n","{'loss': 0.2666, 'learning_rate': 0.0009033333333333334, 'epoch': 29.0}\n"," 10% 2900/30000 [1:00:13<5:56:54,  1.27it/s][INFO|trainer.py:3187] 2023-09-19 18:35:46,321 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3189] 2023-09-19 18:35:46,321 >>   Num examples = 9000\n","[INFO|trainer.py:3192] 2023-09-19 18:35:46,321 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:05,  2.74it/s]\u001b[A\n"," 17% 3/18 [00:01<00:07,  1.92it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.67it/s]\u001b[A\n"," 28% 5/18 [00:02<00:08,  1.50it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.44it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.36it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.31it/s]\u001b[A\n"," 50% 9/18 [00:06<00:07,  1.27it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.27it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.28it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.30it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.31it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.32it/s]\u001b[A\n"," 83% 15/18 [00:10<00:02,  1.34it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.34it/s]\u001b[A\n"," 94% 17/18 [00:11<00:00,  1.50it/s]\u001b[A\n","{'eval_loss': 0.0387570783495903, 'eval_accuracy': 0.9886666666666667, 'eval_runtime': 13.4281, 'eval_samples_per_second': 670.234, 'eval_steps_per_second': 1.34, 'epoch': 29.0}\n","\n"," 10% 2900/30000 [1:00:26<5:56:54,  1.27it/s]\n","                                   \u001b[A[INFO|trainer.py:2913] 2023-09-19 18:35:59,754 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-2900\n","[INFO|configuration_utils.py:460] 2023-09-19 18:35:59,759 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-2900/config.json\n","[INFO|modeling_utils.py:2030] 2023-09-19 18:35:59,879 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-2900/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-19 18:35:59,883 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-2900/preprocessor_config.json\n","[INFO|trainer.py:3000] 2023-09-19 18:36:00,105 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-2700] due to args.save_total_limit\n","{'loss': 0.2738, 'learning_rate': 0.000903, 'epoch': 29.1}\n","{'loss': 0.2772, 'learning_rate': 0.0009026666666666666, 'epoch': 29.2}\n","{'loss': 0.2561, 'learning_rate': 0.0009023333333333333, 'epoch': 29.3}\n","{'loss': 0.2691, 'learning_rate': 0.000902, 'epoch': 29.4}\n","{'loss': 0.2653, 'learning_rate': 0.0009016666666666666, 'epoch': 29.5}\n","{'loss': 0.2835, 'learning_rate': 0.0009013333333333333, 'epoch': 29.6}\n","{'loss': 0.2922, 'learning_rate': 0.000901, 'epoch': 29.7}\n","{'loss': 0.2616, 'learning_rate': 0.0009006666666666666, 'epoch': 29.8}\n","{'loss': 0.2805, 'learning_rate': 0.0009003333333333334, 'epoch': 29.9}\n","{'loss': 0.2819, 'learning_rate': 0.0009000000000000001, 'epoch': 30.0}\n"," 10% 3000/30000 [1:02:17<5:58:19,  1.26it/s][INFO|trainer.py:3187] 2023-09-19 18:37:50,580 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3189] 2023-09-19 18:37:50,580 >>   Num examples = 9000\n","[INFO|trainer.py:3192] 2023-09-19 18:37:50,580 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:05,  2.76it/s]\u001b[A\n"," 17% 3/18 [00:01<00:07,  1.97it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.70it/s]\u001b[A\n"," 28% 5/18 [00:02<00:08,  1.57it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.49it/s]\u001b[A\n"," 39% 7/18 [00:04<00:07,  1.43it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.39it/s]\u001b[A\n"," 50% 9/18 [00:05<00:06,  1.37it/s]\u001b[A\n"," 56% 10/18 [00:06<00:05,  1.34it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.31it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.27it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.29it/s]\u001b[A\n"," 78% 14/18 [00:09<00:03,  1.32it/s]\u001b[A\n"," 83% 15/18 [00:10<00:02,  1.33it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.35it/s]\u001b[A\n"," 94% 17/18 [00:11<00:00,  1.54it/s]\u001b[A\n","{'eval_loss': 1.1445810794830322, 'eval_accuracy': 0.6264444444444445, 'eval_runtime': 13.1741, 'eval_samples_per_second': 683.159, 'eval_steps_per_second': 1.366, 'epoch': 30.0}\n","\n"," 10% 3000/30000 [1:02:30<5:58:19,  1.26it/s]\n","                                   \u001b[A[INFO|trainer.py:2913] 2023-09-19 18:38:03,758 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-3000\n","[INFO|configuration_utils.py:460] 2023-09-19 18:38:03,763 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-3000/config.json\n","[INFO|modeling_utils.py:2030] 2023-09-19 18:38:03,865 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-3000/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-19 18:38:03,869 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-3000/preprocessor_config.json\n","[INFO|trainer.py:3000] 2023-09-19 18:38:04,073 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-2800] due to args.save_total_limit\n","{'loss': 0.2975, 'learning_rate': 0.0008996666666666667, 'epoch': 30.1}\n","{'loss': 0.2625, 'learning_rate': 0.0008993333333333334, 'epoch': 30.2}\n","{'loss': 0.271, 'learning_rate': 0.0008990000000000001, 'epoch': 30.3}\n","{'loss': 0.2807, 'learning_rate': 0.0008986666666666666, 'epoch': 30.4}\n","{'loss': 0.2723, 'learning_rate': 0.0008983333333333333, 'epoch': 30.5}\n","{'loss': 0.2873, 'learning_rate': 0.000898, 'epoch': 30.6}\n","{'loss': 0.2629, 'learning_rate': 0.0008976666666666666, 'epoch': 30.7}\n","{'loss': 0.2551, 'learning_rate': 0.0008973333333333333, 'epoch': 30.8}\n","{'loss': 0.2838, 'learning_rate': 0.000897, 'epoch': 30.9}\n","{'loss': 0.2578, 'learning_rate': 0.0008966666666666666, 'epoch': 31.0}\n"," 10% 3100/30000 [1:04:21<6:11:48,  1.21it/s][INFO|trainer.py:3187] 2023-09-19 18:39:54,468 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3189] 2023-09-19 18:39:54,468 >>   Num examples = 9000\n","[INFO|trainer.py:3192] 2023-09-19 18:39:54,468 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.44it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.70it/s]\u001b[A\n"," 22% 4/18 [00:02<00:09,  1.46it/s]\u001b[A\n"," 28% 5/18 [00:03<00:09,  1.42it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.40it/s]\u001b[A\n"," 39% 7/18 [00:04<00:07,  1.38it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.37it/s]\u001b[A\n"," 50% 9/18 [00:06<00:06,  1.35it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.33it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.31it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.30it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.26it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.25it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.24it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.27it/s]\u001b[A\n"," 94% 17/18 [00:12<00:00,  1.44it/s]\u001b[A\n","{'eval_loss': 0.0454658567905426, 'eval_accuracy': 0.9867777777777778, 'eval_runtime': 13.8661, 'eval_samples_per_second': 649.063, 'eval_steps_per_second': 1.298, 'epoch': 31.0}\n","\n"," 10% 3100/30000 [1:04:35<6:11:48,  1.21it/s]\n","                                   \u001b[A[INFO|trainer.py:2913] 2023-09-19 18:40:08,338 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-3100\n","[INFO|configuration_utils.py:460] 2023-09-19 18:40:08,344 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-3100/config.json\n","[INFO|modeling_utils.py:2030] 2023-09-19 18:40:08,451 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-3100/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-19 18:40:08,455 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-3100/preprocessor_config.json\n","[INFO|trainer.py:3000] 2023-09-19 18:40:08,694 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-2900] due to args.save_total_limit\n","{'loss': 0.255, 'learning_rate': 0.0008963333333333333, 'epoch': 31.1}\n","{'loss': 0.2669, 'learning_rate': 0.000896, 'epoch': 31.2}\n","{'loss': 0.2666, 'learning_rate': 0.0008956666666666668, 'epoch': 31.3}\n","{'loss': 0.2489, 'learning_rate': 0.0008953333333333334, 'epoch': 31.4}\n","{'loss': 0.2703, 'learning_rate': 0.0008950000000000001, 'epoch': 31.5}\n","{'loss': 0.2645, 'learning_rate': 0.0008946666666666668, 'epoch': 31.6}\n","{'loss': 0.2665, 'learning_rate': 0.0008943333333333334, 'epoch': 31.7}\n","{'loss': 0.2658, 'learning_rate': 0.000894, 'epoch': 31.8}\n","{'loss': 0.2561, 'learning_rate': 0.0008936666666666667, 'epoch': 31.9}\n","{'loss': 0.2727, 'learning_rate': 0.0008933333333333333, 'epoch': 32.0}\n"," 11% 3200/30000 [1:06:25<5:57:13,  1.25it/s][INFO|trainer.py:3187] 2023-09-19 18:41:58,254 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3189] 2023-09-19 18:41:58,254 >>   Num examples = 9000\n","[INFO|trainer.py:3192] 2023-09-19 18:41:58,254 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:05,  2.72it/s]\u001b[A\n"," 17% 3/18 [00:01<00:07,  1.95it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.70it/s]\u001b[A\n"," 28% 5/18 [00:02<00:08,  1.55it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.49it/s]\u001b[A\n"," 39% 7/18 [00:04<00:07,  1.46it/s]\u001b[A\n"," 44% 8/18 [00:05<00:06,  1.43it/s]\u001b[A\n"," 50% 9/18 [00:05<00:06,  1.41it/s]\u001b[A\n"," 56% 10/18 [00:06<00:05,  1.40it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.38it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.37it/s]\u001b[A\n"," 72% 13/18 [00:08<00:03,  1.37it/s]\u001b[A\n"," 78% 14/18 [00:09<00:02,  1.36it/s]\u001b[A\n"," 83% 15/18 [00:10<00:02,  1.34it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.32it/s]\u001b[A\n"," 94% 17/18 [00:11<00:00,  1.47it/s]\u001b[A\n","{'eval_loss': 0.14441411197185516, 'eval_accuracy': 0.9561111111111111, 'eval_runtime': 13.0917, 'eval_samples_per_second': 687.457, 'eval_steps_per_second': 1.375, 'epoch': 32.0}\n","\n"," 11% 3200/30000 [1:06:38<5:57:13,  1.25it/s]\n","                                   \u001b[A[INFO|trainer.py:2913] 2023-09-19 18:42:11,350 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-3200\n","[INFO|configuration_utils.py:460] 2023-09-19 18:42:11,356 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-3200/config.json\n","[INFO|modeling_utils.py:2030] 2023-09-19 18:42:11,463 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-3200/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-19 18:42:11,467 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-3200/preprocessor_config.json\n","[INFO|trainer.py:3000] 2023-09-19 18:42:11,703 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-3000] due to args.save_total_limit\n","[INFO|trainer.py:2010] 2023-09-19 18:42:11,718 >> \n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","[INFO|trainer.py:2178] 2023-09-19 18:42:11,719 >> Loading best model from drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/checkpoint-2200 (score: 0.03203807771205902).\n","{'train_runtime': 3998.7832, 'train_samples_per_second': 3826.164, 'train_steps_per_second': 7.502, 'train_loss': 0.3100213171541691, 'epoch': 32.0}\n"," 11% 3200/30000 [1:06:38<9:18:09,  1.25s/it]\n","[INFO|trainer.py:2913] 2023-09-19 18:42:11,790 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/\n","[INFO|configuration_utils.py:460] 2023-09-19 18:42:11,796 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/config.json\n","[INFO|modeling_utils.py:2030] 2023-09-19 18:42:11,925 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-19 18:42:11,930 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/preprocessor_config.json\n","***** train metrics *****\n","  epoch                    =       32.0\n","  train_loss               =       0.31\n","  train_runtime            = 1:06:38.78\n","  train_samples_per_second =   3826.164\n","  train_steps_per_second   =      7.502\n","[INFO|trainer.py:3187] 2023-09-19 18:42:11,952 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3189] 2023-09-19 18:42:11,952 >>   Num examples = 9000\n","[INFO|trainer.py:3192] 2023-09-19 18:42:11,952 >>   Batch size = 512\n","100% 18/18 [00:12<00:00,  1.48it/s]\n","***** eval metrics *****\n","  epoch                   =       32.0\n","  eval_accuracy           =       0.99\n","  eval_loss               =      0.032\n","  eval_runtime            = 0:00:13.69\n","  eval_samples_per_second =     657.32\n","  eval_steps_per_second   =      1.315\n","\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n","\u001b[34m\u001b[1mwandb\u001b[0m:                  eval/accuracy █████▃█▇██▇██▅██▁███▆████████▄███\n","\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/loss ▁▁▁▁▁▅▁▁▁▁▂▁▁▃▁▁█▁▁▁▂▁▁▁▁▁▁▁▁▄▁▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/runtime ▄▃▁▂▄▄▃▃▂▃▄▃▃▄▄▃▅▆▅▆▆▅▅▆█▄▁▃▄▂▆▂▅\n","\u001b[34m\u001b[1mwandb\u001b[0m:        eval/samples_per_second ▄▆█▇▅▅▆▆▇▆▅▅▆▅▅▆▄▃▄▃▃▄▄▃▁▅█▆▅▇▃▇▄\n","\u001b[34m\u001b[1mwandb\u001b[0m:          eval/steps_per_second ▄▆█▇▅▅▆▆▇▆▅▅▆▅▅▆▄▃▄▃▃▄▄▃▁▅█▆▅▇▃▇▄\n","\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\n","\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\n","\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate ███▇▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss █▆▄▄▄▃▃▃▃▃▃▃▂▃▃▃▂▂▂▂▂▃▂▂▂▂▁▂▂▂▁▂▁▁▂▁▂▂▁▂\n","\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n","\u001b[34m\u001b[1mwandb\u001b[0m:                  eval/accuracy 0.99\n","\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/loss 0.03204\n","\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/runtime 13.692\n","\u001b[34m\u001b[1mwandb\u001b[0m:        eval/samples_per_second 657.32\n","\u001b[34m\u001b[1mwandb\u001b[0m:          eval/steps_per_second 1.315\n","\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch 32.0\n","\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step 3200\n","\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate 0.00089\n","\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss 0.2727\n","\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos 1.6481406826708992e+19\n","\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss 0.31002\n","\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime 3998.7832\n","\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second 3826.164\n","\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second 7.502\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mcerulean-pine-23\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/u15048366/colabCnnMnist/runs/edyzdasr\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n","\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230919_173502-edyzdasr/logs\u001b[0m\n"]}],"source":["!python cnn-mnist.py \\\n","    --model_name microsoft/resnet-18 \\\n","    --model_type resnet \\\n","    --dataset_name mnist \\\n","    --output_dir drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_7/ \\\n","    --remove_unused_columns False \\\n","    --do_train \\\n","    --do_eval \\\n","    --push_to_hub False \\\n","    --learning_rate 0.001 \\\n","    --num_train_epochs 300 \\\n","    --per_device_train_batch_size 512 \\\n","    --per_device_eval_batch_size 512 \\\n","    --logging_strategy steps \\\n","    --logging_steps 10 \\\n","    --evaluation_strategy epoch \\\n","    --save_strategy epoch \\\n","    --load_best_model_at_end True \\\n","    --save_total_limit 3 \\\n","    --save_steps 500 \\\n","    --data_seed 7 \\\n","    --seed 7 \\\n","    --report_to wandb \\\n","    --ignore_mismatched_sizes\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3970627,"status":"ok","timestamp":1694114726694,"user":{"displayName":"Andreas Louw","userId":"11183032721846533402"},"user_tz":-120},"id":"GJ6zuVm0Fa-J","outputId":"d5fe2be3-8913-46fd-c54a-a0477fbfaf17"},"outputs":[{"name":"stdout","output_type":"stream","text":["2023-09-07 18:19:16.802216: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mu15048366\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.10\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20230907_181920-nafwnffx\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mabsurd-bush-17\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/u15048366/colabCnnMnist\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/u15048366/colabCnnMnist/runs/nafwnffx\u001b[0m\n","09/07/2023 18:19:21 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n","09/07/2023 18:19:21 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n","_n_gpu=1,\n","adafactor=False,\n","adam_beta1=0.9,\n","adam_beta2=0.999,\n","adam_epsilon=1e-08,\n","auto_find_batch_size=False,\n","bf16=False,\n","bf16_full_eval=False,\n","data_seed=8,\n","dataloader_drop_last=False,\n","dataloader_num_workers=0,\n","dataloader_pin_memory=True,\n","ddp_backend=None,\n","ddp_broadcast_buffers=None,\n","ddp_bucket_cap_mb=None,\n","ddp_find_unused_parameters=None,\n","ddp_timeout=1800,\n","debug=[],\n","deepspeed=None,\n","disable_tqdm=False,\n","dispatch_batches=None,\n","do_eval=True,\n","do_predict=False,\n","do_train=True,\n","eval_accumulation_steps=None,\n","eval_delay=0,\n","eval_steps=None,\n","evaluation_strategy=epoch,\n","fp16=False,\n","fp16_backend=auto,\n","fp16_full_eval=False,\n","fp16_opt_level=O1,\n","fsdp=[],\n","fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n","fsdp_min_num_params=0,\n","fsdp_transformer_layer_cls_to_wrap=None,\n","full_determinism=False,\n","gradient_accumulation_steps=1,\n","gradient_checkpointing=False,\n","greater_is_better=False,\n","group_by_length=False,\n","half_precision_backend=auto,\n","hub_always_push=False,\n","hub_model_id=None,\n","hub_private_repo=False,\n","hub_strategy=every_save,\n","hub_token=<HUB_TOKEN>,\n","ignore_data_skip=False,\n","include_inputs_for_metrics=False,\n","include_tokens_per_second=False,\n","jit_mode_eval=False,\n","label_names=None,\n","label_smoothing_factor=0.0,\n","learning_rate=0.001,\n","length_column_name=length,\n","load_best_model_at_end=True,\n","local_rank=0,\n","log_level=passive,\n","log_level_replica=warning,\n","log_on_each_node=True,\n","logging_dir=drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/runs/Sep07_18-19-21_67f6d3ae3f6c,\n","logging_first_step=False,\n","logging_nan_inf_filter=True,\n","logging_steps=10,\n","logging_strategy=steps,\n","lr_scheduler_type=linear,\n","max_grad_norm=1.0,\n","max_steps=-1,\n","metric_for_best_model=loss,\n","mp_parameters=,\n","no_cuda=False,\n","num_train_epochs=300.0,\n","optim=adamw_torch,\n","optim_args=None,\n","output_dir=drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/,\n","overwrite_output_dir=False,\n","past_index=-1,\n","per_device_eval_batch_size=512,\n","per_device_train_batch_size=512,\n","prediction_loss_only=False,\n","push_to_hub=False,\n","push_to_hub_model_id=None,\n","push_to_hub_organization=None,\n","push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n","ray_scope=last,\n","remove_unused_columns=False,\n","report_to=['wandb'],\n","resume_from_checkpoint=None,\n","run_name=drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/,\n","save_on_each_node=False,\n","save_safetensors=False,\n","save_steps=500.0,\n","save_strategy=epoch,\n","save_total_limit=3,\n","seed=8,\n","sharded_ddp=[],\n","skip_memory_metrics=True,\n","tf32=None,\n","torch_compile=False,\n","torch_compile_backend=None,\n","torch_compile_mode=None,\n","torchdynamo=None,\n","tpu_metrics_debug=False,\n","tpu_num_cores=None,\n","use_cpu=False,\n","use_ipex=False,\n","use_legacy_prediction_loop=False,\n","use_mps_device=False,\n","warmup_ratio=0.0,\n","warmup_steps=0,\n","weight_decay=0.0,\n",")\n","/usr/local/lib/python3.10/dist-packages/datasets/load.py:2103: FutureWarning: 'task' was deprecated in version 2.13.0 and will be removed in 3.0.0.\n","\n","  warnings.warn(\n","\n","\n","\n","None\n","\n","\n","\n","[INFO|configuration_utils.py:715] 2023-09-07 18:19:23,460 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--resnet-18/snapshots/f45a6faa12e0381f5620c5c8d7e916bca90f2c44/config.json\n","[INFO|configuration_utils.py:775] 2023-09-07 18:19:23,461 >> Model config ResNetConfig {\n","  \"_name_or_path\": \"microsoft/resnet-18\",\n","  \"architectures\": [\n","    \"ResNetForImageClassification\"\n","  ],\n","  \"depths\": [\n","    2,\n","    2,\n","    2,\n","    2\n","  ],\n","  \"downsample_in_first_stage\": false,\n","  \"embedding_size\": 64,\n","  \"finetuning_task\": \"image-classification\",\n","  \"hidden_act\": \"relu\",\n","  \"hidden_sizes\": [\n","    64,\n","    128,\n","    256,\n","    512\n","  ],\n","  \"id2label\": {\n","    \"0\": \"0\",\n","    \"1\": \"1\",\n","    \"2\": \"2\",\n","    \"3\": \"3\",\n","    \"4\": \"4\",\n","    \"5\": \"5\",\n","    \"6\": \"6\",\n","    \"7\": \"7\",\n","    \"8\": \"8\",\n","    \"9\": \"9\"\n","  },\n","  \"label2id\": {\n","    \"0\": \"0\",\n","    \"1\": \"1\",\n","    \"2\": \"2\",\n","    \"3\": \"3\",\n","    \"4\": \"4\",\n","    \"5\": \"5\",\n","    \"6\": \"6\",\n","    \"7\": \"7\",\n","    \"8\": \"8\",\n","    \"9\": \"9\"\n","  },\n","  \"layer_type\": \"basic\",\n","  \"model_type\": \"resnet\",\n","  \"num_channels\": 3,\n","  \"out_features\": [\n","    \"stage4\"\n","  ],\n","  \"out_indices\": [\n","    4\n","  ],\n","  \"stage_names\": [\n","    \"stem\",\n","    \"stage1\",\n","    \"stage2\",\n","    \"stage3\",\n","    \"stage4\"\n","  ],\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.34.0.dev0\"\n","}\n","\n","[INFO|modeling_utils.py:2857] 2023-09-07 18:19:23,463 >> loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--microsoft--resnet-18/snapshots/f45a6faa12e0381f5620c5c8d7e916bca90f2c44/model.safetensors\n","[INFO|modeling_utils.py:3643] 2023-09-07 18:19:23,578 >> All model checkpoint weights were used when initializing ResNetForImageClassification.\n","\n","[WARNING|modeling_utils.py:3664] 2023-09-07 18:19:23,578 >> Some weights of ResNetForImageClassification were not initialized from the model checkpoint at microsoft/resnet-18 and are newly initialized because the shapes did not match:\n","- classifier.1.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([10]) in the model instantiated\n","- classifier.1.weight: found shape torch.Size([1000, 512]) in the checkpoint and torch.Size([10, 512]) in the model instantiated\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","[INFO|image_processing_utils.py:369] 2023-09-07 18:19:23,676 >> loading configuration file preprocessor_config.json from cache at /root/.cache/huggingface/hub/models--microsoft--resnet-18/snapshots/f45a6faa12e0381f5620c5c8d7e916bca90f2c44/preprocessor_config.json\n","[WARNING|image_processing_auto.py:355] 2023-09-07 18:19:23,676 >> Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n","[INFO|image_processing_utils.py:732] 2023-09-07 18:19:23,678 >> size should be a dictionary on of the following set of keys: ({'height', 'width'}, {'shortest_edge'}, {'shortest_edge', 'longest_edge'}, {'longest_edge'}), got 224. Converted to {'shortest_edge': 224}.\n","[INFO|image_processing_utils.py:419] 2023-09-07 18:19:23,678 >> Image processor ConvNextImageProcessor {\n","  \"crop_pct\": 0.875,\n","  \"do_normalize\": true,\n","  \"do_rescale\": true,\n","  \"do_resize\": true,\n","  \"image_mean\": [\n","    0.485,\n","    0.456,\n","    0.406\n","  ],\n","  \"image_processor_type\": \"ConvNextImageProcessor\",\n","  \"image_std\": [\n","    0.229,\n","    0.224,\n","    0.225\n","  ],\n","  \"resample\": 3,\n","  \"rescale_factor\": 0.00392156862745098,\n","  \"size\": {\n","    \"shortest_edge\": 224\n","  }\n","}\n","\n","[INFO|trainer.py:1740] 2023-09-07 18:19:25,481 >> ***** Running training *****\n","[INFO|trainer.py:1741] 2023-09-07 18:19:25,481 >>   Num examples = 51,000\n","[INFO|trainer.py:1742] 2023-09-07 18:19:25,482 >>   Num Epochs = 300\n","[INFO|trainer.py:1743] 2023-09-07 18:19:25,482 >>   Instantaneous batch size per device = 512\n","[INFO|trainer.py:1746] 2023-09-07 18:19:25,482 >>   Total train batch size (w. parallel, distributed & accumulation) = 512\n","[INFO|trainer.py:1747] 2023-09-07 18:19:25,482 >>   Gradient Accumulation steps = 1\n","[INFO|trainer.py:1748] 2023-09-07 18:19:25,482 >>   Total optimization steps = 30,000\n","[INFO|trainer.py:1749] 2023-09-07 18:19:25,483 >>   Number of trainable parameters = 11,181,642\n","[INFO|integration_utils.py:716] 2023-09-07 18:19:25,484 >> Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n","{'loss': 1.152, 'learning_rate': 0.0009996666666666667, 'epoch': 0.1}\n","{'loss': 0.6044, 'learning_rate': 0.0009993333333333334, 'epoch': 0.2}\n","{'loss': 0.5524, 'learning_rate': 0.000999, 'epoch': 0.3}\n","{'loss': 0.4918, 'learning_rate': 0.0009986666666666668, 'epoch': 0.4}\n","{'loss': 0.5112, 'learning_rate': 0.0009983333333333333, 'epoch': 0.5}\n","{'loss': 0.5189, 'learning_rate': 0.000998, 'epoch': 0.6}\n","{'loss': 0.4583, 'learning_rate': 0.0009976666666666667, 'epoch': 0.7}\n","{'loss': 0.4382, 'learning_rate': 0.0009973333333333334, 'epoch': 0.8}\n","{'loss': 0.4388, 'learning_rate': 0.000997, 'epoch': 0.9}\n","{'loss': 0.438, 'learning_rate': 0.0009966666666666668, 'epoch': 1.0}\n","  0% 100/30000 [01:53<6:34:15,  1.26it/s][INFO|trainer.py:3160] 2023-09-07 18:21:18,680 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3162] 2023-09-07 18:21:18,680 >>   Num examples = 9000\n","[INFO|trainer.py:3165] 2023-09-07 18:21:18,681 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:05,  2.79it/s]\u001b[A\n"," 17% 3/18 [00:01<00:07,  1.91it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.67it/s]\u001b[A\n"," 28% 5/18 [00:02<00:08,  1.53it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.47it/s]\u001b[A\n"," 39% 7/18 [00:04<00:07,  1.40it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.32it/s]\u001b[A\n"," 50% 9/18 [00:06<00:07,  1.24it/s]\u001b[A\n"," 56% 10/18 [00:07<00:07,  1.11it/s]\u001b[A\n"," 61% 11/18 [00:08<00:06,  1.13it/s]\u001b[A\n"," 67% 12/18 [00:09<00:05,  1.14it/s]\u001b[A\n"," 72% 13/18 [00:09<00:04,  1.20it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.22it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.25it/s]\u001b[A\n"," 89% 16/18 [00:12<00:01,  1.28it/s]\u001b[A\n","                                         \n","\u001b[A{'eval_loss': 0.08669637143611908, 'eval_accuracy': 0.9737777777777777, 'eval_runtime': 14.0674, 'eval_samples_per_second': 639.777, 'eval_steps_per_second': 1.28, 'epoch': 1.0}\n","  0% 100/30000 [02:07<6:34:15,  1.26it/s]\n","100% 18/18 [00:12<00:00,  1.46it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2886] 2023-09-07 18:21:32,752 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-100\n","[INFO|configuration_utils.py:460] 2023-09-07 18:21:32,758 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-100/config.json\n","[INFO|modeling_utils.py:1988] 2023-09-07 18:21:32,859 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-100/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 18:21:32,863 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-100/preprocessor_config.json\n","{'loss': 0.429, 'learning_rate': 0.0009963333333333332, 'epoch': 1.1}\n","{'loss': 0.4235, 'learning_rate': 0.000996, 'epoch': 1.2}\n","{'loss': 0.4022, 'learning_rate': 0.0009956666666666666, 'epoch': 1.3}\n","{'loss': 0.4148, 'learning_rate': 0.0009953333333333333, 'epoch': 1.4}\n","{'loss': 0.3819, 'learning_rate': 0.000995, 'epoch': 1.5}\n","{'loss': 0.4042, 'learning_rate': 0.0009946666666666667, 'epoch': 1.6}\n","{'loss': 0.4191, 'learning_rate': 0.0009943333333333334, 'epoch': 1.7}\n","{'loss': 0.4086, 'learning_rate': 0.000994, 'epoch': 1.8}\n","{'loss': 0.4068, 'learning_rate': 0.0009936666666666668, 'epoch': 1.9}\n","{'loss': 0.3828, 'learning_rate': 0.0009933333333333333, 'epoch': 2.0}\n","  1% 200/30000 [04:01<6:38:57,  1.24it/s][INFO|trainer.py:3160] 2023-09-07 18:23:26,811 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3162] 2023-09-07 18:23:26,811 >>   Num examples = 9000\n","[INFO|trainer.py:3165] 2023-09-07 18:23:26,811 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:05,  2.70it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.78it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.58it/s]\u001b[A\n"," 28% 5/18 [00:03<00:10,  1.29it/s]\u001b[A\n"," 33% 6/18 [00:04<00:09,  1.28it/s]\u001b[A\n"," 39% 7/18 [00:05<00:09,  1.19it/s]\u001b[A\n"," 44% 8/18 [00:05<00:08,  1.21it/s]\u001b[A\n"," 50% 9/18 [00:06<00:07,  1.17it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.17it/s]\u001b[A\n"," 61% 11/18 [00:08<00:06,  1.16it/s]\u001b[A\n"," 67% 12/18 [00:09<00:05,  1.18it/s]\u001b[A\n"," 72% 13/18 [00:10<00:04,  1.23it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.25it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.28it/s]\u001b[A\n"," 89% 16/18 [00:12<00:01,  1.28it/s]\u001b[A\n","                                         \n","\u001b[A{'eval_loss': 0.05600568279623985, 'eval_accuracy': 0.9828888888888889, 'eval_runtime': 14.414, 'eval_samples_per_second': 624.393, 'eval_steps_per_second': 1.249, 'epoch': 2.0}\n","  1% 200/30000 [04:15<6:38:57,  1.24it/s]\n","100% 18/18 [00:13<00:00,  1.45it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2886] 2023-09-07 18:23:41,230 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-200\n","[INFO|configuration_utils.py:460] 2023-09-07 18:23:41,236 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-200/config.json\n","[INFO|modeling_utils.py:1988] 2023-09-07 18:23:41,348 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-200/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 18:23:41,353 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-200/preprocessor_config.json\n","{'loss': 0.383, 'learning_rate': 0.000993, 'epoch': 2.1}\n","{'loss': 0.3793, 'learning_rate': 0.0009926666666666667, 'epoch': 2.2}\n","{'loss': 0.3748, 'learning_rate': 0.0009923333333333333, 'epoch': 2.3}\n","{'loss': 0.3786, 'learning_rate': 0.000992, 'epoch': 2.4}\n","{'loss': 0.3742, 'learning_rate': 0.0009916666666666667, 'epoch': 2.5}\n","{'loss': 0.3884, 'learning_rate': 0.0009913333333333332, 'epoch': 2.6}\n","{'loss': 0.3884, 'learning_rate': 0.000991, 'epoch': 2.7}\n","{'loss': 0.3991, 'learning_rate': 0.0009906666666666668, 'epoch': 2.8}\n","{'loss': 0.3868, 'learning_rate': 0.0009903333333333333, 'epoch': 2.9}\n","{'loss': 0.3543, 'learning_rate': 0.00099, 'epoch': 3.0}\n","  1% 300/30000 [06:10<6:41:14,  1.23it/s][INFO|trainer.py:3160] 2023-09-07 18:25:36,118 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3162] 2023-09-07 18:25:36,118 >>   Num examples = 9000\n","[INFO|trainer.py:3165] 2023-09-07 18:25:36,119 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:05,  2.75it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.87it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.65it/s]\u001b[A\n"," 28% 5/18 [00:03<00:08,  1.50it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.45it/s]\u001b[A\n"," 39% 7/18 [00:04<00:07,  1.40it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.28it/s]\u001b[A\n"," 50% 9/18 [00:06<00:07,  1.23it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.19it/s]\u001b[A\n"," 61% 11/18 [00:08<00:05,  1.18it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.22it/s]\u001b[A\n"," 72% 13/18 [00:09<00:04,  1.25it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.28it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.26it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.28it/s]\u001b[A\n","                                         \n","\u001b[A{'eval_loss': 0.04463878273963928, 'eval_accuracy': 0.9863333333333333, 'eval_runtime': 13.903, 'eval_samples_per_second': 647.344, 'eval_steps_per_second': 1.295, 'epoch': 3.0}\n","  1% 300/30000 [06:24<6:41:14,  1.23it/s]\n","100% 18/18 [00:12<00:00,  1.43it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2886] 2023-09-07 18:25:50,026 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-300\n","[INFO|configuration_utils.py:460] 2023-09-07 18:25:50,032 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-300/config.json\n","[INFO|modeling_utils.py:1988] 2023-09-07 18:25:50,138 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-300/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 18:25:50,143 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-300/preprocessor_config.json\n","{'loss': 0.3546, 'learning_rate': 0.0009896666666666667, 'epoch': 3.1}\n","{'loss': 0.372, 'learning_rate': 0.0009893333333333334, 'epoch': 3.2}\n","{'loss': 0.3407, 'learning_rate': 0.000989, 'epoch': 3.3}\n","{'loss': 0.3587, 'learning_rate': 0.0009886666666666668, 'epoch': 3.4}\n","{'loss': 0.3755, 'learning_rate': 0.0009883333333333333, 'epoch': 3.5}\n","{'loss': 0.3505, 'learning_rate': 0.000988, 'epoch': 3.6}\n","{'loss': 0.3619, 'learning_rate': 0.0009876666666666666, 'epoch': 3.7}\n","{'loss': 0.3629, 'learning_rate': 0.0009873333333333333, 'epoch': 3.8}\n","{'loss': 0.3549, 'learning_rate': 0.000987, 'epoch': 3.9}\n","{'loss': 0.3787, 'learning_rate': 0.0009866666666666667, 'epoch': 4.0}\n","  1% 400/30000 [08:17<6:41:01,  1.23it/s][INFO|trainer.py:3160] 2023-09-07 18:27:42,917 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3162] 2023-09-07 18:27:42,917 >>   Num examples = 9000\n","[INFO|trainer.py:3165] 2023-09-07 18:27:42,917 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:05,  2.69it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.85it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.64it/s]\u001b[A\n"," 28% 5/18 [00:02<00:08,  1.53it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.45it/s]\u001b[A\n"," 39% 7/18 [00:04<00:07,  1.43it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.37it/s]\u001b[A\n"," 50% 9/18 [00:06<00:06,  1.34it/s]\u001b[A\n"," 56% 10/18 [00:06<00:06,  1.30it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.25it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.25it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.29it/s]\u001b[A\n"," 78% 14/18 [00:09<00:03,  1.30it/s]\u001b[A\n"," 83% 15/18 [00:10<00:02,  1.31it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.33it/s]\u001b[A\n","                                         \n","\u001b[A{'eval_loss': 0.061646200716495514, 'eval_accuracy': 0.9813333333333333, 'eval_runtime': 13.4303, 'eval_samples_per_second': 670.127, 'eval_steps_per_second': 1.34, 'epoch': 4.0}\n","  1% 400/30000 [08:30<6:41:01,  1.23it/s]\n","100% 18/18 [00:12<00:00,  1.50it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2886] 2023-09-07 18:27:56,351 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-400\n","[INFO|configuration_utils.py:460] 2023-09-07 18:27:56,357 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-400/config.json\n","[INFO|modeling_utils.py:1988] 2023-09-07 18:27:56,467 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-400/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 18:27:56,471 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-400/preprocessor_config.json\n","[INFO|trainer.py:2973] 2023-09-07 18:27:56,691 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-100] due to args.save_total_limit\n","{'loss': 0.3655, 'learning_rate': 0.0009863333333333332, 'epoch': 4.1}\n","{'loss': 0.3751, 'learning_rate': 0.0009860000000000001, 'epoch': 4.2}\n","{'loss': 0.3589, 'learning_rate': 0.0009856666666666668, 'epoch': 4.3}\n","{'loss': 0.3514, 'learning_rate': 0.0009853333333333333, 'epoch': 4.4}\n","{'loss': 0.3453, 'learning_rate': 0.000985, 'epoch': 4.5}\n","{'loss': 0.3492, 'learning_rate': 0.0009846666666666667, 'epoch': 4.6}\n","{'loss': 0.3614, 'learning_rate': 0.0009843333333333334, 'epoch': 4.7}\n","{'loss': 0.3567, 'learning_rate': 0.000984, 'epoch': 4.8}\n","{'loss': 0.3373, 'learning_rate': 0.0009836666666666668, 'epoch': 4.9}\n","{'loss': 0.3562, 'learning_rate': 0.0009833333333333332, 'epoch': 5.0}\n","  2% 500/30000 [10:23<6:41:47,  1.22it/s][INFO|trainer.py:3160] 2023-09-07 18:29:48,747 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3162] 2023-09-07 18:29:48,747 >>   Num examples = 9000\n","[INFO|trainer.py:3165] 2023-09-07 18:29:48,747 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.60it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.85it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.58it/s]\u001b[A\n"," 28% 5/18 [00:03<00:09,  1.43it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.34it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.27it/s]\u001b[A\n"," 44% 8/18 [00:05<00:08,  1.24it/s]\u001b[A\n"," 50% 9/18 [00:06<00:07,  1.21it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.19it/s]\u001b[A\n"," 61% 11/18 [00:08<00:06,  1.06it/s]\u001b[A\n"," 67% 12/18 [00:09<00:05,  1.09it/s]\u001b[A\n"," 72% 13/18 [00:10<00:04,  1.11it/s]\u001b[A\n"," 78% 14/18 [00:11<00:03,  1.17it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.22it/s]\u001b[A\n"," 89% 16/18 [00:12<00:01,  1.25it/s]\u001b[A\n","                                         \n","\u001b[A{'eval_loss': 0.5994722843170166, 'eval_accuracy': 0.7688888888888888, 'eval_runtime': 14.6879, 'eval_samples_per_second': 612.748, 'eval_steps_per_second': 1.225, 'epoch': 5.0}\n","  2% 500/30000 [10:37<6:41:47,  1.22it/s]\n","100% 18/18 [00:13<00:00,  1.40it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2886] 2023-09-07 18:30:03,440 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-500\n","[INFO|configuration_utils.py:460] 2023-09-07 18:30:03,445 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-500/config.json\n","[INFO|modeling_utils.py:1988] 2023-09-07 18:30:03,559 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-500/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 18:30:03,564 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-500/preprocessor_config.json\n","[INFO|trainer.py:2973] 2023-09-07 18:30:03,789 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-200] due to args.save_total_limit\n","{'loss': 0.3363, 'learning_rate': 0.000983, 'epoch': 5.1}\n","{'loss': 0.3435, 'learning_rate': 0.0009826666666666666, 'epoch': 5.2}\n","{'loss': 0.3425, 'learning_rate': 0.0009823333333333333, 'epoch': 5.3}\n","{'loss': 0.3292, 'learning_rate': 0.000982, 'epoch': 5.4}\n","{'loss': 0.3315, 'learning_rate': 0.0009816666666666667, 'epoch': 5.5}\n","{'loss': 0.3534, 'learning_rate': 0.0009813333333333334, 'epoch': 5.6}\n","{'loss': 0.3357, 'learning_rate': 0.000981, 'epoch': 5.7}\n","{'loss': 0.3166, 'learning_rate': 0.0009806666666666668, 'epoch': 5.8}\n","{'loss': 0.3336, 'learning_rate': 0.0009803333333333333, 'epoch': 5.9}\n","{'loss': 0.3395, 'learning_rate': 0.00098, 'epoch': 6.0}\n","  2% 600/30000 [12:31<6:50:13,  1.19it/s][INFO|trainer.py:3160] 2023-09-07 18:31:56,627 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3162] 2023-09-07 18:31:56,627 >>   Num examples = 9000\n","[INFO|trainer.py:3165] 2023-09-07 18:31:56,627 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:05,  2.70it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.82it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.62it/s]\u001b[A\n"," 28% 5/18 [00:03<00:08,  1.48it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.43it/s]\u001b[A\n"," 39% 7/18 [00:04<00:07,  1.41it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.31it/s]\u001b[A\n"," 50% 9/18 [00:06<00:06,  1.30it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.28it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.22it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.21it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.26it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.30it/s]\u001b[A\n"," 83% 15/18 [00:10<00:02,  1.31it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.32it/s]\u001b[A\n","                                         \n","\u001b[A{'eval_loss': 0.044447775930166245, 'eval_accuracy': 0.9862222222222222, 'eval_runtime': 13.6644, 'eval_samples_per_second': 658.644, 'eval_steps_per_second': 1.317, 'epoch': 6.0}\n","  2% 600/30000 [12:44<6:50:13,  1.19it/s]\n","100% 18/18 [00:12<00:00,  1.50it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2886] 2023-09-07 18:32:10,306 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-600\n","[INFO|configuration_utils.py:460] 2023-09-07 18:32:10,313 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-600/config.json\n","[INFO|modeling_utils.py:1988] 2023-09-07 18:32:10,415 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-600/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 18:32:10,420 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-600/preprocessor_config.json\n","[INFO|trainer.py:2973] 2023-09-07 18:32:10,645 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-300] due to args.save_total_limit\n","{'loss': 0.3373, 'learning_rate': 0.0009796666666666667, 'epoch': 6.1}\n","{'loss': 0.3339, 'learning_rate': 0.0009793333333333334, 'epoch': 6.2}\n","{'loss': 0.3244, 'learning_rate': 0.000979, 'epoch': 6.3}\n","{'loss': 0.3344, 'learning_rate': 0.0009786666666666667, 'epoch': 6.4}\n","{'loss': 0.3332, 'learning_rate': 0.0009783333333333334, 'epoch': 6.5}\n","{'loss': 0.3442, 'learning_rate': 0.000978, 'epoch': 6.6}\n","{'loss': 0.3252, 'learning_rate': 0.0009776666666666666, 'epoch': 6.7}\n","{'loss': 0.3189, 'learning_rate': 0.0009773333333333333, 'epoch': 6.8}\n","{'loss': 0.318, 'learning_rate': 0.000977, 'epoch': 6.9}\n","{'loss': 0.3397, 'learning_rate': 0.0009766666666666667, 'epoch': 7.0}\n","  2% 700/30000 [14:37<6:28:08,  1.26it/s][INFO|trainer.py:3160] 2023-09-07 18:34:02,649 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3162] 2023-09-07 18:34:02,650 >>   Num examples = 9000\n","[INFO|trainer.py:3165] 2023-09-07 18:34:02,650 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:05,  2.75it/s]\u001b[A\n"," 17% 3/18 [00:01<00:07,  1.92it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.66it/s]\u001b[A\n"," 28% 5/18 [00:03<00:08,  1.49it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.45it/s]\u001b[A\n"," 39% 7/18 [00:04<00:07,  1.39it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.38it/s]\u001b[A\n"," 50% 9/18 [00:06<00:07,  1.26it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.25it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.24it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.21it/s]\u001b[A\n"," 72% 13/18 [00:09<00:04,  1.21it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.22it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.25it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.28it/s]\u001b[A\n","                                         \n","\u001b[A{'eval_loss': 0.04917712137103081, 'eval_accuracy': 0.9836666666666667, 'eval_runtime': 13.7753, 'eval_samples_per_second': 653.346, 'eval_steps_per_second': 1.307, 'epoch': 7.0}\n","  2% 700/30000 [14:50<6:28:08,  1.26it/s]\n","100% 18/18 [00:12<00:00,  1.47it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2886] 2023-09-07 18:34:16,429 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-700\n","[INFO|configuration_utils.py:460] 2023-09-07 18:34:16,434 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-700/config.json\n","[INFO|modeling_utils.py:1988] 2023-09-07 18:34:16,542 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-700/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 18:34:16,546 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-700/preprocessor_config.json\n","[INFO|trainer.py:2973] 2023-09-07 18:34:16,765 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-400] due to args.save_total_limit\n","{'loss': 0.326, 'learning_rate': 0.0009763333333333334, 'epoch': 7.1}\n","{'loss': 0.3322, 'learning_rate': 0.000976, 'epoch': 7.2}\n","{'loss': 0.311, 'learning_rate': 0.0009756666666666667, 'epoch': 7.3}\n","{'loss': 0.3309, 'learning_rate': 0.0009753333333333334, 'epoch': 7.4}\n","{'loss': 0.335, 'learning_rate': 0.000975, 'epoch': 7.5}\n","{'loss': 0.311, 'learning_rate': 0.0009746666666666666, 'epoch': 7.6}\n","{'loss': 0.3293, 'learning_rate': 0.0009743333333333335, 'epoch': 7.7}\n","{'loss': 0.3331, 'learning_rate': 0.000974, 'epoch': 7.8}\n","{'loss': 0.3411, 'learning_rate': 0.0009736666666666667, 'epoch': 7.9}\n","{'loss': 0.3127, 'learning_rate': 0.0009733333333333334, 'epoch': 8.0}\n","  3% 800/30000 [16:43<6:38:47,  1.22it/s][INFO|trainer.py:3160] 2023-09-07 18:36:08,795 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3162] 2023-09-07 18:36:08,795 >>   Num examples = 9000\n","[INFO|trainer.py:3165] 2023-09-07 18:36:08,795 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:05,  2.71it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.82it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.58it/s]\u001b[A\n"," 28% 5/18 [00:03<00:08,  1.49it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.42it/s]\u001b[A\n"," 39% 7/18 [00:04<00:07,  1.39it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.38it/s]\u001b[A\n"," 50% 9/18 [00:06<00:06,  1.36it/s]\u001b[A\n"," 56% 10/18 [00:06<00:05,  1.36it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.35it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.29it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.27it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.25it/s]\u001b[A\n"," 83% 15/18 [00:10<00:02,  1.23it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.23it/s]\u001b[A\n","                                         \n","\u001b[A{'eval_loss': 0.04982312023639679, 'eval_accuracy': 0.9842222222222222, 'eval_runtime': 13.6961, 'eval_samples_per_second': 657.119, 'eval_steps_per_second': 1.314, 'epoch': 8.0}\n","  3% 800/30000 [16:57<6:38:47,  1.22it/s]\n","100% 18/18 [00:12<00:00,  1.42it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2886] 2023-09-07 18:36:22,495 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-800\n","[INFO|configuration_utils.py:460] 2023-09-07 18:36:22,501 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-800/config.json\n","[INFO|modeling_utils.py:1988] 2023-09-07 18:36:22,608 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-800/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 18:36:22,613 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-800/preprocessor_config.json\n","[INFO|trainer.py:2973] 2023-09-07 18:36:22,816 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-500] due to args.save_total_limit\n","{'loss': 0.3389, 'learning_rate': 0.000973, 'epoch': 8.1}\n","{'loss': 0.2927, 'learning_rate': 0.0009726666666666667, 'epoch': 8.2}\n","{'loss': 0.3278, 'learning_rate': 0.0009723333333333334, 'epoch': 8.3}\n","{'loss': 0.3207, 'learning_rate': 0.000972, 'epoch': 8.4}\n","{'loss': 0.3184, 'learning_rate': 0.0009716666666666667, 'epoch': 8.5}\n","{'loss': 0.3196, 'learning_rate': 0.0009713333333333334, 'epoch': 8.6}\n","{'loss': 0.2965, 'learning_rate': 0.000971, 'epoch': 8.7}\n","{'loss': 0.3086, 'learning_rate': 0.0009706666666666667, 'epoch': 8.8}\n","{'loss': 0.3128, 'learning_rate': 0.0009703333333333334, 'epoch': 8.9}\n","{'loss': 0.3242, 'learning_rate': 0.0009699999999999999, 'epoch': 9.0}\n","  3% 900/30000 [18:51<6:42:48,  1.20it/s][INFO|trainer.py:3160] 2023-09-07 18:38:16,763 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3162] 2023-09-07 18:38:16,763 >>   Num examples = 9000\n","[INFO|trainer.py:3165] 2023-09-07 18:38:16,764 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:05,  2.72it/s]\u001b[A\n"," 17% 3/18 [00:01<00:07,  1.91it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.61it/s]\u001b[A\n"," 28% 5/18 [00:02<00:08,  1.53it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.44it/s]\u001b[A\n"," 39% 7/18 [00:04<00:07,  1.40it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.40it/s]\u001b[A\n"," 50% 9/18 [00:05<00:06,  1.39it/s]\u001b[A\n"," 56% 10/18 [00:06<00:05,  1.38it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.35it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.33it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.31it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.14it/s]\u001b[A\n"," 83% 15/18 [00:10<00:02,  1.17it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.19it/s]\u001b[A\n","                                         \n","\u001b[A{'eval_loss': 0.35203513503074646, 'eval_accuracy': 0.8961111111111111, 'eval_runtime': 13.8627, 'eval_samples_per_second': 649.225, 'eval_steps_per_second': 1.298, 'epoch': 9.0}\n","  3% 900/30000 [19:05<6:42:48,  1.20it/s]\n","100% 18/18 [00:12<00:00,  1.35it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2886] 2023-09-07 18:38:30,643 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-900\n","[INFO|configuration_utils.py:460] 2023-09-07 18:38:30,651 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-900/config.json\n","[INFO|modeling_utils.py:1988] 2023-09-07 18:38:30,761 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-900/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 18:38:30,766 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-900/preprocessor_config.json\n","[INFO|trainer.py:2973] 2023-09-07 18:38:30,981 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-700] due to args.save_total_limit\n","{'loss': 0.3208, 'learning_rate': 0.0009696666666666667, 'epoch': 9.1}\n","{'loss': 0.2947, 'learning_rate': 0.0009693333333333334, 'epoch': 9.2}\n","{'loss': 0.3053, 'learning_rate': 0.000969, 'epoch': 9.3}\n","{'loss': 0.3205, 'learning_rate': 0.0009686666666666667, 'epoch': 9.4}\n","{'loss': 0.2979, 'learning_rate': 0.0009683333333333334, 'epoch': 9.5}\n","{'loss': 0.3187, 'learning_rate': 0.000968, 'epoch': 9.6}\n","{'loss': 0.322, 'learning_rate': 0.0009676666666666667, 'epoch': 9.7}\n","{'loss': 0.3004, 'learning_rate': 0.0009673333333333334, 'epoch': 9.8}\n","{'loss': 0.3023, 'learning_rate': 0.000967, 'epoch': 9.9}\n","{'loss': 0.3148, 'learning_rate': 0.0009666666666666667, 'epoch': 10.0}\n","  3% 1000/30000 [20:57<6:42:53,  1.20it/s][INFO|trainer.py:3160] 2023-09-07 18:40:22,955 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3162] 2023-09-07 18:40:22,955 >>   Num examples = 9000\n","[INFO|trainer.py:3165] 2023-09-07 18:40:22,955 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.66it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.80it/s]\u001b[A\n"," 22% 4/18 [00:02<00:09,  1.55it/s]\u001b[A\n"," 28% 5/18 [00:03<00:08,  1.46it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.37it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.35it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.35it/s]\u001b[A\n"," 50% 9/18 [00:06<00:06,  1.32it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.31it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.28it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.27it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.28it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.24it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.21it/s]\u001b[A\n"," 89% 16/18 [00:12<00:01,  1.18it/s]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 1.856344223022461, 'eval_accuracy': 0.4514444444444444, 'eval_runtime': 14.1404, 'eval_samples_per_second': 636.476, 'eval_steps_per_second': 1.273, 'epoch': 10.0}\n","  3% 1000/30000 [21:11<6:42:53,  1.20it/s]\n","100% 18/18 [00:12<00:00,  1.32it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2886] 2023-09-07 18:40:37,100 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-1000\n","[INFO|configuration_utils.py:460] 2023-09-07 18:40:37,106 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-1000/config.json\n","[INFO|modeling_utils.py:1988] 2023-09-07 18:40:37,211 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-1000/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 18:40:37,215 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-1000/preprocessor_config.json\n","[INFO|trainer.py:2973] 2023-09-07 18:40:37,439 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-800] due to args.save_total_limit\n","{'loss': 0.3033, 'learning_rate': 0.0009663333333333334, 'epoch': 10.1}\n","{'loss': 0.3036, 'learning_rate': 0.000966, 'epoch': 10.2}\n","{'loss': 0.3217, 'learning_rate': 0.0009656666666666666, 'epoch': 10.3}\n","{'loss': 0.3207, 'learning_rate': 0.0009653333333333333, 'epoch': 10.4}\n","{'loss': 0.323, 'learning_rate': 0.000965, 'epoch': 10.5}\n","{'loss': 0.3218, 'learning_rate': 0.0009646666666666667, 'epoch': 10.6}\n","{'loss': 0.2895, 'learning_rate': 0.0009643333333333334, 'epoch': 10.7}\n","{'loss': 0.3155, 'learning_rate': 0.000964, 'epoch': 10.8}\n","{'loss': 0.3055, 'learning_rate': 0.0009636666666666667, 'epoch': 10.9}\n","{'loss': 0.3199, 'learning_rate': 0.0009633333333333334, 'epoch': 11.0}\n","  4% 1100/30000 [23:06<6:45:09,  1.19it/s][INFO|trainer.py:3160] 2023-09-07 18:42:31,551 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3162] 2023-09-07 18:42:31,551 >>   Num examples = 9000\n","[INFO|trainer.py:3165] 2023-09-07 18:42:31,551 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:05,  2.76it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.84it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.62it/s]\u001b[A\n"," 28% 5/18 [00:02<00:08,  1.53it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.47it/s]\u001b[A\n"," 39% 7/18 [00:04<00:07,  1.43it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.37it/s]\u001b[A\n"," 50% 9/18 [00:05<00:06,  1.36it/s]\u001b[A\n"," 56% 10/18 [00:06<00:05,  1.35it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.33it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.24it/s]\u001b[A\n"," 72% 13/18 [00:09<00:04,  1.21it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.19it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.18it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.19it/s]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 0.03270024433732033, 'eval_accuracy': 0.99, 'eval_runtime': 13.889, 'eval_samples_per_second': 647.994, 'eval_steps_per_second': 1.296, 'epoch': 11.0}\n","  4% 1100/30000 [23:19<6:45:09,  1.19it/s]\n","100% 18/18 [00:12<00:00,  1.37it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2886] 2023-09-07 18:42:45,444 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-1100\n","[INFO|configuration_utils.py:460] 2023-09-07 18:42:45,450 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-1100/config.json\n","[INFO|modeling_utils.py:1988] 2023-09-07 18:42:45,566 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-1100/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 18:42:45,571 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-1100/preprocessor_config.json\n","[INFO|trainer.py:2973] 2023-09-07 18:42:45,782 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-600] due to args.save_total_limit\n","{'loss': 0.2979, 'learning_rate': 0.000963, 'epoch': 11.1}\n","{'loss': 0.3142, 'learning_rate': 0.0009626666666666667, 'epoch': 11.2}\n","{'loss': 0.2994, 'learning_rate': 0.0009623333333333334, 'epoch': 11.3}\n","{'loss': 0.3059, 'learning_rate': 0.000962, 'epoch': 11.4}\n","{'loss': 0.3086, 'learning_rate': 0.0009616666666666667, 'epoch': 11.5}\n","{'loss': 0.306, 'learning_rate': 0.0009613333333333334, 'epoch': 11.6}\n","{'loss': 0.3037, 'learning_rate': 0.0009609999999999999, 'epoch': 11.7}\n","{'loss': 0.299, 'learning_rate': 0.0009606666666666666, 'epoch': 11.8}\n","{'loss': 0.3352, 'learning_rate': 0.0009603333333333334, 'epoch': 11.9}\n","{'loss': 0.3086, 'learning_rate': 0.00096, 'epoch': 12.0}\n","  4% 1200/30000 [25:12<6:29:57,  1.23it/s][INFO|trainer.py:3160] 2023-09-07 18:44:38,261 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3162] 2023-09-07 18:44:38,262 >>   Num examples = 9000\n","[INFO|trainer.py:3165] 2023-09-07 18:44:38,262 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:05,  2.81it/s]\u001b[A\n"," 17% 3/18 [00:01<00:07,  1.98it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.65it/s]\u001b[A\n"," 28% 5/18 [00:02<00:08,  1.51it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.45it/s]\u001b[A\n"," 39% 7/18 [00:04<00:07,  1.39it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.38it/s]\u001b[A\n"," 50% 9/18 [00:05<00:06,  1.38it/s]\u001b[A\n"," 56% 10/18 [00:06<00:05,  1.38it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.36it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.34it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.29it/s]\u001b[A\n"," 78% 14/18 [00:09<00:03,  1.27it/s]\u001b[A\n"," 83% 15/18 [00:10<00:02,  1.25it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.24it/s]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 0.04354429617524147, 'eval_accuracy': 0.987, 'eval_runtime': 13.5267, 'eval_samples_per_second': 665.351, 'eval_steps_per_second': 1.331, 'epoch': 12.0}\n","  4% 1200/30000 [25:26<6:29:57,  1.23it/s]\n","100% 18/18 [00:12<00:00,  1.42it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2886] 2023-09-07 18:44:51,793 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-1200\n","[INFO|configuration_utils.py:460] 2023-09-07 18:44:51,800 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-1200/config.json\n","[INFO|modeling_utils.py:1988] 2023-09-07 18:44:51,925 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-1200/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 18:44:51,929 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-1200/preprocessor_config.json\n","[INFO|trainer.py:2973] 2023-09-07 18:44:52,147 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-900] due to args.save_total_limit\n","{'loss': 0.2817, 'learning_rate': 0.0009596666666666667, 'epoch': 12.1}\n","{'loss': 0.3101, 'learning_rate': 0.0009593333333333334, 'epoch': 12.2}\n","{'loss': 0.3241, 'learning_rate': 0.000959, 'epoch': 12.3}\n","{'loss': 0.2891, 'learning_rate': 0.0009586666666666667, 'epoch': 12.4}\n","{'loss': 0.3213, 'learning_rate': 0.0009583333333333334, 'epoch': 12.5}\n","{'loss': 0.2837, 'learning_rate': 0.000958, 'epoch': 12.6}\n","{'loss': 0.2862, 'learning_rate': 0.0009576666666666667, 'epoch': 12.7}\n","{'loss': 0.317, 'learning_rate': 0.0009573333333333334, 'epoch': 12.8}\n","{'loss': 0.3205, 'learning_rate': 0.000957, 'epoch': 12.9}\n","{'loss': 0.2947, 'learning_rate': 0.0009566666666666666, 'epoch': 13.0}\n","  4% 1300/30000 [27:18<6:34:47,  1.21it/s][INFO|trainer.py:3160] 2023-09-07 18:46:43,802 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3162] 2023-09-07 18:46:43,802 >>   Num examples = 9000\n","[INFO|trainer.py:3165] 2023-09-07 18:46:43,802 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:05,  2.77it/s]\u001b[A\n"," 17% 3/18 [00:01<00:07,  1.89it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.67it/s]\u001b[A\n"," 28% 5/18 [00:02<00:08,  1.53it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.48it/s]\u001b[A\n"," 39% 7/18 [00:04<00:07,  1.44it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.39it/s]\u001b[A\n"," 50% 9/18 [00:05<00:06,  1.38it/s]\u001b[A\n"," 56% 10/18 [00:06<00:05,  1.35it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.35it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.32it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.29it/s]\u001b[A\n"," 78% 14/18 [00:09<00:03,  1.25it/s]\u001b[A\n"," 83% 15/18 [00:10<00:02,  1.24it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.24it/s]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 0.043256524950265884, 'eval_accuracy': 0.9854444444444445, 'eval_runtime': 13.5214, 'eval_samples_per_second': 665.609, 'eval_steps_per_second': 1.331, 'epoch': 13.0}\n","  4% 1300/30000 [27:31<6:34:47,  1.21it/s]\n","100% 18/18 [00:12<00:00,  1.41it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2886] 2023-09-07 18:46:57,328 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-1300\n","[INFO|configuration_utils.py:460] 2023-09-07 18:46:57,334 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-1300/config.json\n","[INFO|modeling_utils.py:1988] 2023-09-07 18:46:57,441 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-1300/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 18:46:57,445 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-1300/preprocessor_config.json\n","[INFO|trainer.py:2973] 2023-09-07 18:46:57,664 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-1000] due to args.save_total_limit\n","{'loss': 0.2978, 'learning_rate': 0.0009563333333333333, 'epoch': 13.1}\n","{'loss': 0.3023, 'learning_rate': 0.0009559999999999999, 'epoch': 13.2}\n","{'loss': 0.3135, 'learning_rate': 0.0009556666666666667, 'epoch': 13.3}\n","{'loss': 0.3026, 'learning_rate': 0.0009553333333333334, 'epoch': 13.4}\n","{'loss': 0.2772, 'learning_rate': 0.000955, 'epoch': 13.5}\n","{'loss': 0.2991, 'learning_rate': 0.0009546666666666667, 'epoch': 13.6}\n","{'loss': 0.2971, 'learning_rate': 0.0009543333333333334, 'epoch': 13.7}\n","{'loss': 0.3037, 'learning_rate': 0.000954, 'epoch': 13.8}\n","{'loss': 0.3066, 'learning_rate': 0.0009536666666666667, 'epoch': 13.9}\n","{'loss': 0.2773, 'learning_rate': 0.0009533333333333334, 'epoch': 14.0}\n","  5% 1400/30000 [29:22<6:18:22,  1.26it/s][INFO|trainer.py:3160] 2023-09-07 18:48:47,598 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3162] 2023-09-07 18:48:47,598 >>   Num examples = 9000\n","[INFO|trainer.py:3165] 2023-09-07 18:48:47,598 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:05,  2.70it/s]\u001b[A\n"," 17% 3/18 [00:01<00:07,  1.93it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.69it/s]\u001b[A\n"," 28% 5/18 [00:03<00:08,  1.46it/s]\u001b[A\n"," 33% 6/18 [00:04<00:09,  1.25it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.25it/s]\u001b[A\n"," 44% 8/18 [00:05<00:08,  1.23it/s]\u001b[A\n"," 50% 9/18 [00:06<00:07,  1.23it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.24it/s]\u001b[A\n"," 61% 11/18 [00:08<00:05,  1.26it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.30it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.31it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.30it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.31it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.30it/s]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 0.03441309556365013, 'eval_accuracy': 0.9878888888888889, 'eval_runtime': 14.1049, 'eval_samples_per_second': 638.076, 'eval_steps_per_second': 1.276, 'epoch': 14.0}\n","  5% 1400/30000 [29:36<6:18:22,  1.26it/s]\n","100% 18/18 [00:12<00:00,  1.45it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2886] 2023-09-07 18:49:01,707 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-1400\n","[INFO|configuration_utils.py:460] 2023-09-07 18:49:01,713 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-1400/config.json\n","[INFO|modeling_utils.py:1988] 2023-09-07 18:49:01,828 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-1400/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 18:49:01,833 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-1400/preprocessor_config.json\n","[INFO|trainer.py:2973] 2023-09-07 18:49:02,066 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-1200] due to args.save_total_limit\n","{'loss': 0.2961, 'learning_rate': 0.000953, 'epoch': 14.1}\n","{'loss': 0.284, 'learning_rate': 0.0009526666666666667, 'epoch': 14.2}\n","{'loss': 0.2924, 'learning_rate': 0.0009523333333333334, 'epoch': 14.3}\n","{'loss': 0.2994, 'learning_rate': 0.0009519999999999999, 'epoch': 14.4}\n","{'loss': 0.3045, 'learning_rate': 0.0009516666666666666, 'epoch': 14.5}\n","{'loss': 0.2914, 'learning_rate': 0.0009513333333333334, 'epoch': 14.6}\n","{'loss': 0.2831, 'learning_rate': 0.000951, 'epoch': 14.7}\n","{'loss': 0.2923, 'learning_rate': 0.0009506666666666667, 'epoch': 14.8}\n","{'loss': 0.2982, 'learning_rate': 0.0009503333333333334, 'epoch': 14.9}\n","{'loss': 0.2926, 'learning_rate': 0.00095, 'epoch': 15.0}\n","  5% 1500/30000 [31:27<6:21:10,  1.25it/s][INFO|trainer.py:3160] 2023-09-07 18:50:53,487 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3162] 2023-09-07 18:50:53,488 >>   Num examples = 9000\n","[INFO|trainer.py:3165] 2023-09-07 18:50:53,488 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:05,  2.68it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.84it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.63it/s]\u001b[A\n"," 28% 5/18 [00:02<00:08,  1.52it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.46it/s]\u001b[A\n"," 39% 7/18 [00:04<00:07,  1.44it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.42it/s]\u001b[A\n"," 50% 9/18 [00:05<00:06,  1.41it/s]\u001b[A\n"," 56% 10/18 [00:06<00:05,  1.40it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.36it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.36it/s]\u001b[A\n"," 72% 13/18 [00:08<00:03,  1.36it/s]\u001b[A\n"," 78% 14/18 [00:09<00:02,  1.35it/s]\u001b[A\n"," 83% 15/18 [00:10<00:02,  1.34it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.24it/s]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 0.04404883831739426, 'eval_accuracy': 0.9851111111111112, 'eval_runtime': 13.4776, 'eval_samples_per_second': 667.776, 'eval_steps_per_second': 1.336, 'epoch': 15.0}\n","  5% 1500/30000 [31:41<6:21:10,  1.25it/s]\n","100% 18/18 [00:11<00:00,  1.38it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2886] 2023-09-07 18:51:06,970 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-1500\n","[INFO|configuration_utils.py:460] 2023-09-07 18:51:06,976 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-1500/config.json\n","[INFO|modeling_utils.py:1988] 2023-09-07 18:51:07,091 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-1500/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 18:51:07,107 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-1500/preprocessor_config.json\n","[INFO|trainer.py:2973] 2023-09-07 18:51:07,338 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-1300] due to args.save_total_limit\n","{'loss': 0.3213, 'learning_rate': 0.0009496666666666667, 'epoch': 15.1}\n","{'loss': 0.3097, 'learning_rate': 0.0009493333333333334, 'epoch': 15.2}\n","{'loss': 0.2899, 'learning_rate': 0.000949, 'epoch': 15.3}\n","{'loss': 0.3005, 'learning_rate': 0.0009486666666666667, 'epoch': 15.4}\n","{'loss': 0.2914, 'learning_rate': 0.0009483333333333334, 'epoch': 15.5}\n","{'loss': 0.2843, 'learning_rate': 0.000948, 'epoch': 15.6}\n","{'loss': 0.2836, 'learning_rate': 0.0009476666666666666, 'epoch': 15.7}\n","{'loss': 0.2925, 'learning_rate': 0.0009473333333333333, 'epoch': 15.8}\n","{'loss': 0.2835, 'learning_rate': 0.0009469999999999999, 'epoch': 15.9}\n","{'loss': 0.3091, 'learning_rate': 0.0009466666666666667, 'epoch': 16.0}\n","  5% 1600/30000 [33:34<6:32:13,  1.21it/s][INFO|trainer.py:3160] 2023-09-07 18:52:59,997 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3162] 2023-09-07 18:52:59,998 >>   Num examples = 9000\n","[INFO|trainer.py:3165] 2023-09-07 18:52:59,998 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.66it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.86it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.64it/s]\u001b[A\n"," 28% 5/18 [00:02<00:08,  1.52it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.47it/s]\u001b[A\n"," 39% 7/18 [00:04<00:07,  1.42it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.37it/s]\u001b[A\n"," 50% 9/18 [00:06<00:06,  1.35it/s]\u001b[A\n"," 56% 10/18 [00:06<00:05,  1.35it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.34it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.32it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.33it/s]\u001b[A\n"," 78% 14/18 [00:09<00:03,  1.31it/s]\u001b[A\n"," 83% 15/18 [00:10<00:02,  1.32it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.32it/s]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 0.032210107892751694, 'eval_accuracy': 0.9905555555555555, 'eval_runtime': 13.5487, 'eval_samples_per_second': 664.268, 'eval_steps_per_second': 1.329, 'epoch': 16.0}\n","  5% 1600/30000 [33:48<6:32:13,  1.21it/s]\n","100% 18/18 [00:12<00:00,  1.44it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2886] 2023-09-07 18:53:13,550 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-1600\n","[INFO|configuration_utils.py:460] 2023-09-07 18:53:13,556 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-1600/config.json\n","[INFO|modeling_utils.py:1988] 2023-09-07 18:53:13,921 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-1600/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 18:53:13,926 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-1600/preprocessor_config.json\n","[INFO|trainer.py:2973] 2023-09-07 18:53:14,137 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-1100] due to args.save_total_limit\n","{'loss': 0.3132, 'learning_rate': 0.0009463333333333334, 'epoch': 16.1}\n","{'loss': 0.2933, 'learning_rate': 0.000946, 'epoch': 16.2}\n","{'loss': 0.2852, 'learning_rate': 0.0009456666666666667, 'epoch': 16.3}\n","{'loss': 0.2801, 'learning_rate': 0.0009453333333333334, 'epoch': 16.4}\n","{'loss': 0.2984, 'learning_rate': 0.000945, 'epoch': 16.5}\n","{'loss': 0.2999, 'learning_rate': 0.0009446666666666667, 'epoch': 16.6}\n","{'loss': 0.2953, 'learning_rate': 0.0009443333333333334, 'epoch': 16.7}\n","{'loss': 0.3079, 'learning_rate': 0.000944, 'epoch': 16.8}\n","{'loss': 0.29, 'learning_rate': 0.0009436666666666667, 'epoch': 16.9}\n","{'loss': 0.3095, 'learning_rate': 0.0009433333333333334, 'epoch': 17.0}\n","  6% 1700/30000 [35:40<6:18:46,  1.25it/s][INFO|trainer.py:3160] 2023-09-07 18:55:05,871 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3162] 2023-09-07 18:55:05,871 >>   Num examples = 9000\n","[INFO|trainer.py:3165] 2023-09-07 18:55:05,871 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.50it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.81it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.60it/s]\u001b[A\n"," 28% 5/18 [00:03<00:08,  1.48it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.43it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.37it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.37it/s]\u001b[A\n"," 50% 9/18 [00:06<00:06,  1.36it/s]\u001b[A\n"," 56% 10/18 [00:06<00:06,  1.33it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.34it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.31it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.33it/s]\u001b[A\n"," 78% 14/18 [00:09<00:03,  1.32it/s]\u001b[A\n"," 83% 15/18 [00:10<00:02,  1.31it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.31it/s]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 0.14791344106197357, 'eval_accuracy': 0.9574444444444444, 'eval_runtime': 13.666, 'eval_samples_per_second': 658.566, 'eval_steps_per_second': 1.317, 'epoch': 17.0}\n","  6% 1700/30000 [35:54<6:18:46,  1.25it/s]\n","100% 18/18 [00:12<00:00,  1.44it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2886] 2023-09-07 18:55:19,543 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-1700\n","[INFO|configuration_utils.py:460] 2023-09-07 18:55:19,548 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-1700/config.json\n","[INFO|modeling_utils.py:1988] 2023-09-07 18:55:19,659 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-1700/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 18:55:19,664 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-1700/preprocessor_config.json\n","[INFO|trainer.py:2973] 2023-09-07 18:55:19,886 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-1400] due to args.save_total_limit\n","{'loss': 0.2806, 'learning_rate': 0.0009429999999999999, 'epoch': 17.1}\n","{'loss': 0.2895, 'learning_rate': 0.0009426666666666666, 'epoch': 17.2}\n","{'loss': 0.3193, 'learning_rate': 0.0009423333333333333, 'epoch': 17.3}\n","{'loss': 0.3118, 'learning_rate': 0.000942, 'epoch': 17.4}\n","{'loss': 0.3151, 'learning_rate': 0.0009416666666666667, 'epoch': 17.5}\n","{'loss': 0.2809, 'learning_rate': 0.0009413333333333334, 'epoch': 17.6}\n","{'loss': 0.2885, 'learning_rate': 0.000941, 'epoch': 17.7}\n","{'loss': 0.3103, 'learning_rate': 0.0009406666666666667, 'epoch': 17.8}\n","{'loss': 0.2928, 'learning_rate': 0.0009403333333333334, 'epoch': 17.9}\n","{'loss': 0.2903, 'learning_rate': 0.00094, 'epoch': 18.0}\n","  6% 1800/30000 [37:45<6:17:38,  1.24it/s][INFO|trainer.py:3160] 2023-09-07 18:57:11,346 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3162] 2023-09-07 18:57:11,346 >>   Num examples = 9000\n","[INFO|trainer.py:3165] 2023-09-07 18:57:11,346 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.49it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.84it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.57it/s]\u001b[A\n"," 28% 5/18 [00:03<00:08,  1.46it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.44it/s]\u001b[A\n"," 39% 7/18 [00:04<00:07,  1.39it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.39it/s]\u001b[A\n"," 50% 9/18 [00:06<00:06,  1.39it/s]\u001b[A\n"," 56% 10/18 [00:06<00:05,  1.35it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.36it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.37it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.34it/s]\u001b[A\n"," 78% 14/18 [00:09<00:03,  1.33it/s]\u001b[A\n"," 83% 15/18 [00:10<00:02,  1.33it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.33it/s]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 0.030952900648117065, 'eval_accuracy': 0.9896666666666667, 'eval_runtime': 13.4129, 'eval_samples_per_second': 670.995, 'eval_steps_per_second': 1.342, 'epoch': 18.0}\n","  6% 1800/30000 [37:59<6:17:38,  1.24it/s]\n","100% 18/18 [00:11<00:00,  1.51it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2886] 2023-09-07 18:57:24,763 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-1800\n","[INFO|configuration_utils.py:460] 2023-09-07 18:57:24,769 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-1800/config.json\n","[INFO|modeling_utils.py:1988] 2023-09-07 18:57:24,878 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-1800/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 18:57:24,882 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-1800/preprocessor_config.json\n","[INFO|trainer.py:2973] 2023-09-07 18:57:25,117 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-1500] due to args.save_total_limit\n","{'loss': 0.2708, 'learning_rate': 0.0009396666666666667, 'epoch': 18.1}\n","{'loss': 0.2771, 'learning_rate': 0.0009393333333333334, 'epoch': 18.2}\n","{'loss': 0.2825, 'learning_rate': 0.000939, 'epoch': 18.3}\n","{'loss': 0.2923, 'learning_rate': 0.0009386666666666666, 'epoch': 18.4}\n","{'loss': 0.2794, 'learning_rate': 0.0009383333333333333, 'epoch': 18.5}\n","{'loss': 0.2892, 'learning_rate': 0.0009379999999999999, 'epoch': 18.6}\n","{'loss': 0.2865, 'learning_rate': 0.0009376666666666666, 'epoch': 18.7}\n","{'loss': 0.301, 'learning_rate': 0.0009373333333333334, 'epoch': 18.8}\n","{'loss': 0.2835, 'learning_rate': 0.0009370000000000001, 'epoch': 18.9}\n","{'loss': 0.3002, 'learning_rate': 0.0009366666666666667, 'epoch': 19.0}\n","  6% 1900/30000 [39:50<6:06:31,  1.28it/s][INFO|trainer.py:3160] 2023-09-07 18:59:15,667 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3162] 2023-09-07 18:59:15,668 >>   Num examples = 9000\n","[INFO|trainer.py:3165] 2023-09-07 18:59:15,668 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:07,  2.07it/s]\u001b[A\n"," 17% 3/18 [00:01<00:09,  1.52it/s]\u001b[A\n"," 22% 4/18 [00:02<00:10,  1.35it/s]\u001b[A\n"," 28% 5/18 [00:03<00:09,  1.32it/s]\u001b[A\n"," 33% 6/18 [00:04<00:08,  1.34it/s]\u001b[A\n"," 39% 7/18 [00:05<00:08,  1.33it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.34it/s]\u001b[A\n"," 50% 9/18 [00:06<00:06,  1.37it/s]\u001b[A\n"," 56% 10/18 [00:07<00:05,  1.35it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.36it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.34it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.36it/s]\u001b[A\n"," 78% 14/18 [00:10<00:02,  1.36it/s]\u001b[A\n"," 83% 15/18 [00:10<00:02,  1.36it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.34it/s]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 1.2723578214645386, 'eval_accuracy': 0.6082222222222222, 'eval_runtime': 13.6732, 'eval_samples_per_second': 658.22, 'eval_steps_per_second': 1.316, 'epoch': 19.0}\n","  6% 1900/30000 [40:03<6:06:31,  1.28it/s]\n","100% 18/18 [00:12<00:00,  1.51it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2886] 2023-09-07 18:59:29,346 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-1900\n","[INFO|configuration_utils.py:460] 2023-09-07 18:59:29,351 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-1900/config.json\n","[INFO|modeling_utils.py:1988] 2023-09-07 18:59:29,453 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-1900/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 18:59:29,457 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-1900/preprocessor_config.json\n","[INFO|trainer.py:2973] 2023-09-07 18:59:29,670 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-1600] due to args.save_total_limit\n","{'loss': 0.2878, 'learning_rate': 0.0009363333333333334, 'epoch': 19.1}\n","{'loss': 0.2973, 'learning_rate': 0.0009360000000000001, 'epoch': 19.2}\n","{'loss': 0.2936, 'learning_rate': 0.0009356666666666667, 'epoch': 19.3}\n","{'loss': 0.2898, 'learning_rate': 0.0009353333333333334, 'epoch': 19.4}\n","{'loss': 0.2937, 'learning_rate': 0.0009350000000000001, 'epoch': 19.5}\n","{'loss': 0.2825, 'learning_rate': 0.0009346666666666667, 'epoch': 19.6}\n","{'loss': 0.295, 'learning_rate': 0.0009343333333333333, 'epoch': 19.7}\n","{'loss': 0.2849, 'learning_rate': 0.000934, 'epoch': 19.8}\n","{'loss': 0.3073, 'learning_rate': 0.0009336666666666666, 'epoch': 19.9}\n","{'loss': 0.2966, 'learning_rate': 0.0009333333333333333, 'epoch': 20.0}\n","  7% 2000/30000 [41:55<6:01:05,  1.29it/s][INFO|trainer.py:3160] 2023-09-07 19:01:21,420 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3162] 2023-09-07 19:01:21,421 >>   Num examples = 9000\n","[INFO|trainer.py:3165] 2023-09-07 19:01:21,421 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:07,  2.28it/s]\u001b[A\n"," 17% 3/18 [00:01<00:09,  1.61it/s]\u001b[A\n"," 22% 4/18 [00:02<00:09,  1.40it/s]\u001b[A\n"," 28% 5/18 [00:03<00:09,  1.33it/s]\u001b[A\n"," 33% 6/18 [00:04<00:09,  1.29it/s]\u001b[A\n"," 39% 7/18 [00:05<00:08,  1.29it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.30it/s]\u001b[A\n"," 50% 9/18 [00:06<00:06,  1.32it/s]\u001b[A\n"," 56% 10/18 [00:07<00:05,  1.33it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.34it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.34it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.35it/s]\u001b[A\n"," 78% 14/18 [00:10<00:02,  1.34it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.31it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.33it/s]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 0.03065907396376133, 'eval_accuracy': 0.99, 'eval_runtime': 13.8062, 'eval_samples_per_second': 651.88, 'eval_steps_per_second': 1.304, 'epoch': 20.0}\n","  7% 2000/30000 [42:09<6:01:05,  1.29it/s]\n","100% 18/18 [00:12<00:00,  1.48it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2886] 2023-09-07 19:01:35,231 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-2000\n","[INFO|configuration_utils.py:460] 2023-09-07 19:01:35,237 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-2000/config.json\n","[INFO|modeling_utils.py:1988] 2023-09-07 19:01:35,346 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-2000/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 19:01:35,350 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-2000/preprocessor_config.json\n","[INFO|trainer.py:2973] 2023-09-07 19:01:35,563 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-1700] due to args.save_total_limit\n","{'loss': 0.2809, 'learning_rate': 0.000933, 'epoch': 20.1}\n","{'loss': 0.2824, 'learning_rate': 0.0009326666666666667, 'epoch': 20.2}\n","{'loss': 0.2846, 'learning_rate': 0.0009323333333333334, 'epoch': 20.3}\n","{'loss': 0.2834, 'learning_rate': 0.0009320000000000001, 'epoch': 20.4}\n","{'loss': 0.3037, 'learning_rate': 0.0009316666666666667, 'epoch': 20.5}\n","{'loss': 0.3037, 'learning_rate': 0.0009313333333333334, 'epoch': 20.6}\n","{'loss': 0.2997, 'learning_rate': 0.0009310000000000001, 'epoch': 20.7}\n","{'loss': 0.2874, 'learning_rate': 0.0009306666666666667, 'epoch': 20.8}\n","{'loss': 0.2739, 'learning_rate': 0.0009303333333333334, 'epoch': 20.9}\n","{'loss': 0.2617, 'learning_rate': 0.00093, 'epoch': 21.0}\n","  7% 2100/30000 [44:01<6:09:38,  1.26it/s][INFO|trainer.py:3160] 2023-09-07 19:03:27,486 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3162] 2023-09-07 19:03:27,486 >>   Num examples = 9000\n","[INFO|trainer.py:3165] 2023-09-07 19:03:27,486 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:01<00:09,  1.73it/s]\u001b[A\n"," 17% 3/18 [00:02<00:10,  1.44it/s]\u001b[A\n"," 22% 4/18 [00:02<00:10,  1.32it/s]\u001b[A\n"," 28% 5/18 [00:03<00:10,  1.26it/s]\u001b[A\n"," 33% 6/18 [00:04<00:09,  1.22it/s]\u001b[A\n"," 39% 7/18 [00:05<00:08,  1.24it/s]\u001b[A\n"," 44% 8/18 [00:06<00:07,  1.27it/s]\u001b[A\n"," 50% 9/18 [00:06<00:06,  1.30it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.31it/s]\u001b[A\n"," 61% 11/18 [00:08<00:05,  1.32it/s]\u001b[A\n"," 67% 12/18 [00:09<00:04,  1.32it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.30it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.32it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.32it/s]\u001b[A\n"," 89% 16/18 [00:12<00:01,  1.29it/s]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 0.028695061802864075, 'eval_accuracy': 0.9896666666666667, 'eval_runtime': 14.1916, 'eval_samples_per_second': 634.178, 'eval_steps_per_second': 1.268, 'epoch': 21.0}\n","  7% 2100/30000 [44:16<6:09:38,  1.26it/s]\n","100% 18/18 [00:12<00:00,  1.46it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2886] 2023-09-07 19:03:41,683 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-2100\n","[INFO|configuration_utils.py:460] 2023-09-07 19:03:41,688 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-2100/config.json\n","[INFO|modeling_utils.py:1988] 2023-09-07 19:03:41,800 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-2100/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 19:03:41,805 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-2100/preprocessor_config.json\n","[INFO|trainer.py:2973] 2023-09-07 19:03:42,037 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-1800] due to args.save_total_limit\n","{'loss': 0.2749, 'learning_rate': 0.0009296666666666666, 'epoch': 21.1}\n","{'loss': 0.2598, 'learning_rate': 0.0009293333333333333, 'epoch': 21.2}\n","{'loss': 0.2918, 'learning_rate': 0.000929, 'epoch': 21.3}\n","{'loss': 0.276, 'learning_rate': 0.0009286666666666666, 'epoch': 21.4}\n","{'loss': 0.2671, 'learning_rate': 0.0009283333333333333, 'epoch': 21.5}\n","{'loss': 0.2931, 'learning_rate': 0.0009280000000000001, 'epoch': 21.6}\n","{'loss': 0.2695, 'learning_rate': 0.0009276666666666667, 'epoch': 21.7}\n","{'loss': 0.2782, 'learning_rate': 0.0009273333333333334, 'epoch': 21.8}\n","{'loss': 0.2847, 'learning_rate': 0.0009270000000000001, 'epoch': 21.9}\n","{'loss': 0.28, 'learning_rate': 0.0009266666666666667, 'epoch': 22.0}\n","  7% 2200/30000 [46:08<6:08:14,  1.26it/s][INFO|trainer.py:3160] 2023-09-07 19:05:34,306 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3162] 2023-09-07 19:05:34,307 >>   Num examples = 9000\n","[INFO|trainer.py:3165] 2023-09-07 19:05:34,307 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.60it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.75it/s]\u001b[A\n"," 22% 4/18 [00:02<00:09,  1.53it/s]\u001b[A\n"," 28% 5/18 [00:03<00:09,  1.39it/s]\u001b[A\n"," 33% 6/18 [00:04<00:09,  1.31it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.27it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.28it/s]\u001b[A\n"," 50% 9/18 [00:06<00:06,  1.30it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.32it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.34it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.34it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.36it/s]\u001b[A\n"," 78% 14/18 [00:10<00:02,  1.34it/s]\u001b[A\n"," 83% 15/18 [00:10<00:02,  1.35it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.36it/s]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 1.583783507347107, 'eval_accuracy': 0.6632222222222223, 'eval_runtime': 13.5513, 'eval_samples_per_second': 664.143, 'eval_steps_per_second': 1.328, 'epoch': 22.0}\n","  7% 2200/30000 [46:22<6:08:14,  1.26it/s]\n","100% 18/18 [00:12<00:00,  1.51it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2886] 2023-09-07 19:05:47,862 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-2200\n","[INFO|configuration_utils.py:460] 2023-09-07 19:05:47,867 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-2200/config.json\n","[INFO|modeling_utils.py:1988] 2023-09-07 19:05:47,970 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-2200/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 19:05:47,974 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-2200/preprocessor_config.json\n","[INFO|trainer.py:2973] 2023-09-07 19:05:48,183 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-1900] due to args.save_total_limit\n","{'loss': 0.2819, 'learning_rate': 0.0009263333333333334, 'epoch': 22.1}\n","{'loss': 0.2824, 'learning_rate': 0.0009260000000000001, 'epoch': 22.2}\n","{'loss': 0.266, 'learning_rate': 0.0009256666666666667, 'epoch': 22.3}\n","{'loss': 0.2771, 'learning_rate': 0.0009253333333333333, 'epoch': 22.4}\n","{'loss': 0.272, 'learning_rate': 0.000925, 'epoch': 22.5}\n","{'loss': 0.2707, 'learning_rate': 0.0009246666666666666, 'epoch': 22.6}\n","{'loss': 0.2867, 'learning_rate': 0.0009243333333333333, 'epoch': 22.7}\n","{'loss': 0.2756, 'learning_rate': 0.000924, 'epoch': 22.8}\n","{'loss': 0.286, 'learning_rate': 0.0009236666666666666, 'epoch': 22.9}\n","{'loss': 0.2949, 'learning_rate': 0.0009233333333333334, 'epoch': 23.0}\n","  8% 2300/30000 [48:15<6:10:38,  1.25it/s][INFO|trainer.py:3160] 2023-09-07 19:07:40,673 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3162] 2023-09-07 19:07:40,673 >>   Num examples = 9000\n","[INFO|trainer.py:3165] 2023-09-07 19:07:40,673 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:05,  2.76it/s]\u001b[A\n"," 17% 3/18 [00:01<00:09,  1.65it/s]\u001b[A\n"," 22% 4/18 [00:02<00:09,  1.47it/s]\u001b[A\n"," 28% 5/18 [00:03<00:09,  1.38it/s]\u001b[A\n"," 33% 6/18 [00:04<00:09,  1.31it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.30it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.33it/s]\u001b[A\n"," 50% 9/18 [00:06<00:06,  1.34it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.33it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.33it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.34it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.35it/s]\u001b[A\n"," 78% 14/18 [00:10<00:02,  1.35it/s]\u001b[A\n"," 83% 15/18 [00:10<00:02,  1.36it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.35it/s]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 0.0412810742855072, 'eval_accuracy': 0.9883333333333333, 'eval_runtime': 13.4964, 'eval_samples_per_second': 666.842, 'eval_steps_per_second': 1.334, 'epoch': 23.0}\n","  8% 2300/30000 [48:28<6:10:38,  1.25it/s]\n","100% 18/18 [00:12<00:00,  1.52it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2886] 2023-09-07 19:07:54,174 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-2300\n","[INFO|configuration_utils.py:460] 2023-09-07 19:07:54,180 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-2300/config.json\n","[INFO|modeling_utils.py:1988] 2023-09-07 19:07:54,287 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-2300/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 19:07:54,290 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-2300/preprocessor_config.json\n","[INFO|trainer.py:2973] 2023-09-07 19:07:54,499 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-2000] due to args.save_total_limit\n","{'loss': 0.2517, 'learning_rate': 0.0009230000000000001, 'epoch': 23.1}\n","{'loss': 0.274, 'learning_rate': 0.0009226666666666667, 'epoch': 23.2}\n","{'loss': 0.2879, 'learning_rate': 0.0009223333333333334, 'epoch': 23.3}\n","{'loss': 0.2719, 'learning_rate': 0.0009220000000000001, 'epoch': 23.4}\n","{'loss': 0.2627, 'learning_rate': 0.0009216666666666667, 'epoch': 23.5}\n","{'loss': 0.2843, 'learning_rate': 0.0009213333333333334, 'epoch': 23.6}\n","{'loss': 0.2841, 'learning_rate': 0.000921, 'epoch': 23.7}\n","{'loss': 0.2811, 'learning_rate': 0.0009206666666666666, 'epoch': 23.8}\n","{'loss': 0.2755, 'learning_rate': 0.0009203333333333333, 'epoch': 23.9}\n","{'loss': 0.2708, 'learning_rate': 0.00092, 'epoch': 24.0}\n","  8% 2400/30000 [50:21<6:03:31,  1.27it/s][INFO|trainer.py:3160] 2023-09-07 19:09:46,962 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3162] 2023-09-07 19:09:46,963 >>   Num examples = 9000\n","[INFO|trainer.py:3165] 2023-09-07 19:09:46,963 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.64it/s]\u001b[A\n"," 17% 3/18 [00:01<00:07,  1.88it/s]\u001b[A\n"," 22% 4/18 [00:02<00:09,  1.46it/s]\u001b[A\n"," 28% 5/18 [00:03<00:09,  1.32it/s]\u001b[A\n"," 33% 6/18 [00:04<00:09,  1.24it/s]\u001b[A\n"," 39% 7/18 [00:05<00:09,  1.21it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.26it/s]\u001b[A\n"," 50% 9/18 [00:06<00:06,  1.30it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.32it/s]\u001b[A\n"," 61% 11/18 [00:08<00:05,  1.32it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.33it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.33it/s]\u001b[A\n"," 78% 14/18 [00:10<00:02,  1.35it/s]\u001b[A\n"," 83% 15/18 [00:10<00:02,  1.34it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.34it/s]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 0.08287066966295242, 'eval_accuracy': 0.9683333333333334, 'eval_runtime': 13.7583, 'eval_samples_per_second': 654.15, 'eval_steps_per_second': 1.308, 'epoch': 24.0}\n","  8% 2400/30000 [50:35<6:03:31,  1.27it/s]\n","100% 18/18 [00:12<00:00,  1.51it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2886] 2023-09-07 19:10:00,725 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-2400\n","[INFO|configuration_utils.py:460] 2023-09-07 19:10:00,730 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-2400/config.json\n","[INFO|modeling_utils.py:1988] 2023-09-07 19:10:00,834 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-2400/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 19:10:00,838 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-2400/preprocessor_config.json\n","[INFO|trainer.py:2973] 2023-09-07 19:10:01,066 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-2200] due to args.save_total_limit\n","{'loss': 0.2825, 'learning_rate': 0.0009196666666666666, 'epoch': 24.1}\n","{'loss': 0.2822, 'learning_rate': 0.0009193333333333333, 'epoch': 24.2}\n","{'loss': 0.2725, 'learning_rate': 0.0009190000000000001, 'epoch': 24.3}\n","{'loss': 0.2631, 'learning_rate': 0.0009186666666666667, 'epoch': 24.4}\n","{'loss': 0.2607, 'learning_rate': 0.0009183333333333334, 'epoch': 24.5}\n","{'loss': 0.2787, 'learning_rate': 0.0009180000000000001, 'epoch': 24.6}\n","{'loss': 0.2792, 'learning_rate': 0.0009176666666666667, 'epoch': 24.7}\n","{'loss': 0.283, 'learning_rate': 0.0009173333333333334, 'epoch': 24.8}\n","{'loss': 0.2855, 'learning_rate': 0.0009170000000000001, 'epoch': 24.9}\n","{'loss': 0.2755, 'learning_rate': 0.0009166666666666666, 'epoch': 25.0}\n","  8% 2500/30000 [52:28<6:08:41,  1.24it/s][INFO|trainer.py:3160] 2023-09-07 19:11:53,524 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3162] 2023-09-07 19:11:53,524 >>   Num examples = 9000\n","[INFO|trainer.py:3165] 2023-09-07 19:11:53,525 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:05,  2.80it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.82it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.59it/s]\u001b[A\n"," 28% 5/18 [00:03<00:09,  1.42it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.35it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.26it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.26it/s]\u001b[A\n"," 50% 9/18 [00:06<00:07,  1.27it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.27it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.29it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.30it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.32it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.31it/s]\u001b[A\n"," 83% 15/18 [00:10<00:02,  1.34it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.33it/s]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 0.04055558145046234, 'eval_accuracy': 0.9862222222222222, 'eval_runtime': 13.6466, 'eval_samples_per_second': 659.503, 'eval_steps_per_second': 1.319, 'epoch': 25.0}\n","  8% 2500/30000 [52:41<6:08:41,  1.24it/s]\n","100% 18/18 [00:12<00:00,  1.49it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2886] 2023-09-07 19:12:07,175 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-2500\n","[INFO|configuration_utils.py:460] 2023-09-07 19:12:07,180 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-2500/config.json\n","[INFO|modeling_utils.py:1988] 2023-09-07 19:12:07,289 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-2500/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 19:12:07,294 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-2500/preprocessor_config.json\n","[INFO|trainer.py:2973] 2023-09-07 19:12:07,505 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-2300] due to args.save_total_limit\n","{'loss': 0.2765, 'learning_rate': 0.0009163333333333333, 'epoch': 25.1}\n","{'loss': 0.293, 'learning_rate': 0.000916, 'epoch': 25.2}\n","{'loss': 0.2751, 'learning_rate': 0.0009156666666666666, 'epoch': 25.3}\n","{'loss': 0.2447, 'learning_rate': 0.0009153333333333333, 'epoch': 25.4}\n","{'loss': 0.2692, 'learning_rate': 0.000915, 'epoch': 25.5}\n","{'loss': 0.2773, 'learning_rate': 0.0009146666666666666, 'epoch': 25.6}\n","{'loss': 0.24, 'learning_rate': 0.0009143333333333334, 'epoch': 25.7}\n","{'loss': 0.2663, 'learning_rate': 0.0009140000000000001, 'epoch': 25.8}\n","{'loss': 0.2682, 'learning_rate': 0.0009136666666666667, 'epoch': 25.9}\n","{'loss': 0.2786, 'learning_rate': 0.0009133333333333334, 'epoch': 26.0}\n","  9% 2600/30000 [54:34<6:10:16,  1.23it/s][INFO|trainer.py:3160] 2023-09-07 19:14:00,332 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3162] 2023-09-07 19:14:00,332 >>   Num examples = 9000\n","[INFO|trainer.py:3165] 2023-09-07 19:14:00,332 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:05,  2.70it/s]\u001b[A\n"," 17% 3/18 [00:01<00:07,  1.90it/s]\u001b[A\n"," 22% 4/18 [00:02<00:09,  1.53it/s]\u001b[A\n"," 28% 5/18 [00:03<00:09,  1.36it/s]\u001b[A\n"," 33% 6/18 [00:04<00:09,  1.26it/s]\u001b[A\n"," 39% 7/18 [00:05<00:08,  1.22it/s]\u001b[A\n"," 44% 8/18 [00:05<00:08,  1.21it/s]\u001b[A\n"," 50% 9/18 [00:06<00:07,  1.24it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.28it/s]\u001b[A\n"," 61% 11/18 [00:08<00:05,  1.29it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.26it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.27it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.14it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.20it/s]\u001b[A\n"," 89% 16/18 [00:12<00:01,  1.22it/s]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 0.031863242387771606, 'eval_accuracy': 0.9902222222222222, 'eval_runtime': 14.3323, 'eval_samples_per_second': 627.95, 'eval_steps_per_second': 1.256, 'epoch': 26.0}\n","  9% 2600/30000 [54:49<6:10:16,  1.23it/s]\n","100% 18/18 [00:12<00:00,  1.40it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2886] 2023-09-07 19:14:14,670 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-2600\n","[INFO|configuration_utils.py:460] 2023-09-07 19:14:14,675 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-2600/config.json\n","[INFO|modeling_utils.py:1988] 2023-09-07 19:14:14,785 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-2600/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 19:14:14,789 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-2600/preprocessor_config.json\n","[INFO|trainer.py:2973] 2023-09-07 19:14:15,007 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-2400] due to args.save_total_limit\n","{'loss': 0.27, 'learning_rate': 0.0009130000000000001, 'epoch': 26.1}\n","{'loss': 0.2661, 'learning_rate': 0.0009126666666666667, 'epoch': 26.2}\n","{'loss': 0.2657, 'learning_rate': 0.0009123333333333334, 'epoch': 26.3}\n","{'loss': 0.2548, 'learning_rate': 0.000912, 'epoch': 26.4}\n","{'loss': 0.2916, 'learning_rate': 0.0009116666666666666, 'epoch': 26.5}\n","{'loss': 0.2769, 'learning_rate': 0.0009113333333333333, 'epoch': 26.6}\n","{'loss': 0.2722, 'learning_rate': 0.000911, 'epoch': 26.7}\n","{'loss': 0.2886, 'learning_rate': 0.0009106666666666666, 'epoch': 26.8}\n","{'loss': 0.2848, 'learning_rate': 0.0009103333333333333, 'epoch': 26.9}\n","{'loss': 0.2638, 'learning_rate': 0.00091, 'epoch': 27.0}\n","  9% 2700/30000 [56:44<6:04:58,  1.25it/s][INFO|trainer.py:3160] 2023-09-07 19:16:10,386 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3162] 2023-09-07 19:16:10,386 >>   Num examples = 9000\n","[INFO|trainer.py:3165] 2023-09-07 19:16:10,386 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.37it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.69it/s]\u001b[A\n"," 22% 4/18 [00:02<00:09,  1.44it/s]\u001b[A\n"," 28% 5/18 [00:03<00:09,  1.35it/s]\u001b[A\n"," 33% 6/18 [00:04<00:08,  1.35it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.35it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.36it/s]\u001b[A\n"," 50% 9/18 [00:06<00:06,  1.36it/s]\u001b[A\n"," 56% 10/18 [00:07<00:05,  1.36it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.35it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.36it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.36it/s]\u001b[A\n"," 78% 14/18 [00:10<00:02,  1.35it/s]\u001b[A\n"," 83% 15/18 [00:10<00:02,  1.36it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.36it/s]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 0.03555254265666008, 'eval_accuracy': 0.9895555555555555, 'eval_runtime': 13.5962, 'eval_samples_per_second': 661.95, 'eval_steps_per_second': 1.324, 'epoch': 27.0}\n","  9% 2700/30000 [56:58<6:04:58,  1.25it/s]\n","100% 18/18 [00:12<00:00,  1.53it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2886] 2023-09-07 19:16:23,987 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-2700\n","[INFO|configuration_utils.py:460] 2023-09-07 19:16:23,993 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-2700/config.json\n","[INFO|modeling_utils.py:1988] 2023-09-07 19:16:24,098 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-2700/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 19:16:24,102 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-2700/preprocessor_config.json\n","[INFO|trainer.py:2973] 2023-09-07 19:16:24,327 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-2500] due to args.save_total_limit\n","{'loss': 0.2684, 'learning_rate': 0.0009096666666666667, 'epoch': 27.1}\n","{'loss': 0.2696, 'learning_rate': 0.0009093333333333334, 'epoch': 27.2}\n","{'loss': 0.27, 'learning_rate': 0.0009090000000000001, 'epoch': 27.3}\n","{'loss': 0.2844, 'learning_rate': 0.0009086666666666667, 'epoch': 27.4}\n","{'loss': 0.2913, 'learning_rate': 0.0009083333333333334, 'epoch': 27.5}\n","{'loss': 0.2741, 'learning_rate': 0.0009080000000000001, 'epoch': 27.6}\n","{'loss': 0.2772, 'learning_rate': 0.0009076666666666666, 'epoch': 27.7}\n","{'loss': 0.2708, 'learning_rate': 0.0009073333333333333, 'epoch': 27.8}\n","{'loss': 0.2781, 'learning_rate': 0.000907, 'epoch': 27.9}\n","{'loss': 0.2775, 'learning_rate': 0.0009066666666666666, 'epoch': 28.0}\n","  9% 2800/30000 [58:51<5:57:57,  1.27it/s][INFO|trainer.py:3160] 2023-09-07 19:18:17,203 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3162] 2023-09-07 19:18:17,204 >>   Num examples = 9000\n","[INFO|trainer.py:3165] 2023-09-07 19:18:17,204 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:07,  2.28it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.68it/s]\u001b[A\n"," 22% 4/18 [00:02<00:09,  1.46it/s]\u001b[A\n"," 28% 5/18 [00:03<00:09,  1.34it/s]\u001b[A\n"," 33% 6/18 [00:04<00:09,  1.30it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.31it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.31it/s]\u001b[A\n"," 50% 9/18 [00:06<00:06,  1.32it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.32it/s]\u001b[A\n"," 61% 11/18 [00:08<00:05,  1.30it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.31it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.32it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.33it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.31it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.32it/s]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 0.03254273161292076, 'eval_accuracy': 0.9903333333333333, 'eval_runtime': 13.8324, 'eval_samples_per_second': 650.647, 'eval_steps_per_second': 1.301, 'epoch': 28.0}\n","  9% 2800/30000 [59:05<5:57:57,  1.27it/s]\n","100% 18/18 [00:12<00:00,  1.45it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2886] 2023-09-07 19:18:31,040 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-2800\n","[INFO|configuration_utils.py:460] 2023-09-07 19:18:31,046 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-2800/config.json\n","[INFO|modeling_utils.py:1988] 2023-09-07 19:18:31,153 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-2800/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 19:18:31,157 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-2800/preprocessor_config.json\n","[INFO|trainer.py:2973] 2023-09-07 19:18:31,365 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-2600] due to args.save_total_limit\n","{'loss': 0.2682, 'learning_rate': 0.0009063333333333333, 'epoch': 28.1}\n","{'loss': 0.2625, 'learning_rate': 0.000906, 'epoch': 28.2}\n","{'loss': 0.2793, 'learning_rate': 0.0009056666666666666, 'epoch': 28.3}\n","{'loss': 0.2871, 'learning_rate': 0.0009053333333333333, 'epoch': 28.4}\n","{'loss': 0.2863, 'learning_rate': 0.0009050000000000001, 'epoch': 28.5}\n","{'loss': 0.2648, 'learning_rate': 0.0009046666666666667, 'epoch': 28.6}\n","{'loss': 0.254, 'learning_rate': 0.0009043333333333334, 'epoch': 28.7}\n","{'loss': 0.2647, 'learning_rate': 0.0009040000000000001, 'epoch': 28.8}\n","{'loss': 0.2701, 'learning_rate': 0.0009036666666666667, 'epoch': 28.9}\n","{'loss': 0.2539, 'learning_rate': 0.0009033333333333334, 'epoch': 29.0}\n"," 10% 2900/30000 [1:01:01<6:01:52,  1.25it/s][INFO|trainer.py:3160] 2023-09-07 19:20:26,729 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3162] 2023-09-07 19:20:26,729 >>   Num examples = 9000\n","[INFO|trainer.py:3165] 2023-09-07 19:20:26,730 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.34it/s]\u001b[A\n"," 17% 3/18 [00:01<00:09,  1.63it/s]\u001b[A\n"," 22% 4/18 [00:02<00:09,  1.41it/s]\u001b[A\n"," 28% 5/18 [00:03<00:09,  1.33it/s]\u001b[A\n"," 33% 6/18 [00:04<00:09,  1.31it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.30it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.30it/s]\u001b[A\n"," 50% 9/18 [00:06<00:07,  1.27it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.28it/s]\u001b[A\n"," 61% 11/18 [00:08<00:05,  1.26it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.28it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.26it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.27it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.29it/s]\u001b[A\n"," 89% 16/18 [00:12<00:01,  1.29it/s]\u001b[A\n","                                            \n","\u001b[A{'eval_loss': 0.0311061292886734, 'eval_accuracy': 0.9902222222222222, 'eval_runtime': 14.1807, 'eval_samples_per_second': 634.665, 'eval_steps_per_second': 1.269, 'epoch': 29.0}\n"," 10% 2900/30000 [1:01:15<6:01:52,  1.25it/s]\n","100% 18/18 [00:12<00:00,  1.43it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2886] 2023-09-07 19:20:40,915 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-2900\n","[INFO|configuration_utils.py:460] 2023-09-07 19:20:40,922 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-2900/config.json\n","[INFO|modeling_utils.py:1988] 2023-09-07 19:20:41,035 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-2900/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 19:20:41,039 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-2900/preprocessor_config.json\n","[INFO|trainer.py:2973] 2023-09-07 19:20:41,263 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-2700] due to args.save_total_limit\n","{'loss': 0.2688, 'learning_rate': 0.000903, 'epoch': 29.1}\n","{'loss': 0.2806, 'learning_rate': 0.0009026666666666666, 'epoch': 29.2}\n","{'loss': 0.2754, 'learning_rate': 0.0009023333333333333, 'epoch': 29.3}\n","{'loss': 0.2479, 'learning_rate': 0.000902, 'epoch': 29.4}\n","{'loss': 0.2686, 'learning_rate': 0.0009016666666666666, 'epoch': 29.5}\n","{'loss': 0.2668, 'learning_rate': 0.0009013333333333333, 'epoch': 29.6}\n","{'loss': 0.2829, 'learning_rate': 0.000901, 'epoch': 29.7}\n","{'loss': 0.2717, 'learning_rate': 0.0009006666666666666, 'epoch': 29.8}\n","{'loss': 0.2537, 'learning_rate': 0.0009003333333333334, 'epoch': 29.9}\n","{'loss': 0.277, 'learning_rate': 0.0009000000000000001, 'epoch': 30.0}\n"," 10% 3000/30000 [1:03:11<6:38:21,  1.13it/s][INFO|trainer.py:3160] 2023-09-07 19:22:37,216 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3162] 2023-09-07 19:22:37,217 >>   Num examples = 9000\n","[INFO|trainer.py:3165] 2023-09-07 19:22:37,217 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.57it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.80it/s]\u001b[A\n"," 22% 4/18 [00:02<00:09,  1.51it/s]\u001b[A\n"," 28% 5/18 [00:03<00:09,  1.43it/s]\u001b[A\n"," 33% 6/18 [00:04<00:08,  1.35it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.35it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.34it/s]\u001b[A\n"," 50% 9/18 [00:06<00:06,  1.33it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.32it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.32it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.31it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.32it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.32it/s]\u001b[A\n"," 83% 15/18 [00:10<00:02,  1.30it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.29it/s]\u001b[A\n","                                            \n","\u001b[A{'eval_loss': 1.1904778480529785, 'eval_accuracy': 0.7304444444444445, 'eval_runtime': 13.9358, 'eval_samples_per_second': 645.82, 'eval_steps_per_second': 1.292, 'epoch': 30.0}\n"," 10% 3000/30000 [1:03:25<6:38:21,  1.13it/s]\n","100% 18/18 [00:12<00:00,  1.45it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2886] 2023-09-07 19:22:51,158 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-3000\n","[INFO|configuration_utils.py:460] 2023-09-07 19:22:51,164 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-3000/config.json\n","[INFO|modeling_utils.py:1988] 2023-09-07 19:22:51,287 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-3000/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 19:22:51,292 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-3000/preprocessor_config.json\n","[INFO|trainer.py:2973] 2023-09-07 19:22:51,555 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-2800] due to args.save_total_limit\n","{'loss': 0.2701, 'learning_rate': 0.0008996666666666667, 'epoch': 30.1}\n","{'loss': 0.2727, 'learning_rate': 0.0008993333333333334, 'epoch': 30.2}\n","{'loss': 0.2586, 'learning_rate': 0.0008990000000000001, 'epoch': 30.3}\n","{'loss': 0.2577, 'learning_rate': 0.0008986666666666666, 'epoch': 30.4}\n","{'loss': 0.2657, 'learning_rate': 0.0008983333333333333, 'epoch': 30.5}\n","{'loss': 0.2566, 'learning_rate': 0.000898, 'epoch': 30.6}\n","{'loss': 0.2667, 'learning_rate': 0.0008976666666666666, 'epoch': 30.7}\n","{'loss': 0.2746, 'learning_rate': 0.0008973333333333333, 'epoch': 30.8}\n","{'loss': 0.2821, 'learning_rate': 0.000897, 'epoch': 30.9}\n","{'loss': 0.2635, 'learning_rate': 0.0008966666666666666, 'epoch': 31.0}\n"," 10% 3100/30000 [1:05:19<5:56:00,  1.26it/s][INFO|trainer.py:3160] 2023-09-07 19:24:44,496 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3162] 2023-09-07 19:24:44,496 >>   Num examples = 9000\n","[INFO|trainer.py:3165] 2023-09-07 19:24:44,497 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:07,  2.11it/s]\u001b[A\n"," 17% 3/18 [00:01<00:09,  1.65it/s]\u001b[A\n"," 22% 4/18 [00:02<00:09,  1.51it/s]\u001b[A\n"," 28% 5/18 [00:03<00:09,  1.41it/s]\u001b[A\n"," 33% 6/18 [00:04<00:08,  1.38it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.32it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.33it/s]\u001b[A\n"," 50% 9/18 [00:06<00:06,  1.30it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.31it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.31it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.32it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.32it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.33it/s]\u001b[A\n"," 83% 15/18 [00:10<00:02,  1.33it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.30it/s]\u001b[A\n","                                            \n","\u001b[A{'eval_loss': 1.084712266921997, 'eval_accuracy': 0.7122222222222222, 'eval_runtime': 14.0185, 'eval_samples_per_second': 642.009, 'eval_steps_per_second': 1.284, 'epoch': 31.0}\n"," 10% 3100/30000 [1:05:33<5:56:00,  1.26it/s]\n","100% 18/18 [00:12<00:00,  1.46it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2886] 2023-09-07 19:24:58,520 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-3100\n","[INFO|configuration_utils.py:460] 2023-09-07 19:24:58,526 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-3100/config.json\n","[INFO|modeling_utils.py:1988] 2023-09-07 19:24:58,644 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-3100/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 19:24:58,650 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-3100/preprocessor_config.json\n","[INFO|trainer.py:2973] 2023-09-07 19:24:58,880 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-2900] due to args.save_total_limit\n","[INFO|trainer.py:1988] 2023-09-07 19:24:58,902 >> \n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","[INFO|trainer.py:2156] 2023-09-07 19:24:58,903 >> Loading best model from drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/checkpoint-2100 (score: 0.028695061802864075).\n","{'train_runtime': 3933.4899, 'train_samples_per_second': 3889.676, 'train_steps_per_second': 7.627, 'train_loss': 0.31247593425935316, 'epoch': 31.0}\n"," 10% 3100/30000 [1:05:33<9:28:52,  1.27s/it]\n","[INFO|trainer.py:2886] 2023-09-07 19:24:58,978 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/\n","[INFO|configuration_utils.py:460] 2023-09-07 19:24:58,983 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/config.json\n","[INFO|modeling_utils.py:1988] 2023-09-07 19:24:59,120 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 19:24:59,124 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/preprocessor_config.json\n","***** train metrics *****\n","  epoch                    =       31.0\n","  train_loss               =     0.3125\n","  train_runtime            = 1:05:33.48\n","  train_samples_per_second =   3889.676\n","  train_steps_per_second   =      7.627\n","[INFO|trainer.py:3160] 2023-09-07 19:24:59,149 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3162] 2023-09-07 19:24:59,150 >>   Num examples = 9000\n","[INFO|trainer.py:3165] 2023-09-07 19:24:59,150 >>   Batch size = 512\n","100% 18/18 [00:12<00:00,  1.39it/s]\n","***** eval metrics *****\n","  epoch                   =       31.0\n","  eval_accuracy           =     0.9897\n","  eval_loss               =     0.0287\n","  eval_runtime            = 0:00:14.46\n","  eval_samples_per_second =    622.202\n","  eval_steps_per_second   =      1.244\n","\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n","\u001b[34m\u001b[1mwandb\u001b[0m:                  eval/accuracy ████▅███▇▁████████▃██▄███████▅▄█\n","\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/loss ▁▁▁▁▃▁▁▁▂█▁▁▁▁▁▁▁▁▆▁▁▇▁▁▁▁▁▁▁▅▅▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/runtime ▅▆▄▁█▂▃▃▃▅▄▂▂▅▁▂▂▁▂▃▅▂▁▃▂▆▂▃▅▄▄▇\n","\u001b[34m\u001b[1mwandb\u001b[0m:        eval/samples_per_second ▄▂▅█▁▇▆▆▅▄▅▇▇▄█▇▇█▆▆▄▇█▆▇▃▇▆▄▅▅▂\n","\u001b[34m\u001b[1mwandb\u001b[0m:          eval/steps_per_second ▄▂▅█▁▇▆▆▅▄▅▇▇▄█▇▇█▆▆▄▇█▆▇▃▇▆▄▅▅▂\n","\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███\n","\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███\n","\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate ████▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss █▆▅▅▄▅▄▄▃▃▃▂▃▃▃▂▃▂▂▃▂▂▂▂▂▂▂▁▂▁▂▁▂▂▂▁▂▂▂▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n","\u001b[34m\u001b[1mwandb\u001b[0m:                  eval/accuracy 0.98967\n","\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/loss 0.0287\n","\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/runtime 14.4648\n","\u001b[34m\u001b[1mwandb\u001b[0m:        eval/samples_per_second 622.202\n","\u001b[34m\u001b[1mwandb\u001b[0m:          eval/steps_per_second 1.244\n","\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch 31.0\n","\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step 3100\n","\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate 0.0009\n","\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss 0.2635\n","\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos 1.5966362863374336e+19\n","\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss 0.31248\n","\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime 3933.4899\n","\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second 3889.676\n","\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second 7.627\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mabsurd-bush-17\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/u15048366/colabCnnMnist/runs/nafwnffx\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n","\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230907_181920-nafwnffx/logs\u001b[0m\n","Exception in thread NetStatThr:\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n","Exception in thread IntMsgThr:\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n","    self.run()\n","    self.run()\n","  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n","  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 267, in check_network_status\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 299, in check_internal_messages\n","    self._loop_check_status(\n","  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 223, in _loop_check_status\n","    local_handle = request()\n","    self._loop_check_status(\n","  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface.py\", line 735, in deliver_network_status\n","  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py\", line 223, in _loop_check_status\n","    local_handle = request()\n","    return self._deliver_network_status(status)\n","  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface.py\", line 743, in deliver_internal_messages\n","  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_shared.py\", line 466, in _deliver_network_status\n","    return self._deliver_internal_messages(internal_message)\n","    return self._deliver_record(record)\n","  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_shared.py\", line 472, in _deliver_internal_messages\n","  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_shared.py\", line 425, in _deliver_record\n","        return self._deliver_record(record)handle = mailbox._deliver_record(record, interface=self)\n","\n","  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_shared.py\", line 425, in _deliver_record\n","  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/mailbox.py\", line 455, in _deliver_record\n","        handle = mailbox._deliver_record(record, interface=self)interface._publish(record)\n","\n","  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/mailbox.py\", line 455, in _deliver_record\n","  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_sock.py\", line 51, in _publish\n","    interface._publish(record)\n","    self._sock_client.send_record_publish(record)\n","  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/interface/interface_sock.py\", line 51, in _publish\n","  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 221, in send_record_publish\n","    self._sock_client.send_record_publish(record)\n","    self.send_server_request(server_req)\n","  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 221, in send_record_publish\n","  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 155, in send_server_request\n","    self.send_server_request(server_req)\n","  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 155, in send_server_request\n","    self._send_message(msg)\n","  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 152, in _send_message\n","    self._send_message(msg)\n","  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 152, in _send_message\n","    self._sendall_with_error_handle(header + data)\n","  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 130, in _sendall_with_error_handle\n","    self._sendall_with_error_handle(header + data)\n","    sent = self._sock.send(data)\n","  File \"/usr/local/lib/python3.10/dist-packages/wandb/sdk/lib/sock_client.py\", line 130, in _sendall_with_error_handle\n","BrokenPipeError: [Errno 32] Broken pipe\n","    sent = self._sock.send(data)\n","BrokenPipeError: [Errno 32] Broken pipe\n"]}],"source":["!python cnn-mnist.py \\\n","    --model_name microsoft/resnet-18 \\\n","    --model_type resnet \\\n","    --dataset_name mnist \\\n","    --output_dir drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_8/ \\\n","    --remove_unused_columns False \\\n","    --do_train \\\n","    --do_eval \\\n","    --push_to_hub False \\\n","    --learning_rate 0.001 \\\n","    --num_train_epochs 300 \\\n","    --per_device_train_batch_size 512 \\\n","    --per_device_eval_batch_size 512 \\\n","    --logging_strategy steps \\\n","    --logging_steps 10 \\\n","    --evaluation_strategy epoch \\\n","    --save_strategy epoch \\\n","    --load_best_model_at_end True \\\n","    --save_total_limit 3 \\\n","    --save_steps 500 \\\n","    --data_seed 8 \\\n","    --seed 8 \\\n","    --report_to wandb \\\n","    --ignore_mismatched_sizes\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"jLPgVSaRFd--","outputId":"7350b04f-03f8-4c82-ce62-05fdb640e15f"},"outputs":[{"name":"stdout","output_type":"stream","text":["2023-09-07 19:25:27.716911: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mu15048366\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.10\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20230907_192531-0hg71jvb\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mneat-valley-18\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/u15048366/colabCnnMnist\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/u15048366/colabCnnMnist/runs/0hg71jvb\u001b[0m\n","09/07/2023 19:25:32 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n","09/07/2023 19:25:32 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n","_n_gpu=1,\n","adafactor=False,\n","adam_beta1=0.9,\n","adam_beta2=0.999,\n","adam_epsilon=1e-08,\n","auto_find_batch_size=False,\n","bf16=False,\n","bf16_full_eval=False,\n","data_seed=9,\n","dataloader_drop_last=False,\n","dataloader_num_workers=0,\n","dataloader_pin_memory=True,\n","ddp_backend=None,\n","ddp_broadcast_buffers=None,\n","ddp_bucket_cap_mb=None,\n","ddp_find_unused_parameters=None,\n","ddp_timeout=1800,\n","debug=[],\n","deepspeed=None,\n","disable_tqdm=False,\n","dispatch_batches=None,\n","do_eval=True,\n","do_predict=False,\n","do_train=True,\n","eval_accumulation_steps=None,\n","eval_delay=0,\n","eval_steps=None,\n","evaluation_strategy=epoch,\n","fp16=False,\n","fp16_backend=auto,\n","fp16_full_eval=False,\n","fp16_opt_level=O1,\n","fsdp=[],\n","fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n","fsdp_min_num_params=0,\n","fsdp_transformer_layer_cls_to_wrap=None,\n","full_determinism=False,\n","gradient_accumulation_steps=1,\n","gradient_checkpointing=False,\n","greater_is_better=False,\n","group_by_length=False,\n","half_precision_backend=auto,\n","hub_always_push=False,\n","hub_model_id=None,\n","hub_private_repo=False,\n","hub_strategy=every_save,\n","hub_token=<HUB_TOKEN>,\n","ignore_data_skip=False,\n","include_inputs_for_metrics=False,\n","include_tokens_per_second=False,\n","jit_mode_eval=False,\n","label_names=None,\n","label_smoothing_factor=0.0,\n","learning_rate=0.001,\n","length_column_name=length,\n","load_best_model_at_end=True,\n","local_rank=0,\n","log_level=passive,\n","log_level_replica=warning,\n","log_on_each_node=True,\n","logging_dir=drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/runs/Sep07_19-25-32_67f6d3ae3f6c,\n","logging_first_step=False,\n","logging_nan_inf_filter=True,\n","logging_steps=10,\n","logging_strategy=steps,\n","lr_scheduler_type=linear,\n","max_grad_norm=1.0,\n","max_steps=-1,\n","metric_for_best_model=loss,\n","mp_parameters=,\n","no_cuda=False,\n","num_train_epochs=300.0,\n","optim=adamw_torch,\n","optim_args=None,\n","output_dir=drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/,\n","overwrite_output_dir=False,\n","past_index=-1,\n","per_device_eval_batch_size=512,\n","per_device_train_batch_size=512,\n","prediction_loss_only=False,\n","push_to_hub=False,\n","push_to_hub_model_id=None,\n","push_to_hub_organization=None,\n","push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n","ray_scope=last,\n","remove_unused_columns=False,\n","report_to=['wandb'],\n","resume_from_checkpoint=None,\n","run_name=drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/,\n","save_on_each_node=False,\n","save_safetensors=False,\n","save_steps=500.0,\n","save_strategy=epoch,\n","save_total_limit=3,\n","seed=9,\n","sharded_ddp=[],\n","skip_memory_metrics=True,\n","tf32=None,\n","torch_compile=False,\n","torch_compile_backend=None,\n","torch_compile_mode=None,\n","torchdynamo=None,\n","tpu_metrics_debug=False,\n","tpu_num_cores=None,\n","use_cpu=False,\n","use_ipex=False,\n","use_legacy_prediction_loop=False,\n","use_mps_device=False,\n","warmup_ratio=0.0,\n","warmup_steps=0,\n","weight_decay=0.0,\n",")\n","/usr/local/lib/python3.10/dist-packages/datasets/load.py:2103: FutureWarning: 'task' was deprecated in version 2.13.0 and will be removed in 3.0.0.\n","\n","  warnings.warn(\n","\n","\n","\n","None\n","\n","\n","\n","[INFO|configuration_utils.py:715] 2023-09-07 19:25:34,690 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--resnet-18/snapshots/f45a6faa12e0381f5620c5c8d7e916bca90f2c44/config.json\n","[INFO|configuration_utils.py:775] 2023-09-07 19:25:34,693 >> Model config ResNetConfig {\n","  \"_name_or_path\": \"microsoft/resnet-18\",\n","  \"architectures\": [\n","    \"ResNetForImageClassification\"\n","  ],\n","  \"depths\": [\n","    2,\n","    2,\n","    2,\n","    2\n","  ],\n","  \"downsample_in_first_stage\": false,\n","  \"embedding_size\": 64,\n","  \"finetuning_task\": \"image-classification\",\n","  \"hidden_act\": \"relu\",\n","  \"hidden_sizes\": [\n","    64,\n","    128,\n","    256,\n","    512\n","  ],\n","  \"id2label\": {\n","    \"0\": \"0\",\n","    \"1\": \"1\",\n","    \"2\": \"2\",\n","    \"3\": \"3\",\n","    \"4\": \"4\",\n","    \"5\": \"5\",\n","    \"6\": \"6\",\n","    \"7\": \"7\",\n","    \"8\": \"8\",\n","    \"9\": \"9\"\n","  },\n","  \"label2id\": {\n","    \"0\": \"0\",\n","    \"1\": \"1\",\n","    \"2\": \"2\",\n","    \"3\": \"3\",\n","    \"4\": \"4\",\n","    \"5\": \"5\",\n","    \"6\": \"6\",\n","    \"7\": \"7\",\n","    \"8\": \"8\",\n","    \"9\": \"9\"\n","  },\n","  \"layer_type\": \"basic\",\n","  \"model_type\": \"resnet\",\n","  \"num_channels\": 3,\n","  \"out_features\": [\n","    \"stage4\"\n","  ],\n","  \"out_indices\": [\n","    4\n","  ],\n","  \"stage_names\": [\n","    \"stem\",\n","    \"stage1\",\n","    \"stage2\",\n","    \"stage3\",\n","    \"stage4\"\n","  ],\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.34.0.dev0\"\n","}\n","\n","[INFO|modeling_utils.py:2857] 2023-09-07 19:25:34,696 >> loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--microsoft--resnet-18/snapshots/f45a6faa12e0381f5620c5c8d7e916bca90f2c44/model.safetensors\n","[INFO|modeling_utils.py:3643] 2023-09-07 19:25:34,822 >> All model checkpoint weights were used when initializing ResNetForImageClassification.\n","\n","[WARNING|modeling_utils.py:3664] 2023-09-07 19:25:34,822 >> Some weights of ResNetForImageClassification were not initialized from the model checkpoint at microsoft/resnet-18 and are newly initialized because the shapes did not match:\n","- classifier.1.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([10]) in the model instantiated\n","- classifier.1.weight: found shape torch.Size([1000, 512]) in the checkpoint and torch.Size([10, 512]) in the model instantiated\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","[INFO|image_processing_utils.py:369] 2023-09-07 19:25:34,925 >> loading configuration file preprocessor_config.json from cache at /root/.cache/huggingface/hub/models--microsoft--resnet-18/snapshots/f45a6faa12e0381f5620c5c8d7e916bca90f2c44/preprocessor_config.json\n","[WARNING|image_processing_auto.py:355] 2023-09-07 19:25:34,926 >> Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n","[INFO|image_processing_utils.py:732] 2023-09-07 19:25:34,927 >> size should be a dictionary on of the following set of keys: ({'height', 'width'}, {'shortest_edge'}, {'longest_edge', 'shortest_edge'}, {'longest_edge'}), got 224. Converted to {'shortest_edge': 224}.\n","[INFO|image_processing_utils.py:419] 2023-09-07 19:25:34,928 >> Image processor ConvNextImageProcessor {\n","  \"crop_pct\": 0.875,\n","  \"do_normalize\": true,\n","  \"do_rescale\": true,\n","  \"do_resize\": true,\n","  \"image_mean\": [\n","    0.485,\n","    0.456,\n","    0.406\n","  ],\n","  \"image_processor_type\": \"ConvNextImageProcessor\",\n","  \"image_std\": [\n","    0.229,\n","    0.224,\n","    0.225\n","  ],\n","  \"resample\": 3,\n","  \"rescale_factor\": 0.00392156862745098,\n","  \"size\": {\n","    \"shortest_edge\": 224\n","  }\n","}\n","\n","[INFO|trainer.py:1740] 2023-09-07 19:25:36,820 >> ***** Running training *****\n","[INFO|trainer.py:1741] 2023-09-07 19:25:36,820 >>   Num examples = 51,000\n","[INFO|trainer.py:1742] 2023-09-07 19:25:36,821 >>   Num Epochs = 300\n","[INFO|trainer.py:1743] 2023-09-07 19:25:36,821 >>   Instantaneous batch size per device = 512\n","[INFO|trainer.py:1746] 2023-09-07 19:25:36,821 >>   Total train batch size (w. parallel, distributed & accumulation) = 512\n","[INFO|trainer.py:1747] 2023-09-07 19:25:36,821 >>   Gradient Accumulation steps = 1\n","[INFO|trainer.py:1748] 2023-09-07 19:25:36,821 >>   Total optimization steps = 30,000\n","[INFO|trainer.py:1749] 2023-09-07 19:25:36,822 >>   Number of trainable parameters = 11,181,642\n","[INFO|integration_utils.py:716] 2023-09-07 19:25:36,823 >> Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n","{'loss': 1.1465, 'learning_rate': 0.0009996666666666667, 'epoch': 0.1}\n","{'loss': 0.6156, 'learning_rate': 0.0009993333333333334, 'epoch': 0.2}\n","{'loss': 0.5179, 'learning_rate': 0.000999, 'epoch': 0.3}\n","{'loss': 0.5366, 'learning_rate': 0.0009986666666666668, 'epoch': 0.4}\n","{'loss': 0.4967, 'learning_rate': 0.0009983333333333333, 'epoch': 0.5}\n","{'loss': 0.4816, 'learning_rate': 0.000998, 'epoch': 0.6}\n","{'loss': 0.4425, 'learning_rate': 0.0009976666666666667, 'epoch': 0.7}\n","{'loss': 0.4419, 'learning_rate': 0.0009973333333333334, 'epoch': 0.8}\n","{'loss': 0.4669, 'learning_rate': 0.000997, 'epoch': 0.9}\n","{'loss': 0.4724, 'learning_rate': 0.0009966666666666668, 'epoch': 1.0}\n","  0% 100/30000 [01:58<6:37:53,  1.25it/s][INFO|trainer.py:3160] 2023-09-07 19:27:34,875 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3162] 2023-09-07 19:27:34,876 >>   Num examples = 9000\n","[INFO|trainer.py:3165] 2023-09-07 19:27:34,876 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.36it/s]\u001b[A\n"," 17% 3/18 [00:01<00:09,  1.54it/s]\u001b[A\n"," 22% 4/18 [00:02<00:10,  1.38it/s]\u001b[A\n"," 28% 5/18 [00:03<00:09,  1.36it/s]\u001b[A\n"," 33% 6/18 [00:04<00:08,  1.35it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.35it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.29it/s]\u001b[A\n"," 50% 9/18 [00:06<00:06,  1.30it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.30it/s]\u001b[A\n"," 61% 11/18 [00:08<00:05,  1.29it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.31it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.30it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.31it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.32it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.32it/s]\u001b[A\n","                                         \n","\u001b[A{'eval_loss': 0.1047397330403328, 'eval_accuracy': 0.9652222222222222, 'eval_runtime': 13.9944, 'eval_samples_per_second': 643.114, 'eval_steps_per_second': 1.286, 'epoch': 1.0}\n","  0% 100/30000 [02:12<6:37:53,  1.25it/s]\n","100% 18/18 [00:12<00:00,  1.49it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2886] 2023-09-07 19:27:48,874 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-100\n","[INFO|configuration_utils.py:460] 2023-09-07 19:27:48,880 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-100/config.json\n","[INFO|modeling_utils.py:1988] 2023-09-07 19:27:48,988 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-100/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 19:27:48,993 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-100/preprocessor_config.json\n","{'loss': 0.4254, 'learning_rate': 0.0009963333333333332, 'epoch': 1.1}\n","{'loss': 0.4287, 'learning_rate': 0.000996, 'epoch': 1.2}\n","{'loss': 0.4412, 'learning_rate': 0.0009956666666666666, 'epoch': 1.3}\n","{'loss': 0.4192, 'learning_rate': 0.0009953333333333333, 'epoch': 1.4}\n","{'loss': 0.4239, 'learning_rate': 0.000995, 'epoch': 1.5}\n","{'loss': 0.4135, 'learning_rate': 0.0009946666666666667, 'epoch': 1.6}\n","{'loss': 0.4027, 'learning_rate': 0.0009943333333333334, 'epoch': 1.7}\n","{'loss': 0.4024, 'learning_rate': 0.000994, 'epoch': 1.8}\n","{'loss': 0.4026, 'learning_rate': 0.0009936666666666668, 'epoch': 1.9}\n","{'loss': 0.3856, 'learning_rate': 0.0009933333333333333, 'epoch': 2.0}\n","  1% 200/30000 [04:04<6:30:18,  1.27it/s][INFO|trainer.py:3160] 2023-09-07 19:29:41,543 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3162] 2023-09-07 19:29:41,543 >>   Num examples = 9000\n","[INFO|trainer.py:3165] 2023-09-07 19:29:41,543 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.44it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.77it/s]\u001b[A\n"," 22% 4/18 [00:02<00:09,  1.46it/s]\u001b[A\n"," 28% 5/18 [00:03<00:10,  1.19it/s]\u001b[A\n"," 33% 6/18 [00:04<00:09,  1.24it/s]\u001b[A\n"," 39% 7/18 [00:05<00:08,  1.27it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.29it/s]\u001b[A\n"," 50% 9/18 [00:06<00:06,  1.30it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.30it/s]\u001b[A\n"," 61% 11/18 [00:08<00:05,  1.31it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.32it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.31it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.33it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.34it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.34it/s]\u001b[A\n","                                         \n","\u001b[A{'eval_loss': 0.07921969890594482, 'eval_accuracy': 0.9744444444444444, 'eval_runtime': 13.9092, 'eval_samples_per_second': 647.052, 'eval_steps_per_second': 1.294, 'epoch': 2.0}\n","  1% 200/30000 [04:18<6:30:18,  1.27it/s]\n","100% 18/18 [00:12<00:00,  1.51it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2886] 2023-09-07 19:29:55,457 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-200\n","[INFO|configuration_utils.py:460] 2023-09-07 19:29:55,462 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-200/config.json\n","[INFO|modeling_utils.py:1988] 2023-09-07 19:29:55,569 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-200/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 19:29:55,573 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-200/preprocessor_config.json\n","{'loss': 0.3952, 'learning_rate': 0.000993, 'epoch': 2.1}\n","{'loss': 0.4022, 'learning_rate': 0.0009926666666666667, 'epoch': 2.2}\n","{'loss': 0.3875, 'learning_rate': 0.0009923333333333333, 'epoch': 2.3}\n","{'loss': 0.4202, 'learning_rate': 0.000992, 'epoch': 2.4}\n","{'loss': 0.3724, 'learning_rate': 0.0009916666666666667, 'epoch': 2.5}\n","{'loss': 0.3718, 'learning_rate': 0.0009913333333333332, 'epoch': 2.6}\n","{'loss': 0.3705, 'learning_rate': 0.000991, 'epoch': 2.7}\n","{'loss': 0.3844, 'learning_rate': 0.0009906666666666668, 'epoch': 2.8}\n","{'loss': 0.3741, 'learning_rate': 0.0009903333333333333, 'epoch': 2.9}\n","{'loss': 0.354, 'learning_rate': 0.00099, 'epoch': 3.0}\n","  1% 300/30000 [06:10<6:31:21,  1.26it/s][INFO|trainer.py:3160] 2023-09-07 19:31:47,575 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3162] 2023-09-07 19:31:47,575 >>   Num examples = 9000\n","[INFO|trainer.py:3165] 2023-09-07 19:31:47,575 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:05,  2.67it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.86it/s]\u001b[A\n"," 22% 4/18 [00:02<00:09,  1.54it/s]\u001b[A\n"," 28% 5/18 [00:03<00:09,  1.30it/s]\u001b[A\n"," 33% 6/18 [00:04<00:09,  1.23it/s]\u001b[A\n"," 39% 7/18 [00:05<00:09,  1.22it/s]\u001b[A\n"," 44% 8/18 [00:05<00:08,  1.21it/s]\u001b[A\n"," 50% 9/18 [00:06<00:07,  1.25it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.27it/s]\u001b[A\n"," 61% 11/18 [00:08<00:05,  1.28it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.28it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.30it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.31it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.31it/s]\u001b[A\n"," 89% 16/18 [00:12<00:01,  1.30it/s]\u001b[A\n","                                         \n","\u001b[A{'eval_loss': 0.050387755036354065, 'eval_accuracy': 0.9842222222222222, 'eval_runtime': 14.0026, 'eval_samples_per_second': 642.738, 'eval_steps_per_second': 1.285, 'epoch': 3.0}\n","  1% 300/30000 [06:24<6:31:21,  1.26it/s]\n","100% 18/18 [00:12<00:00,  1.45it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2886] 2023-09-07 19:32:01,582 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-300\n","[INFO|configuration_utils.py:460] 2023-09-07 19:32:01,589 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-300/config.json\n","[INFO|modeling_utils.py:1988] 2023-09-07 19:32:01,701 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-300/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 19:32:01,705 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-300/preprocessor_config.json\n","{'loss': 0.3441, 'learning_rate': 0.0009896666666666667, 'epoch': 3.1}\n","{'loss': 0.352, 'learning_rate': 0.0009893333333333334, 'epoch': 3.2}\n","{'loss': 0.3565, 'learning_rate': 0.000989, 'epoch': 3.3}\n","{'loss': 0.365, 'learning_rate': 0.0009886666666666668, 'epoch': 3.4}\n","{'loss': 0.3633, 'learning_rate': 0.0009883333333333333, 'epoch': 3.5}\n","{'loss': 0.3592, 'learning_rate': 0.000988, 'epoch': 3.6}\n","{'loss': 0.3439, 'learning_rate': 0.0009876666666666666, 'epoch': 3.7}\n","{'loss': 0.3506, 'learning_rate': 0.0009873333333333333, 'epoch': 3.8}\n","{'loss': 0.3795, 'learning_rate': 0.000987, 'epoch': 3.9}\n","{'loss': 0.351, 'learning_rate': 0.0009866666666666667, 'epoch': 4.0}\n","  1% 400/30000 [08:18<6:28:29,  1.27it/s][INFO|trainer.py:3160] 2023-09-07 19:33:55,445 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3162] 2023-09-07 19:33:55,445 >>   Num examples = 9000\n","[INFO|trainer.py:3165] 2023-09-07 19:33:55,445 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.64it/s]\u001b[A\n"," 17% 3/18 [00:01<00:07,  1.88it/s]\u001b[A\n"," 22% 4/18 [00:02<00:09,  1.52it/s]\u001b[A\n"," 28% 5/18 [00:03<00:09,  1.37it/s]\u001b[A\n"," 33% 6/18 [00:04<00:09,  1.29it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.25it/s]\u001b[A\n"," 44% 8/18 [00:05<00:08,  1.23it/s]\u001b[A\n"," 50% 9/18 [00:06<00:07,  1.26it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.29it/s]\u001b[A\n"," 61% 11/18 [00:08<00:05,  1.30it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.32it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.32it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.33it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.32it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.32it/s]\u001b[A\n","                                         \n","\u001b[A{'eval_loss': 0.06023365631699562, 'eval_accuracy': 0.98, 'eval_runtime': 13.7255, 'eval_samples_per_second': 655.715, 'eval_steps_per_second': 1.311, 'epoch': 4.0}\n","  1% 400/30000 [08:32<6:28:29,  1.27it/s]\n","100% 18/18 [00:12<00:00,  1.49it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2886] 2023-09-07 19:34:09,175 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-400\n","[INFO|configuration_utils.py:460] 2023-09-07 19:34:09,182 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-400/config.json\n","[INFO|modeling_utils.py:1988] 2023-09-07 19:34:09,292 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-400/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 19:34:09,297 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-400/preprocessor_config.json\n","[INFO|trainer.py:2973] 2023-09-07 19:34:09,503 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-100] due to args.save_total_limit\n","{'loss': 0.3549, 'learning_rate': 0.0009863333333333332, 'epoch': 4.1}\n","{'loss': 0.3399, 'learning_rate': 0.0009860000000000001, 'epoch': 4.2}\n","{'loss': 0.3617, 'learning_rate': 0.0009856666666666668, 'epoch': 4.3}\n","{'loss': 0.3672, 'learning_rate': 0.0009853333333333333, 'epoch': 4.4}\n","{'loss': 0.357, 'learning_rate': 0.000985, 'epoch': 4.5}\n","{'loss': 0.3455, 'learning_rate': 0.0009846666666666667, 'epoch': 4.6}\n","{'loss': 0.3608, 'learning_rate': 0.0009843333333333334, 'epoch': 4.7}\n","{'loss': 0.3457, 'learning_rate': 0.000984, 'epoch': 4.8}\n","{'loss': 0.3546, 'learning_rate': 0.0009836666666666668, 'epoch': 4.9}\n","{'loss': 0.3366, 'learning_rate': 0.0009833333333333332, 'epoch': 5.0}\n","  2% 500/30000 [10:25<6:30:32,  1.26it/s][INFO|trainer.py:3160] 2023-09-07 19:36:02,213 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3162] 2023-09-07 19:36:02,213 >>   Num examples = 9000\n","[INFO|trainer.py:3165] 2023-09-07 19:36:02,213 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.66it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.85it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.59it/s]\u001b[A\n"," 28% 5/18 [00:03<00:08,  1.47it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.34it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.27it/s]\u001b[A\n"," 44% 8/18 [00:05<00:08,  1.23it/s]\u001b[A\n"," 50% 9/18 [00:06<00:07,  1.20it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.23it/s]\u001b[A\n"," 61% 11/18 [00:08<00:06,  1.14it/s]\u001b[A\n"," 67% 12/18 [00:09<00:05,  1.18it/s]\u001b[A\n"," 72% 13/18 [00:09<00:04,  1.22it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.26it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.25it/s]\u001b[A\n"," 89% 16/18 [00:12<00:01,  1.27it/s]\u001b[A\n","                                         \n","\u001b[A{'eval_loss': 0.07670392841100693, 'eval_accuracy': 0.9752222222222222, 'eval_runtime': 14.1567, 'eval_samples_per_second': 635.74, 'eval_steps_per_second': 1.271, 'epoch': 5.0}\n","  2% 500/30000 [10:39<6:30:32,  1.26it/s]\n","100% 18/18 [00:12<00:00,  1.46it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2886] 2023-09-07 19:36:16,374 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-500\n","[INFO|configuration_utils.py:460] 2023-09-07 19:36:16,379 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-500/config.json\n","[INFO|modeling_utils.py:1988] 2023-09-07 19:36:16,492 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-500/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 19:36:16,496 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-500/preprocessor_config.json\n","[INFO|trainer.py:2973] 2023-09-07 19:36:16,728 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-200] due to args.save_total_limit\n","{'loss': 0.3598, 'learning_rate': 0.000983, 'epoch': 5.1}\n","{'loss': 0.3477, 'learning_rate': 0.0009826666666666666, 'epoch': 5.2}\n","{'loss': 0.3609, 'learning_rate': 0.0009823333333333333, 'epoch': 5.3}\n","{'loss': 0.3304, 'learning_rate': 0.000982, 'epoch': 5.4}\n","{'loss': 0.3518, 'learning_rate': 0.0009816666666666667, 'epoch': 5.5}\n","{'loss': 0.3485, 'learning_rate': 0.0009813333333333334, 'epoch': 5.6}\n","{'loss': 0.3383, 'learning_rate': 0.000981, 'epoch': 5.7}\n","{'loss': 0.3299, 'learning_rate': 0.0009806666666666668, 'epoch': 5.8}\n","{'loss': 0.3316, 'learning_rate': 0.0009803333333333333, 'epoch': 5.9}\n","{'loss': 0.3382, 'learning_rate': 0.00098, 'epoch': 6.0}\n","  2% 600/30000 [12:34<6:39:30,  1.23it/s][INFO|trainer.py:3160] 2023-09-07 19:38:11,489 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3162] 2023-09-07 19:38:11,489 >>   Num examples = 9000\n","[INFO|trainer.py:3165] 2023-09-07 19:38:11,489 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:05,  2.69it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.84it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.58it/s]\u001b[A\n"," 28% 5/18 [00:03<00:08,  1.46it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.38it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.29it/s]\u001b[A\n"," 44% 8/18 [00:05<00:08,  1.24it/s]\u001b[A\n"," 50% 9/18 [00:06<00:07,  1.26it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.29it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.30it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.31it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.31it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.31it/s]\u001b[A\n"," 83% 15/18 [00:10<00:02,  1.31it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.32it/s]\u001b[A\n","                                         \n","\u001b[A{'eval_loss': 0.041206035763025284, 'eval_accuracy': 0.9871111111111112, 'eval_runtime': 13.6636, 'eval_samples_per_second': 658.682, 'eval_steps_per_second': 1.317, 'epoch': 6.0}\n","  2% 600/30000 [12:48<6:39:30,  1.23it/s]\n","100% 18/18 [00:12<00:00,  1.49it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2886] 2023-09-07 19:38:25,157 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-600\n","[INFO|configuration_utils.py:460] 2023-09-07 19:38:25,163 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-600/config.json\n","[INFO|modeling_utils.py:1988] 2023-09-07 19:38:25,275 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-600/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 19:38:25,280 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-600/preprocessor_config.json\n","[INFO|trainer.py:2973] 2023-09-07 19:38:25,491 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-300] due to args.save_total_limit\n","{'loss': 0.3467, 'learning_rate': 0.0009796666666666667, 'epoch': 6.1}\n","{'loss': 0.3381, 'learning_rate': 0.0009793333333333334, 'epoch': 6.2}\n","{'loss': 0.3602, 'learning_rate': 0.000979, 'epoch': 6.3}\n","{'loss': 0.3233, 'learning_rate': 0.0009786666666666667, 'epoch': 6.4}\n","{'loss': 0.3298, 'learning_rate': 0.0009783333333333334, 'epoch': 6.5}\n","{'loss': 0.3218, 'learning_rate': 0.000978, 'epoch': 6.6}\n","{'loss': 0.3398, 'learning_rate': 0.0009776666666666666, 'epoch': 6.7}\n","{'loss': 0.326, 'learning_rate': 0.0009773333333333333, 'epoch': 6.8}\n","{'loss': 0.3237, 'learning_rate': 0.000977, 'epoch': 6.9}\n","{'loss': 0.3256, 'learning_rate': 0.0009766666666666667, 'epoch': 7.0}\n","  2% 700/30000 [14:41<6:25:37,  1.27it/s][INFO|trainer.py:3160] 2023-09-07 19:40:18,477 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3162] 2023-09-07 19:40:18,477 >>   Num examples = 9000\n","[INFO|trainer.py:3165] 2023-09-07 19:40:18,478 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.59it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.85it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.56it/s]\u001b[A\n"," 28% 5/18 [00:03<00:09,  1.44it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.37it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.31it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.27it/s]\u001b[A\n"," 50% 9/18 [00:06<00:07,  1.25it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.27it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.28it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.22it/s]\u001b[A\n"," 72% 13/18 [00:09<00:04,  1.24it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.23it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.22it/s]\u001b[A\n"," 89% 16/18 [00:12<00:01,  1.20it/s]\u001b[A\n","                                         \n","\u001b[A{'eval_loss': 0.050476040691137314, 'eval_accuracy': 0.9833333333333333, 'eval_runtime': 14.1653, 'eval_samples_per_second': 635.355, 'eval_steps_per_second': 1.271, 'epoch': 7.0}\n","  2% 700/30000 [14:55<6:25:37,  1.27it/s]\n","100% 18/18 [00:12<00:00,  1.38it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2886] 2023-09-07 19:40:32,646 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-700\n","[INFO|configuration_utils.py:460] 2023-09-07 19:40:32,651 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-700/config.json\n","[INFO|modeling_utils.py:1988] 2023-09-07 19:40:32,759 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-700/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 19:40:32,763 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-700/preprocessor_config.json\n","[INFO|trainer.py:2973] 2023-09-07 19:40:32,983 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-400] due to args.save_total_limit\n","{'loss': 0.313, 'learning_rate': 0.0009763333333333334, 'epoch': 7.1}\n","{'loss': 0.3488, 'learning_rate': 0.000976, 'epoch': 7.2}\n","{'loss': 0.3223, 'learning_rate': 0.0009756666666666667, 'epoch': 7.3}\n","{'loss': 0.3184, 'learning_rate': 0.0009753333333333334, 'epoch': 7.4}\n","{'loss': 0.3152, 'learning_rate': 0.000975, 'epoch': 7.5}\n","{'loss': 0.3267, 'learning_rate': 0.0009746666666666666, 'epoch': 7.6}\n","{'loss': 0.3158, 'learning_rate': 0.0009743333333333335, 'epoch': 7.7}\n","{'loss': 0.3299, 'learning_rate': 0.000974, 'epoch': 7.8}\n","{'loss': 0.33, 'learning_rate': 0.0009736666666666667, 'epoch': 7.9}\n","{'loss': 0.3317, 'learning_rate': 0.0009733333333333334, 'epoch': 8.0}\n","  3% 800/30000 [16:50<6:35:07,  1.23it/s][INFO|trainer.py:3160] 2023-09-07 19:42:26,924 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3162] 2023-09-07 19:42:26,924 >>   Num examples = 9000\n","[INFO|trainer.py:3165] 2023-09-07 19:42:26,924 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.57it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.82it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.58it/s]\u001b[A\n"," 28% 5/18 [00:03<00:09,  1.44it/s]\u001b[A\n"," 33% 6/18 [00:04<00:09,  1.28it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.26it/s]\u001b[A\n"," 44% 8/18 [00:05<00:08,  1.22it/s]\u001b[A\n"," 50% 9/18 [00:06<00:07,  1.20it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.23it/s]\u001b[A\n"," 61% 11/18 [00:08<00:05,  1.25it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.27it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.27it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.26it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.28it/s]\u001b[A\n"," 89% 16/18 [00:12<00:01,  1.27it/s]\u001b[A\n","                                         \n","\u001b[A{'eval_loss': 0.04246997833251953, 'eval_accuracy': 0.985, 'eval_runtime': 14.0943, 'eval_samples_per_second': 638.555, 'eval_steps_per_second': 1.277, 'epoch': 8.0}\n","  3% 800/30000 [17:04<6:35:07,  1.23it/s]\n","100% 18/18 [00:12<00:00,  1.44it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2886] 2023-09-07 19:42:41,023 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-800\n","[INFO|configuration_utils.py:460] 2023-09-07 19:42:41,029 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-800/config.json\n","[INFO|modeling_utils.py:1988] 2023-09-07 19:42:41,137 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-800/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 19:42:41,153 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-800/preprocessor_config.json\n","[INFO|trainer.py:2973] 2023-09-07 19:42:41,369 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-500] due to args.save_total_limit\n","{'loss': 0.3228, 'learning_rate': 0.000973, 'epoch': 8.1}\n","{'loss': 0.3217, 'learning_rate': 0.0009726666666666667, 'epoch': 8.2}\n","{'loss': 0.3269, 'learning_rate': 0.0009723333333333334, 'epoch': 8.3}\n","{'loss': 0.3291, 'learning_rate': 0.000972, 'epoch': 8.4}\n","{'loss': 0.3277, 'learning_rate': 0.0009716666666666667, 'epoch': 8.5}\n","{'loss': 0.3213, 'learning_rate': 0.0009713333333333334, 'epoch': 8.6}\n","{'loss': 0.3136, 'learning_rate': 0.000971, 'epoch': 8.7}\n","{'loss': 0.3117, 'learning_rate': 0.0009706666666666667, 'epoch': 8.8}\n","{'loss': 0.3175, 'learning_rate': 0.0009703333333333334, 'epoch': 8.9}\n","{'loss': 0.3243, 'learning_rate': 0.0009699999999999999, 'epoch': 9.0}\n","  3% 900/30000 [18:59<6:27:43,  1.25it/s][INFO|trainer.py:3160] 2023-09-07 19:44:36,025 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3162] 2023-09-07 19:44:36,025 >>   Num examples = 9000\n","[INFO|trainer.py:3165] 2023-09-07 19:44:36,026 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.61it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.86it/s]\u001b[A\n"," 22% 4/18 [00:02<00:09,  1.48it/s]\u001b[A\n"," 28% 5/18 [00:03<00:09,  1.37it/s]\u001b[A\n"," 33% 6/18 [00:04<00:09,  1.33it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.27it/s]\u001b[A\n"," 44% 8/18 [00:05<00:08,  1.23it/s]\u001b[A\n"," 50% 9/18 [00:06<00:07,  1.24it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.25it/s]\u001b[A\n"," 61% 11/18 [00:08<00:05,  1.27it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.29it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.30it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.18it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.20it/s]\u001b[A\n"," 89% 16/18 [00:12<00:01,  1.22it/s]\u001b[A\n","                                         \n","\u001b[A{'eval_loss': 0.04742660000920296, 'eval_accuracy': 0.9833333333333333, 'eval_runtime': 14.226, 'eval_samples_per_second': 632.645, 'eval_steps_per_second': 1.265, 'epoch': 9.0}\n","  3% 900/30000 [19:13<6:27:43,  1.25it/s]\n","100% 18/18 [00:12<00:00,  1.41it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2886] 2023-09-07 19:44:50,255 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-900\n","[INFO|configuration_utils.py:460] 2023-09-07 19:44:50,261 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-900/config.json\n","[INFO|modeling_utils.py:1988] 2023-09-07 19:44:50,371 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-900/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 19:44:50,375 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-900/preprocessor_config.json\n","[INFO|trainer.py:2973] 2023-09-07 19:44:50,595 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-700] due to args.save_total_limit\n","{'loss': 0.3038, 'learning_rate': 0.0009696666666666667, 'epoch': 9.1}\n","{'loss': 0.2995, 'learning_rate': 0.0009693333333333334, 'epoch': 9.2}\n","{'loss': 0.3121, 'learning_rate': 0.000969, 'epoch': 9.3}\n","{'loss': 0.3222, 'learning_rate': 0.0009686666666666667, 'epoch': 9.4}\n","{'loss': 0.314, 'learning_rate': 0.0009683333333333334, 'epoch': 9.5}\n","{'loss': 0.3063, 'learning_rate': 0.000968, 'epoch': 9.6}\n","{'loss': 0.3211, 'learning_rate': 0.0009676666666666667, 'epoch': 9.7}\n","{'loss': 0.3046, 'learning_rate': 0.0009673333333333334, 'epoch': 9.8}\n","{'loss': 0.3381, 'learning_rate': 0.000967, 'epoch': 9.9}\n","{'loss': 0.3278, 'learning_rate': 0.0009666666666666667, 'epoch': 10.0}\n","  3% 1000/30000 [21:07<6:32:41,  1.23it/s][INFO|trainer.py:3160] 2023-09-07 19:46:44,035 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3162] 2023-09-07 19:46:44,035 >>   Num examples = 9000\n","[INFO|trainer.py:3165] 2023-09-07 19:46:44,035 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.53it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.77it/s]\u001b[A\n"," 22% 4/18 [00:02<00:10,  1.39it/s]\u001b[A\n"," 28% 5/18 [00:03<00:09,  1.31it/s]\u001b[A\n"," 33% 6/18 [00:04<00:09,  1.25it/s]\u001b[A\n"," 39% 7/18 [00:05<00:09,  1.20it/s]\u001b[A\n"," 44% 8/18 [00:06<00:08,  1.18it/s]\u001b[A\n"," 50% 9/18 [00:06<00:07,  1.18it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.21it/s]\u001b[A\n"," 61% 11/18 [00:08<00:05,  1.23it/s]\u001b[A\n"," 67% 12/18 [00:09<00:04,  1.23it/s]\u001b[A\n"," 72% 13/18 [00:10<00:04,  1.25it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.26it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.27it/s]\u001b[A\n"," 89% 16/18 [00:12<00:01,  1.27it/s]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 0.06202973052859306, 'eval_accuracy': 0.9798888888888889, 'eval_runtime': 14.4714, 'eval_samples_per_second': 621.916, 'eval_steps_per_second': 1.244, 'epoch': 10.0}\n","  3% 1000/30000 [21:21<6:32:41,  1.23it/s]\n","100% 18/18 [00:13<00:00,  1.42it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2886] 2023-09-07 19:46:58,512 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-1000\n","[INFO|configuration_utils.py:460] 2023-09-07 19:46:58,517 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-1000/config.json\n","[INFO|modeling_utils.py:1988] 2023-09-07 19:46:58,632 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-1000/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 19:46:58,637 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-1000/preprocessor_config.json\n","[INFO|trainer.py:2973] 2023-09-07 19:46:58,865 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-800] due to args.save_total_limit\n","{'loss': 0.3045, 'learning_rate': 0.0009663333333333334, 'epoch': 10.1}\n","{'loss': 0.3135, 'learning_rate': 0.000966, 'epoch': 10.2}\n","{'loss': 0.3146, 'learning_rate': 0.0009656666666666666, 'epoch': 10.3}\n","{'loss': 0.3369, 'learning_rate': 0.0009653333333333333, 'epoch': 10.4}\n","{'loss': 0.3099, 'learning_rate': 0.000965, 'epoch': 10.5}\n","{'loss': 0.3297, 'learning_rate': 0.0009646666666666667, 'epoch': 10.6}\n","{'loss': 0.3177, 'learning_rate': 0.0009643333333333334, 'epoch': 10.7}\n","{'loss': 0.2836, 'learning_rate': 0.000964, 'epoch': 10.8}\n","{'loss': 0.3096, 'learning_rate': 0.0009636666666666667, 'epoch': 10.9}\n","{'loss': 0.295, 'learning_rate': 0.0009633333333333334, 'epoch': 11.0}\n","  4% 1100/30000 [23:17<6:26:32,  1.25it/s][INFO|trainer.py:3160] 2023-09-07 19:48:53,982 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3162] 2023-09-07 19:48:53,983 >>   Num examples = 9000\n","[INFO|trainer.py:3165] 2023-09-07 19:48:53,983 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.62it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.83it/s]\u001b[A\n"," 22% 4/18 [00:02<00:09,  1.54it/s]\u001b[A\n"," 28% 5/18 [00:03<00:09,  1.42it/s]\u001b[A\n"," 33% 6/18 [00:04<00:08,  1.34it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.28it/s]\u001b[A\n"," 44% 8/18 [00:05<00:08,  1.25it/s]\u001b[A\n"," 50% 9/18 [00:06<00:07,  1.27it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.29it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.29it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.30it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.31it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.31it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.30it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.30it/s]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 0.03603455051779747, 'eval_accuracy': 0.9867777777777778, 'eval_runtime': 13.8017, 'eval_samples_per_second': 652.092, 'eval_steps_per_second': 1.304, 'epoch': 11.0}\n","  4% 1100/30000 [23:30<6:26:32,  1.25it/s]\n","100% 18/18 [00:12<00:00,  1.46it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2886] 2023-09-07 19:49:07,789 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-1100\n","[INFO|configuration_utils.py:460] 2023-09-07 19:49:07,794 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-1100/config.json\n","[INFO|modeling_utils.py:1988] 2023-09-07 19:49:07,916 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-1100/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 19:49:07,920 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-1100/preprocessor_config.json\n","[INFO|trainer.py:2973] 2023-09-07 19:49:08,153 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-600] due to args.save_total_limit\n","{'loss': 0.3238, 'learning_rate': 0.000963, 'epoch': 11.1}\n","{'loss': 0.3098, 'learning_rate': 0.0009626666666666667, 'epoch': 11.2}\n","{'loss': 0.3109, 'learning_rate': 0.0009623333333333334, 'epoch': 11.3}\n","{'loss': 0.3136, 'learning_rate': 0.000962, 'epoch': 11.4}\n","{'loss': 0.2901, 'learning_rate': 0.0009616666666666667, 'epoch': 11.5}\n","{'loss': 0.2957, 'learning_rate': 0.0009613333333333334, 'epoch': 11.6}\n","{'loss': 0.3011, 'learning_rate': 0.0009609999999999999, 'epoch': 11.7}\n","{'loss': 0.2994, 'learning_rate': 0.0009606666666666666, 'epoch': 11.8}\n","{'loss': 0.3054, 'learning_rate': 0.0009603333333333334, 'epoch': 11.9}\n","{'loss': 0.3203, 'learning_rate': 0.00096, 'epoch': 12.0}\n","  4% 1200/30000 [25:25<6:24:10,  1.25it/s][INFO|trainer.py:3160] 2023-09-07 19:51:02,424 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3162] 2023-09-07 19:51:02,424 >>   Num examples = 9000\n","[INFO|trainer.py:3165] 2023-09-07 19:51:02,424 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:05,  2.70it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.83it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.58it/s]\u001b[A\n"," 28% 5/18 [00:03<00:09,  1.42it/s]\u001b[A\n"," 33% 6/18 [00:04<00:09,  1.30it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.25it/s]\u001b[A\n"," 44% 8/18 [00:05<00:08,  1.24it/s]\u001b[A\n"," 50% 9/18 [00:06<00:07,  1.27it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.26it/s]\u001b[A\n"," 61% 11/18 [00:08<00:05,  1.28it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.28it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.28it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.29it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.28it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.28it/s]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 0.09979789704084396, 'eval_accuracy': 0.9676666666666667, 'eval_runtime': 14.0002, 'eval_samples_per_second': 642.85, 'eval_steps_per_second': 1.286, 'epoch': 12.0}\n","  4% 1200/30000 [25:39<6:24:10,  1.25it/s]\n","100% 18/18 [00:12<00:00,  1.42it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2886] 2023-09-07 19:51:16,429 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-1200\n","[INFO|configuration_utils.py:460] 2023-09-07 19:51:16,435 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-1200/config.json\n","[INFO|modeling_utils.py:1988] 2023-09-07 19:51:16,545 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-1200/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 19:51:16,550 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-1200/preprocessor_config.json\n","[INFO|trainer.py:2973] 2023-09-07 19:51:16,786 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-900] due to args.save_total_limit\n","{'loss': 0.2998, 'learning_rate': 0.0009596666666666667, 'epoch': 12.1}\n","{'loss': 0.3027, 'learning_rate': 0.0009593333333333334, 'epoch': 12.2}\n","{'loss': 0.3026, 'learning_rate': 0.000959, 'epoch': 12.3}\n","{'loss': 0.2991, 'learning_rate': 0.0009586666666666667, 'epoch': 12.4}\n","{'loss': 0.2842, 'learning_rate': 0.0009583333333333334, 'epoch': 12.5}\n","{'loss': 0.3039, 'learning_rate': 0.000958, 'epoch': 12.6}\n","{'loss': 0.3044, 'learning_rate': 0.0009576666666666667, 'epoch': 12.7}\n","{'loss': 0.2945, 'learning_rate': 0.0009573333333333334, 'epoch': 12.8}\n","{'loss': 0.2934, 'learning_rate': 0.000957, 'epoch': 12.9}\n","{'loss': 0.3074, 'learning_rate': 0.0009566666666666666, 'epoch': 13.0}\n","  4% 1300/30000 [27:33<6:25:22,  1.24it/s][INFO|trainer.py:3160] 2023-09-07 19:53:09,968 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3162] 2023-09-07 19:53:09,968 >>   Num examples = 9000\n","[INFO|trainer.py:3165] 2023-09-07 19:53:09,969 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.63it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.85it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.60it/s]\u001b[A\n"," 28% 5/18 [00:03<00:09,  1.43it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.35it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.31it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.27it/s]\u001b[A\n"," 50% 9/18 [00:06<00:07,  1.24it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.25it/s]\u001b[A\n"," 61% 11/18 [00:08<00:05,  1.27it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.28it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.28it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.29it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.29it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.29it/s]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 0.04012392461299896, 'eval_accuracy': 0.9864444444444445, 'eval_runtime': 13.8811, 'eval_samples_per_second': 648.365, 'eval_steps_per_second': 1.297, 'epoch': 13.0}\n","  4% 1300/30000 [27:47<6:25:22,  1.24it/s]\n","100% 18/18 [00:12<00:00,  1.45it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2886] 2023-09-07 19:53:23,854 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-1300\n","[INFO|configuration_utils.py:460] 2023-09-07 19:53:23,860 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-1300/config.json\n","[INFO|modeling_utils.py:1988] 2023-09-07 19:53:23,970 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-1300/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 19:53:23,974 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-1300/preprocessor_config.json\n","[INFO|trainer.py:2973] 2023-09-07 19:53:24,189 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-1000] due to args.save_total_limit\n","{'loss': 0.3058, 'learning_rate': 0.0009563333333333333, 'epoch': 13.1}\n","{'loss': 0.2882, 'learning_rate': 0.0009559999999999999, 'epoch': 13.2}\n","{'loss': 0.3141, 'learning_rate': 0.0009556666666666667, 'epoch': 13.3}\n","{'loss': 0.3, 'learning_rate': 0.0009553333333333334, 'epoch': 13.4}\n","{'loss': 0.2942, 'learning_rate': 0.000955, 'epoch': 13.5}\n","{'loss': 0.2998, 'learning_rate': 0.0009546666666666667, 'epoch': 13.6}\n","{'loss': 0.3283, 'learning_rate': 0.0009543333333333334, 'epoch': 13.7}\n","{'loss': 0.2849, 'learning_rate': 0.000954, 'epoch': 13.8}\n","{'loss': 0.3092, 'learning_rate': 0.0009536666666666667, 'epoch': 13.9}\n","{'loss': 0.2972, 'learning_rate': 0.0009533333333333334, 'epoch': 14.0}\n","  5% 1400/30000 [29:41<6:20:31,  1.25it/s][INFO|trainer.py:3160] 2023-09-07 19:55:18,044 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3162] 2023-09-07 19:55:18,044 >>   Num examples = 9000\n","[INFO|trainer.py:3165] 2023-09-07 19:55:18,044 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.65it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.86it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.61it/s]\u001b[A\n"," 28% 5/18 [00:03<00:08,  1.50it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.41it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.36it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.33it/s]\u001b[A\n"," 50% 9/18 [00:06<00:07,  1.28it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.25it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.24it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.27it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.28it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.30it/s]\u001b[A\n"," 83% 15/18 [00:10<00:02,  1.29it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.30it/s]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 0.039323996752500534, 'eval_accuracy': 0.9858888888888889, 'eval_runtime': 13.7059, 'eval_samples_per_second': 656.651, 'eval_steps_per_second': 1.313, 'epoch': 14.0}\n","  5% 1400/30000 [29:54<6:20:31,  1.25it/s]\n","100% 18/18 [00:12<00:00,  1.48it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2886] 2023-09-07 19:55:31,755 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-1400\n","[INFO|configuration_utils.py:460] 2023-09-07 19:55:31,773 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-1400/config.json\n","[INFO|modeling_utils.py:1988] 2023-09-07 19:55:31,889 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-1400/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 19:55:31,894 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-1400/preprocessor_config.json\n","[INFO|trainer.py:2973] 2023-09-07 19:55:32,110 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-1200] due to args.save_total_limit\n","{'loss': 0.2991, 'learning_rate': 0.000953, 'epoch': 14.1}\n","{'loss': 0.304, 'learning_rate': 0.0009526666666666667, 'epoch': 14.2}\n","{'loss': 0.3019, 'learning_rate': 0.0009523333333333334, 'epoch': 14.3}\n","{'loss': 0.3106, 'learning_rate': 0.0009519999999999999, 'epoch': 14.4}\n","{'loss': 0.2871, 'learning_rate': 0.0009516666666666666, 'epoch': 14.5}\n","{'loss': 0.2693, 'learning_rate': 0.0009513333333333334, 'epoch': 14.6}\n","{'loss': 0.2947, 'learning_rate': 0.000951, 'epoch': 14.7}\n","{'loss': 0.3032, 'learning_rate': 0.0009506666666666667, 'epoch': 14.8}\n","{'loss': 0.2863, 'learning_rate': 0.0009503333333333334, 'epoch': 14.9}\n","{'loss': 0.2943, 'learning_rate': 0.00095, 'epoch': 15.0}\n","  5% 1500/30000 [31:48<6:20:33,  1.25it/s][INFO|trainer.py:3160] 2023-09-07 19:57:25,625 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3162] 2023-09-07 19:57:25,625 >>   Num examples = 9000\n","[INFO|trainer.py:3165] 2023-09-07 19:57:25,625 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.55it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.85it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.62it/s]\u001b[A\n"," 28% 5/18 [00:03<00:08,  1.50it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.44it/s]\u001b[A\n"," 39% 7/18 [00:04<00:07,  1.39it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.37it/s]\u001b[A\n"," 50% 9/18 [00:06<00:07,  1.25it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.24it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.23it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.22it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.25it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.28it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.29it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.30it/s]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 0.029298357665538788, 'eval_accuracy': 0.99, 'eval_runtime': 13.7302, 'eval_samples_per_second': 655.487, 'eval_steps_per_second': 1.311, 'epoch': 15.0}\n","  5% 1500/30000 [32:02<6:20:33,  1.25it/s]\n","100% 18/18 [00:12<00:00,  1.47it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2886] 2023-09-07 19:57:39,361 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-1500\n","[INFO|configuration_utils.py:460] 2023-09-07 19:57:39,367 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-1500/config.json\n","[INFO|modeling_utils.py:1988] 2023-09-07 19:57:39,480 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-1500/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 19:57:39,485 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-1500/preprocessor_config.json\n","[INFO|trainer.py:2973] 2023-09-07 19:57:39,718 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-1100] due to args.save_total_limit\n","{'loss': 0.3161, 'learning_rate': 0.0009496666666666667, 'epoch': 15.1}\n","{'loss': 0.27, 'learning_rate': 0.0009493333333333334, 'epoch': 15.2}\n","{'loss': 0.3005, 'learning_rate': 0.000949, 'epoch': 15.3}\n","{'loss': 0.2943, 'learning_rate': 0.0009486666666666667, 'epoch': 15.4}\n","{'loss': 0.3014, 'learning_rate': 0.0009483333333333334, 'epoch': 15.5}\n","{'loss': 0.2986, 'learning_rate': 0.000948, 'epoch': 15.6}\n","{'loss': 0.2706, 'learning_rate': 0.0009476666666666666, 'epoch': 15.7}\n","{'loss': 0.3071, 'learning_rate': 0.0009473333333333333, 'epoch': 15.8}\n","{'loss': 0.2911, 'learning_rate': 0.0009469999999999999, 'epoch': 15.9}\n","{'loss': 0.2984, 'learning_rate': 0.0009466666666666667, 'epoch': 16.0}\n","  5% 1600/30000 [33:55<6:24:15,  1.23it/s][INFO|trainer.py:3160] 2023-09-07 19:59:32,351 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3162] 2023-09-07 19:59:32,351 >>   Num examples = 9000\n","[INFO|trainer.py:3165] 2023-09-07 19:59:32,351 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:05,  2.72it/s]\u001b[A\n"," 17% 3/18 [00:01<00:07,  1.92it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.65it/s]\u001b[A\n"," 28% 5/18 [00:02<00:08,  1.52it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.46it/s]\u001b[A\n"," 39% 7/18 [00:04<00:07,  1.41it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.39it/s]\u001b[A\n"," 50% 9/18 [00:05<00:06,  1.36it/s]\u001b[A\n"," 56% 10/18 [00:06<00:06,  1.30it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.30it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.25it/s]\u001b[A\n"," 72% 13/18 [00:09<00:04,  1.24it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.23it/s]\u001b[A\n"," 83% 15/18 [00:10<00:02,  1.26it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.28it/s]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 0.034870438277721405, 'eval_accuracy': 0.9885555555555555, 'eval_runtime': 13.5762, 'eval_samples_per_second': 662.923, 'eval_steps_per_second': 1.326, 'epoch': 16.0}\n","  5% 1600/30000 [34:09<6:24:15,  1.23it/s]\n","100% 18/18 [00:12<00:00,  1.45it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2886] 2023-09-07 19:59:45,932 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-1600\n","[INFO|configuration_utils.py:460] 2023-09-07 19:59:45,938 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-1600/config.json\n","[INFO|modeling_utils.py:1988] 2023-09-07 19:59:46,306 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-1600/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 19:59:46,311 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-1600/preprocessor_config.json\n","[INFO|trainer.py:2973] 2023-09-07 19:59:46,524 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-1300] due to args.save_total_limit\n","{'loss': 0.2815, 'learning_rate': 0.0009463333333333334, 'epoch': 16.1}\n","{'loss': 0.3139, 'learning_rate': 0.000946, 'epoch': 16.2}\n","{'loss': 0.2844, 'learning_rate': 0.0009456666666666667, 'epoch': 16.3}\n","{'loss': 0.2934, 'learning_rate': 0.0009453333333333334, 'epoch': 16.4}\n","{'loss': 0.2778, 'learning_rate': 0.000945, 'epoch': 16.5}\n","{'loss': 0.2896, 'learning_rate': 0.0009446666666666667, 'epoch': 16.6}\n","{'loss': 0.3142, 'learning_rate': 0.0009443333333333334, 'epoch': 16.7}\n","{'loss': 0.285, 'learning_rate': 0.000944, 'epoch': 16.8}\n","{'loss': 0.2929, 'learning_rate': 0.0009436666666666667, 'epoch': 16.9}\n","{'loss': 0.2856, 'learning_rate': 0.0009433333333333334, 'epoch': 17.0}\n","  6% 1700/30000 [36:02<6:18:39,  1.25it/s][INFO|trainer.py:3160] 2023-09-07 20:01:39,597 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3162] 2023-09-07 20:01:39,597 >>   Num examples = 9000\n","[INFO|trainer.py:3165] 2023-09-07 20:01:39,597 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.63it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.81it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.58it/s]\u001b[A\n"," 28% 5/18 [00:03<00:08,  1.47it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.43it/s]\u001b[A\n"," 39% 7/18 [00:04<00:07,  1.40it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.36it/s]\u001b[A\n"," 50% 9/18 [00:06<00:06,  1.31it/s]\u001b[A\n"," 56% 10/18 [00:06<00:06,  1.30it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.27it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.24it/s]\u001b[A\n"," 72% 13/18 [00:09<00:04,  1.23it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.24it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.27it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.27it/s]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 2.037733316421509, 'eval_accuracy': 0.45166666666666666, 'eval_runtime': 13.7702, 'eval_samples_per_second': 653.585, 'eval_steps_per_second': 1.307, 'epoch': 17.0}\n","  6% 1700/30000 [36:16<6:18:39,  1.25it/s]\n","100% 18/18 [00:12<00:00,  1.45it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2886] 2023-09-07 20:01:53,372 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-1700\n","[INFO|configuration_utils.py:460] 2023-09-07 20:01:53,377 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-1700/config.json\n","[INFO|modeling_utils.py:1988] 2023-09-07 20:01:53,484 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-1700/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 20:01:53,503 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-1700/preprocessor_config.json\n","[INFO|trainer.py:2973] 2023-09-07 20:01:53,716 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-1400] due to args.save_total_limit\n","{'loss': 0.2904, 'learning_rate': 0.0009429999999999999, 'epoch': 17.1}\n","{'loss': 0.2905, 'learning_rate': 0.0009426666666666666, 'epoch': 17.2}\n","{'loss': 0.2903, 'learning_rate': 0.0009423333333333333, 'epoch': 17.3}\n","{'loss': 0.2936, 'learning_rate': 0.000942, 'epoch': 17.4}\n","{'loss': 0.2734, 'learning_rate': 0.0009416666666666667, 'epoch': 17.5}\n","{'loss': 0.29, 'learning_rate': 0.0009413333333333334, 'epoch': 17.6}\n","{'loss': 0.2991, 'learning_rate': 0.000941, 'epoch': 17.7}\n","{'loss': 0.2995, 'learning_rate': 0.0009406666666666667, 'epoch': 17.8}\n","{'loss': 0.2832, 'learning_rate': 0.0009403333333333334, 'epoch': 17.9}\n","{'loss': 0.2867, 'learning_rate': 0.00094, 'epoch': 18.0}\n","  6% 1800/30000 [38:08<6:28:58,  1.21it/s][INFO|trainer.py:3160] 2023-09-07 20:03:45,314 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3162] 2023-09-07 20:03:45,315 >>   Num examples = 9000\n","[INFO|trainer.py:3165] 2023-09-07 20:03:45,315 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.66it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.83it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.59it/s]\u001b[A\n"," 28% 5/18 [00:03<00:08,  1.50it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.45it/s]\u001b[A\n"," 39% 7/18 [00:04<00:07,  1.43it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.41it/s]\u001b[A\n"," 50% 9/18 [00:05<00:06,  1.40it/s]\u001b[A\n"," 56% 10/18 [00:06<00:05,  1.36it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.34it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.31it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.29it/s]\u001b[A\n"," 78% 14/18 [00:09<00:03,  1.26it/s]\u001b[A\n"," 83% 15/18 [00:10<00:02,  1.22it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.21it/s]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 0.03211795911192894, 'eval_accuracy': 0.9888888888888889, 'eval_runtime': 13.7011, 'eval_samples_per_second': 656.88, 'eval_steps_per_second': 1.314, 'epoch': 18.0}\n","  6% 1800/30000 [38:22<6:28:58,  1.21it/s]\n","100% 18/18 [00:12<00:00,  1.39it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2886] 2023-09-07 20:03:59,020 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-1800\n","[INFO|configuration_utils.py:460] 2023-09-07 20:03:59,026 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-1800/config.json\n","[INFO|modeling_utils.py:1988] 2023-09-07 20:03:59,138 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-1800/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 20:03:59,143 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-1800/preprocessor_config.json\n","[INFO|trainer.py:2973] 2023-09-07 20:03:59,358 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-1600] due to args.save_total_limit\n","{'loss': 0.29, 'learning_rate': 0.0009396666666666667, 'epoch': 18.1}\n","{'loss': 0.2955, 'learning_rate': 0.0009393333333333334, 'epoch': 18.2}\n","{'loss': 0.2864, 'learning_rate': 0.000939, 'epoch': 18.3}\n","{'loss': 0.2679, 'learning_rate': 0.0009386666666666666, 'epoch': 18.4}\n","{'loss': 0.2792, 'learning_rate': 0.0009383333333333333, 'epoch': 18.5}\n","{'loss': 0.2977, 'learning_rate': 0.0009379999999999999, 'epoch': 18.6}\n","{'loss': 0.2811, 'learning_rate': 0.0009376666666666666, 'epoch': 18.7}\n","{'loss': 0.2852, 'learning_rate': 0.0009373333333333334, 'epoch': 18.8}\n","{'loss': 0.2774, 'learning_rate': 0.0009370000000000001, 'epoch': 18.9}\n","{'loss': 0.2966, 'learning_rate': 0.0009366666666666667, 'epoch': 19.0}\n","  6% 1900/30000 [40:14<6:23:33,  1.22it/s][INFO|trainer.py:3160] 2023-09-07 20:05:51,798 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3162] 2023-09-07 20:05:51,798 >>   Num examples = 9000\n","[INFO|trainer.py:3165] 2023-09-07 20:05:51,798 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:05,  2.73it/s]\u001b[A\n"," 17% 3/18 [00:01<00:07,  1.95it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.68it/s]\u001b[A\n"," 28% 5/18 [00:02<00:08,  1.55it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.47it/s]\u001b[A\n"," 39% 7/18 [00:04<00:07,  1.43it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.40it/s]\u001b[A\n"," 50% 9/18 [00:05<00:06,  1.39it/s]\u001b[A\n"," 56% 10/18 [00:06<00:05,  1.38it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.37it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.37it/s]\u001b[A\n"," 72% 13/18 [00:08<00:03,  1.36it/s]\u001b[A\n"," 78% 14/18 [00:09<00:02,  1.36it/s]\u001b[A\n"," 83% 15/18 [00:10<00:02,  1.34it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.25it/s]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 0.2954949140548706, 'eval_accuracy': 0.9031111111111111, 'eval_runtime': 13.3599, 'eval_samples_per_second': 673.658, 'eval_steps_per_second': 1.347, 'epoch': 19.0}\n","  6% 1900/30000 [40:28<6:23:33,  1.22it/s]\n","100% 18/18 [00:11<00:00,  1.41it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2886] 2023-09-07 20:06:05,162 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-1900\n","[INFO|configuration_utils.py:460] 2023-09-07 20:06:05,168 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-1900/config.json\n","[INFO|modeling_utils.py:1988] 2023-09-07 20:06:05,277 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-1900/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 20:06:05,282 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-1900/preprocessor_config.json\n","[INFO|trainer.py:2973] 2023-09-07 20:06:05,501 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-1700] due to args.save_total_limit\n","{'loss': 0.2802, 'learning_rate': 0.0009363333333333334, 'epoch': 19.1}\n","{'loss': 0.2783, 'learning_rate': 0.0009360000000000001, 'epoch': 19.2}\n","{'loss': 0.2737, 'learning_rate': 0.0009356666666666667, 'epoch': 19.3}\n","{'loss': 0.2966, 'learning_rate': 0.0009353333333333334, 'epoch': 19.4}\n","{'loss': 0.279, 'learning_rate': 0.0009350000000000001, 'epoch': 19.5}\n","{'loss': 0.2997, 'learning_rate': 0.0009346666666666667, 'epoch': 19.6}\n","{'loss': 0.2709, 'learning_rate': 0.0009343333333333333, 'epoch': 19.7}\n","{'loss': 0.2819, 'learning_rate': 0.000934, 'epoch': 19.8}\n","{'loss': 0.2713, 'learning_rate': 0.0009336666666666666, 'epoch': 19.9}\n","{'loss': 0.285, 'learning_rate': 0.0009333333333333333, 'epoch': 20.0}\n","  7% 2000/30000 [42:19<6:09:16,  1.26it/s][INFO|trainer.py:3160] 2023-09-07 20:07:56,010 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3162] 2023-09-07 20:07:56,011 >>   Num examples = 9000\n","[INFO|trainer.py:3165] 2023-09-07 20:07:56,011 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.46it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.75it/s]\u001b[A\n"," 22% 4/18 [00:02<00:09,  1.48it/s]\u001b[A\n"," 28% 5/18 [00:03<00:08,  1.45it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.42it/s]\u001b[A\n"," 39% 7/18 [00:04<00:07,  1.40it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.39it/s]\u001b[A\n"," 50% 9/18 [00:06<00:06,  1.37it/s]\u001b[A\n"," 56% 10/18 [00:06<00:05,  1.37it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.37it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.38it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.39it/s]\u001b[A\n"," 78% 14/18 [00:09<00:02,  1.39it/s]\u001b[A\n"," 83% 15/18 [00:10<00:02,  1.39it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.39it/s]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 0.04357277229428291, 'eval_accuracy': 0.9854444444444445, 'eval_runtime': 13.1817, 'eval_samples_per_second': 682.765, 'eval_steps_per_second': 1.366, 'epoch': 20.0}\n","  7% 2000/30000 [42:32<6:09:16,  1.26it/s]\n","100% 18/18 [00:11<00:00,  1.56it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2886] 2023-09-07 20:08:09,197 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-2000\n","[INFO|configuration_utils.py:460] 2023-09-07 20:08:09,201 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-2000/config.json\n","[INFO|modeling_utils.py:1988] 2023-09-07 20:08:09,305 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-2000/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 20:08:09,309 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-2000/preprocessor_config.json\n","[INFO|trainer.py:2973] 2023-09-07 20:08:09,529 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-1800] due to args.save_total_limit\n","{'loss': 0.2719, 'learning_rate': 0.000933, 'epoch': 20.1}\n","{'loss': 0.2745, 'learning_rate': 0.0009326666666666667, 'epoch': 20.2}\n","{'loss': 0.2824, 'learning_rate': 0.0009323333333333334, 'epoch': 20.3}\n","{'loss': 0.2757, 'learning_rate': 0.0009320000000000001, 'epoch': 20.4}\n","{'loss': 0.2913, 'learning_rate': 0.0009316666666666667, 'epoch': 20.5}\n","{'loss': 0.2746, 'learning_rate': 0.0009313333333333334, 'epoch': 20.6}\n","{'loss': 0.2822, 'learning_rate': 0.0009310000000000001, 'epoch': 20.7}\n","{'loss': 0.273, 'learning_rate': 0.0009306666666666667, 'epoch': 20.8}\n","{'loss': 0.2642, 'learning_rate': 0.0009303333333333334, 'epoch': 20.9}\n","{'loss': 0.2897, 'learning_rate': 0.00093, 'epoch': 21.0}\n","  7% 2100/30000 [44:23<6:01:46,  1.29it/s][INFO|trainer.py:3160] 2023-09-07 20:09:59,901 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3162] 2023-09-07 20:09:59,902 >>   Num examples = 9000\n","[INFO|trainer.py:3165] 2023-09-07 20:09:59,902 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:05,  2.80it/s]\u001b[A\n"," 17% 3/18 [00:01<00:07,  1.95it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.57it/s]\u001b[A\n"," 28% 5/18 [00:03<00:09,  1.44it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.37it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.32it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.27it/s]\u001b[A\n"," 50% 9/18 [00:06<00:06,  1.30it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.31it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.32it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.34it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.34it/s]\u001b[A\n"," 78% 14/18 [00:09<00:02,  1.34it/s]\u001b[A\n"," 83% 15/18 [00:10<00:02,  1.34it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.36it/s]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 0.03606031835079193, 'eval_accuracy': 0.9887777777777778, 'eval_runtime': 13.3345, 'eval_samples_per_second': 674.94, 'eval_steps_per_second': 1.35, 'epoch': 21.0}\n","  7% 2100/30000 [44:36<6:01:46,  1.29it/s]\n","100% 18/18 [00:12<00:00,  1.52it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2886] 2023-09-07 20:10:13,241 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-2100\n","[INFO|configuration_utils.py:460] 2023-09-07 20:10:13,246 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-2100/config.json\n","[INFO|modeling_utils.py:1988] 2023-09-07 20:10:13,352 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-2100/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 20:10:13,356 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-2100/preprocessor_config.json\n","[INFO|trainer.py:2973] 2023-09-07 20:10:13,568 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-1900] due to args.save_total_limit\n","{'loss': 0.2579, 'learning_rate': 0.0009296666666666666, 'epoch': 21.1}\n","{'loss': 0.2896, 'learning_rate': 0.0009293333333333333, 'epoch': 21.2}\n","{'loss': 0.2869, 'learning_rate': 0.000929, 'epoch': 21.3}\n","{'loss': 0.2927, 'learning_rate': 0.0009286666666666666, 'epoch': 21.4}\n","{'loss': 0.2779, 'learning_rate': 0.0009283333333333333, 'epoch': 21.5}\n","{'loss': 0.2767, 'learning_rate': 0.0009280000000000001, 'epoch': 21.6}\n","{'loss': 0.266, 'learning_rate': 0.0009276666666666667, 'epoch': 21.7}\n","{'loss': 0.2775, 'learning_rate': 0.0009273333333333334, 'epoch': 21.8}\n","{'loss': 0.2838, 'learning_rate': 0.0009270000000000001, 'epoch': 21.9}\n","{'loss': 0.2848, 'learning_rate': 0.0009266666666666667, 'epoch': 22.0}\n","  7% 2200/30000 [46:27<6:03:15,  1.28it/s][INFO|trainer.py:3160] 2023-09-07 20:12:04,508 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3162] 2023-09-07 20:12:04,508 >>   Num examples = 9000\n","[INFO|trainer.py:3165] 2023-09-07 20:12:04,508 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.66it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.85it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.62it/s]\u001b[A\n"," 28% 5/18 [00:03<00:08,  1.52it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.42it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.33it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.28it/s]\u001b[A\n"," 50% 9/18 [00:06<00:07,  1.25it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.23it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.25it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.29it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.31it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.33it/s]\u001b[A\n"," 83% 15/18 [00:10<00:02,  1.34it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.35it/s]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 0.9624725580215454, 'eval_accuracy': 0.695, 'eval_runtime': 13.5153, 'eval_samples_per_second': 665.912, 'eval_steps_per_second': 1.332, 'epoch': 22.0}\n","  7% 2200/30000 [46:41<6:03:15,  1.28it/s]\n","100% 18/18 [00:12<00:00,  1.53it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2886] 2023-09-07 20:12:18,027 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-2200\n","[INFO|configuration_utils.py:460] 2023-09-07 20:12:18,033 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-2200/config.json\n","[INFO|modeling_utils.py:1988] 2023-09-07 20:12:18,135 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-2200/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 20:12:18,138 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-2200/preprocessor_config.json\n","[INFO|trainer.py:2973] 2023-09-07 20:12:18,345 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-2000] due to args.save_total_limit\n","{'loss': 0.2904, 'learning_rate': 0.0009263333333333334, 'epoch': 22.1}\n","{'loss': 0.2673, 'learning_rate': 0.0009260000000000001, 'epoch': 22.2}\n","{'loss': 0.2613, 'learning_rate': 0.0009256666666666667, 'epoch': 22.3}\n","{'loss': 0.2987, 'learning_rate': 0.0009253333333333333, 'epoch': 22.4}\n","{'loss': 0.2822, 'learning_rate': 0.000925, 'epoch': 22.5}\n","{'loss': 0.271, 'learning_rate': 0.0009246666666666666, 'epoch': 22.6}\n","{'loss': 0.2885, 'learning_rate': 0.0009243333333333333, 'epoch': 22.7}\n","{'loss': 0.2898, 'learning_rate': 0.000924, 'epoch': 22.8}\n","{'loss': 0.283, 'learning_rate': 0.0009236666666666666, 'epoch': 22.9}\n","{'loss': 0.3005, 'learning_rate': 0.0009233333333333334, 'epoch': 23.0}\n","  8% 2300/30000 [48:32<6:08:46,  1.25it/s][INFO|trainer.py:3160] 2023-09-07 20:14:09,397 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3162] 2023-09-07 20:14:09,397 >>   Num examples = 9000\n","[INFO|trainer.py:3165] 2023-09-07 20:14:09,397 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:05,  2.73it/s]\u001b[A\n"," 17% 3/18 [00:01<00:07,  1.89it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.66it/s]\u001b[A\n"," 28% 5/18 [00:02<00:08,  1.54it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.48it/s]\u001b[A\n"," 39% 7/18 [00:04<00:07,  1.45it/s]\u001b[A\n"," 44% 8/18 [00:05<00:06,  1.43it/s]\u001b[A\n"," 50% 9/18 [00:05<00:06,  1.40it/s]\u001b[A\n"," 56% 10/18 [00:06<00:05,  1.39it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.31it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.28it/s]\u001b[A\n"," 72% 13/18 [00:09<00:04,  1.24it/s]\u001b[A\n"," 78% 14/18 [00:09<00:03,  1.23it/s]\u001b[A\n"," 83% 15/18 [00:10<00:02,  1.27it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.30it/s]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 0.04342188313603401, 'eval_accuracy': 0.985, 'eval_runtime': 13.3401, 'eval_samples_per_second': 674.659, 'eval_steps_per_second': 1.349, 'epoch': 23.0}\n","  8% 2300/30000 [48:45<6:08:46,  1.25it/s]\n","100% 18/18 [00:12<00:00,  1.48it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2886] 2023-09-07 20:14:22,742 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-2300\n","[INFO|configuration_utils.py:460] 2023-09-07 20:14:22,749 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-2300/config.json\n","[INFO|modeling_utils.py:1988] 2023-09-07 20:14:22,861 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-2300/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 20:14:22,866 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-2300/preprocessor_config.json\n","[INFO|trainer.py:2973] 2023-09-07 20:14:23,103 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-2100] due to args.save_total_limit\n","{'loss': 0.2749, 'learning_rate': 0.0009230000000000001, 'epoch': 23.1}\n","{'loss': 0.2758, 'learning_rate': 0.0009226666666666667, 'epoch': 23.2}\n","{'loss': 0.2793, 'learning_rate': 0.0009223333333333334, 'epoch': 23.3}\n","{'loss': 0.2737, 'learning_rate': 0.0009220000000000001, 'epoch': 23.4}\n","{'loss': 0.2604, 'learning_rate': 0.0009216666666666667, 'epoch': 23.5}\n","{'loss': 0.2866, 'learning_rate': 0.0009213333333333334, 'epoch': 23.6}\n","{'loss': 0.2618, 'learning_rate': 0.000921, 'epoch': 23.7}\n","{'loss': 0.2751, 'learning_rate': 0.0009206666666666666, 'epoch': 23.8}\n","{'loss': 0.2944, 'learning_rate': 0.0009203333333333333, 'epoch': 23.9}\n","{'loss': 0.2707, 'learning_rate': 0.00092, 'epoch': 24.0}\n","  8% 2400/30000 [50:37<6:23:31,  1.20it/s][INFO|trainer.py:3160] 2023-09-07 20:16:13,867 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3162] 2023-09-07 20:16:13,868 >>   Num examples = 9000\n","[INFO|trainer.py:3165] 2023-09-07 20:16:13,868 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:05,  2.72it/s]\u001b[A\n"," 17% 3/18 [00:01<00:07,  1.92it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.68it/s]\u001b[A\n"," 28% 5/18 [00:02<00:08,  1.56it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.49it/s]\u001b[A\n"," 39% 7/18 [00:04<00:07,  1.44it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.39it/s]\u001b[A\n"," 50% 9/18 [00:05<00:06,  1.38it/s]\u001b[A\n"," 56% 10/18 [00:06<00:05,  1.37it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.37it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.35it/s]\u001b[A\n"," 72% 13/18 [00:08<00:03,  1.35it/s]\u001b[A\n"," 78% 14/18 [00:09<00:02,  1.33it/s]\u001b[A\n"," 83% 15/18 [00:10<00:02,  1.32it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.28it/s]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 0.04788052663207054, 'eval_accuracy': 0.9834444444444445, 'eval_runtime': 13.3318, 'eval_samples_per_second': 675.08, 'eval_steps_per_second': 1.35, 'epoch': 24.0}\n","  8% 2400/30000 [50:50<6:23:31,  1.20it/s]\n","100% 18/18 [00:11<00:00,  1.43it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2886] 2023-09-07 20:16:27,204 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-2400\n","[INFO|configuration_utils.py:460] 2023-09-07 20:16:27,210 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-2400/config.json\n","[INFO|modeling_utils.py:1988] 2023-09-07 20:16:27,319 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-2400/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 20:16:27,324 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-2400/preprocessor_config.json\n","[INFO|trainer.py:2973] 2023-09-07 20:16:27,549 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-2200] due to args.save_total_limit\n","{'loss': 0.287, 'learning_rate': 0.0009196666666666666, 'epoch': 24.1}\n","{'loss': 0.2985, 'learning_rate': 0.0009193333333333333, 'epoch': 24.2}\n","{'loss': 0.29, 'learning_rate': 0.0009190000000000001, 'epoch': 24.3}\n","{'loss': 0.2801, 'learning_rate': 0.0009186666666666667, 'epoch': 24.4}\n","{'loss': 0.2653, 'learning_rate': 0.0009183333333333334, 'epoch': 24.5}\n","{'loss': 0.2813, 'learning_rate': 0.0009180000000000001, 'epoch': 24.6}\n","{'loss': 0.2783, 'learning_rate': 0.0009176666666666667, 'epoch': 24.7}\n","{'loss': 0.2723, 'learning_rate': 0.0009173333333333334, 'epoch': 24.8}\n","{'loss': 0.2707, 'learning_rate': 0.0009170000000000001, 'epoch': 24.9}\n","{'loss': 0.2686, 'learning_rate': 0.0009166666666666666, 'epoch': 25.0}\n","  8% 2500/30000 [52:42<6:20:54,  1.20it/s][INFO|trainer.py:3160] 2023-09-07 20:18:19,725 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3162] 2023-09-07 20:18:19,725 >>   Num examples = 9000\n","[INFO|trainer.py:3165] 2023-09-07 20:18:19,725 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.55it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.86it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.64it/s]\u001b[A\n"," 28% 5/18 [00:03<00:08,  1.52it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.46it/s]\u001b[A\n"," 39% 7/18 [00:04<00:07,  1.42it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.39it/s]\u001b[A\n"," 50% 9/18 [00:06<00:06,  1.34it/s]\u001b[A\n"," 56% 10/18 [00:06<00:06,  1.33it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.32it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.30it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.30it/s]\u001b[A\n"," 78% 14/18 [00:09<00:03,  1.32it/s]\u001b[A\n"," 83% 15/18 [00:10<00:02,  1.33it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.32it/s]\u001b[A\n","                                          \n","\u001b[A{'eval_loss': 1.6242692470550537, 'eval_accuracy': 0.4448888888888889, 'eval_runtime': 13.62, 'eval_samples_per_second': 660.795, 'eval_steps_per_second': 1.322, 'epoch': 25.0}\n","  8% 2500/30000 [52:56<6:20:54,  1.20it/s]\n","100% 18/18 [00:12<00:00,  1.44it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2886] 2023-09-07 20:18:33,351 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-2500\n","[INFO|configuration_utils.py:460] 2023-09-07 20:18:33,357 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-2500/config.json\n","[INFO|modeling_utils.py:1988] 2023-09-07 20:18:33,470 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-2500/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 20:18:33,474 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-2500/preprocessor_config.json\n","[INFO|trainer.py:2973] 2023-09-07 20:18:33,706 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-2300] due to args.save_total_limit\n","[INFO|trainer.py:1988] 2023-09-07 20:18:33,721 >> \n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","[INFO|trainer.py:2156] 2023-09-07 20:18:33,722 >> Loading best model from drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/checkpoint-1500 (score: 0.029298357665538788).\n","{'train_runtime': 3176.9733, 'train_samples_per_second': 4815.905, 'train_steps_per_second': 9.443, 'train_loss': 0.3224456847190857, 'epoch': 25.0}\n","  8% 2500/30000 [52:56<9:42:26,  1.27s/it]\n","[INFO|trainer.py:2886] 2023-09-07 20:18:33,800 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/\n","[INFO|configuration_utils.py:460] 2023-09-07 20:18:33,805 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/config.json\n","[INFO|modeling_utils.py:1988] 2023-09-07 20:18:33,919 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 20:18:33,923 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/preprocessor_config.json\n","***** train metrics *****\n","  epoch                    =       25.0\n","  train_loss               =     0.3224\n","  train_runtime            = 0:52:56.97\n","  train_samples_per_second =   4815.905\n","  train_steps_per_second   =      9.443\n","[INFO|trainer.py:3160] 2023-09-07 20:18:33,963 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3162] 2023-09-07 20:18:33,963 >>   Num examples = 9000\n","[INFO|trainer.py:3165] 2023-09-07 20:18:33,963 >>   Batch size = 512\n","100% 18/18 [00:12<00:00,  1.40it/s]\n","***** eval metrics *****\n","  epoch                   =       25.0\n","  eval_accuracy           =       0.99\n","  eval_loss               =     0.0293\n","  eval_runtime            = 0:00:14.42\n","  eval_samples_per_second =    623.699\n","  eval_steps_per_second   =      1.247\n","\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n","\u001b[34m\u001b[1mwandb\u001b[0m:                  eval/accuracy ████████████████▁█▇██▄██▁█\n","\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▂▁▁▄▁▁▇▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/runtime ▅▅▅▄▆▄▆▆▇█▄▅▅▄▄▃▄▄▂▁▂▃▂▂▃█\n","\u001b[34m\u001b[1mwandb\u001b[0m:        eval/samples_per_second ▃▄▃▅▃▅▃▃▂▁▄▃▄▅▅▆▅▅▇█▇▆▇▇▅▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:          eval/steps_per_second ▃▄▃▅▃▅▃▃▂▁▄▃▄▅▅▆▅▅▇█▇▆▇▇▅▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\n","\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\n","\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate ███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss █▄▄▃▃▃▃▂▃▂▂▂▂▂▂▂▂▁▁▂▁▂▂▂▁▂▁▁▁▂▁▁▁▁▁▂▂▁▂▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second ▁\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n","\u001b[34m\u001b[1mwandb\u001b[0m:                  eval/accuracy 0.99\n","\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/loss 0.0293\n","\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/runtime 14.43\n","\u001b[34m\u001b[1mwandb\u001b[0m:        eval/samples_per_second 623.699\n","\u001b[34m\u001b[1mwandb\u001b[0m:          eval/steps_per_second 1.247\n","\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch 25.0\n","\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step 2500\n","\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate 0.00092\n","\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss 0.2686\n","\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos 1.28760990833664e+19\n","\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss 0.32245\n","\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime 3176.9733\n","\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second 4815.905\n","\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second 9.443\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mneat-valley-18\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/u15048366/colabCnnMnist/runs/0hg71jvb\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n","\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230907_192531-0hg71jvb/logs\u001b[0m\n"]}],"source":["!python cnn-mnist.py \\\n","    --model_name microsoft/resnet-18 \\\n","    --model_type resnet \\\n","    --dataset_name mnist \\\n","    --output_dir drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_9/ \\\n","    --remove_unused_columns False \\\n","    --do_train \\\n","    --do_eval \\\n","    --push_to_hub False \\\n","    --learning_rate 0.001 \\\n","    --num_train_epochs 300 \\\n","    --per_device_train_batch_size 512 \\\n","    --per_device_eval_batch_size 512 \\\n","    --logging_strategy steps \\\n","    --logging_steps 10 \\\n","    --evaluation_strategy epoch \\\n","    --save_strategy epoch \\\n","    --load_best_model_at_end True \\\n","    --save_total_limit 3 \\\n","    --save_steps 500 \\\n","    --data_seed 9 \\\n","    --seed 9 \\\n","    --report_to wandb \\\n","    --ignore_mismatched_sizes\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3PTS2JTqFgJM","colab":{"base_uri":"https://localhost:8080/"},"outputId":"28f289e2-696c-4644-a7c2-035128cc10c3"},"outputs":[{"output_type":"stream","name":"stdout","text":["2023-09-07 20:19:00.537231: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mu15048366\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.10\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20230907_201904-4ailr4r3\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mgood-deluge-19\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/u15048366/colabCnnMnist\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/u15048366/colabCnnMnist/runs/4ailr4r3\u001b[0m\n","09/07/2023 20:19:05 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n","09/07/2023 20:19:05 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n","_n_gpu=1,\n","adafactor=False,\n","adam_beta1=0.9,\n","adam_beta2=0.999,\n","adam_epsilon=1e-08,\n","auto_find_batch_size=False,\n","bf16=False,\n","bf16_full_eval=False,\n","data_seed=10,\n","dataloader_drop_last=False,\n","dataloader_num_workers=0,\n","dataloader_pin_memory=True,\n","ddp_backend=None,\n","ddp_broadcast_buffers=None,\n","ddp_bucket_cap_mb=None,\n","ddp_find_unused_parameters=None,\n","ddp_timeout=1800,\n","debug=[],\n","deepspeed=None,\n","disable_tqdm=False,\n","dispatch_batches=None,\n","do_eval=True,\n","do_predict=False,\n","do_train=True,\n","eval_accumulation_steps=None,\n","eval_delay=0,\n","eval_steps=None,\n","evaluation_strategy=epoch,\n","fp16=False,\n","fp16_backend=auto,\n","fp16_full_eval=False,\n","fp16_opt_level=O1,\n","fsdp=[],\n","fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n","fsdp_min_num_params=0,\n","fsdp_transformer_layer_cls_to_wrap=None,\n","full_determinism=False,\n","gradient_accumulation_steps=1,\n","gradient_checkpointing=False,\n","greater_is_better=False,\n","group_by_length=False,\n","half_precision_backend=auto,\n","hub_always_push=False,\n","hub_model_id=None,\n","hub_private_repo=False,\n","hub_strategy=every_save,\n","hub_token=<HUB_TOKEN>,\n","ignore_data_skip=False,\n","include_inputs_for_metrics=False,\n","include_tokens_per_second=False,\n","jit_mode_eval=False,\n","label_names=None,\n","label_smoothing_factor=0.0,\n","learning_rate=0.001,\n","length_column_name=length,\n","load_best_model_at_end=True,\n","local_rank=0,\n","log_level=passive,\n","log_level_replica=warning,\n","log_on_each_node=True,\n","logging_dir=drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_10/runs/Sep07_20-19-05_67f6d3ae3f6c,\n","logging_first_step=False,\n","logging_nan_inf_filter=True,\n","logging_steps=10,\n","logging_strategy=steps,\n","lr_scheduler_type=linear,\n","max_grad_norm=1.0,\n","max_steps=-1,\n","metric_for_best_model=loss,\n","mp_parameters=,\n","no_cuda=False,\n","num_train_epochs=300.0,\n","optim=adamw_torch,\n","optim_args=None,\n","output_dir=drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_10/,\n","overwrite_output_dir=False,\n","past_index=-1,\n","per_device_eval_batch_size=512,\n","per_device_train_batch_size=512,\n","prediction_loss_only=False,\n","push_to_hub=False,\n","push_to_hub_model_id=None,\n","push_to_hub_organization=None,\n","push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n","ray_scope=last,\n","remove_unused_columns=False,\n","report_to=['wandb'],\n","resume_from_checkpoint=None,\n","run_name=drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_10/,\n","save_on_each_node=False,\n","save_safetensors=False,\n","save_steps=500.0,\n","save_strategy=epoch,\n","save_total_limit=3,\n","seed=10,\n","sharded_ddp=[],\n","skip_memory_metrics=True,\n","tf32=None,\n","torch_compile=False,\n","torch_compile_backend=None,\n","torch_compile_mode=None,\n","torchdynamo=None,\n","tpu_metrics_debug=False,\n","tpu_num_cores=None,\n","use_cpu=False,\n","use_ipex=False,\n","use_legacy_prediction_loop=False,\n","use_mps_device=False,\n","warmup_ratio=0.0,\n","warmup_steps=0,\n","weight_decay=0.0,\n",")\n","/usr/local/lib/python3.10/dist-packages/datasets/load.py:2103: FutureWarning: 'task' was deprecated in version 2.13.0 and will be removed in 3.0.0.\n","\n","  warnings.warn(\n","\n","\n","\n","None\n","\n","\n","\n","[INFO|configuration_utils.py:715] 2023-09-07 20:19:07,673 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--resnet-18/snapshots/f45a6faa12e0381f5620c5c8d7e916bca90f2c44/config.json\n","[INFO|configuration_utils.py:775] 2023-09-07 20:19:07,675 >> Model config ResNetConfig {\n","  \"_name_or_path\": \"microsoft/resnet-18\",\n","  \"architectures\": [\n","    \"ResNetForImageClassification\"\n","  ],\n","  \"depths\": [\n","    2,\n","    2,\n","    2,\n","    2\n","  ],\n","  \"downsample_in_first_stage\": false,\n","  \"embedding_size\": 64,\n","  \"finetuning_task\": \"image-classification\",\n","  \"hidden_act\": \"relu\",\n","  \"hidden_sizes\": [\n","    64,\n","    128,\n","    256,\n","    512\n","  ],\n","  \"id2label\": {\n","    \"0\": \"0\",\n","    \"1\": \"1\",\n","    \"2\": \"2\",\n","    \"3\": \"3\",\n","    \"4\": \"4\",\n","    \"5\": \"5\",\n","    \"6\": \"6\",\n","    \"7\": \"7\",\n","    \"8\": \"8\",\n","    \"9\": \"9\"\n","  },\n","  \"label2id\": {\n","    \"0\": \"0\",\n","    \"1\": \"1\",\n","    \"2\": \"2\",\n","    \"3\": \"3\",\n","    \"4\": \"4\",\n","    \"5\": \"5\",\n","    \"6\": \"6\",\n","    \"7\": \"7\",\n","    \"8\": \"8\",\n","    \"9\": \"9\"\n","  },\n","  \"layer_type\": \"basic\",\n","  \"model_type\": \"resnet\",\n","  \"num_channels\": 3,\n","  \"out_features\": [\n","    \"stage4\"\n","  ],\n","  \"out_indices\": [\n","    4\n","  ],\n","  \"stage_names\": [\n","    \"stem\",\n","    \"stage1\",\n","    \"stage2\",\n","    \"stage3\",\n","    \"stage4\"\n","  ],\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.34.0.dev0\"\n","}\n","\n","[INFO|modeling_utils.py:2857] 2023-09-07 20:19:07,677 >> loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--microsoft--resnet-18/snapshots/f45a6faa12e0381f5620c5c8d7e916bca90f2c44/model.safetensors\n","[INFO|modeling_utils.py:3643] 2023-09-07 20:19:07,799 >> All model checkpoint weights were used when initializing ResNetForImageClassification.\n","\n","[WARNING|modeling_utils.py:3664] 2023-09-07 20:19:07,799 >> Some weights of ResNetForImageClassification were not initialized from the model checkpoint at microsoft/resnet-18 and are newly initialized because the shapes did not match:\n","- classifier.1.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([10]) in the model instantiated\n","- classifier.1.weight: found shape torch.Size([1000, 512]) in the checkpoint and torch.Size([10, 512]) in the model instantiated\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","[INFO|image_processing_utils.py:369] 2023-09-07 20:19:08,064 >> loading configuration file preprocessor_config.json from cache at /root/.cache/huggingface/hub/models--microsoft--resnet-18/snapshots/f45a6faa12e0381f5620c5c8d7e916bca90f2c44/preprocessor_config.json\n","[WARNING|image_processing_auto.py:355] 2023-09-07 20:19:08,065 >> Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n","[INFO|image_processing_utils.py:732] 2023-09-07 20:19:08,067 >> size should be a dictionary on of the following set of keys: ({'width', 'height'}, {'shortest_edge'}, {'shortest_edge', 'longest_edge'}, {'longest_edge'}), got 224. Converted to {'shortest_edge': 224}.\n","[INFO|image_processing_utils.py:419] 2023-09-07 20:19:08,067 >> Image processor ConvNextImageProcessor {\n","  \"crop_pct\": 0.875,\n","  \"do_normalize\": true,\n","  \"do_rescale\": true,\n","  \"do_resize\": true,\n","  \"image_mean\": [\n","    0.485,\n","    0.456,\n","    0.406\n","  ],\n","  \"image_processor_type\": \"ConvNextImageProcessor\",\n","  \"image_std\": [\n","    0.229,\n","    0.224,\n","    0.225\n","  ],\n","  \"resample\": 3,\n","  \"rescale_factor\": 0.00392156862745098,\n","  \"size\": {\n","    \"shortest_edge\": 224\n","  }\n","}\n","\n","[INFO|trainer.py:1740] 2023-09-07 20:19:09,938 >> ***** Running training *****\n","[INFO|trainer.py:1741] 2023-09-07 20:19:09,938 >>   Num examples = 51,000\n","[INFO|trainer.py:1742] 2023-09-07 20:19:09,938 >>   Num Epochs = 300\n","[INFO|trainer.py:1743] 2023-09-07 20:19:09,938 >>   Instantaneous batch size per device = 512\n","[INFO|trainer.py:1746] 2023-09-07 20:19:09,938 >>   Total train batch size (w. parallel, distributed & accumulation) = 512\n","[INFO|trainer.py:1747] 2023-09-07 20:19:09,938 >>   Gradient Accumulation steps = 1\n","[INFO|trainer.py:1748] 2023-09-07 20:19:09,938 >>   Total optimization steps = 30,000\n","[INFO|trainer.py:1749] 2023-09-07 20:19:09,939 >>   Number of trainable parameters = 11,181,642\n","[INFO|integration_utils.py:716] 2023-09-07 20:19:09,940 >> Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n","{'loss': 1.1842, 'learning_rate': 0.0009996666666666667, 'epoch': 0.1}\n","{'loss': 0.6117, 'learning_rate': 0.0009993333333333334, 'epoch': 0.2}\n","{'loss': 0.5845, 'learning_rate': 0.000999, 'epoch': 0.3}\n","{'loss': 0.4932, 'learning_rate': 0.0009986666666666668, 'epoch': 0.4}\n","{'loss': 0.4675, 'learning_rate': 0.0009983333333333333, 'epoch': 0.5}\n","{'loss': 0.4834, 'learning_rate': 0.000998, 'epoch': 0.6}\n","{'loss': 0.4576, 'learning_rate': 0.0009976666666666667, 'epoch': 0.7}\n","{'loss': 0.4345, 'learning_rate': 0.0009973333333333334, 'epoch': 0.8}\n","{'loss': 0.4136, 'learning_rate': 0.000997, 'epoch': 0.9}\n","{'loss': 0.4437, 'learning_rate': 0.0009966666666666668, 'epoch': 1.0}\n","  0% 100/30000 [01:59<6:49:53,  1.22it/s][INFO|trainer.py:3160] 2023-09-07 20:21:08,971 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3162] 2023-09-07 20:21:08,972 >>   Num examples = 9000\n","[INFO|trainer.py:3165] 2023-09-07 20:21:08,972 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:07,  2.20it/s]\u001b[A\n"," 17% 3/18 [00:01<00:09,  1.58it/s]\u001b[A\n"," 22% 4/18 [00:02<00:10,  1.39it/s]\u001b[A\n"," 28% 5/18 [00:03<00:09,  1.33it/s]\u001b[A\n"," 33% 6/18 [00:04<00:09,  1.29it/s]\u001b[A\n"," 39% 7/18 [00:05<00:08,  1.30it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.29it/s]\u001b[A\n"," 50% 9/18 [00:06<00:06,  1.30it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.31it/s]\u001b[A\n"," 61% 11/18 [00:08<00:05,  1.32it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.33it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.34it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.30it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.30it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.29it/s]\u001b[A\n","                                         \n","\u001b[A{'eval_loss': 0.06864427030086517, 'eval_accuracy': 0.9811111111111112, 'eval_runtime': 14.3543, 'eval_samples_per_second': 626.991, 'eval_steps_per_second': 1.254, 'epoch': 1.0}\n","  0% 100/30000 [02:13<6:49:53,  1.22it/s]\n","100% 18/18 [00:12<00:00,  1.39it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2886] 2023-09-07 20:21:23,331 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_10/checkpoint-100\n","[INFO|configuration_utils.py:460] 2023-09-07 20:21:23,336 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_10/checkpoint-100/config.json\n","[INFO|modeling_utils.py:1988] 2023-09-07 20:21:23,458 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_10/checkpoint-100/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 20:21:23,463 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_10/checkpoint-100/preprocessor_config.json\n","{'loss': 0.425, 'learning_rate': 0.0009963333333333332, 'epoch': 1.1}\n","{'loss': 0.4189, 'learning_rate': 0.000996, 'epoch': 1.2}\n","{'loss': 0.4227, 'learning_rate': 0.0009956666666666666, 'epoch': 1.3}\n","{'loss': 0.4201, 'learning_rate': 0.0009953333333333333, 'epoch': 1.4}\n","{'loss': 0.4223, 'learning_rate': 0.000995, 'epoch': 1.5}\n","{'loss': 0.4094, 'learning_rate': 0.0009946666666666667, 'epoch': 1.6}\n","{'loss': 0.4151, 'learning_rate': 0.0009943333333333334, 'epoch': 1.7}\n","{'loss': 0.3921, 'learning_rate': 0.000994, 'epoch': 1.8}\n","{'loss': 0.3977, 'learning_rate': 0.0009936666666666668, 'epoch': 1.9}\n","{'loss': 0.4021, 'learning_rate': 0.0009933333333333333, 'epoch': 2.0}\n","  1% 200/30000 [04:08<6:45:56,  1.22it/s][INFO|trainer.py:3160] 2023-09-07 20:23:17,975 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3162] 2023-09-07 20:23:17,975 >>   Num examples = 9000\n","[INFO|trainer.py:3165] 2023-09-07 20:23:17,976 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.34it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.73it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.57it/s]\u001b[A\n"," 28% 5/18 [00:03<00:09,  1.31it/s]\u001b[A\n"," 33% 6/18 [00:04<00:09,  1.32it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.34it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.35it/s]\u001b[A\n"," 50% 9/18 [00:06<00:06,  1.35it/s]\u001b[A\n"," 56% 10/18 [00:07<00:05,  1.34it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.34it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.33it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.34it/s]\u001b[A\n"," 78% 14/18 [00:10<00:02,  1.35it/s]\u001b[A\n"," 83% 15/18 [00:10<00:02,  1.36it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.34it/s]\u001b[A\n","                                         \n","\u001b[A{'eval_loss': 0.05514499172568321, 'eval_accuracy': 0.9838888888888889, 'eval_runtime': 13.7836, 'eval_samples_per_second': 652.951, 'eval_steps_per_second': 1.306, 'epoch': 2.0}\n","  1% 200/30000 [04:21<6:45:56,  1.22it/s]\n","100% 18/18 [00:12<00:00,  1.51it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2886] 2023-09-07 20:23:31,774 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_10/checkpoint-200\n","[INFO|configuration_utils.py:460] 2023-09-07 20:23:31,782 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_10/checkpoint-200/config.json\n","[INFO|modeling_utils.py:1988] 2023-09-07 20:23:31,890 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_10/checkpoint-200/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 20:23:31,894 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_10/checkpoint-200/preprocessor_config.json\n","{'loss': 0.3865, 'learning_rate': 0.000993, 'epoch': 2.1}\n","{'loss': 0.3651, 'learning_rate': 0.0009926666666666667, 'epoch': 2.2}\n","{'loss': 0.3717, 'learning_rate': 0.0009923333333333333, 'epoch': 2.3}\n","{'loss': 0.4095, 'learning_rate': 0.000992, 'epoch': 2.4}\n","{'loss': 0.3778, 'learning_rate': 0.0009916666666666667, 'epoch': 2.5}\n","{'loss': 0.3722, 'learning_rate': 0.0009913333333333332, 'epoch': 2.6}\n","{'loss': 0.3815, 'learning_rate': 0.000991, 'epoch': 2.7}\n","{'loss': 0.3907, 'learning_rate': 0.0009906666666666668, 'epoch': 2.8}\n","{'loss': 0.3656, 'learning_rate': 0.0009903333333333333, 'epoch': 2.9}\n","{'loss': 0.366, 'learning_rate': 0.00099, 'epoch': 3.0}\n","  1% 300/30000 [06:18<7:17:39,  1.13it/s][INFO|trainer.py:3160] 2023-09-07 20:25:28,059 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3162] 2023-09-07 20:25:28,059 >>   Num examples = 9000\n","[INFO|trainer.py:3165] 2023-09-07 20:25:28,059 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.66it/s]\u001b[A\n"," 17% 3/18 [00:01<00:07,  1.88it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.65it/s]\u001b[A\n"," 28% 5/18 [00:02<00:08,  1.54it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.45it/s]\u001b[A\n"," 39% 7/18 [00:04<00:07,  1.43it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.40it/s]\u001b[A\n"," 50% 9/18 [00:05<00:06,  1.38it/s]\u001b[A\n"," 56% 10/18 [00:06<00:05,  1.38it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.38it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.37it/s]\u001b[A\n"," 72% 13/18 [00:08<00:03,  1.34it/s]\u001b[A\n"," 78% 14/18 [00:09<00:03,  1.28it/s]\u001b[A\n"," 83% 15/18 [00:10<00:02,  1.28it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.26it/s]\u001b[A\n","                                         \n","\u001b[A{'eval_loss': 0.06258764863014221, 'eval_accuracy': 0.9804444444444445, 'eval_runtime': 13.5819, 'eval_samples_per_second': 662.647, 'eval_steps_per_second': 1.325, 'epoch': 3.0}\n","  1% 300/30000 [06:31<7:17:39,  1.13it/s]\n","100% 18/18 [00:12<00:00,  1.40it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2886] 2023-09-07 20:25:41,647 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_10/checkpoint-300\n","[INFO|configuration_utils.py:460] 2023-09-07 20:25:41,653 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_10/checkpoint-300/config.json\n","[INFO|modeling_utils.py:1988] 2023-09-07 20:25:41,768 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_10/checkpoint-300/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 20:25:41,773 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_10/checkpoint-300/preprocessor_config.json\n","{'loss': 0.3708, 'learning_rate': 0.0009896666666666667, 'epoch': 3.1}\n","{'loss': 0.3676, 'learning_rate': 0.0009893333333333334, 'epoch': 3.2}\n","{'loss': 0.3602, 'learning_rate': 0.000989, 'epoch': 3.3}\n","{'loss': 0.374, 'learning_rate': 0.0009886666666666668, 'epoch': 3.4}\n","{'loss': 0.3742, 'learning_rate': 0.0009883333333333333, 'epoch': 3.5}\n","{'loss': 0.3815, 'learning_rate': 0.000988, 'epoch': 3.6}\n","{'loss': 0.356, 'learning_rate': 0.0009876666666666666, 'epoch': 3.7}\n","{'loss': 0.3671, 'learning_rate': 0.0009873333333333333, 'epoch': 3.8}\n","{'loss': 0.3592, 'learning_rate': 0.000987, 'epoch': 3.9}\n","{'loss': 0.3642, 'learning_rate': 0.0009866666666666667, 'epoch': 4.0}\n","  1% 400/30000 [08:25<6:33:59,  1.25it/s][INFO|trainer.py:3160] 2023-09-07 20:27:35,368 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3162] 2023-09-07 20:27:35,369 >>   Num examples = 9000\n","[INFO|trainer.py:3165] 2023-09-07 20:27:35,369 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:05,  2.75it/s]\u001b[A\n"," 17% 3/18 [00:01<00:07,  1.96it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.68it/s]\u001b[A\n"," 28% 5/18 [00:02<00:08,  1.56it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.48it/s]\u001b[A\n"," 39% 7/18 [00:04<00:07,  1.41it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.39it/s]\u001b[A\n"," 50% 9/18 [00:05<00:06,  1.37it/s]\u001b[A\n"," 56% 10/18 [00:06<00:05,  1.33it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.34it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.34it/s]\u001b[A\n"," 72% 13/18 [00:08<00:03,  1.34it/s]\u001b[A\n"," 78% 14/18 [00:09<00:03,  1.32it/s]\u001b[A\n"," 83% 15/18 [00:10<00:02,  1.31it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.28it/s]\u001b[A\n","                                         \n","\u001b[A{'eval_loss': 0.059752874076366425, 'eval_accuracy': 0.9806666666666667, 'eval_runtime': 13.578, 'eval_samples_per_second': 662.839, 'eval_steps_per_second': 1.326, 'epoch': 4.0}\n","  1% 400/30000 [08:39<6:33:59,  1.25it/s]\n","100% 18/18 [00:11<00:00,  1.42it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2886] 2023-09-07 20:27:48,969 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_10/checkpoint-400\n","[INFO|configuration_utils.py:460] 2023-09-07 20:27:48,974 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_10/checkpoint-400/config.json\n","[INFO|modeling_utils.py:1988] 2023-09-07 20:27:49,096 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_10/checkpoint-400/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 20:27:49,100 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_10/checkpoint-400/preprocessor_config.json\n","[INFO|trainer.py:2973] 2023-09-07 20:27:49,324 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_10/checkpoint-100] due to args.save_total_limit\n","{'loss': 0.3471, 'learning_rate': 0.0009863333333333332, 'epoch': 4.1}\n","{'loss': 0.3677, 'learning_rate': 0.0009860000000000001, 'epoch': 4.2}\n","{'loss': 0.3381, 'learning_rate': 0.0009856666666666668, 'epoch': 4.3}\n","{'loss': 0.3618, 'learning_rate': 0.0009853333333333333, 'epoch': 4.4}\n","{'loss': 0.3725, 'learning_rate': 0.000985, 'epoch': 4.5}\n","{'loss': 0.3493, 'learning_rate': 0.0009846666666666667, 'epoch': 4.6}\n","{'loss': 0.3653, 'learning_rate': 0.0009843333333333334, 'epoch': 4.7}\n","{'loss': 0.3572, 'learning_rate': 0.000984, 'epoch': 4.8}\n","{'loss': 0.3212, 'learning_rate': 0.0009836666666666668, 'epoch': 4.9}\n","{'loss': 0.3387, 'learning_rate': 0.0009833333333333332, 'epoch': 5.0}\n","  2% 500/30000 [10:32<6:28:44,  1.26it/s][INFO|trainer.py:3160] 2023-09-07 20:29:42,174 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3162] 2023-09-07 20:29:42,174 >>   Num examples = 9000\n","[INFO|trainer.py:3165] 2023-09-07 20:29:42,175 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:05,  2.73it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.87it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.62it/s]\u001b[A\n"," 28% 5/18 [00:03<00:08,  1.51it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.44it/s]\u001b[A\n"," 39% 7/18 [00:04<00:07,  1.40it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.37it/s]\u001b[A\n"," 50% 9/18 [00:06<00:06,  1.35it/s]\u001b[A\n"," 56% 10/18 [00:06<00:05,  1.33it/s]\u001b[A\n"," 61% 11/18 [00:07<00:06,  1.16it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.21it/s]\u001b[A\n"," 72% 13/18 [00:09<00:04,  1.23it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.20it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.18it/s]\u001b[A\n"," 89% 16/18 [00:12<00:01,  1.13it/s]\u001b[A\n","                                         \n","\u001b[A{'eval_loss': 1.0121500492095947, 'eval_accuracy': 0.659, 'eval_runtime': 14.4842, 'eval_samples_per_second': 621.368, 'eval_steps_per_second': 1.243, 'epoch': 5.0}\n","  2% 500/30000 [10:46<6:28:44,  1.26it/s]\n","100% 18/18 [00:12<00:00,  1.28it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2886] 2023-09-07 20:29:56,664 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_10/checkpoint-500\n","[INFO|configuration_utils.py:460] 2023-09-07 20:29:56,670 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_10/checkpoint-500/config.json\n","[INFO|modeling_utils.py:1988] 2023-09-07 20:29:56,787 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_10/checkpoint-500/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 20:29:56,791 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_10/checkpoint-500/preprocessor_config.json\n","[INFO|trainer.py:2973] 2023-09-07 20:29:57,030 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_10/checkpoint-300] due to args.save_total_limit\n","{'loss': 0.3688, 'learning_rate': 0.000983, 'epoch': 5.1}\n","{'loss': 0.3466, 'learning_rate': 0.0009826666666666666, 'epoch': 5.2}\n","{'loss': 0.3575, 'learning_rate': 0.0009823333333333333, 'epoch': 5.3}\n","{'loss': 0.3437, 'learning_rate': 0.000982, 'epoch': 5.4}\n","{'loss': 0.3542, 'learning_rate': 0.0009816666666666667, 'epoch': 5.5}\n","{'loss': 0.3388, 'learning_rate': 0.0009813333333333334, 'epoch': 5.6}\n","{'loss': 0.334, 'learning_rate': 0.000981, 'epoch': 5.7}\n","{'loss': 0.3395, 'learning_rate': 0.0009806666666666668, 'epoch': 5.8}\n","{'loss': 0.3393, 'learning_rate': 0.0009803333333333333, 'epoch': 5.9}\n","{'loss': 0.3376, 'learning_rate': 0.00098, 'epoch': 6.0}\n","  2% 600/30000 [12:42<6:41:49,  1.22it/s][INFO|trainer.py:3160] 2023-09-07 20:31:52,547 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3162] 2023-09-07 20:31:52,547 >>   Num examples = 9000\n","[INFO|trainer.py:3165] 2023-09-07 20:31:52,548 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:05,  2.73it/s]\u001b[A\n"," 17% 3/18 [00:01<00:07,  1.91it/s]\u001b[A\n"," 22% 4/18 [00:02<00:09,  1.54it/s]\u001b[A\n"," 28% 5/18 [00:03<00:08,  1.46it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.42it/s]\u001b[A\n"," 39% 7/18 [00:04<00:07,  1.40it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.39it/s]\u001b[A\n"," 50% 9/18 [00:06<00:06,  1.38it/s]\u001b[A\n"," 56% 10/18 [00:06<00:05,  1.34it/s]\u001b[A\n"," 61% 11/18 [00:07<00:05,  1.32it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.31it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.25it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.21it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.20it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.24it/s]\u001b[A\n","                                         \n","\u001b[A{'eval_loss': 1.4921808242797852, 'eval_accuracy': 0.5422222222222223, 'eval_runtime': 14.0691, 'eval_samples_per_second': 639.701, 'eval_steps_per_second': 1.279, 'epoch': 6.0}\n","  2% 600/30000 [12:56<6:41:49,  1.22it/s]\n","100% 18/18 [00:12<00:00,  1.35it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2886] 2023-09-07 20:32:06,621 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_10/checkpoint-600\n","[INFO|configuration_utils.py:460] 2023-09-07 20:32:06,626 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_10/checkpoint-600/config.json\n","[INFO|modeling_utils.py:1988] 2023-09-07 20:32:06,735 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_10/checkpoint-600/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 20:32:06,739 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_10/checkpoint-600/preprocessor_config.json\n","[INFO|trainer.py:2973] 2023-09-07 20:32:06,950 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_10/checkpoint-400] due to args.save_total_limit\n","{'loss': 0.336, 'learning_rate': 0.0009796666666666667, 'epoch': 6.1}\n","{'loss': 0.3395, 'learning_rate': 0.0009793333333333334, 'epoch': 6.2}\n","{'loss': 0.3187, 'learning_rate': 0.000979, 'epoch': 6.3}\n","{'loss': 0.3644, 'learning_rate': 0.0009786666666666667, 'epoch': 6.4}\n","{'loss': 0.3287, 'learning_rate': 0.0009783333333333334, 'epoch': 6.5}\n","{'loss': 0.3224, 'learning_rate': 0.000978, 'epoch': 6.6}\n","{'loss': 0.3222, 'learning_rate': 0.0009776666666666666, 'epoch': 6.7}\n","{'loss': 0.3439, 'learning_rate': 0.0009773333333333333, 'epoch': 6.8}\n","{'loss': 0.3151, 'learning_rate': 0.000977, 'epoch': 6.9}\n","{'loss': 0.3431, 'learning_rate': 0.0009766666666666667, 'epoch': 7.0}\n","  2% 700/30000 [14:52<6:56:25,  1.17it/s][INFO|trainer.py:3160] 2023-09-07 20:34:02,585 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3162] 2023-09-07 20:34:02,585 >>   Num examples = 9000\n","[INFO|trainer.py:3165] 2023-09-07 20:34:02,585 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.65it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.78it/s]\u001b[A\n"," 22% 4/18 [00:02<00:08,  1.57it/s]\u001b[A\n"," 28% 5/18 [00:03<00:08,  1.47it/s]\u001b[A\n"," 33% 6/18 [00:03<00:08,  1.42it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.34it/s]\u001b[A\n"," 44% 8/18 [00:05<00:08,  1.23it/s]\u001b[A\n"," 50% 9/18 [00:06<00:07,  1.23it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.16it/s]\u001b[A\n"," 61% 11/18 [00:08<00:06,  1.16it/s]\u001b[A\n"," 67% 12/18 [00:09<00:05,  1.20it/s]\u001b[A\n"," 72% 13/18 [00:09<00:04,  1.16it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.22it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.18it/s]\u001b[A\n"," 89% 16/18 [00:12<00:01,  1.16it/s]\u001b[A\n","                                         \n","\u001b[A{'eval_loss': 0.09192399680614471, 'eval_accuracy': 0.9767777777777777, 'eval_runtime': 14.5412, 'eval_samples_per_second': 618.932, 'eval_steps_per_second': 1.238, 'epoch': 7.0}\n","  2% 700/30000 [15:07<6:56:25,  1.17it/s]\n","100% 18/18 [00:13<00:00,  1.35it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2886] 2023-09-07 20:34:17,143 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_10/checkpoint-700\n","[INFO|configuration_utils.py:460] 2023-09-07 20:34:17,151 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_10/checkpoint-700/config.json\n","[INFO|modeling_utils.py:1988] 2023-09-07 20:34:17,271 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_10/checkpoint-700/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 20:34:17,276 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_10/checkpoint-700/preprocessor_config.json\n","[INFO|trainer.py:2973] 2023-09-07 20:34:17,498 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_10/checkpoint-500] due to args.save_total_limit\n","{'loss': 0.3247, 'learning_rate': 0.0009763333333333334, 'epoch': 7.1}\n","{'loss': 0.3061, 'learning_rate': 0.000976, 'epoch': 7.2}\n","{'loss': 0.3331, 'learning_rate': 0.0009756666666666667, 'epoch': 7.3}\n","{'loss': 0.3317, 'learning_rate': 0.0009753333333333334, 'epoch': 7.4}\n","{'loss': 0.3502, 'learning_rate': 0.000975, 'epoch': 7.5}\n","{'loss': 0.3255, 'learning_rate': 0.0009746666666666666, 'epoch': 7.6}\n","{'loss': 0.3296, 'learning_rate': 0.0009743333333333335, 'epoch': 7.7}\n","{'loss': 0.321, 'learning_rate': 0.000974, 'epoch': 7.8}\n","{'loss': 0.3094, 'learning_rate': 0.0009736666666666667, 'epoch': 7.9}\n","{'loss': 0.3353, 'learning_rate': 0.0009733333333333334, 'epoch': 8.0}\n","  3% 800/30000 [17:02<6:37:40,  1.22it/s][INFO|trainer.py:3160] 2023-09-07 20:36:12,737 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3162] 2023-09-07 20:36:12,737 >>   Num examples = 9000\n","[INFO|trainer.py:3165] 2023-09-07 20:36:12,737 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.55it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.83it/s]\u001b[A\n"," 22% 4/18 [00:02<00:09,  1.50it/s]\u001b[A\n"," 28% 5/18 [00:03<00:09,  1.39it/s]\u001b[A\n"," 33% 6/18 [00:04<00:08,  1.36it/s]\u001b[A\n"," 39% 7/18 [00:04<00:08,  1.30it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.26it/s]\u001b[A\n"," 50% 9/18 [00:06<00:07,  1.23it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.26it/s]\u001b[A\n"," 61% 11/18 [00:08<00:05,  1.28it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.30it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.30it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.30it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.31it/s]\u001b[A\n"," 89% 16/18 [00:11<00:01,  1.32it/s]\u001b[A\n","                                         \n","\u001b[A{'eval_loss': 0.03905992582440376, 'eval_accuracy': 0.9877777777777778, 'eval_runtime': 13.902, 'eval_samples_per_second': 647.391, 'eval_steps_per_second': 1.295, 'epoch': 8.0}\n","  3% 800/30000 [17:16<6:37:40,  1.22it/s]\n","100% 18/18 [00:12<00:00,  1.48it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2886] 2023-09-07 20:36:26,644 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_10/checkpoint-800\n","[INFO|configuration_utils.py:460] 2023-09-07 20:36:26,649 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_10/checkpoint-800/config.json\n","[INFO|modeling_utils.py:1988] 2023-09-07 20:36:26,756 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_10/checkpoint-800/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 20:36:26,760 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_10/checkpoint-800/preprocessor_config.json\n","[INFO|trainer.py:2973] 2023-09-07 20:36:26,966 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_10/checkpoint-200] due to args.save_total_limit\n","{'loss': 0.3248, 'learning_rate': 0.000973, 'epoch': 8.1}\n","{'loss': 0.3063, 'learning_rate': 0.0009726666666666667, 'epoch': 8.2}\n","{'loss': 0.3122, 'learning_rate': 0.0009723333333333334, 'epoch': 8.3}\n","{'loss': 0.323, 'learning_rate': 0.000972, 'epoch': 8.4}\n","{'loss': 0.2918, 'learning_rate': 0.0009716666666666667, 'epoch': 8.5}\n","{'loss': 0.3281, 'learning_rate': 0.0009713333333333334, 'epoch': 8.6}\n","{'loss': 0.3167, 'learning_rate': 0.000971, 'epoch': 8.7}\n","{'loss': 0.3152, 'learning_rate': 0.0009706666666666667, 'epoch': 8.8}\n","{'loss': 0.316, 'learning_rate': 0.0009703333333333334, 'epoch': 8.9}\n","{'loss': 0.3187, 'learning_rate': 0.0009699999999999999, 'epoch': 9.0}\n","  3% 900/30000 [19:11<6:39:14,  1.21it/s][INFO|trainer.py:3160] 2023-09-07 20:38:21,550 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3162] 2023-09-07 20:38:21,550 >>   Num examples = 9000\n","[INFO|trainer.py:3165] 2023-09-07 20:38:21,550 >>   Batch size = 512\n","\n","  0% 0/18 [00:00<?, ?it/s]\u001b[A\n"," 11% 2/18 [00:00<00:06,  2.57it/s]\u001b[A\n"," 17% 3/18 [00:01<00:08,  1.79it/s]\u001b[A\n"," 22% 4/18 [00:02<00:09,  1.54it/s]\u001b[A\n"," 28% 5/18 [00:03<00:09,  1.38it/s]\u001b[A\n"," 33% 6/18 [00:04<00:09,  1.26it/s]\u001b[A\n"," 39% 7/18 [00:05<00:08,  1.23it/s]\u001b[A\n"," 44% 8/18 [00:05<00:07,  1.26it/s]\u001b[A\n"," 50% 9/18 [00:06<00:07,  1.28it/s]\u001b[A\n"," 56% 10/18 [00:07<00:06,  1.30it/s]\u001b[A\n"," 61% 11/18 [00:08<00:05,  1.30it/s]\u001b[A\n"," 67% 12/18 [00:08<00:04,  1.24it/s]\u001b[A\n"," 72% 13/18 [00:09<00:03,  1.27it/s]\u001b[A\n"," 78% 14/18 [00:10<00:03,  1.16it/s]\u001b[A\n"," 83% 15/18 [00:11<00:02,  1.16it/s]\u001b[A\n"," 89% 16/18 [00:12<00:01,  1.19it/s]\u001b[A\n","                                         \n","\u001b[A{'eval_loss': 0.04083378240466118, 'eval_accuracy': 0.9884444444444445, 'eval_runtime': 14.6301, 'eval_samples_per_second': 615.169, 'eval_steps_per_second': 1.23, 'epoch': 9.0}\n","  3% 900/30000 [19:26<6:39:14,  1.21it/s]\n","100% 18/18 [00:13<00:00,  1.33it/s]\u001b[A\n","                                   \u001b[A[INFO|trainer.py:2886] 2023-09-07 20:38:36,185 >> Saving model checkpoint to drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_10/checkpoint-900\n","[INFO|configuration_utils.py:460] 2023-09-07 20:38:36,191 >> Configuration saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_10/checkpoint-900/config.json\n","[INFO|modeling_utils.py:1988] 2023-09-07 20:38:36,304 >> Model weights saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_10/checkpoint-900/pytorch_model.bin\n","[INFO|image_processing_utils.py:253] 2023-09-07 20:38:36,309 >> Image processor saved in drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_10/checkpoint-900/preprocessor_config.json\n","[INFO|trainer.py:2973] 2023-09-07 20:38:36,536 >> Deleting older checkpoint [drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_10/checkpoint-600] due to args.save_total_limit\n","{'loss': 0.324, 'learning_rate': 0.0009696666666666667, 'epoch': 9.1}\n","{'loss': 0.3177, 'learning_rate': 0.0009693333333333334, 'epoch': 9.2}\n","{'loss': 0.3133, 'learning_rate': 0.000969, 'epoch': 9.3}\n","{'loss': 0.3191, 'learning_rate': 0.0009686666666666667, 'epoch': 9.4}\n","{'loss': 0.3221, 'learning_rate': 0.0009683333333333334, 'epoch': 9.5}\n","  3% 958/30000 [20:33<9:18:44,  1.15s/it]"]}],"source":["!python cnn-mnist.py \\\n","    --model_name microsoft/resnet-18 \\\n","    --model_type resnet \\\n","    --dataset_name mnist \\\n","    --output_dir drive/MyDrive/hons-research/output/cnn/mnist/mnist_outputs_10/ \\\n","    --remove_unused_columns False \\\n","    --do_train \\\n","    --do_eval \\\n","    --push_to_hub False \\\n","    --learning_rate 0.001 \\\n","    --num_train_epochs 300 \\\n","    --per_device_train_batch_size 512 \\\n","    --per_device_eval_batch_size 512 \\\n","    --logging_strategy steps \\\n","    --logging_steps 10 \\\n","    --evaluation_strategy epoch \\\n","    --save_strategy epoch \\\n","    --load_best_model_at_end True \\\n","    --save_total_limit 3 \\\n","    --save_steps 500 \\\n","    --data_seed 10 \\\n","    --seed 10 \\\n","    --report_to wandb \\\n","    --ignore_mismatched_sizes\n"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"n_-Vhnw7vJjE","executionInfo":{"status":"ok","timestamp":1695148957597,"user_tz":-120,"elapsed":8,"user":{"displayName":"Andreas Louw","userId":"11183032721846533402"}}},"outputs":[],"source":["# End run\n","\n","from google.colab import runtime\n","runtime.unassign()"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[],"gpuType":"V100"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}